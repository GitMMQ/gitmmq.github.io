<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.fastolf.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="recording">
<meta property="og:type" content="website">
<meta property="og:title" content="Qi">
<meta property="og:url" content="https://www.fastolf.com/page/15/index.html">
<meta property="og:site_name" content="Qi">
<meta property="og:description" content="recording">
<meta property="og:locale">
<meta property="article:author" content="Meng Qi">
<meta property="article:tag" content="Tech;Data;Vision">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.fastolf.com/page/15/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <title>Qi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
<a target="_blank" rel="noopener" href="https://github.com/gitmmq" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Qi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Cogito ergo sum</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/fc93d163.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/fc93d163.html" class="post-title-link" itemprop="url">mysql-主库出问题了从库怎么办</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-02 06:01:31" itemprop="dateCreated datePublished" datetime="2019-12-02T06:01:31+08:00">2019-12-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>29 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>27 | 主库出问题了，从库怎么办？2019-01-14 林晓斌</p>
<p>在前面的第24、25和26篇文章中，我和你介绍了MySQL主备复制的基础结构，但这些都是一主</p>
<p>一备的结构。大多数的互联网应用场景都是读多写少，因此你负责的业务，在发展过程中很可能先会遇到读性</p>
<p>能的问题。而在数据库层解决读性能问题，就要涉及到接下来两篇文章要讨论的架构：一主多</p>
<p>从。今天这篇文章，我们就先聊聊一主多从的切换正确性。然后，我们在下一篇文章中再聊聊解决一</p>
<p>主多从的查询逻辑正确性的方法。如图1所示，就是一个基本的一主多从结构。图1 一主多从基本结构</p>
<p>图中，虚线箭头表示的是主备关系，也就是A和A’互为主备， 从库B、C、D指向的是主库A。一</p>
<p>主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分</p>
<p>担。今天我们要讨论的就是，在一主多从架构下，主库故障后的主备切换问题。如图2所示，就是主库发生故障，主备切换后的结果。图2 一主多从基本结构–主备切换</p>
<p>相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库B、C、D也</p>
<p>要改接到A’。正是由于多了从库B、C、D重新指向的这个过程，所以主备切换的复杂性也相应增</p>
<p>加了。接下来，我们再一起看看一个切换系统会怎么完成一主多从的主备切换过程。基于位点的主备切换</p>
<p>这里，我们需要先来回顾一个知识点。当我们把节点B设置成节点A’的从库的时候，需要执行一条change master命令：</p>
<p>CHANGE MASTER TO </p>
<p>MASTER_HOST&#x3D;$host_name </p>
<p>MASTER_PORT&#x3D;$port </p>
<p>MASTER_USER&#x3D;$user_name </p>
<p>MASTER_PASSWORD&#x3D;$password </p>
<p>MASTER_LOG_FILE&#x3D;$master_log_name </p>
<p>MASTER_LOG_POS&#x3D;$master_log_pos  </p>
<p>这条命令有这么6个参数：</p>
<p>MASTER_HOST、MASTER_PORT、MASTER_USER和MASTER_PASSWORD四个参</p>
<p>数，分别代表了主库A’的IP、端口、用户名和密码。最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示，要从主库的</p>
<p>master_log_name文件的master_log_pos这个位置的日志继续同步。而这个位置就是我们所</p>
<p>说的同步位点，也就是主库对应的文件名和日志偏移量。那么，这里就有一个问题了，节点B要设置成A’的从库，就要执行change master命令，就不可</p>
<p>避免地要设置位点的这两个参数，但是这两个参数到底应该怎么设置呢？原来节点B是A的从库，本地记录的也是A的位点。但是相同的日志，A的位点和A’的位点是不同</p>
<p>的。因此，从库B要切换的时候，就需要先经过“找同步位点”这个逻辑。这个位点很难精确取到，只能取一个大概位置。为什么这么说呢？我来和你分析一下看看这个位点一般是怎么获取到的，你就清楚其中不精确的原因了。考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通</p>
<p>过判断跳过那些在从库B上已经执行过的事务。一种取同步位点的方法是这样的：</p>
<ol>
<li><p>等待新主库A’把中转日志（relay log）全部同步完成；</p>
</li>
<li><p>在A’上执行show master status命令，得到当前A’上最新的File 和 Position；</p>
</li>
<li><p>取原主库A故障的时刻T；</p>
</li>
<li><p>用mysqlbinlog工具解析A’的File，得到T时刻的位点。图3 mysqlbinlog 部分输出结果</p>
</li>
</ol>
<p>图中，end_log_pos后面的值“123”，表示的就是A’这个实例，在T时刻写入新的binlog的位置。然后，我们就可以把123这个值作为$master_log_pos ，用在节点B的change master命令里。mysqlbinlog File –stop-datetime&#x3D;T –start-datetime&#x3D;T</p>
<p>当然这个值并不精确。为什么呢？你可以设想有这么一种情况，假设在T这个时刻，主库A已经执行完成了一个insert 语句插入了一</p>
<p>行数据R，并且已经将binlog传给了A’和B，然后在传完的瞬间主库A的主机就掉电了。那么，这时候系统的状态是这样的：</p>
<ol>
<li><p>在从库B上，由于同步了binlog， R这一行已经存在；</p>
</li>
<li><p>在新主库A’上， R这一行也已经存在，日志是写在123这个位置之后的；</p>
</li>
<li><p>我们在从库B上执行change master命令，指向A’的File文件的123位置，就会把插入R这一行</p>
</li>
</ol>
<p>数据的binlog又同步到从库B去执行。这时候，从库B的同步线程就会报告 Duplicate entry ‘id_of_R’ for key ‘PRIMARY’ 错误，提示出</p>
<p>现了主键冲突，然后停止同步。所以，通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方</p>
<p>法。一种做法是，主动跳过一个事务。跳过命令的写法是：</p>
<p>因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库B刚开始接到新主库</p>
<p>A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情</p>
<p>况，以此来跳过可能涉及的所有事务。另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。在执行主备切换时，有这么两类错误，是经常会遇到的：</p>
<p>1062错误是插入数据时唯一键冲突；</p>
<p>1032错误是删除数据时找不到行。因此，我们可以把slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳</p>
<p>过。这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同</p>
<p>步位点，所以只能采用这种方法来创建从库和新主库的主备关系。这个背景是，我们很清楚在主备切换过程中，直接跳过1032和1062这两类错误是无损的，所以</p>
<p>set global sql_slave_skip_counter&#x3D;1;</p>
<p>start slave;</p>
<p>才可以这么设置slave_skip_errors参数。等到主备间的同步关系建立完成，并稳定执行一段时间</p>
<p>之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。GTID</p>
<p>通过sql_slave_skip_counter跳过事务和通过slave_skip_errors忽略错误的方法，虽然都最终可以</p>
<p>建立从库B和新主库A’的主备关系，但这两种操作都很复杂，而且容易出错。所以，MySQL 5.6</p>
<p>版本引入了GTID，彻底解决了这个困难。那么，GTID到底是什么意思，又是如何解决找同步位点这个问题呢？现在，我就和你简单介绍</p>
<p>一下。GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成</p>
<p>的，是这个事务的唯一标识。它由两部分组成，格式是：</p>
<p>其中：</p>
<p>server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值；</p>
<p>gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。这里我需要和你说明一下，在MySQL的官方文档里，GTID格式是这么定义的：</p>
<p>这里的source_id就是server_uuid；而后面的这个transaction_id，我觉得容易造成误导，所以我</p>
<p>改成了gno。为什么说使用transaction_id容易造成误解呢？因为，在MySQL里面我们说transaction_id就是指事务id，事务id是在事务执行过程中分配的，如</p>
<p>果这个事务回滚了，事务id也会递增，而gno是在事务提交的时候才会分配。从效果上看，GTID往往是连续的，因此我们用gno来表示更容易理解。GTID模式的启动也很简单，我们只需要在启动一个MySQL实例的时候，加上参数gtid_mode&#x3D;on</p>
<p>和enforce_gtid_consistency&#x3D;on就可以了。在GTID模式下，每个事务都会跟一个GTID一一对应。这个GTID有两种生成方式，而使用哪种</p>
<p>方式取决于session变量gtid_next的值。1. 如果gtid_next&#x3D;automatic，代表使用默认值。这时，MySQL就会把server_uuid:gno分配给</p>
<p>GTID&#x3D;server_uuid:gno</p>
<p>GTID&#x3D;source_id:transaction_id</p>
<p>这个事务。a. 记录binlog的时候，先记录一行 SET @@SESSION.GTID_NEXT&#x3D;‘server_uuid:gno’;</p>
<p>b. 把这个GTID加入本实例的GTID集合。2. 如果gtid_next是一个指定的GTID的值，比如通过set gtid_next&#x3D;’current_gtid’指定为</p>
<p>current_gtid，那么就有两种可能：</p>
<p>a. 如果current_gtid已经存在于实例的GTID集合中，接下来执行的这个事务会直接被系统忽</p>
<p>略；</p>
<p>b. 如果current_gtid没有存在于实例的GTID集合中，就将这个current_gtid分配给接下来要执</p>
<p>行的事务，也就是说系统不需要给这个事务生成新的GTID，因此gno也不用加1。注意，一个current_gtid只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要</p>
<p>执行set 命令，把gtid_next设置成另外一个gtid或者automatic。这样，每个MySQL实例都维护了一个GTID集合，用来对应“这个实例执行过的所有事务”。这样看上去不太容易理解，接下来我就用一个简单的例子，来和你说明GTID的基本用法。我们在实例X中创建一个表t。图4 初始化数据的binlog</p>
<p>可以看到，事务的BEGIN之前有一条SET @@SESSION.GTID_NEXT命令。这时，如果实例X</p>
<p>有从库，那么将CREATE TABLE和insert语句的binlog同步过去执行的话，执行事务之前就会先</p>
<p>执行这两个SET命令， 这样被加入从库的GTID集合的，就是图中的这两个GTID。CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t values(1,1);</p>
<p>假设，现在这个实例X是另外一个实例Y的从库，并且此时在实例Y上执行了下面这条插入语句：</p>
<p>并且，这条语句在实例Y上的GTID是 “aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”。那么，实例X作为Y的从库，就要同步这个事务过来执行，显然会出现主键冲突，导致实例X的同</p>
<p>步线程停止。这时，我们应该怎么处理呢？处理方法就是，你可以执行下面的这个语句序列：</p>
<p>其中，前三条语句的作用，是通过提交一个空事务，把这个GTID加到实例X的GTID集合中。如</p>
<p>图5所示，就是执行完这个空事务之后的show master status的结果。图5 show master status结果</p>
<p>可以看到实例X的Executed_Gtid_set里面，已经加入了这个GTID。这样，我再执行start slave命令让同步线程执行起来的时候，虽然实例X上还是会继续执行实例Y</p>
<p>传过来的事务，但是由于“aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”已经存在于实例X的GTID集</p>
<p>合中了，所以实例X就会直接跳过这个事务，也就不会再出现主键冲突的错误。在上面的这个语句序列中，start slave命令之前还有一句set gtid_next&#x3D;automatic。这句话的作</p>
<p>用是“恢复GTID的默认分配行为”，也就是说如果之后有新的事务再执行，就还是按照原来的分</p>
<p>配方式，继续分配gno&#x3D;3。insert into t values(1,1);</p>
<p>set gtid_next&#x3D;’aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10’;</p>
<p>begin;</p>
<p>commit;</p>
<p>set gtid_next&#x3D;automatic;</p>
<p>start slave;</p>
<p>基于GTID的主备切换</p>
<p>现在，我们已经理解GTID的概念，再一起来看看基于GTID的主备复制的用法。在GTID模式下，备库B要设置为新主库A’的从库的语法如下：</p>
<p>其中，master_auto_position&#x3D;1就表示这个主备关系使用的是GTID协议。可以看到，前面让我</p>
<p>们头疼不已的MASTER_LOG_FILE和MASTER_LOG_POS参数，已经不需要指定了。我们把现在这个时刻，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b。接下来，</p>
<p>我们就看看现在的主备切换逻辑。我们在实例B上执行start slave命令，取binlog的逻辑是这样的：</p>
<ol>
<li>实例B指定主库A’，基于主备协议建立连接。2. 实例B把set_b发给主库A’。3. 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的</li>
</ol>
<p>集合，判断A’本地是否包含了这个差集需要的所有binlog事务。a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；</p>
<p>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</p>
<ol start="4">
<li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。其实，这个逻辑里面包含了一个设计思想：在基于GTID的主备关系里，系统认为只要建立主备</li>
</ol>
<p>关系，就必须保证主库发给备库的日志是完整的。因此，如果实例B需要的日志已经不存</p>
<p>在，A’就拒绝把日志发给B。这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就</p>
<p>发哪个位点，不做日志的完整性判断。基于上面的介绍，我们再来看看引入GTID后，一主多从的切换场景下，主备切换是如何实现</p>
<p>的。CHANGE MASTER TO </p>
<p>MASTER_HOST&#x3D;$host_name </p>
<p>MASTER_PORT&#x3D;$port </p>
<p>MASTER_USER&#x3D;$user_name </p>
<p>MASTER_PASSWORD&#x3D;$password </p>
<p>master_auto_position&#x3D;1 </p>
<p>由于不需要找位点了，所以从库B、C、D只需要分别执行change master命令指向实例A’即可。其实，严谨地说，主备切换不是不需要找位点了，而是找位点这个工作，在实例A’内部就已经自</p>
<p>动完成了。但由于这个工作是自动的，所以对HA系统的开发人员来说，非常友好。之后这个系统就由新主库A’写入，主库A’的自己生成的binlog中的GTID集合格式是：</p>
<p>server_uuid_of_A’:1-M。如果之前从库B的GTID集合格式是 server_uuid_of_A:1-N， 那么切换之后GTID集合的格式就变</p>
<p>成了server_uuid_of_A:1-N, server_uuid_of_A’:1-M。当然，主库A’之前也是A的备库，因此主库A’和从库B的GTID集合是一样的。这就达到了我们预</p>
<p>期。GTID和在线DDL</p>
<p>接下来，我再举个例子帮你理解GTID。之前在第22篇文章《MySQL有哪些“饮鸩止渴”提高性能的方法？》中，我和你提到业务高峰期</p>
<p>的慢查询性能问题时，分析到如果是由于索引缺失引起的性能问题，我们可以通过在线加索引来</p>
<p>解决。但是，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再</p>
<p>切换。当时我说，在双M结构下，备库执行的DDL语句也会传给主库，为了避免传回后对主库造成影</p>
<p>响，要通过set sql_log_bin&#x3D;off关掉binlog。评论区有位同学提出了一个问题：这样操作的话，数据库里面是加了索引，但是binlog并没有记</p>
<p>录下这一个更新，是不是会导致数据和日志不一致？这个问题提得非常好。当时，我在留言的回复中就引用了GTID来说明。今天，我再和你展开说</p>
<p>明一下。假设，这两个互为主备关系的库还是实例X和实例Y，且当前主库是X，并且都打开了GTID模</p>
<p>式。这时的主备切换流程可以变成下面这样：</p>
<p>在实例X上执行stop slave。在实例Y上执行DDL语句。注意，这里并不需要关闭binlog。执行完成后，查出这个DDL语句对应的GTID，并记为 server_uuid_of_Y:gno。到实例X上执行以下语句序列：</p>
<p>这样做的目的在于，既可以让实例Y的更新有binlog记录，同时也可以确保不会在实例X上执行这</p>
<p>条更新。接下来，执行完主备切换，然后照着上述流程再执行一遍即可。小结</p>
<p>在今天这篇文章中，我先和你介绍了一主多从的主备切换流程。在这个过程中，从库找新主库的</p>
<p>位点是一个痛点。由此，我们引出了MySQL 5.6版本引入的GTID模式，介绍了GTID的基本概念</p>
<p>和用法。可以看到，在GTID模式下，一主多从切换就非常方便了。因此，如果你使用的MySQL版本支持GTID的话，我都建议你尽量使用GTID模式来做一主多从</p>
<p>的切换。在下一篇文章中，我们还能看到GTID模式在读写分离场景的应用。最后，又到了我们的思考题时间。你在GTID模式下设置主从关系的时候，从库执行start slave命令后，主库发现需要的binlog已经</p>
<p>被删除掉了，导致主备创建不成功。这种情况下，你觉得可以怎么处理呢？你可以把你的方法写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也</p>
<p>欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上一篇文章最后，我给你留的问题是，如果主库都是单线程压力模式，在从库追主库的过程</p>
<p>中，binlog-transaction-dependency-tracking 应该选用什么参数？这个问题的答案是，应该将这个参数设置为WRITESET。由于主库是单线程压力模式，所以每个事务的commit_id都不同，那么设置为COMMIT_ORDER</p>
<p>模式的话，从库也只能单线程执行。同样地，由于WRITESET_SESSION模式要求在备库应用日志的时候，同一个线程的日志必须</p>
<p>set GTID_NEXT&#x3D;”server_uuid_of_Y:gno”;</p>
<p>begin;</p>
<p>commit;</p>
<p>set gtid_next&#x3D;automatic;</p>
<p>start slave;</p>
<p>与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。所以，应该将binlog-transaction-dependency-tracking 设置为WRITESET。评论区留言点赞板：</p>
<p>Mr.Strive.Z.H.L   1</p>
<p>老师您好：</p>
<p>在实际工作中，主从备份似乎是mysql用的最多的高可用方案。但是个人认为主从备份这个方案的问题实在太多了：</p>
<ol>
<li>binlog数据传输前，主库宕机，导致提交了的事务数据丢失。2. 一主多从，即使采用半同步，也只能保证binlog至少在两台机器上，没有一个机制能够选出</li>
</ol>
<p>拥有最完整binlog的从库作为新的主库。3. 主从切换涉及到 人为操作，而不是全自动化的。即使在使用GTID的情况下，也会有binlog被</p>
<p>删除，需要重新做从库的情况。4. 互为主备，如果互为主备的两个实例全部宕机，mysql直接不可用。@慧鑫coming 问了一个好问题，对同一行作更新的几个事务，如果commit_id相同，是不是在</p>
<p>备库并行执行的时候会导致数据不一致？这个问题的答案是更新同一行的事务是不可能同时进</p>
<p>入commit状态的。@老杨同志 对这个问题给出了更详细的回答，大家可以去看一下。精选留言</p>
<p>mysql应该有更强大更完备的高可用方案（类似于zab协议或者raft协议这种），而在实际环境</p>
<p>下，为什么主从备份用得最多呢？2019-01-18</p>
<p> 作者回复</p>
<p>3 这个应该是可以做到自动化的。4 这个概率比较小，其实即使是别的三节点的方案，也架不住挂两个实例，所以这个不是MyS</p>
<p>QL主备的锅。前面两点提得很对哈。其实MySQL到现在，还是提供了很多方案可选的。很多是业务权衡的结果。比如说，异步复制，在主库异常掉电的时候可能会丢数据。这个大家知道以后，有一些就改成semi-sync了，但是还是有一些就留着异步复制的模式，因为</p>
<p>semi-sync有性能影响（一开始35%，现在好点15%左右，看具体环境），而可能这些业务认为</p>
<p>丢一两行，可以从应用层日志去补。 就保留了异步复制模式。最后，为什么主从备份用得最多，我觉得有历史原因。多年前MySQL刚要开始火的时候，大家</p>
<p>发现这个主备模式好方便，就都用了。而基于其他协议的方案，都是后来出现的，并且还是陆陆续续出点bug。涉及到线上服务，大家使用新方案的热情总是局限在测试环境的多。semi-sync也是近几年才开始稳定并被一些公司开始作为默认配置。新技术的推广，在数据库上，确实比其他领域更需要谨慎些，也算是业务决定的吧^_^</p>
<p>好问题 </p>
<p>以上仅一家之言哈 </p>
<p>2019-01-18</p>
<p>某、人   1</p>
<p>1.如果业务允许主从不一致的情况那么可以在主上先show global variables like ‘gtid_purged’;然</p>
<p>后在从上执行set global gtid_purged &#x3D;’ ‘.指定从库从哪个gtid开始同步,binlog缺失那一部分,数据</p>
<p>在从库上会丢失,就会造成主从不一致</p>
<p>2.需要主从数据一致的话,最好还是通过重新搭建从库来做。3.如果有其它的从库保留有全量的binlog的话，可以把从库指定为保留了全量binlog的从库为主</p>
<p>库(级联复制)</p>
<p>4.如果binlog有备份的情况,可以先在从库上应用缺失的binlog,然后在start slave</p>
<p>2019-01-15</p>
<p> 作者回复</p>
<p>非常好 </p>
<p>2019-01-15</p>
<p>悟空   0</p>
<p>看过上篇后想到一个问题:</p>
<p>级联复制A-&gt;B-&gt;C结构下, 从库C的Seconds_Behind_Master的时间计算问题.</p>
<p>假定当前主库A仅有一个DDL要进行变更,耗时1分钟.那么从库C的SBM值最大应该是多少时间?</p>
<p>是1分钟, 2分钟, 还是3分钟呢 ?</p>
<p>带着疑问看了一下测试从库C的binlog文件中的时间戳,得出结论应该是3分钟.</p>
<p>打破之前认知  ♀  . 请老师解惑 , 谢谢 !</p>
<p>2019-01-14</p>
<p> 作者回复</p>
<p>是的，因为算的是：当前执行时间，跟<em>日志时间</em>的差距</p>
<p>而这个日志时间，是在A上执行出来的。好问题，很好的验证过程。2019-01-14</p>
<p>张永志   2</p>
<p>今天问题回答：</p>
<p>GTID主从同步设置时，主库A发现需同步的GTID日志有删掉的，那么A就会报错。解决办法：</p>
<p>从库B在启动同步前需要设置 gtid_purged，指定GTID同步的起点，使用备份搭建从库时需要这</p>
<p>样设置。如果在从库上执行了单独的操作，导致主库上缺少GTID，那么可以在主库上模拟一个与从库B</p>
<p>上GTID一样的空事务，这样主从同步就不会报错了。2019-01-14</p>
<p> 作者回复</p>
<p>你已经理解GTID的机制啦 </p>
<p>2019-01-15</p>
<p>时隐时现   0</p>
<p>其实基于gtid复制有个大坑，在主库上千万不要执行reset master，否则从库不会报错，只会跳</p>
<p>过gno &lt; current_no的事务，造成一个现象就是主库复制没有中断，但是主库上的数据无法同步</p>
<p>到从库。2019-01-31</p>
<p> 作者回复</p>
<p>是的，</p>
<p>不过reset master这种语句。。就算是基于position的协议，谁在线上主库上执行，也是直接当</p>
<p>做删数据论处的了 </p>
<p>2019-01-31</p>
<p>Leon    0</p>
<p>从的执行是</p>
<p>CHANGE MASTER TO </p>
<p>MASTER_HOST&#x3D;”172.27.27.2”,</p>
<p>MASTER_PORT&#x3D;3306,</p>
<p>MASTER_USER&#x3D;”ming”,</p>
<p>MASTER_PASSWORD&#x3D;”123456”,</p>
<p>master_auto_position&#x3D;1;</p>
<p>start slave</p>
<p>2019-01-24</p>
<p>Leon    0</p>
<p>老师，我这边docker起了两个msyql，一主一从</p>
<p>主: </p>
<p>create user ‘ming‘@’172.27.27.2’ identified by ‘123456’;</p>
<p>GRANT REPLICATION SLAVE,RELOAD,SUPER ON <em>.</em> TO ‘ming‘@’%’ WITH GRANT OPTIO</p>
<p>N;</p>
<p>master 172.27.27.2 slave 172.27.27.3</p>
<p>从那边无法同步</p>
<p>Last_SQL_Errno: 1410</p>
<p>Last_SQL_Error: Error ‘You are not allowed to create a user with GRANT’ on query. Default dat</p>
<p>abase: ‘test’. Query: ‘GRANT REPLICATION SLAVE, REPLICATION CLIENT ON <em>.</em> TO ‘slave’</p>
<p>@’%’’</p>
<p>网上查询是授权问题，但是从容器内可以用ming的用户名和密码登录主mysql</p>
<p>我增加了授权还是这样，请问是什么情况</p>
<p>2019-01-24</p>
<p> 作者回复</p>
<p>你把这个create 语句直接到备库执行能执行吗？2019-01-28</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师您好：</p>
<p>之前讲过 互为主备 的场景下，会出现循环复制的问题，今天这节讲了GTID。如果使用GTID，那么 循环复制 的问题自然而然就解决了呀？？！！</p>
<p>2019-01-18</p>
<p> 作者回复</p>
<p>哈哈，you got it</p>
<p>2019-01-18</p>
<p>春困秋乏夏打盹   0</p>
<p>回答undifined的第二个问题</p>
<p>A-A’-B这样的级联结构</p>
<p>A (binlog：A:1-M)</p>
<p>A’(binlog: A:1-M,B:1-N) ,A’上面的操作记为B:1-N</p>
<p>B (binlog: A:1-M,B:1-N,C:1-X) B上面的操作记为C:1-X</p>
<p>—A,B,C分别为A-A’-B的uuid</p>
<p>2019-01-16</p>
<p> 作者回复</p>
<p>对的</p>
<p>总之就是，一个主备关系里，备库的GTID集合应该包含主库的GTID集合。2019-01-16</p>
<p>tchz   0</p>
<p>1.purge gtid，2.重做备库数据</p>
<p>2019-01-15</p>
<p> 作者回复</p>
<p>2 是ok的</p>
<p>purge gtid是啥</p>
<p>2019-01-15</p>
<p>fuyu   0</p>
<p>seta 和 setb 里的集合大小不会很大？2019-01-15</p>
<p> 作者回复</p>
<p>大没关系呀，是分段的，比如 server_uuid_of_a:1-1000000，就一个段</p>
<p>2019-01-15</p>
<p>Leo   0</p>
<p>老师你好，PingCAP的大牛说分布式数据库的一个难点是时间同步。此话怎讲？mysql主从架构</p>
<p>下时间不同步会有哪些问题？2019-01-15</p>
<p> 作者回复</p>
<p>今晚发布的第28篇会提到哈</p>
<p>2019-01-15</p>
<p>_CountingStars   0</p>
<p>老师我有一个问题 如果数据库已经有完成了很多事务 实例 A’的 GTID集合和 实例 B的 GTID集</p>
<p>合 是不是很大，这个GTID是从binglog里一点一点的解析出来所有的事务的吗？这样是不是会</p>
<p>很慢 ？在所有binlog里定位某个GTID是不是效率也很低</p>
<p>2019-01-15</p>
<p> 作者回复</p>
<p>好问题， </p>
<p>在binlog文件开头，有一个Previous_gtids, 用于记录 “生成这个binlog的时候，实例的Executed_</p>
<p>gtid_set”, 所以启动的时候只需要解析最后一个文件；</p>
<p>同样的，由于有这个Previous_gtids，可以快速地定位GTID在哪个文件里。2019-01-15</p>
<p>小超   0</p>
<p>老师，问个上一篇的问题，从库不是只根据binlog来做相应的操作么，这个并行复制策略根据</p>
<p>事务相同commit_id判断好理解，但是根据同时进入redo log prepare 和 commit 来判断这个怎</p>
<p>么理解？事务提交的时候，其他事务的redo log处于prepare的状态事务的某个标识也会记录到</p>
<p>每一个事务的binlog中么？2019-01-14</p>
<p>PengfeiWang   0</p>
<p>老师，您好： 文中对于sql_slave_skip_counter&#x3D;1的理解似乎有偏差，官方文档中的解释是：</p>
<p>When you use SET GLOBAL sql_slave_skip_counter to skip events and the result is in the mid</p>
<p>dle of a group, the slave continues to skip events until it reaches the end of the group. Executio</p>
<p>n then starts with the next event group.</p>
<p>按照官方文档的解释，命令sql_slave_skip_counter&#x3D;1 应该是跳过一个事务中的1个event，除非</p>
<p>这个事务是有单个event组成的，才会跳过一个事务。2019-01-14</p>
<p> 作者回复</p>
<p>你这个是好问题，</p>
<p>确实只是跳过一个event，不过文档中说了呀</p>
<p>“the slave continues to skip events until it reaches the end of the group. ”， </p>
<p>所以效果上等效于跳过一个事务哦</p>
<p>2019-01-14</p>
<p>PengfeiWang   0</p>
<p>老师，你好：在生产环境（基于位点的主备切换）中，经常会遇到这样的场景：备库由于硬件</p>
<p>或其他原因异常宕机，恢复后重启备库，执行start slave命令，总会遇到1062主键重复的报错</p>
<p>，一直解释不清楚为什么？2019-01-14</p>
<p> 作者回复</p>
<p>看一下这个语句的结果, 会受这几个参数的影响哈</p>
<p>select * from information_schema.GLOBAL_VARIABLES where VARIABLE_NAME in (‘master_</p>
<p>info_repository’,’relay_log_info_repository’,’sync_master_info’,’sync_relay_log_info’, ‘sync_binl</p>
<p>og’, ‘innodb_flush_log_at_trx_commit’);</p>
<p>2019-01-14</p>
<p>路过   0</p>
<p>老师，请教：</p>
<p>show slave status\G的输出中，包含如下：</p>
<p>Executed_Gtid_Set: 572ece6c-e3ed-11e8-92c4-005056a509d8:1-1136659,</p>
<p>ecb34895-e3eb-11e8-80e9-005056a55d62:1-1015</p>
<p>是不是表示当前slave曾经和两个master同步过？2019-01-14</p>
<p> 作者回复</p>
<p>一个是它自己吧？select @@server_uuid 看看</p>
<p>2019-01-14</p>
<p>undifined   0</p>
<p>老师 有几个问题：</p>
<ol>
<li>会不会出现主库切换后，B 中已经执行过的事务，而 A’由于网络延迟还没有收到，此时已经</li>
</ol>
<p>对 B 执行切换主库，这时候，B 中有该 GTID，但是 A’中没有，这种情况会怎么处理</p>
<ol start="2">
<li>如果 A 是主库，A’ 备库，B 是 A’的从库，此时 B 的 GTID 集合应该是 server_uuid_of_A’:1-N</li>
</ol>
<p>，此时 A’宕机，B 改为监听 A，这时候A 和 B 的 GTID 集合没有交集，会不会发生 A 将所有的b</p>
<p>inlog 重新发给B</p>
<ol start="3">
<li>思考题我的理解是从主库中 dump 出相关的数据，在备库中执行后再次执行 start slave；评</li>
</ol>
<p>论中说到从其他从库获取，但是如果只有一主一从，有 binlog 丢失，是不是只要 dump 文件恢</p>
<p>复这一个办法</p>
<p>2019-01-14</p>
<p> 作者回复</p>
<ol>
<li>这个也是异步复制导致的，只有semi-sync能解了。。2. 不是哦，如果“ A 是主库，A’ 备库，B 是 A’的从库”，那所有A的更新也都会通过A’传给B，所</li>
</ol>
<p>以B的GTID集合正常就是包含了A和A’的</p>
<ol start="3">
<li>“如果只有一主一从，有 binlog 丢失”，是的，就只有备库重做了</li>
</ol>
<p>2019-01-16</p>
<p>亮   0</p>
<p>老师您好，假如a宕机了，需要把从切换到a’，这时候业务已经有感知了吧？怎么能让业务尽量</p>
<p>没有感知呢？谢谢老师</p>
<p>2019-01-14</p>
<p> 作者回复</p>
<p>这种情况下，不可能业务完全无感知，</p>
<p>但是如果业务代码有“重连并重试”的逻辑，并且切换足够快，就可以对业务无影响，前提是要</p>
<p>解决主备延迟问题，就是25、26两篇提到的</p>
<p>2019-01-14</p>
<p>大坤   0</p>
<p>今天问题回答，由于GTID具有全局唯一性，那么其它正常的gtid已经被复制到了其他从库上了</p>
<p>，只需要切换gtid到其他从库，等待同步完毕后在切换回主库即可</p>
<p>2019-01-14</p>
<p> 作者回复</p>
<p>这个想法很不错  </p>
<p>2019-01-14</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/8e19404c.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/8e19404c.html" class="post-title-link" itemprop="url">mysql-备库为什么会延迟好几个小时</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-01 06:09:43" itemprop="dateCreated datePublished" datetime="2019-12-01T06:09:43+08:00">2019-12-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>37 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>26 | 备库为什么会延迟好几个小时？2019-01-11 林晓斌</p>
<p>在上一篇文章中，我和你介绍了几种可能导致备库延迟的原因。你会发现，这些场景里，不论是</p>
<p>偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都</p>
<p>能够追上来。但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级</p>
<p>别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。这就涉及到今天我要给你介绍的话题：备库并行复制能力。为了便于你理解，我们再一起看一下第24篇文章《MySQL是怎么保证主备一致的？》的主备流</p>
<p>程图。图1 主备流程图</p>
<p>谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主</p>
<p>库，另一箭头代表的是备库上sql_thread执行中转日志（relay log）。如果用箭头的粗细来代表</p>
<p>并行度的话，那么真实情况就如图1所示，第一个箭头要明显粗于第二个箭头。在主库上，影响并发度的原因就是各种锁了。由于InnoDB引擎支持行锁，除了所有并发事务都</p>
<p>在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性</p>
<p>能测试的时候会发现，并发压测线程32就比单线程时，总体吞吐量高。而日志在备库上的执行，就是图中备库上sql_thread更新数据(DATA)的逻辑。如果是用单线程的</p>
<p>话，就会导致备库应用日志不够快，造成主备延迟。在官方的5.6版本之前，MySQL只支持单线程复制，由此在主库并发高、TPS高时就会出现严重</p>
<p>的主备延迟问题。从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。接下来，我就跟你说说</p>
<p>MySQL多线程复制的演进过程。其实说到底，所有的多线程复制机制，都是要把图1中只有一个线程的sql_thread，拆成多个线</p>
<p>程，也就是都符合下面的这个模型：</p>
<p>图2 多线程模型</p>
<p>图2中，coordinator就是原来的sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日</p>
<p>志和分发事务。真正更新日志的，变成了worker线程。而work线程的个数，就是由参数</p>
<p>slave_parallel_workers决定的。根据我的经验，把这个值设置为8~16之间最好（32核物理机的</p>
<p>情况），毕竟备库还有可能要提供读查询，不能把CPU都吃光了。接下来，你需要先思考一个问题：事务能不能按照轮询的方式分发给各个worker，也就是第一个</p>
<p>事务分给worker_1，第二个事务发给worker_2呢？其实是不行的。因为，事务被分发给worker以后，不同的worker就独立执行了。但是，由于CPU</p>
<p>的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的</p>
<p>是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不</p>
<p>一致的问题。接下来，请你再设想一下另外一个问题：同一个事务的多个更新语句，能不能分给不同的worker</p>
<p>来执行呢？答案是，也不行。举个例子，一个事务更新了表t1和表t2中的各一行，如果这两条更新语句被分</p>
<p>到不同worker的话，虽然最终的结果是主备一致的，但如果表t1执行完成的瞬间，备库上有一个</p>
<p>查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的隔离性。所以，coordinator在分发的时候，需要满足以下这两个基本要求：</p>
<ol>
<li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个worker中。2. 同一个事务不能被拆开，必须放到同一个worker中。各个版本的多线程复制，都遵循了这两条基本原则。接下来，我们就看看各个版本的并行复制策</li>
</ol>
<p>略。MySQL 5.5版本的并行复制策略</p>
<p>官方MySQL 5.5版本是不支持并行复制的。但是，在2012年的时候，我自己服务的业务出现了</p>
<p>严重的主备延迟，原因就是备库只有单线程复制。然后，我就先后写了两个版本的并行策略。这里，我给你介绍一下这两个版本的并行策略，即按表分发策略和按行分发策略，以帮助你理解</p>
<p>MySQL官方版本并行复制策略的迭代。按表分发策略</p>
<p>按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在</p>
<p>表里的，所以按表分发，可以保证两个worker不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如图3所示，就是按表分发的规</p>
<p>则。图3 按表并行复制程模型</p>
<p>可以看到，每个worker线程对应一个hash表，用于保存当前正在这个worker的“执行队列”里的事</p>
<p>务所涉及的表。hash表的key是“库名.表名”，value是一个数字，表示队列中有多少个事务修改这</p>
<p>个表。在有事务分配给worker时，事务里面涉及的表会被加到对应的hash表中。worker执行完成后，这</p>
<p>个表会被从hash表中去掉。图3中，hash_table_1表示，现在worker_1的“待执行事务队列”里，有4个事务涉及到db1.t1表，</p>
<p>有1个事务涉及到db2.t2表；hash_table_2表示，现在worker_2中有一个事务会更新到表t3的数</p>
<p>据。假设在图中的情况下，coordinator从中转日志中读入一个新事务T，这个事务修改的行涉及到表</p>
<p>t1和t3。现在我们用事务T的分配流程，来看一下分配规则。1. 由于事务T中涉及修改表t1，而worker_1队列中有事务在修改表t1，事务T和队列中的某个事</p>
<p>务要修改同一个表的数据，这种情况我们说事务T和worker_1是冲突的。2. 按照这个逻辑，顺序判断事务T和每个worker队列的冲突关系，会发现事务T跟worker_2也冲</p>
<p>突。3. 事务T跟多于一个worker冲突，coordinator线程就进入等待。4. 每个worker继续执行，同时修改hash_table。假设hash_table_2里面涉及到修改表t3的事务</p>
<p>先执行完成，就会从hash_table_2中把db1.t3这一项去掉。5. 这样coordinator会发现跟事务T冲突的worker只有worker_1了，因此就把它分配给</p>
<p>worker_1。6. coordinator继续读下一个中转日志，继续分配事务。也就是说，每个事务在分发的时候，跟所有worker的冲突关系包括以下三种情况：</p>
<ol>
<li><p>如果跟所有worker都不冲突，coordinator线程就会把这个事务分配给最空闲的woker;</p>
</li>
<li><p>如果跟多于一个worker冲突，coordinator线程就进入等待状态，直到和这个事务存在冲突关</p>
</li>
</ol>
<p>系的worker只剩下1个；</p>
<ol start="3">
<li>如果只跟一个worker冲突，coordinator线程就会把这个事务分配给这个存在冲突关系的</li>
</ol>
<p>worker。这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如</p>
<p>所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个worker中，就变成单</p>
<p>线程复制了。按行分发策略</p>
<p>要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果</p>
<p>两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求binlog格式必须</p>
<p>是row。这时候，我们判断一个事务T和worker是否冲突，用的就规则就不是“修改同一个表”，而是“修改</p>
<p>同一行”。按行复制和按表复制的数据结构差不多，也是为每个worker，分配一个hash表。只是要实现按</p>
<p>行分发，这时候的key，就必须是“库名+表名+唯一键的值”。但是，这个“唯一键”只有主键id还是不够的，我们还需要考虑下面这种场景，表t1中除了主键，</p>
<p>还有唯一索引a：</p>
<p>假设，接下来我们要在主库执行这两个事务：</p>
<p>图4 唯一键冲突示例</p>
<p>可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的worker，就有可能</p>
<p>session B的语句先执行。这时候id&#x3D;1的行的a的值还是1，就会报唯一键冲突。因此，基于行的策略，事务hash表中还需要考虑唯一键，即key应该是“库名+表名+索引a的名字</p>
<p>+a的值”。比如，在上面这个例子中，我要在表t1上执行update t1 set a&#x3D;1 where id&#x3D;2语句，在binlog里面</p>
<p>记录了整行的数据修改前各个字段的值，和修改后各个字段的值。因此，coordinator在解析这个语句的binlog的时候，这个事务的hash表就有三个项:</p>
<ol>
<li>key&#x3D;hash_func(db1+t1+“PRIMARY”+2), value&#x3D;2; 这里value&#x3D;2是因为修改前后的行id值不</li>
</ol>
<p>变，出现了两次。2. key&#x3D;hash_func(db1+t1+“a”+2), value&#x3D;1，表示会影响到这个表a&#x3D;2的行。3. key&#x3D;hash_func(db1+t1+“a”+1), value&#x3D;1，表示会影响到这个表a&#x3D;1的行。可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的</p>
<p>计算资源。你可能也发现了，这两个方案其实都有一些约束条件：</p>
<ol>
<li>要能够从binlog里面解析出表名、主键值和唯一索引的值。也就是说，主库的binlog格式必</li>
</ol>
<p>CREATE TABLE t̀1  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;a  ̀int(11) DEFAULT NULL,</p>
<p>  &#96;b  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  UNIQUE KEY &#96;a  ̀(̀ a )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);</p>
<p>须是row；</p>
<ol start="2">
<li><p>表必须有主键；</p>
</li>
<li><p>不能有外键。表上如果有外键，级联更新的行不会记录在binlog中，这样冲突检测就不准</p>
</li>
</ol>
<p>确。但，好在这三条约束规则，本来就是DBA之前要求业务开发人员必须遵守的线上使用规范，所</p>
<p>以这两个并行复制策略在应用上也没有碰到什么麻烦。对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很</p>
<p>多行的大事务的话，按行分发的策略有两个问题：</p>
<ol>
<li>耗费内存。比如一个语句要删除100万行数据，这时候hash表就要记录100万个项。2. 耗费CPU。解析binlog，然后计算hash值，对于大事务，这个成本还是很高的。所以，我在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如</li>
</ol>
<p>果单个事务更新的行数超过10万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样</p>
<p>的：</p>
<ol>
<li><p>coordinator暂时先hold住这个事务；</p>
</li>
<li><p>等待所有worker都执行完成，变成空队列；</p>
</li>
<li><p>coordinator直接执行这个事务；</p>
</li>
<li><p>恢复并行模式。读到这里，你可能会感到奇怪，这两个策略又没有被合到官方，我为什么要介绍这么详细呢？其</p>
</li>
</ol>
<p>实，介绍这两个策略的目的是抛砖引玉，方便你理解后面要介绍的社区版本策略。MySQL 5.6版本的并行复制策略</p>
<p>官方MySQL5.6版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分</p>
<p>发策略和按行分发策略，你就理解了，用于决定分发策略的hash表里，key就是数据库名。这个策略的并行效果，取决于压力模型。如果在主库上有多个DB，并且各个DB的压力均衡，使</p>
<p>用这个策略的效果会很好。相比于按表和按行分发，这个策略有两个优势：</p>
<ol>
<li>构造hash值的时候很快，只需要库名；而且一个实例上DB数也不会很多，不会出现需要构</li>
</ol>
<p>造100万个项这种情况。2. 不要求binlog的格式。因为statement格式的binlog也可以很容易拿到库名。但是，如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；或者如果不同DB的</p>
<p>热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。理论上你可以创建不同的DB，把相同热度的表均匀分到这些不同的DB中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。MariaDB的并行复制策略</p>
<p>在第23篇文章中，我给你介绍了redo log组提交(group commit)优化， 而MariaDB的并行复制策</p>
<p>略利用的就是这个特性：</p>
<ol>
<li><p>能够在同一组里提交的事务，一定不会修改同一行；</p>
</li>
<li><p>主库上可以并行执行的事务，备库上也一定是可以并行执行的。在实现上，MariaDB是这么做的：</p>
</li>
<li><p>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；</p>
</li>
<li><p>commit_id直接写到binlog里面；</p>
</li>
<li><p>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；</p>
</li>
<li><p>这一组全部执行完成后，coordinator再去取下一批。当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析binlog，并拆分到</p>
</li>
</ol>
<p>worker”上。而MariaDB的这个策略，目标是“模拟主库的并行模式”。但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组</p>
<p>事务在commit的时候，下一组事务是同时处于“执行中”状态的。如图5所示，假设了三组事务在主库的执行情况，你可以看到在trx1、trx2和trx3提交的时</p>
<p>候，trx4、trx5和trx6是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进</p>
<p>入commit状态。图5 主库并行事务</p>
<p>而按照MariaDB的并行复制策略，备库上的执行效果如图6所示。图6 MariaDB 并行复制，备库并行效果</p>
<p>可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，</p>
<p>这样系统的吞吐量就不够。另外，这个方案很容易被大事务拖后腿。假设trx2是一个超大事务，那么在备库应用的时</p>
<p>候，trx1和trx3执行完成后，就只能等trx2完全执行完成，下一组才能开始执行。这段时间，只有</p>
<p>一个worker线程在工作，是对资源的浪费。不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很</p>
<p>优雅。MySQL 5.7的并行复制策略</p>
<p>在MariaDB并行复制实现之后，官方的MySQL5.7版本也提供了类似的功能，由参数slave-</p>
<p>parallel-type来控制并行复制策略：</p>
<ol>
<li><p>配置为DATABASE，表示使用MySQL 5.6版本的按库并行策略；</p>
</li>
<li><p>配置为 LOGICAL_CLOCK，表示的就是类似MariaDB的策略。不过，MySQL 5.7这个策</p>
</li>
</ol>
<p>略，针对并行度做了优化。这个优化的思路也很有趣儿。你可以先考虑这样一个问题：同时处于“执行状态”的所有事务，是不是可以并行？答案是，不能。因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同</p>
<p>的worker，就会出现备库跟主库不一致的情况。而上面提到的MariaDB这个策略的核心，是“所有处于commit”状态的事务可以并行。事务处于</p>
<p>commit状态，表示已经通过了锁冲突的检验了。这时候，你可以再回顾一下两阶段提交，我把前面第23篇文章中介绍过的两阶段提交过程图贴</p>
<p>过来。图7 两阶段提交细化过程图</p>
<p>其实，不用等到commit阶段，只要能够到达redo log prepare阶段，就表示事务已经通过锁冲突</p>
<p>的检验了。因此，MySQL 5.7并行复制策略的思想是：</p>
<ol>
<li><p>同时处于prepare状态的事务，在备库执行时是可以并行的；</p>
</li>
<li><p>处于prepare状态的事务，与处于commit状态的事务之间，在备库执行时也是可以并行的。我在第23篇文章，讲binlog的组提交的时候，介绍过两个参数：</p>
</li>
<li><p>binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync;</p>
</li>
<li><p>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。这两个参数是用于故意拉长binlog从write到fsync的时间，以此减少binlog的写盘次数。在MySQL</p>
</li>
</ol>
<p>5.7的并行复制策略里，它们可以用来制造更多的“同时处于prepare阶段的事务”。这样就增加了</p>
<p>备库复制的并行度。也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在MySQL</p>
<p>5.7处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。MySQL 5.7.22的并行复制策略</p>
<p>在2018年4月份发布的MySQL 5.7.22版本里，MySQL增加了一个新的并行复制策略，基于</p>
<p>WRITESET的并行复制。相应地，新增了一个参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策</p>
<p>略。这个参数的可选值有以下三种。1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可</p>
<p>以并行的策略。2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合</p>
<p>writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并</p>
<p>行。3. WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程</p>
<p>先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。当然为了唯一标识，这个hash值是通过“库名+表名+索引名+值”计算出来的。如果一个表上除了</p>
<p>有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert语句对应的writeset就要多增</p>
<p>加一个hash值。你可能看出来了，这跟我们前面介绍的基于MySQL 5.5版本的按行分发的策略是差不多的。不</p>
<p>过，MySQL官方的这个实现还是有很大的优势：</p>
<ol>
<li>writeset是在主库生成后直接写入到binlog里面的，这样在备库执行的时候，不需要解析</li>
</ol>
<p>binlog内容（event里的行数据），节省了很多计算量；</p>
<ol start="2">
<li><p>不需要把整个事务的binlog都扫一遍才能决定分发到哪个worker，更省内存；</p>
</li>
<li><p>由于备库的分发策略不依赖于binlog内容，所以binlog是statement格式也是可以的。因此，MySQL 5.7.22的并行复制策略在通用性上还是有保证的。当然，对于“表上没主键”和“外键约束”的场景，WRITESET策略也是没法并行的，也会暂时退化</p>
</li>
</ol>
<p>为单线程模型。小结</p>
<p>在今天这篇文章中，我和你介绍了MySQL的各种多线程复制策略。为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大</p>
<p>的主库，备库是可能一直追不上主库的。从现象上看就是，备库上seconds_behind_master的值</p>
<p>越来越大。在介绍完每个并行复制策略后，我还和你分享了不同策略的优缺点：</p>
<p>如果你是DBA，就需要根据不同的业务场景，选择不同的策略；</p>
<p>如果是你业务开发人员，也希望你能从中获取灵感用到平时的开发工作中。从这些分析中，你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。官方MySQL5.7版本新增的备库并行策略，修改了binlog的内容，也就是说binlog协议并不是向上</p>
<p>兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。最后，我给你留下一个思考题吧。假设一个MySQL 5.7.22版本的主库，单线程插入了很多数据，过了3个小时后，我们要给这个主</p>
<p>库搭建一个相同版本的备库。这时候，你为了更快地让备库追上主库，要开并行复制。在binlog-transaction-dependency-</p>
<p>tracking参数的COMMIT_ORDER、WRITESET和WRITE_SESSION这三个取值中，你会选择</p>
<p>哪一个呢？你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？你可以把你的答案和分析写在评论区，我会在下一篇文章跟你讨论这个问题。感谢你的收听，也</p>
<p>欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期的问题是，什么情况下，备库的主备延迟会表现为一个45度的线段？评论区有不少同学的</p>
<p>回复都说到了重点：备库的同步在这段时间完全被堵住了。产生这种现象典型的场景主要包括两种：</p>
<p>一种是大事务（包括大表DDL、一个事务操作很多行）；</p>
<p>还有一种情况比较隐蔽，就是备库起了一个长事务，比如</p>
<p>然后就不动了。这时候主库对表t做了一个加字段操作，即使这个表很小，这个DDL在备库应用的时候也会被堵</p>
<p>住，也不能看到这个现象。评论区还有同学说是不是主库多线程、从库单线程，备库跟不上主库的更新节奏导致的？今天这</p>
<p>篇文章，我们刚好讲的是并行复制。所以，你知道了，这种情况会导致主备延迟，但不会表现为</p>
<p>这种标准的呈45度的直线。评论区留言点赞板：</p>
<p>begin; </p>
<p>select * from t limit 1;</p>
<p>@易翔 、 @万勇、@老杨同志 等同学的回复都提到了我们上面说的场景；</p>
<p>@Max 同学提了一个很不错的问题。主备关系里面，备库主动连接，之后的binlog发送是主库</p>
<p>主动推送的。之所以这么设计也是为了效率和实时性考虑，毕竟靠备库轮询，会有时间差。老杨同志   5</p>
<p>尝试回答 慧鑫coming 的问题。老师图片的步骤有下面5步</p>
<p>1 redo log prepare write</p>
<p>2 binlog write</p>
<p>3 redo log prepare fsync</p>
<p>4 binlog fsync</p>
<p>5 redo log commit write</p>
<p>1)如果更新通一条记录是有锁的，只能一个事务执行，其他事务等待锁。2)第4步的时候会因为下面两个参数，等其他没有锁冲突的事务，一起刷盘，此时一起执行的事</p>
<p>务拥有相同的commit_id</p>
<p>binlog_group_commit_sync_delay</p>
<p>binlog_group_commit_sync_no_delay_count</p>
<p>3)执行步骤5后，释放锁，等待锁的事务开始执行。所以对同一行更新的事务，不可能拥有相同的commit_id</p>
<p>2019-01-11</p>
<p> 作者回复</p>
<p>精选留言</p>
<p> ，你比我回复得详细，顶起</p>
<p>2019-01-11</p>
<p>长杰   2</p>
<p>举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker </p>
<p>的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会</p>
<p>看到这个事务“更新了一半的结果”，破坏了事务逻辑的原子性。老师这块不太明白，备库有查询会看到更新了一半的结果，t1的worker执行完了更新会commit</p>
<p>吗？如果不commit，备库查询应该看不到吧？如果commit，就破坏了事物的原子性，肯定是</p>
<p>有问题的。2019-01-11</p>
<p> 作者回复</p>
<p>应该是说，它迟早要commit，但是两个worker是两个线程，没办法约好“同时提交”，这样就有</p>
<p>可能出现一个先提交一个后提交。这两个提交之间的时间差，就能被用户看到“一半事务”，好问题</p>
<p>2019-01-11</p>
<p>jike   1</p>
<p>老师您好，开启并行复制后，事务是按照组来提交的，从库也是根据commit_id来回放，如果</p>
<p>从库也开启binlog的话，那是不是存在主从的binlog event写入顺序不一致的情况呢？2019-01-15</p>
<p> 作者回复</p>
<p>是有可能binlog event写入顺序不同的，好问题</p>
<p>2019-01-15</p>
<p>HuaMax   7</p>
<p>课后题。关键点在于主库单线程，针对三种不同的策略，COMMIT_ORDER：没有同时到达re</p>
<p>do log的prepare 状态的事务，备库退化为单线程；WRITESET：通过对比更新的事务是否存在</p>
<p>冲突的行，可以并发执行；WRITE_SESSION：在WRITESET的基础上增加了线程的约束，则</p>
<p>退化为单线程。综上，应选择WRITESET策略</p>
<p>2019-01-12</p>
<p> 作者回复</p>
<p>准确 </p>
<p>2019-01-12</p>
<p>慧鑫coming   2</p>
<p>老师，有个问题，mariadb的并行策略，当同一组中有3个事务，它们都对同一行同一字段值进</p>
<p>行更改，而它们的commit_id相同，可以在从库并行执行，那么3者的先后顺序是怎么保证不影</p>
<p>响该行该字段的最终结果与主库一致？2019-01-11</p>
<p> 作者回复</p>
<p>好问题</p>
<p>不过这个是不可能的哈，对同一行的修改，第一个拿到行锁的事务还没提交前，另外两个会被</p>
<p>行锁堵住的，这两个进入不了commit状态。所以这三个的commit_id不会相同的 </p>
<p>2019-01-11</p>
<p>IceGeek17   1</p>
<p>好文，总结对比不同的并行策略，讲的深入浅出，看完豁然开朗。有看源代码的冲动。2019-01-24</p>
<p> 作者回复</p>
<p>看完分享你的心得哈  </p>
<p>2019-01-24</p>
<p>每天晒白牙   1</p>
<p>我是做java的，看老师的这个专栏，确实挺吃力的，老师专栏的干货太多了，下面的留言也是</p>
<p>相当有水平，质量都很高，互动也好，应该是好多DBA吧，做java的我，看的头大</p>
<p>2019-01-13</p>
<p> 作者回复</p>
<p>这几篇偏深，但确实是大家在使用的时候需要了解的，</p>
<p>到30篇后面的文章会偏应用哈</p>
<p>2019-01-13</p>
<p>某、人   1</p>
<p>总结下多线程复制的流程,有不对之处请老师指出:</p>
<p>双1,配置为logical_clock,假设有三个事务并发执行也已经执行完成(都处于prepare阶段)</p>
<p>1.三个事务把redo log从redo log buffer写到fs page cache中</p>
<p>2.把binlog_cache flush到binlog文件中,最先进入flush队列的为leader,</p>
<p>其它两个事务为follower.把组员编号以及组的编号写进binlog文件中(三个事务为同一组).</p>
<p>3.三个事务的redo log做fsync,binlog做fsync.</p>
<p>4.dump线程从binlog文件里把binlog event发送给从库</p>
<p>5.I&#x2F;O线程接收到binlog event,写到relay log中</p>
<p>6.sql thread读取relay log,判断出这三个事务是处于同一个组,</p>
<p>则把这三个事务的event打包发送给三个空闲的worker线程(如果有)并执行。配置为writeset的多线程复制流程:</p>
<p>1.三个事务把redo log从redo log buffer写到fs page cache中</p>
<p>2.把binlog_cache flush到binlog文件中,根据表名、主键和唯一键(如果有)生成hash值(writeset),</p>
<p>保存到hash表中</p>
<p>判断这三个事务的writeset是否有冲突,如果没有冲突,则视为同组,如果有冲突,则视为不同组.</p>
<p>并把把组员编号以及组的编号写进binlog文件中</p>
<p>(不过一个组的事务个数也不是无限大,由参数binlog_transaction_dependency_history_size决定</p>
<p>组内最多事务数)</p>
<p>3.然后做redo log和binlog的fsync</p>
<p>4.dump线程从binlog文件里把binlog event发送给从库</p>
<p>5.I&#x2F;O线程接收到binlog event,写到relay log中</p>
<p>6.sql thread读取relay log,如果是同一个组的事务,则把事务分配到不同的worker线程去应用relay</p>
<p>log.</p>
<p>不同组的事务,需要等到上一个组的事务全部执行完成,才能分配worker线程应用relay log.</p>
<p>老师我有几个问题想请教下:</p>
<p>1.在备库是单线程下,second_behind_master是通过计算T3-T1得到,</p>
<p>在多线程的情况下,是怎么计算出second_behind_master的值？用的是哪一个事务的时间戳?</p>
<p>2.多线程复制下,如果从库宕机了,是不是从库有一个记录表记录那些事务已经应用完成,</p>
<p>恢复的时候,只需要恢复未应用的事务.</p>
<p>3.binlog延迟sync的两个参数,是延迟已经flush未sync时间。意思是让事务组占用flush时间更长,</p>
<p>之后的事务有更多的时间,从binlog cache进入到flush队列,使得组员变多,起到从库并发的目的</p>
<p>因为我理解的是加入到组是在binlog cache flush到binlog文件之前做的,如果此时有事务正在flus</p>
<p>h,</p>
<p>未sync,则后面的事务必须等待。不知道理解得对不</p>
<p>2019-01-13</p>
<p> 作者回复</p>
<p>上面的描述部分，writeset的多线程复制流程里面，这段需要修改下：</p>
<p>『2.把binlog_cache flush到binlog文件中,根据表名、主键和唯一键(如果有)生成hash值(writeset</p>
<p>),保存到hash表中</p>
<p>【判断这三个事务的writeset是否有冲突,如果没有冲突,则视为同组,如果有冲突,则视为不同组.</p>
<p>并把把组员编号以及组的编号写进binlog文件中】』</p>
<p>上面中括号这段要去掉，</p>
<p>判断writeset之间是否可以并行这个逻辑，是在备库的coordinator线程做的。—-</p>
<ol>
<li><p>在多线程并发的时候，Seconds_behind_master很不准，后面会介绍别的判断方法；</p>
</li>
<li><p>是的,备库有记录，就是show slave status 里面的Relay_Log_File 和 Relay_Log_Pos 这两个</p>
</li>
</ol>
<p>值表示的，好问题</p>
<ol start="3">
<li>”加入到组是在binlog cache flush到binlog文件之前做的,如果此时有事务正在flush,未sync,则</li>
</ol>
<p>后面的事务必须等待“ 这句话是对的，但是我没看出这个跟前面提的两个延迟参数作用的关系^</p>
<p>_^</p>
<p>2019-01-13</p>
<p>观弈道人   1</p>
<p>丁老师你好，问个题外问题，mysql已经通过gap锁解决了在rr级别下的幻读问题，那么serializa</p>
<p>ble隔离级别目前还有什么用途，一般文章上说的，serializable 主要是为了解决幻读，谢谢回答</p>
<p>。2019-01-12</p>
<p> 作者回复</p>
<p>serializable隔离级别确实用得很少（我没有见过在生产上使用的哈）</p>
<p>2019-01-12</p>
<p>J!   0</p>
<p>同时处于 prepare 状态的事务，在备库执行时是可以并行.复制的，是这个prepare 就可以生成</p>
<p>了改组的commited Id吗</p>
<p>极客时间版权所有: <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/77083">https://time.geekbang.org/column/article/77083</a></p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p>进入prepare 的时候就给这个事务分配 commitid，这个commitid就是当前系统最大的一个com</p>
<p>mitid</p>
<p>2019-02-02</p>
<p>J!   0</p>
<p>5.7 版本的基于组提交的并行复制。last_commitid 是在什么时候生成的？2019-02-01</p>
<p> 作者回复</p>
<p>事务提交的时候</p>
<p>2019-02-02</p>
<p>alias cd&#x3D;rm -rf   0</p>
<p>老师您好：</p>
<p>思考题答案的猜测：建议采用 WRITESET。WRITESET_SESSION：因为主库是单线程插入，如果采用WRITESET_SESSION，那么会退</p>
<p>化成单线程主从复制。COMMIT_ORDER：因为是追历史数据，所以会退化成单线程。2019-02-01</p>
<p> 作者回复</p>
<p>对的， </p>
<p>2019-02-02</p>
<p>时隐时现   0</p>
<p>Furthermore, given that changes are propagated and applied in row-based format, this means t</p>
<p>hat they are received in an optimized and compact format, and likely reducing the number of IO </p>
<p>operations required when compared to the originating member.</p>
<p>这个是官档上对MGR的一段解读，我的疑问是：</p>
<p>为何row-base replication在从库回放时会节省大量IO？候选答案：</p>
<p>1、省去了sql解析，直接调用do_command</p>
<p>2、？？可是row复制有其他可能存在的劣势，比如单个大dml会被解析成多个dml_event进行重放，万</p>
<p>一该表没有主键或唯一索引，只能采用二级索引或者全表扫描(开启hash_scan也可以)，所以，</p>
<p>官档上直接说会减少大量IO是不是有点太武断了</p>
<p>2019-01-31</p>
<p> 作者回复</p>
<p>这个描述应该是主要考虑在有主键的时候，可以通过row里面的信息取出主键直接定位记录。你说的这些其实劣势确实也是存在的  </p>
<p>2019-01-31</p>
<p>牛牛   0</p>
<p>老师、请教两个问题～</p>
<ol>
<li>我在job里按主键删除线上表数据的时候、造成了主从延迟、delete from table where id in…</li>
</ol>
<p>id是主键、每次delete 300条、sleep 500ms、这种延迟可能是什么造成的呢？300条应该不算大</p>
<p>事务？还是说快速的数据删除导致了索引重建？2. 如果一个表快速往里写数据、每次300条、sleep 1s、这个库上的读取会慢吗？多谢老师 ～</p>
<p>2019-01-27</p>
<p> 作者回复</p>
<ol>
<li>delete 300条 ， sleep 500ms已经是很克制的操作了，单线程吗？如果还是单线程，那延迟</li>
</ol>
<p>应该不是这个操作导致的</p>
<ol start="2">
<li>这都是很小的压力，不会读取慢才对</li>
</ol>
<p>2019-02-01</p>
<p>Leon    0</p>
<p>老师，semisync啥时候讲下，昨天面试被问到一脸懵逼</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>semi-sync在第28篇会提到，但是也不是大篇幅介绍</p>
<p>后面可能也不会大篇幅专门介绍了，你说下你的问题哈。2019-01-22</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师您好：</p>
<p>关于COMMIT_ORDER的并行复制方案，从库根据 commit_id来判断“处于prepare和commit状</p>
<p>态的事务”。这里我有个很大的疑惑：commit_id是什么时候加入到binlog的，又是在什么时候递</p>
<p>增的？？（</p>
<p>对于我这个问题的进一步解释：</p>
<p>既然commit_id是要被写入到binlog的，那么commit_id毫无疑问就是在write binlog阶段写入的</p>
<p>。我们知道redolog是组提交的，如果只是按照redolog的组提交方式生成commit_id，那么这个co</p>
<p>mmit_id包含的并行事务数量并不够多！因为在binlog write阶段，又有事务进入到redolog prepa</p>
<p>re阶段，他们之间的commit_id是不一样的，但是他们是可以并行的。所以commit_id什么时候递增？这个是非常关键的，我也很疑惑，commit_id到底是根据什么条</p>
<p>件递增的？？）</p>
<p>2019-01-17</p>
<p> 作者回复</p>
<p>可以这么理解，每个事务都有两个数字表示它在执行提交阶段的时间范围, 构成区间(c1, c2).</p>
<p>如果两个事务的区间有交集，就是可以并行的。这里c1是事务启动的时候，当前系统里最大的commit_id；</p>
<p>一个事务提交的时候，commit_id+1.</p>
<p>2019-01-17</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师您好：</p>
<p>今天的内容中写到：“外键约束”会导致并行复制退化为单线程。这个地方我就突然联想到，在业务中，类似于“外键”这种关系是一定存在的。但是一般在设计</p>
<p>表的时候，比如：表A的某个唯一键是表B的外键。并不会真正”显示”的在数据库表中创建外键</p>
<p>关系。（查询的时候，查询出A的这个唯一键，然后再根据这个唯一键查询表B的数据，并不会</p>
<p>有真正的外键关系，一次性查出所有关联数据）</p>
<p>这是为什么呢？2019-01-17</p>
<p> 作者回复</p>
<p>我也建议尽量少使用外键，我自己理解的几个原因吧</p>
<ol>
<li><p>这个关系应该维护在开发系统的逻辑中，放在数据库里面，比较隐蔽，容易忘记</p>
</li>
<li><p>外键约束可能会导致有些更新失败</p>
</li>
<li><p>外键约束（尤其是级联更新）容易出现非预期的结果</p>
</li>
</ol>
<p>2019-01-17</p>
<p>亢星东   0</p>
<p>老师好，如何将大事务拆成小事务</p>
<p>2019-01-16</p>
<p> 作者回复</p>
<p>这个是要结合业务的，比如要删除100万行，改成100个事务，每个事务删除1万行，这样的</p>
<p>2019-01-16</p>
<p>道   0</p>
<p>老师，这段不太理解：“举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新</p>
<p>语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，</p>
<p>备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的原子性。”备库</p>
<p>上的查询属于另外一个事务，按照可重复读隔离级别，这个查询不应该看到另外一个事务“更新</p>
<p>了一半的结果”啊。即便是这两条更新语句被分到不同 worker ，也应该保证事务的原子性啊，</p>
<p>难道是技术上有困难吗？2019-01-16</p>
<p> 作者回复</p>
<p>因为这两个worker没办法“约好一起提交”，这个是属于两个线程了</p>
<p>2019-01-16</p>
<p>crazyone   0</p>
<p>“不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁</p>
<p>冲突的检验了。”这句话不怎么理解。事务获取锁是在执行到对应的语句才做检查的，redo log</p>
<p>在事务当中，应该也是一条条操作语句写的吧？难道写完了，才会进入到prepare阶段？这个pr</p>
<p>epare阶段是指事务已经完全扫描执行完所有事务操作，准备写入到redo log文件的阶段?</p>
<p>2019-01-15</p>
<p> 作者回复</p>
<p>就是两阶段提交里的，写redo 的第一阶段</p>
<p>2019-01-16</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/9d443267.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/9d443267.html" class="post-title-link" itemprop="url">mysql-MySQL是怎么保证高可用的</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-30 06:08:44" itemprop="dateCreated datePublished" datetime="2019-11-30T06:08:44+08:00">2019-11-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>28 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>25 | MySQL是怎么保证高可用的？2019-01-09 林晓斌</p>
<p>在上一篇文章中，我和你介绍了binlog的基本内容，在一个主备关系中，每个备库接收主库的</p>
<p>binlog并执行。正常情况下，只要主库执行更新生成的所有binlog，都可以传到备库并被正确地执行，备库就能</p>
<p>达到跟主库一致的状态，这就是最终一致性。但是，MySQL要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？今天我就着重</p>
<p>和你分析一下。这里，我再放一次上一篇文章中讲到的双M结构的主备切换流程图。图 1 MySQL主备切换流程–双M结构</p>
<p>主备延迟</p>
<p>主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动</p>
<p>操作，比如主库所在机器掉电。接下来，我们先一起看看主动切换的场景。在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有</p>
<p>关的时间点主要包括以下三个：</p>
<ol>
<li><p>主库A执行完成一个事务，写入binlog，我们把这个时刻记为T1;</p>
</li>
<li><p>之后传给备库B，我们把备库B接收完这个binlog的时刻记为T2;</p>
</li>
<li><p>备库B执行完成这个事务，我们把这个时刻记为T3。所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也</p>
</li>
</ol>
<p>就是T3-T1。你可以在备库上执行show slave status命令，它的返回结果里面会显示</p>
<p>seconds_behind_master，用于表示当前备库延迟了多少秒。seconds_behind_master的计算方法是这样的：</p>
<ol>
<li><p>每个事务的binlog 里面都有一个时间字段，用于记录主库上写入的时间；</p>
</li>
<li><p>备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到</p>
</li>
</ol>
<p>seconds_behind_master。可以看到，其实seconds_behind_master这个参数计算的就是T3-T1。所以，我们可以用</p>
<p>seconds_behind_master来作为主备延迟的值，这个值的时间精度是秒。你可能会问，如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？其实不会的。因为，备库连接到主库的时候，会通过执行SELECT UNIX_TIMESTAMP()函数来</p>
<p>获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行</p>
<p>seconds_behind_master计算的时候会自动扣掉这个差值。需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即T2-T1的值是</p>
<p>非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完binlog和执行完这个</p>
<p>事务之间的时间差。所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产binlog</p>
<p>的速度要慢。接下来，我就和你一起分析下，这可能是由哪些原因导致的。主备延迟的来源</p>
<p>首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或</p>
<p>者，他们会把20个主库放在4台机器上，而把备库集中在一台机器上。其实我们都知道，更新请求对IOPS的压力，在主库和备库上是无差别的。所以，做这种部署</p>
<p>时，一般都会将备库设置为“非双1”的模式。但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的</p>
<p>时候，就可能会导致主备延迟了。当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，所以主备库选</p>
<p>用相同规格的机器，并且做对称部署，是现在比较常见的情况。追问1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？这就是第二种常见的可能了，即备库的压力大。一般的想法是，主库既然提供了写能力，那么</p>
<p>备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在</p>
<p>备库上跑。我真就见过不少这样的情况。由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备</p>
<p>库的压力控制。结果就是，备库上的查询耗费了大量的CPU资源，影响了同步速度，造成主备延</p>
<p>迟。这种情况，我们一般可以这么处理：</p>
<ol>
<li>一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。2. 通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力。其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能</li>
</ol>
<p>力。而从库，就很适合用来做备份。追问2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？这就是第三种可能了，即大事务。大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入binlog，再传给备库。所</p>
<p>以，如果一个主库上的语句执行10分钟，那这个事务很可能就会导致从库延迟10分钟。不知道你所在公司的DBA有没有跟你这么说过：不要一次性地用delete语句删除太多数据。其</p>
<p>实，这就是一个典型的大事务场景。比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次</p>
<p>性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很</p>
<p>不错的），所以会在晚上执行这些大量数据的删除操作。结果，负责的DBA同学半夜就会收到延迟报警。然后，DBA团队就要求你后续再删除数据的时</p>
<p>候，要控制每个事务删除的数据量，分成多次删除。另一种典型的大事务场景，就是大表DDL。这个场景，我在前面的文章中介绍过。处理方案</p>
<p>就是，计划内的DDL，建议使用gh-ost方案（这里，你可以再回顾下第13篇文章《为什么表数据</p>
<p>删掉一半，表文件大小不变？》中的相关内容）。追问3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。这个话题，我会留在下一篇</p>
<p>文章再和你详细介绍。备注：这里需要说明一下，从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描</p>
<p>述，我把会在HA过程中被选成新主库的，称为备库，其他的称为从库。其实还是有不少其他情况会导致主备延迟，如果你还碰到过其他场景，欢迎你在评论区给我留</p>
<p>言，我来和你一起分析、讨论。由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。可靠性优先策略</p>
<p>在图1的双M结构下，从状态1到状态2切换的详细过程是这样的：</p>
<ol>
<li>判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则</li>
</ol>
<p>持续重试这一步；</p>
<ol start="2">
<li><p>把主库A改成只读状态，即把readonly设置为true；</p>
</li>
<li><p>判断备库B的seconds_behind_master的值，直到这个值变成0为止；</p>
</li>
<li><p>把备库B改成可读写状态，也就是把readonly 设置为false；</p>
</li>
<li><p>把业务请求切到备库B。这个切换流程，一般是由专门的HA系统来完成的，我们暂时称之为可靠性优先流程。图2 MySQL可靠性优先主备切换流程</p>
</li>
</ol>
<p>备注：图中的SBM，是seconds_behind_master参数的简写。可以看到，这个切换流程中是有不可用时间的。因为在步骤2之后，主库A和备库B都处于</p>
<p>readonly状态，也就是说这时系统处于不可写状态，直到步骤5完成后才能恢复。在这个不可用状态中，比较耗费时间的是步骤3，可能需要耗费好几秒的时间。这也是为什么需</p>
<p>要在步骤1先做判断，确保seconds_behind_master的值足够小。试想如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会</p>
<p>长达30分钟，这种情况一般业务都是不可接受的。当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的</p>
<p>策略，来把这个不可用时间几乎降为0。可用性优先策略</p>
<p>如果我强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库</p>
<p>B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一</p>
<p>致的情况。接下来，我就和你分享一个可用性优先流程产生数据不一致的例子。假设有一个表 t：</p>
<p>这个表定义了一个自增主键id，初始化数据后，主库和备库上都是3行数据。接下来，业务人员</p>
<p>要继续在表t上执行两条插入语句的命令，依次是：</p>
<p>假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到5秒。在插入一条c&#x3D;4的语句</p>
<p>mysql&gt; CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) unsigned NOT NULL AUTO_INCREMENT,</p>
<p>  &#96;c  ̀int(11) unsigned DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t(c) values(1),(2),(3);</p>
<p>insert into t(c) values(4);</p>
<p>insert into t(c) values(5);</p>
<p>后，发起了主备切换。图3是可用性优先策略，且binlog_format&#x3D;mixed时的切换流程和数据结果。图3 可用性优先策略，且binlog_format&#x3D;mixed</p>
<p>现在，我们一起分析下这个切换流程：</p>
<ol>
<li>步骤2中，主库A执行完insert语句，插入了一行数据（4,4），之后开始进行主备切换。2. 步骤3中，由于主备之间有5秒的延迟，所以备库B还没来得及应用“插入c&#x3D;4”这个中转日志，</li>
</ol>
<p>就开始接收客户端“插入 c&#x3D;5”的命令。3. 步骤4中，备库B插入了一行数据（4,5），并且把这个binlog发给主库A。4. 步骤5中，备库B执行“插入c&#x3D;4”这个中转日志，插入了一行数据（5,4）。而直接在备库B执</p>
<p>行的“插入c&#x3D;5”这个语句，传到主库A，就插入了一行新数据（5,5）。最后的结果就是，主库A和备库B上出现了两行不一致的数据。可以看到，这个数据不一致，是</p>
<p>由可用性优先流程导致的。那么，如果我还是用可用性优先策略，但设置binlog_format&#x3D;row，情况又会怎样呢？因为row格式在记录binlog的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一</p>
<p>致。而且，两边的主备同步的应用线程会报错duplicate key error并停止。也就是说，这种情况</p>
<p>下，备库B的(5,4)和主库A的(5,5)这两行数据，都不会被对方执行。图4中我画出了详细过程，你可以自己再分析一下。图4 可用性优先策略，且binlog_format&#x3D;row</p>
<p>从上面的分析中，你可以看到一些结论：</p>
<ol>
<li>使用row格式的binlog时，数据不一致的问题更容易被发现。而使用mixed或者statement格</li>
</ol>
<p>式的binlog时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，</p>
<p>很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。2. 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠</p>
<p>性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。但事无绝对，有没有哪种情况数据的可用性优先级更高呢？答案是，有的。我曾经碰到过这样的一个场景：</p>
<p>有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过binlog来修补，而这个短</p>
<p>暂的不一致也不会引发业务问题。同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法</p>
<p>执行。这时候，你可能就需要选择先强行切换，事后再补数据的策略。当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写</p>
<p>入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临</p>
<p>时库里面。这样的话，这种场景就又可以使用可靠性优先策略了。接下来我们再看看，按照可靠性优先的思路，异常切换会是什么效果？假设，主库A和备库B间的主备延迟是30分钟，这时候主库A掉电了，HA系统要切换B作为主</p>
<p>库。我们在主动切换的时候，可以等到主备延迟小于5秒的时候再启动切换，但这时候已经别无</p>
<p>选择了。图5 可靠性优先策略，主库不可用</p>
<p>采用可靠性优先策略的话，你就必须得等到备库B的seconds_behind_master&#x3D;0之后，才能切</p>
<p>换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用</p>
<p>的状态。因为，主库A掉电后，我们的连接还没有切到备库B。你可能会问，那能不能直接切换到备库B，但是保持B只读呢？这样也不行。因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前</p>
<p>执行完成的事务，会认为有“数据丢失”。虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢</p>
<p>失数据的状态”也是不能被接受的。聊到这里你就知道了，在满足数据可靠性的前提下，MySQL高可用系统的可用性，是依赖于主</p>
<p>备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。小结</p>
<p>今天这篇文章，我先和你介绍了MySQL高可用系统的基础，就是主备切换逻辑。紧接着，我又</p>
<p>和你讨论了几种会导致主备延迟的情况，以及相应的改进方向。然后，由于主备延迟的存在，切换策略就有不同的选择。所以，我又和你一起分析了可靠性优先</p>
<p>和可用性优先策略的区别。在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底</p>
<p>线。在这个基础上，通过减少主备延迟，提升系统的可用性。最后，我给你留下一个思考题吧。一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集</p>
<p>seconds_behind_master的值。假设，现在你看到你维护的一个备库，它的延迟监控的图像类似图6，是一个45°斜向上的线段，</p>
<p>你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？图6 备库延迟</p>
<p>你可以把你的分析写在评论区，我会在下一篇文章的末尾跟你讨论这个问题。感谢你的收听，也</p>
<p>欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期我留给你的问题是，什么情况下双M结构会出现循环复制。一种场景是，在一个主库更新事务后，用命令set global server_id&#x3D;x修改了server_id。等日志再</p>
<p>传回来的时候，发现server_id跟自己的server_id不同，就只能执行了。另一种场景是，有三个节点的时候，如图7所示，trx1是在节点 B执行的，因此binlog上的</p>
<p>server_id就是B，binlog传给节点 A，然后A和A’搭建了双M结构，就会出现循环复制。图7 三节点循环复制</p>
<p>这种三节点复制的场景，做数据库迁移的时候会出现。如果出现了循环复制，可以在A或者A’上，执行如下命令：</p>
<p>这样这个节点收到日志后就不会再执行。过一段时间后，再执行下面的命令把这个值改回来。评论区留言点赞板：</p>
<p>stop slave；</p>
<p>CHANGE MASTER TO IGNORE_SERVER_IDS&#x3D;(server_id_of_B);</p>
<p>start slave;</p>
<p>stop slave；</p>
<p>CHANGE MASTER TO IGNORE_SERVER_IDS&#x3D;();</p>
<p>start slave;</p>
<p>某、人   12</p>
<p>遇到过下面几种造成主从延迟的情况:</p>
<p>1.主库DML语句并发大,从库qps高</p>
<p>2.从库服务器配置差或者一台服务器上几台从库(资源竞争激烈,特别是io)</p>
<p>3.主库和从库的参数配置不一样</p>
<p>4.大事务(DDL,我觉得DDL也相当于一个大事务)</p>
<p>5.从库上在进行备份操作</p>
<p>6.表上无主键的情况(主库利用索引更改数据,备库回放只能用全表扫描,这种情况可以调整slave_</p>
<p>rows_search_algorithms参数适当优化下)</p>
<p>7.设置的是延迟备库</p>
<p>8.备库空间不足的情况下</p>
<p>这期的问题：</p>
<p>看这曲线,应该是从库正在应用一个大事务,或者一个大表上无主键的情况(有该表的更新)</p>
<p>@一大只、@HuaMax 同学提到了第一个复现方法；</p>
<p>@Jonh同学提到了IGNORE_SERVER_IDS这个解决方法；</p>
<p>@React 提到，如果主备设置不同的步长，备库是不是可以设置为可读写。我的建议是，只要</p>
<p>这个节点设计内就不会有业务直接在上面执行更新，就建议设置为readonly。精选留言</p>
<p>应该是T3随着时间的增长在增长,而T1这个时间点是没变的,造成的现象就是</p>
<p>随着时间的增长,second_behind_master也是有规律的增长</p>
<p>2019-01-10</p>
<p> 作者回复</p>
<p>分析的点很准确 </p>
<p>2019-01-11</p>
<p>undifined   2</p>
<p>问题答案：</p>
<ol>
<li><p>备库在执行复杂查询，导致资源被占用</p>
</li>
<li><p>备库正在执行一个大事务</p>
</li>
<li><p>DML 语句执行</p>
</li>
</ol>
<p>老师我的理解对吗</p>
<p>2019-01-09</p>
<p> 作者回复</p>
<p>1不太准确，明天我会提到哈</p>
<p>23对的</p>
<p>2019-01-09</p>
<p>7号   1</p>
<p>老师，生产环境有一张表需要清理，该表大小140G。要保留最近一个月的数据，又不能按时间</p>
<p>直接用detele删（全表扫描），本来想通过清空分区表删，但是分区表又是哈希的。。有没好</p>
<p>的办法呢？2019-01-09</p>
<p> 作者回复</p>
<p>估计下一个月占多少比例，如果比较小就建新表，把数据导过去吧</p>
<p>如果一个月占比高的话，只能一点点删了。时间字段有索引的话，每个分区按时间过滤出来删除</p>
<p>2019-01-09</p>
<p>Sr7vy   1</p>
<p>问题1：T3的解释是：备库执行完这个事物。则：Seconds_Behind_Master&#x3D;T3-T1。如T1&#x3D;30</p>
<p>min，主执行完成，备没有执行。猜测1：那么Seconds_Behind_Master&#x3D;30min吗？猜测2：备</p>
<p>执需要先把这个30min的事务执行完后，Seconds_Behind_Master&#x3D;30min？问题2：很多时候是否能把Seconds_Behind_Master当作真正的延迟时间（面试常被问）？如</p>
<p>果能，pt-heartbeat存在还有啥意义啊？2019-01-09</p>
<p> 作者回复</p>
<p>问题1:</p>
<p>1.备库没收到，还是收到没执行，前者0，后者30</p>
<ol start="2">
<li>第二问没看懂</li>
</ol>
<p>问题2:</p>
<p>类似的，主库把日志都发给备库了吗</p>
<p>2019-01-09</p>
<p>万勇   1</p>
<p>主备同步延迟，工作中常遇到几种情况：</p>
<p>1.主库做大量的dml操作，引起延迟</p>
<p>2.主库有个大事务在处理，引起延迟</p>
<p>3.对myisam存储引擎的表做dml操作，从库会有延迟。4.利用pt工具对主库的大表做字段新增、修改和添加索引等操作，从库会有延迟。2019-01-09</p>
<p> 作者回复</p>
<p>  </p>
<p>你是有故事的 </p>
<p>2019-01-09</p>
<p>梁中华   1</p>
<p>我有一个比较极端一点的HA问题，假设主库的binlog刚写成功还未来得及把binlog同步到从库，</p>
<p>主库就掉电了，这时候从库的数据会不完整吗？第二个问题，原主库重启加入集群后，那条没有传出去的binlog会如何处理？2019-01-09</p>
<p> 作者回复</p>
<p>1.可能会丢</p>
<ol start="2">
<li>要看重启之后的拓扑结构了，如果还有节点是这个库的从库，还是会拿走的</li>
</ol>
<p>2019-01-09</p>
<p> JJ   1</p>
<p>请问老师，主库断电了，怎么把binlog传给从库同步数据，怎么使的SBM为0主从切换呢？2019-01-09</p>
<p> 作者回复</p>
<p>等应用完就认为是SBM&#x3D;0</p>
<p>如果不能接受主库有来不及传的，就使用semi-sync</p>
<p>2019-01-09</p>
<p>via   1</p>
<p>通过 binlog 输出到外部系统，比如 Hadoop 这类…</p>
<p>文中这个具体是可采用什么工具呢？2019-01-09</p>
<p> 作者回复</p>
<p>canal 可以了解下</p>
<p>2019-01-10</p>
<p>Sinyo   1</p>
<p>老师，在 binlog row模式下，insert 到表中一条记录，这条记录中某个字段不填，该字段在表中</p>
<p>有设置默认值，利用canal解析binlog出来，这个不填的字段会不存在；难道 binlog 只记录有插</p>
<p>入的字段数据，表字段的默认数据就不会记录么？mysql版本5.7.22 canal版本1.0.3</p>
<p>2019-01-09</p>
<p> 作者回复</p>
<p>不会啊</p>
<p>insert记录的时候肯定都记录的</p>
<p>你的默认值是什么？2019-01-10</p>
<p>700   0</p>
<p>老师请教下，MySQL 主从跨 IDC 的痛点是什么？同城 IDC 和异地 IDC 的痛点一样吗？怎么来</p>
<p>解决这些痛点？2019-01-22</p>
<p> 作者回复</p>
<p>跨IDC还好吧，跨城市或者跨洲才比较麻烦</p>
<p>其实主要还是延迟的问题，这个确实不好解决。业务开发的时候尽量是本城市访问，否则容易出现抖动</p>
<p>2019-01-23</p>
<p>强哥   0</p>
<p>今天跟公司的dba咨询了下，目前公司用的主备切换策略都是可用性优先，说是可靠性优先的</p>
<p>话，可能会引起雪崩，主要还是业务的并发高，这种场景您是怎么看呢？麻烦给下思路谢谢。2019-01-21</p>
<p> 作者回复</p>
<p>额 那这个是要跟业务好好讨论一下架构设计的，可以这么跟业务说，如果是由于问题导致整个</p>
<p>连不通，会不会雪崩？也就是说，可用性不可能100%，如果不可用就雪崩，表示架构需要优化。之后才谈策略选择（否则这样根本没得谈哈）</p>
<p>2019-01-21</p>
<p>cheriston   0</p>
<p>老师 seconds_behind_master&#x3D;0 也不能100%代表主库与从库之间没有延迟 吧 ?</p>
<p>2019-01-18</p>
<p> 作者回复</p>
<p>嗯嗯，看下28篇 </p>
<p>2019-01-18</p>
<p>悟空   0</p>
<p>老师文章末尾思考题部分，有点困惑求解答。循环复制我之前理解是B-&gt;A-&gt;A’-&gt;B这样的拓扑结构。而双M结构理解是A-&gt;A’-&gt;A，此时A是A’的主库和从库，B只能是A的从库。那么trx1在从库B上</p>
<p>的更新就不会传给A。文中是一种假设吗？还是我理解偏差了 ~</p>
<p>——–正文——–</p>
<p>trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后A 和 A’搭</p>
<p>建了双 M 结构，就会出现循环复制。2019-01-12</p>
<p> 作者回复</p>
<p>这个说的是迁移过程，</p>
<p>也就是说，一开始A是B的从库，后来迁移过程中，停止了A和B的主备关系，让A和A’互为主备</p>
<p>2019-01-12</p>
<p>崔伟协   0</p>
<p>发生主从切换的时候，主有的最新数据没同步到从，会出现这种情况吗，出现了会怎么样</p>
<p>2019-01-11</p>
<p> 作者回复</p>
<p>异常切换有可能的</p>
<p>要根据你的处理策略了，如果不能丢，有几个可选的</p>
<p>1.不切换（等这个库自己恢复起来）</p>
<ol start="2">
<li><p>使用semi-sync策略</p>
</li>
<li><p>启动后业务做数据对账（这个一般用得少，成本高）</p>
</li>
</ol>
<p>2019-01-11</p>
<p>任鹏斌   0</p>
<p>老师好发现我们系统中一条sql写法比较独特</p>
<p>SELECT</p>
<p>IF(ha.curricula_type &#x3D; ‘02’</p>
<p>AND ((cla.model_code IN (‘CM05004’ , ‘CM05001’)</p>
<p>AND cla.is_vip_video &#x3D; 1)</p>
<p>OR cla.model_code &#x3D; ‘CM05008’),</p>
<p>‘1’,</p>
<p>‘0’) AS ‘isUK’</p>
<p>FROM</p>
<p>h_curricula ha,</p>
<p>h_class cla</p>
<p>WHERE</p>
<p>ha.<code>code</code> &#x3D; ‘2’ </p>
<p>AND cla.<code>code</code> &#x3D;’2’ </p>
<p>使用查询分析器后所有列都无信息显示，只在Extra列显示，</p>
<p>Impossible WHERE noticed after reading const tables，不知道如何分析其执行计划。如果code列均为两个表的主键类型是varchar，想知道这种情况下是否会产生笛卡尔积？2019-01-11</p>
<p> 作者回复</p>
<p>Impossible WHERE noticed after reading const tables</p>
<p>这个语句是不是执行结果是空？2019-01-11</p>
<p>康磊   0</p>
<p>老师你好，现在一般采用读写分离，读的是从库，那么主从如果出现延迟的话，读库就读的不</p>
<p>是最新数据，对这种问题有什么好建议吗？2019-01-11</p>
<p> 作者回复</p>
<p>第28篇专门讲这个问题，敬请期待 </p>
<p>2019-01-11</p>
<p>cyberty   0</p>
<p>请问老师，如果备库连接主库之后，主库的系统时间修改了，备库同步的时候是否会自动修正</p>
<p>？2019-01-10</p>
<p> 作者回复</p>
<p>好问题，不会</p>
<p>2019-01-10</p>
<p>风萧雨瑟   0</p>
<p>老师问一下集群在开启并行复制的情况下：</p>
<p>主库参数：binlog_group_commit_sync_delay&#x3D;1000；binlog_group_commit_sync_no_delay_c</p>
<p>ount&#x3D;10</p>
<p>从库：slave_parallel_type&#x3D;LOGICAL_CLOCK；slave_parallel_workers&#x3D;8</p>
<p>MySQL：社区版5.7.20</p>
<p>在从库上查看slave status的时Seconds_Behind_Master总是显示落后10-15，在有大量更新的</p>
<p>情况下数据会一直增大，通过binlog来看的话Read_Master_Log_Pos 和Exec_Master_Log_Po</p>
<p>s相差总是在1000+，甚至变大的更大。但将slave_parallel_type更改回默认值DATABASE时，R</p>
<p>ead_Master_Log_Pos 和Exec_Master_Log_Pos相差很小，甚至可以相同。在不同的集群上开启并行复制都会出现相同的情况，但将slave_parallel_type更改回默认值DAT</p>
<p>ABASE时都要比LOGICAL_CLOCK延迟情况要好。更换5.7.24版本的情况下有同样的问题。如果有两台从库，机器配置相同其它参数一样。一台设置成slave_parallel_type&#x3D;DATABASE。而另一台设置成LOGICAL_CLOCK，不管是线上的表现还是通过sysbench压测来看，设置成L</p>
<p>OGICAL_CLOCK的从库延迟确实要比DATABASE大一些。这个情况从哪里排查一下？谢谢。2019-01-10</p>
<p> 作者回复</p>
<p>先看看26篇，然后再下面留下你的理解和新的疑问哈 </p>
<p>2019-01-10</p>
<p>xm   0</p>
<p>一般主从延时多少算是合理的？是秒级别吗？2019-01-10</p>
<p> 作者回复</p>
<p>一般大于1就不好 ^_^</p>
<p>2019-01-10</p>
<p>Chris   0</p>
<p>老师，咨询个问题，现在遇到一个问题，mysql数据库总是crash，重新启动服务又正常，然后</p>
<p>运行一段时间又会crash，报错如下InnoDB: Assertion failure in thread 6792 in file fil0fil.cc line 5</p>
<p>805</p>
<p>InnoDB: Failing assertion: err &#x3D;&#x3D; DB_SUCCESS</p>
<p>InnoDB: We intentionally generate a memory trap.</p>
<p>InnoDB: Submit a detailed bug report to <a target="_blank" rel="noopener" href="http://bugs.mysql.com/">http://bugs.mysql.com</a>.</p>
<p>InnoDB: If you get repeated assertion failures or crashes, even</p>
<p>InnoDB: immediately after the mysqld startup, there may be</p>
<p>InnoDB: corruption in the InnoDB tablespace. Please refer to</p>
<p>InnoDB: <a target="_blank" rel="noopener" href="http://dev.mysql.com/doc/refman/5.7/en/forcing-innodb-recovery.html">http://dev.mysql.com/doc/refman/5.7/en/forcing-innodb-recovery.html</a></p>
<p>InnoDB: about forcing recovery.</p>
<p>08:52:33 UTC - mysqld got exception 0x80000003 ;</p>
<p>This could be because you hit a bug. It is also possible that this binary</p>
<p>or one of the libraries it was linked against is corrupt, improperly built,</p>
<p>or misconfigured. This error can also be caused by malfunctioning hardware.</p>
<p>Attempting to collect some information that could help diagnose the problem.</p>
<p>As this is a crash and something is definitely wrong, the information</p>
<p>collection process might fail.</p>
<p>key_buffer_size&#x3D;8388608</p>
<p>read_buffer_size&#x3D;131072</p>
<p>max_used_connections&#x3D;60</p>
<p>max_threads&#x3D;151</p>
<p>thread_count&#x3D;45</p>
<p>connection_count&#x3D;45</p>
<p>It is possible that mysqld could use up to </p>
<p>key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads &#x3D; 68010 K bytes of mem</p>
<p>ory</p>
<p>Hope that’s ok; if not, decrease some variables in the equation.</p>
<p>Thread pointer: 0x0</p>
<p>Attempting backtrace. You can use the following information to find out</p>
<p>where mysqld died. If you see no messages after this, something went</p>
<p>terribly wrong…</p>
<p>13f9b9812 mysqld.exe!my_sigabrt_handler()[my_thr_init.c:449]</p>
<p>13fd5e349 mysqld.exe!raise()[winsig.c:587]</p>
<p>13fd5d240 mysqld.exe!abort()[abort.c:82]</p>
<p>13fab9b08 mysqld.exe!ut_dbg_assertion_failed()[ut0dbg.cc:67]</p>
<p>13fae06da mysqld.exe!fil_aio_wait()[fil0fil.cc:5807]</p>
<p>13fa7eb84 mysqld.exe!io_handler_thread()</p>
<p>The manual page at <a target="_blank" rel="noopener" href="http://dev.mysql.com/doc/mysql/en/crashing">http://dev.mysql.com/doc/mysql/en/crashing</a>.</p>
<p>2019-01-10</p>
<p> 作者回复</p>
<p>看着好像是磁盘问题了，你这个是5.7的哪个小版本？还有，尽量不要用windows系统哦 </p>
<p>2019-01-11</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/9b1409.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/9b1409.html" class="post-title-link" itemprop="url">mysql-MySQL是怎么保证主备一致的</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-29 06:14:07" itemprop="dateCreated datePublished" datetime="2019-11-29T06:14:07+08:00">2019-11-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>8.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>31 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>24 | MySQL是怎么保证主备一致的？2019-01-07 林晓斌</p>
<p>在前面的文章中，我不止一次地和你提到了binlog，大家知道binlog可以用来归档，也可以用来</p>
<p>做主备同步，但它的内容是什么样的呢？为什么备库执行了binlog就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。毫不夸张地说，MySQL能够成为现下最流行的开源数据库，binlog功不可没。在最开始，MySQL是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的</p>
<p>高可用架构，都直接依赖于binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是</p>
<p>从最基本的一主一备演化过来的。今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的</p>
<p>角度，来借鉴这些设计思想。MySQL主备的基本原理</p>
<p>如图1所示就是基本的主备切换流程。图 1 MySQL主备切换流程</p>
<p>在状态1中，客户端的读写都直接访问节点A，而节点B是A的备库，只是将A的更新都同步过</p>
<p>来，到本地执行。这样可以保持节点B和A的数据是相同的。当需要切换的时候，就切成状态2。这时候客户端读写访问的都是节点B，而节点A是B的备库。在状态1中，虽然节点B没有被直接访问，但是我依然建议你把节点B（也就是备库）设置成只读</p>
<p>（readonly）模式。这样做，有以下几个考虑：</p>
<ol>
<li><p>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；</p>
</li>
<li><p>防止切换逻辑有bug，比如切换过程中出现双写，造成主备不一致；</p>
</li>
<li><p>可以用readonly状态，来判断节点的角色。你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？这个问题，你不用担心。因为readonly设置对超级(super)权限用户是无效的，而用于同步更新的</p>
</li>
</ol>
<p>线程，就拥有超级权限。接下来，我们再看看节点A到B这条线的内部流程是什么样的。图2中画出的就是一个update</p>
<p>语句在节点A执行，然后同步到节点B的完整流程图。图2 主备流程图</p>
<p>图2中，包含了我在上一篇文章中讲到的binlog和redo log的写入机制相关的内容，可以看到：主</p>
<p>库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写binlog。备库B跟主库A之间维持了一个长连接。主库A内部有一个线程，专门用于服务备库B的这个长连</p>
<p>接。一个事务日志同步的完整过程是这样的：</p>
<ol>
<li>在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个</li>
</ol>
<p>位置开始请求binlog，这个位置包含文件名和日志偏移量。2. 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和</p>
<p>sql_thread。其中io_thread负责与主库建立连接。3. 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。4. 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。5. sql_thread读取中转日志，解析出日志里的命令，并执行。这里需要说明，后来由于多线程复制方案的引入，sql_thread演化成为了多个线程，跟我们今天</p>
<p>要介绍的原理没有直接关系，暂且不展开。分析完了这个长连接的逻辑，我们再来看一个问题：binlog里面到底是什么内容，为什么备库拿</p>
<p>过去可以直接执行。binlog的三种格式对比</p>
<p>我在第15篇答疑文章中，和你提到过binlog有两种格式，一种是statement，一种是row。可能你</p>
<p>在其他资料上还会看到有第三种格式，叫作mixed，其实它就是前两种格式的混合。为了便于描述binlog的这三种格式间的区别，我创建了一个表，并初始化几行数据。如果要在表中删除一行数据的话，我们来看看这个delete语句的binlog是怎么记录的。注意，下面这个语句包含注释，如果你用MySQL客户端来做这个实验的话，要记得加-c参数，否</p>
<p>则客户端会自动去掉注释。当binlog_format&#x3D;statement时，binlog里面记录的就是SQL语句的原文。你可以用</p>
<p>mysql&gt; CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;a  ̀int(11) DEFAULT NULL,</p>
<p>  t̀_modified  ̀timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  KEY &#96;a  ̀(̀ a )̀,</p>
<p>  KEY t̀_modified (̀̀ t_modified )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t values(1,1,’2018-11-13’);</p>
<p>insert into t values(2,2,’2018-11-12’);</p>
<p>insert into t values(3,3,’2018-11-11’);</p>
<p>insert into t values(4,4,’2018-11-10’);</p>
<p>insert into t values(5,5,’2018-11-09’);</p>
<p>mysql&gt; delete from t &#x2F;<em>comment</em>&#x2F;  where a&gt;&#x3D;4 and t_modified&lt;&#x3D;’2018-11-10’ limit 1;</p>
<p>mysql&gt; show binlog events in ‘master.000001’;</p>
<p>命令看binlog中的内容。图3 statement格式binlog 示例</p>
<p>现在，我们来看一下图3的输出结果。第一行SET @@SESSION.GTID_NEXT&#x3D;’ANONYMOUS’你可以先忽略，后面文章我们会在</p>
<p>介绍主备切换的时候再提到；</p>
<p>第二行是一个BEGIN，跟第四行的commit对应，表示中间是一个事务；</p>
<p>第三行就是真实执行的语句了。可以看到，在真实执行的delete命令之前，还有一个“use</p>
<p>‘test’”命令。这条命令不是我们主动执行的，而是MySQL根据当前要操作的表所在的数据库，</p>
<p>自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库</p>
<p>里，都能够正确地更新到test库的表t。use ‘test’命令之后的delete 语句，就是我们输入的SQL原文了。可以看到，binlog“忠实”地记</p>
<p>录了SQL命令，甚至连注释也一并记录了。最后一行是一个COMMIT。你可以看到里面写着xid&#x3D;61。你还记得这个XID是做什么用的吗？如果记忆模糊了，可以再回顾一下第15篇文章中的相关内容。为了说明statement 和 row格式的区别，我们来看一下这条delete命令的执行效果图：</p>
<p>图4 delete执行warnings</p>
<p>可以看到，运行这条delete命令产生了一个warning，原因是当前binlog设置的是statement格</p>
<p>式，并且语句中有limit，所以这个命令可能是unsafe的。为什么这么说呢？这是因为delete 带limit，很可能会出现主备数据不一致的情况。比如上面这个</p>
<p>例子：</p>
<ol>
<li>如果delete语句使用的是索引a，那么会根据索引a找到第一个满足条件的行，也就是说删除</li>
</ol>
<p>的是a&#x3D;4这一行；</p>
<ol start="2">
<li>但如果使用的是索引t_modified，那么删除的就是 t_modified&#x3D;’2018-11-09’也就是a&#x3D;5这一</li>
</ol>
<p>行。由于statement格式下，记录到binlog里的是语句原文，因此可能会出现这样一种情况：在主库</p>
<p>执行这条SQL语句的时候，用的是索引a；而在备库执行这条SQL语句的时候，却使用了索引</p>
<p>t_modified。因此，MySQL认为这样写是有风险的。那么，如果我把binlog的格式改为binlog_format&#x3D;‘row’， 是不是就没有这个问题了呢？我们先来</p>
<p>看看这时候binog中的内容吧。图5 row格式binlog 示例</p>
<p>可以看到，与statement格式的binlog相比，前后的BEGIN和COMMIT是一样的。但是，row格式</p>
<p>的binlog里没有了SQL语句的原文，而是替换成了两个event：Table_map和Delete_rows。1. Table_map event，用于说明接下来要操作的表是test库的表t;</p>
<ol start="2">
<li>Delete_rows event，用于定义删除的行为。其实，我们通过图5是看不到详细信息的，还需要借助mysqlbinlog工具，用下面这个命令解析和</li>
</ol>
<p>查看binlog中的内容。因为图5中的信息显示，这个事务的binlog是从8900这个位置开始的，所以</p>
<p>可以用start-position参数来指定从这个位置的日志开始解析。mysqlbinlog  -vv data&#x2F;master.000001 –start-position&#x3D;8900;</p>
<p>图6 row格式binlog 示例的详细信息</p>
<p>从这个图中，我们可以看到以下几个信息：</p>
<p>server id 1，表示这个事务是在server_id&#x3D;1的这个库上执行的。每个event都有CRC32的值，这是因为我把参数binlog_checksum设置成了CRC32。Table_map event跟在图5中看到的相同，显示了接下来要打开的表，map到数字226。现在我</p>
<p>们这条SQL语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的Table_map</p>
<p>event、都会map到一个单独的数字，用于区分对不同表的操作。我们在mysqlbinlog的命令中，使用了-vv参数是为了把内容都解析出来，所以从结果里面可以</p>
<p>看到各个字段的值（比如，@1&#x3D;4、 @2&#x3D;4这些值）。binlog_row_image的默认配置是FULL，因此Delete_event里面，包含了删掉的行的所有字段</p>
<p>的值。如果把binlog_row_image设置为MINIMAL，则只会记录必要的信息，在这个例子里，</p>
<p>就是只会记录id&#x3D;4这个信息。最后的Xid event，用于表示事务被正确地提交了。你可以看到，当binlog_format使用row格式的时候，binlog里面记录了真实删除行的主键id，这样</p>
<p>binlog传到备库去的时候，就肯定会删除id&#x3D;4的行，不会有主备删除不同行的问题。为什么会有mixed格式的binlog？基于上面的信息，我们来讨论一个问题：为什么会有mixed这种binlog格式的存在场景？推论</p>
<p>过程是这样的：</p>
<p>因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。但row格式的缺点是，很占空间。比如你用一个delete语句删掉10万行数据，用statement的</p>
<p>话就是一个SQL语句被记录到binlog中，占用几十个字节的空间。但如果用row格式的binlog，</p>
<p>就要把这10万条记录都写到binlog中。这样做，不仅会占用更大的空间，同时写binlog也要耗</p>
<p>费IO资源，影响执行速度。所以，MySQL就取了个折中方案，也就是有了mixed格式的binlog。mixed格式的意思</p>
<p>是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，</p>
<p>否则就用statement格式。也就是说，mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险。因此，如果你的线上MySQL设置的binlog格式是statement的话，那基本上就可以认为这是一个</p>
<p>不合理的设置。你至少应该把binlog的格式设置为mixed。比如我们这个例子，设置为mixed后，就会记录为row格式；而如果执行的语句去掉limit 1，就会</p>
<p>记录为statement格式。当然我要说的是，现在越来越多的场景要求把MySQL的binlog格式设置成row。这么做的理由有</p>
<p>很多，我来给你举一个可以直接看出来的好处：恢复数据。接下来，我们就分别从delete、insert和update这三种SQL语句的角度，来看看数据恢复的问</p>
<p>题。通过图6你可以看出来，即使我执行的是delete语句，row格式的binlog也会把被删掉的行的整行</p>
<p>信息保存起来。所以，如果你在执行完一条delete语句以后，发现删错数据了，可以直接把</p>
<p>binlog中记录的delete语句转成insert，把被错删的数据插入回去就可以恢复了。如果你是执行错了insert语句呢？那就更直接了。row格式下，insert语句的binlog里会记录所有的</p>
<p>字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把insert语句转成</p>
<p>delete语句，删除掉这被误插入的一行数据就可以了。如果执行的是update语句的话，binlog里面会记录修改前整行的数据和修改后的整行数据。所</p>
<p>以，如果你误执行了update语句的话，只需要把这个event前后的两行信息对调一下，再去数据</p>
<p>库里面执行，就能恢复这个更新操作了。其实，由delete、insert或者update语句导致的数据操作错误，需要恢复到操作之前状态的情</p>
<p>况，也时有发生。MariaDB的Flashback工具就是基于上面介绍的原理来回滚数据的。虽然mixed格式的binlog现在已经用得不多了，但这里我还是要再借用一下mixed格式来说明一个</p>
<p>问题，来看一下这条SQL语句：</p>
<p>如果我们把binlog格式设置为mixed，你觉得MySQL会把它记录为row格式还是statement格式</p>
<p>呢？先不要着急说结果，我们一起来看一下这条语句执行的效果。图7 mixed格式和now()</p>
<p>可以看到，MySQL用的居然是statement格式。你一定会奇怪，如果这个binlog过了1分钟才传给</p>
<p>备库的话，那主备的数据不就不一致了吗？接下来，我们再用mysqlbinlog工具来看看：</p>
<p>mysql&gt; insert into t values(10,10, now());</p>
<p>图8 TIMESTAMP 命令</p>
<p>从图中的结果可以看到，原来binlog在记录event的时候，多记了一条命令：SET</p>
<p>TIMESTAMP&#x3D;1546103491。它用 SET TIMESTAMP命令约定了接下来的now()函数的返回时</p>
<p>间。因此，不论这个binlog是1分钟之后被备库执行，还是3天后用来恢复这个库的备份，这个insert</p>
<p>语句插入的行，值都是固定的。也就是说，通过这条SET TIMESTAMP命令，MySQL就确保了</p>
<p>主备数据的一致性。我之前看过有人在重放binlog数据的时候，是这么做的：用mysqlbinlog解析出日志，然后把里面</p>
<p>的statement语句直接拷贝出来执行。你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执</p>
<p>行的结果很可能是错误的。所以，用binlog来恢复数据的标准做法是，用 mysqlbinlog工具解析出来，然后把解析结果整个发</p>
<p>给MySQL执行。类似下面的命令：</p>
<p>这个命令的意思是，将 master.000001 文件里面从第2738字节到第2973字节中间这段内容解析</p>
<p>出来，放到MySQL去执行。循环复制问题</p>
<p>通过上面对MySQL中binlog基本内容的理解，你现在可以知道，binlog的特性确保了在备库执行</p>
<p>相同的binlog，可以得到与主库相同的状态。因此，我们可以认为正常情况下主备的数据是一致的。也就是说，图1中A、B两个节点的内容是</p>
<p>一致的。其实，图1中我画的是M-S结构，但实际生产上使用比较多的是双M结构，也就是图9所</p>
<p>示的主备切换流程。mysqlbinlog master.000001  –start-position&#x3D;2738 –stop-position&#x3D;2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;</p>
<p>图 9 MySQL主备切换流程–双M结构</p>
<p>对比图9和图1，你可以发现，双M结构和M-S结构，其实区别只是多了一条线，即：节点A和B</p>
<p>之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。但是，双M结构还有一个问题需要解决。业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新</p>
<p>语句后也会生成binlog。（我建议你把参数log_slave_updates设置为on，表示备库执行relay log</p>
<p>后生成binlog）。那么，如果节点A同时是节点B的备库，相当于又把节点B新生成的binlog拿过来执行了一次，然</p>
<p>后节点A和B间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？从上面的图6中可以看到，MySQL在binlog中记录了这个命令第一次执行时所在实例的server</p>
<p>id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：</p>
<ol>
<li><p>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系；</p>
</li>
<li><p>一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog；</p>
</li>
<li><p>每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这</p>
</li>
</ol>
<p>个日志是自己生成的，就直接丢弃这个日志。按照这个逻辑，如果我们设置了双M结构，日志的执行流就会变成这样：</p>
<ol>
<li><p>从节点A更新的事务，binlog里面记的都是A的server id；</p>
</li>
<li><p>传到节点B执行一次以后，节点B生成的binlog 的server id也是A的server id；</p>
</li>
<li><p>再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循</p>
</li>
</ol>
<p>环在这里就断掉了。小结</p>
<p>今天这篇文章，我给你介绍了MySQL binlog的格式和一些基本机制，是后面我要介绍的读写分</p>
<p>离等系列文章的背景知识，希望你可以认真消化理解。binlog在MySQL的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有MySQL高可用</p>
<p>方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication等相对复杂的方</p>
<p>案。我也跟你介绍了MySQL不同格式binlog的优缺点，和设计者的思考。希望你在做系统开发时候，</p>
<p>也能借鉴这些设计思想。最后，我给你留下一个思考题吧。说到循环复制问题的时候，我们说MySQL通过判断server id的方式，断掉死循环。但是，这个机</p>
<p>制其实并不完备，在某些场景下，还是有可能出现死循环。你能构造出一个这样的场景吗？又应该怎么解决呢？你可以把你的设计和分析写在评论区，我会在下一篇文章跟你讨论这个问题。感谢你的收听，也</p>
<p>欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期我留给你的问题是，你在什么时候会把线上生产库设置成“非双1”。我目前知道的场景，有</p>
<p>以下这些：</p>
<ol>
<li>业务高峰期。一般如果有预知的高峰期，DBA会有预案，把主库设置成“非双1”。2. 备库延迟，为了让备库尽快赶上主库。@永恒记忆和@Second Sight提到了这个场景。3. 用备份恢复主库的副本，应用binlog的过程，这个跟上一种场景类似。4. 批量导入数据的时候。一般情况下，把生产库改成“非双1”配置，是设置innodb_flush_logs_at_trx_commit&#x3D;2、</li>
</ol>
<p>sync_binlog&#x3D;1000。评论区留言点赞板：</p>
<p>Sinyo   2</p>
<p>@way 同学提到了一个有趣的现象，由于从库设置了 binlog_group_commit_sync_delay和</p>
<p>binlog_group_commit_sync_no_delay_count导致一直延迟的情况。我们在主库设置这两个参</p>
<p>数，是为了减少binlog的写盘压力。备库这么设置，尤其在“快要追上”的时候，就反而会受这</p>
<p>两个参数的拖累。一般追主备就用“非双1”（追上记得改回来）。@一大只 同学验证了在sync_binlog&#x3D;0的情况下，设置sync_delay和sync_no_delay_count的</p>
<p>现象，点赞这种发现边界的意识和手动验证的好习惯。是这样的：sync_delay和</p>
<p>sync_no_delay_count的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入</p>
<p>sync_binlog阶段。这时候如果判断sync_binlog&#x3D;0，就直接跳过，还是不调fsync。@锅子 同学提到，设置sync_binlog&#x3D;0的时候，还是可以看到binlog文件马上做了修改。这个</p>
<p>是对的，我们说“写到了page cache”，就是文件系统的page cache。而你用ls命令看到的就是</p>
<p>文件系统返回的结果。精选留言</p>
<p>主库 A 从本地读取 binlog，发给从库 B；</p>
<p>老师，请问这里的本地是指文件系统的 page cache还是disk呢？2019-01-21</p>
<p> 作者回复</p>
<p>好问题，</p>
<p>是这样的，对于A的线程来说，就是“读文件”，</p>
<ol>
<li><p>如果这个文件现在还在 page cache中，那就最好了，直接读走；</p>
</li>
<li><p>如果不在page cache里，就只好去磁盘读</p>
</li>
</ol>
<p>这个行为是文件系统控制的，MySQL只是执行“读文件”这个操作</p>
<p>2019-01-21</p>
<p>Leon    1</p>
<p>老师，我想问下双M架构下，主从复制，是不是一方判断自己的数据比对方少就从对方复制，</p>
<p>判断依据是什么</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>好问题。一开始创建主备关系的时候， 是由备库指定的。比如基于位点的主备关系，备库说“我要从binlog文件A的位置P”开始同步， 主库就从这个指定</p>
<p>的位置开始往后发。而主备复制关系搭建完成以后，是主库来决定“要发数据给备库”的。所以主库有生成新的日志，就会发给备库。2019-01-25</p>
<p>观弈道人   6</p>
<p>老师你好，问个备份问题，假如周日23点做了备份，周二20点需要恢复数据，那么在用binlog</p>
<p>恢复时，如何恰好定位到周日23点的binlog,谢谢。2019-01-07</p>
<p> 作者回复</p>
<p>Mysqlbinlog有个参数—stop-datetime</p>
<p>2019-01-07</p>
<p>堕落天使   3</p>
<p>老师，您好，问一个关于change buffer的问题。对于insert语句来说，change buffer的优化主要在非唯一的二级索引上，因为主键是唯一索引，</p>
<p>插入必须要判断是否存在。那么对于update语句呢？如下（假设c有非唯一索引，id是主键，d没有索引）：</p>
<p>update t set d&#x3D;2 where c&#x3D;10;</p>
<p>原先以为：从索引c取出id之后，不会回表，也不会把修改行的数据读入内存，而是直接在chan</p>
<p>ge buffer中记录一下。但看了今天得内容之后又迷糊了，因为如果不把修改行的数据读入内存</p>
<p>，它又怎么把旧数据写入binlog中呢？所以我想问的就是，上面的sql语句会不会把修改行的内容也读进内存？如果读进内存，那读进</p>
<p>内存的这一步难道就为了写binlog吗？如果不读进内存，那binlog中的旧数据又是怎么来的呢？还有delete语句也同理。2019-01-07</p>
<p> 作者回复</p>
<p>修改的行要读入内存呀</p>
<p>写binlog只需要主键索引上的值</p>
<p>你这个语句的话，如果字段c d上都有索引，那么c用不上chsnge buffer,</p>
<p>D可能可以同上</p>
<p>2019-01-07</p>
<p>hua168   2</p>
<p>大神，我前些天去面试，面试官问了一题:</p>
<p>mysql做主从，一段时间后发现从库在高峰期会发生一两条条数据丢失（不记得是查询行空白</p>
<p>还是查询不到了），主从正常，怎么判断？1.我问他是不是所以从库都是一样，他说不一样</p>
<p>2.我说低峰期重做新的从库观察，查看日志有没有报错？他好像不满意这个答案。二、他还问主库挂了怎么办？1. mysql主从+keepalived&#x2F;heartbeat</p>
<p>有脑裂，还是有前面丢数据问题</p>
<ol start="2">
<li>用MMM或HMA之类</li>
</ol>
<p>3.用ZK之类</p>
<p>三、写的压力大怎么办？我回答，分库，分表</p>
<p>感觉整天他都不怎么满意，果然没让我复试了，我郁闷呀，我就面试运维的，问数据这么详细</p>
<p>。 </p>
<p>大神，能说下我哪里有问题吗？现在我都想不明白 </p>
<p>2019-01-08</p>
<p> 作者回复</p>
<p>运维现在要求也挺高的</p>
<p>第一个问题其实我也没看懂，“高峰期丢数据”是指主备延迟查不到数据，还是真的丢了，得先</p>
<p>问清楚下</p>
<p>不过你回答的第二点不太好，低峰期重做这个大家都知道要这么做，而且只是修复动作，没办</p>
<p>法用来定位原因，面试官是要问你分析问题的方法（方向错误）</p>
<p>重搭从库错误日志里面什么都没有的（这个比较可惜，暴露了对字节不够了解，一般不了解的</p>
<p>方法在面试的时候是不如不说的）</p>
<p>第二个问题三点都是你回答的吗？那还算回答得可以的，但是不能只讲名词，要找个你熟悉细</p>
<p>节的方案展开一下</p>
<p>三方向也是对的</p>
<p>我估计就是第一个问题减分比较厉害</p>
<p>2019-01-08</p>
<p>HuaMax   2</p>
<p>课后题。如果在同步的过程中修改了server id，那用原server id 生成的log被两个M认为都不是</p>
<p>自己的而被循环执行，不知这种情况会不会发生</p>
<p>2019-01-07</p>
<p> 作者回复</p>
<p>是的，会</p>
<p>2019-01-07</p>
<p>风二中   1</p>
<p>在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使</p>
<p>用了索引 t_modified</p>
<p>老师，您好，这里索引选择不一样，是因为前面提到的mysql 会选错索引吗？这种情况应该发</p>
<p>生比较少吧，这里应该都会选择索引a吧，还是说这里只是一个事例，还有更复杂的情况</p>
<p>2019-01-12</p>
<p> 作者回复</p>
<p>对，只是一个举例的</p>
<p>2019-01-12</p>
<p>夜空中最亮的星（华仔）   1</p>
<p>级联复制，3个数据库，首尾相连，应会出现死循环</p>
<p>2019-01-08</p>
<p> 作者回复</p>
<p>不会哦，1给2，2给3，3给1，1就放弃了</p>
<p>不过引入第三个节点的思路是对的哈 </p>
<p>2019-01-08</p>
<p>changshan   1</p>
<p>老师好，mixed是row和statement的优点整合折中方案，这应该是好多系统设计理念吧？那么</p>
<p>问题一：mixed既然能判断是什么时候使用row，什么时候使用statement，那么为什么好多推</p>
<p>荐都是使用row而且不是使用mixed呢？是因为mixed这种模式下的自动选择转换不准确可能会</p>
<p>出现主从问题吗？问题二：当使用mixed模式情况下，mysql内部是怎么判断的呢？比如有limit</p>
<p>语句就会选择记录row格式，有now()函数还是同样会记录statement格式，mysql只是简单的某</p>
<p>些特定场景下会使用记录row格式吗？谢谢。2019-01-07</p>
<p> 作者回复</p>
<ol>
<li><p>就是我们文中后面说的那些原因，要用这些binlog的内容去做别的事情 </p>
</li>
<li><p>对，固定模式下的。好问题，我去拉不下最新版本代码看下规则</p>
</li>
</ol>
<p>2019-01-07</p>
<p>柚子   1</p>
<p>大佬您好，文中说现在越来越多的使用row方式的binlog，那么只能选择接受写入慢和占用空间</p>
<p>大的弊端么？2019-01-07</p>
<p> 作者回复</p>
<p>是的，当然还有minimal可选，会好些 </p>
<p>2019-01-07</p>
<p>汪炜   0</p>
<p>老师，问个问题，希望能被回答：</p>
<p>mmysql不是双一设置的时候，破坏了二阶段提交，事务已提交，redo没有及时刷盘，binlog刷</p>
<p>盘了，这种情况，mysql是怎么恢复的，这个事务到底算不算提交？2019-01-23</p>
<p> 作者回复</p>
<p>如果”redo没有及时刷盘，binlog刷盘了”之后瞬间数据库所在主机掉电，</p>
<p>主机重启，MySQL重启以后，这个事务会丢失；这里确实会引起日志和数据不一致，</p>
<p>这个就是我们说要默认设置为双1的原因之一哈</p>
<p>2019-01-23</p>
<p>Mackie .Weng   0</p>
<p>老师，你的课真好， 你讲的都是生产实际用到的，点赞~</p>
<p>不过近期有点苦恼，要请教一下近期遇到的事</p>
<p>场景：</p>
<p>SSD硬盘，我们数据一天一备份，想通过昨天凌晨备份+binlog恢复到最新数据，导出的binlog</p>
<p>为2G，然后发现导入binlog花费了4，5小时，看了下binlog日志里面有很多这种信息</p>
<h1 id="at-2492"><a href="#at-2492" class="headerlink" title="at 2492"></a>at 2492</h1><p>#190108 17:08:38 server id 2 end_log_pos 2601 CRC32 0x8b0598ec Query thread_id&#x3D;1227779</p>
<p>5 exec_time&#x3D;0 error_code&#x3D;0</p>
<p>SET TIMESTAMP&#x3D;1546938518&#x2F;<em>!</em>&#x2F;;</p>
<p>BEGIN</p>
<p>&#x2F;<em>!</em>&#x2F;;</p>
<h1 id="at-2601"><a href="#at-2601" class="headerlink" title="at 2601"></a>at 2601</h1><h1 id="at-2633"><a href="#at-2633" class="headerlink" title="at 2633"></a>at 2633</h1><h1 id="at-2919"><a href="#at-2919" class="headerlink" title="at 2919"></a>at 2919</h1><p>#190108 17:08:38 server id 2 end_log_pos 2950 CRC32 0x13806369 Xid &#x3D; 1924155105</p>
<p>COMMIT&#x2F;<em>!</em>&#x2F;;</p>
<p>问题：</p>
<p>1、在导出binlog为2G而且看了下里面很多这种事务，这是什么东西，有什么用吗</p>
<p>2、这种事务在导出binlog的时候可以不记录吗，然后来提高恢复数据的速度？3、如果这是正常的情况，有无推荐更好的数据恢复方案或者工具</p>
<p>感谢老师</p>
<p>2019-01-14</p>
<p> 作者回复</p>
<ol>
<li><p>有用，最好保留这些信息一起执行；</p>
</li>
<li><p>提升不了多少速度的，花时间主要还是在更新数据的那些日志上，那些日志又不能去掉的：</p>
</li>
</ol>
<p>）</p>
<ol start="3">
<li>这个方案是串行恢复。你可以把全量恢复出来的库，接成线上一个从库的备库，开并行复制</li>
</ol>
<p>，</p>
<p>2019-01-14</p>
<p>秋一匹   0</p>
<p>老师，您好。我这慢了一步。。。学习晚了点。我这之前碰到了个问题，有一段时间主从复制</p>
<p>延迟比较厉害，达到5s左右吧，一般都是1～2秒吧。首先排除不是网络原因。想问下还有哪些</p>
<p>因素会影响主从复制呢？2019-01-10</p>
<p> 作者回复</p>
<p>还是要给一下更具体的信息</p>
<p>比如主库的tps</p>
<p>备库的跟复制相关的配置等信息</p>
<p>2019-01-10</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师你好：</p>
<p>有一个疑惑，多条语句同时在commit阶段过程中，如果发生写入binlog和写入redolog的顺序不</p>
<p>一致的情况。主从备份的时候，从库是不是会导致数据不一致呀？2019-01-10</p>
<p>未知   0</p>
<p>老师在讲row模式的数据恢复时，感觉insert，update，delete的数据格式和undo log的差不多。之前文章一直说redo和binlog，老师抽空也讲下undo和回滚段的知识。2019-01-10</p>
<p> 作者回复</p>
<p>Undo前面大致有说过了，你要了解undo的什么内容呢</p>
<p>2019-01-10</p>
<p>光   0</p>
<p>林老师今天遇到个问题就是主从同步延迟，查到主从状态中出现：Slave_SQL_Running_State: </p>
<p>Waiting for Slave Workers to free pending events。不知道这个是否会引起延迟。查了些资料说</p>
<p>得都不是很明白。老师是否可以简短解答下。以及这种延迟如何避免。2019-01-09</p>
<p> 作者回复</p>
<p>这个的意思是， 现在工作线程里面等待的队列太多，都已经超过上限了，要等工作线程消化掉</p>
<p>一些事务再分</p>
<p>简单说，就是备库的应用日志的队列太慢了。。2019-01-10</p>
<p>梁中华   0</p>
<p>我有一个比较极端一点的HA问题，假设主库的binlog刚写成功还未来得及把binlog同步到从库，</p>
<p>主库就掉电了，这时候从库的数据会不完整吗？第二个问题，原主库重启加入集群后，那条没有传出去的binlog会如何处理？2019-01-09</p>
<p>不迷失   0</p>
<p>请教一下，生产环境能不能使用正常使用表连接？要注意哪些地方？DBA总是说不建议用，还</p>
<p>催促我将使用了表连接的地方改造，但也说不出个所以然。目前在两个百万级数据的表中有用</p>
<p>到内连接，并没有觉得有什么问题</p>
<p>2019-01-08</p>
<p> 作者回复</p>
<p>索引使用正确，不要出现全表扫描，其实OK的</p>
<p>2019-01-08</p>
<p>hua168   0</p>
<p>这样，我是想增加一些经验，怕后面试又遇到，想问一下大神分析思路，这种问题没经验回答</p>
<p>。我就差点回答用阿里云的DRDS了 </p>
<p>现在开源的mysql中间件生存环境中用什么比较多呀？mycat还是网易的cetus？海量存储阿里云有OSS，有没有对应的开源软件呀？用于生存环境的，没有接触过，想问下，</p>
<p>搞下实验后再去找工作。 </p>
<p>2019-01-08</p>
<p> 作者回复</p>
<p>中间件作为练手这些都可以的</p>
<p>你搜“开源分布式存储系统”</p>
<p>2019-01-08</p>
<p>React   0</p>
<p>老师好，文章前面说主从最好从机设置readonly.那么在双主的情况(互为主备)下，设置不同的</p>
<p>自增值是否就可以不用设置只读了？且此时复制是否可以跳过主键冲突，因为自增值不同？2019-01-08</p>
<p> 作者回复</p>
<p>如果自增值严格控制了，也没必要设置跳过主键冲突了对吧（反正不冲突）</p>
<p>除非你的业务就是设计好支持多点写入，否则还是把不写入的都设置上readonly吧</p>
<p>2019-01-08</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/4c5bdfaf.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/4c5bdfaf.html" class="post-title-link" itemprop="url">mysql-MySQL是怎么保证数据不丢的</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-28 06:14:46" itemprop="dateCreated datePublished" datetime="2019-11-28T06:14:46+08:00">2019-11-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>27 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>23 | MySQL是怎么保证数据不丢的？2019-01-04 林晓斌</p>
<p>今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL是怎</p>
<p>么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。在专栏前面文章和答疑篇中，我都着重介绍了WAL机制（你可以再回顾下第2篇、第9篇、第12</p>
<p>篇和第15篇文章中的相关内容），得到的结论是：只要redo log和binlog保证持久化到磁盘，就</p>
<p>能确保MySQL异常重启后，数据可以恢复。评论区有同学又继续追问，redo log的写入流程是怎么样的，如何保证redo log真实地写入了磁</p>
<p>盘。那么今天，我们就再一起看看MySQL写入binlog和redo log的流程。binlog的写入机制</p>
<p>其实，binlog的写入逻辑比较简单：事务执行过程中，先把日志写到binlog cache，事务提交的</p>
<p>时候，再把binlog cache写到binlog文件中。一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到</p>
<p>了binlog cache的保存问题。系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程</p>
<p>内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。状</p>
<p>态如图1所示。图1 binlog写盘状态</p>
<p>可以看到，每个线程有自己binlog cache，但是共用同一份binlog文件。图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁</p>
<p>盘，所以速度比较快。图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的</p>
<p>IOPS。write 和fsync的时机，是由参数sync_binlog控制的：</p>
<ol>
<li><p>sync_binlog&#x3D;0的时候，表示每次提交事务都只write，不fsync；</p>
</li>
<li><p>sync_binlog&#x3D;1的时候，表示每次提交事务都会执行fsync；</p>
</li>
<li><p>sync_binlog&#x3D;N(N&gt;1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。因此，在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际</p>
</li>
</ol>
<p>的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其</p>
<p>设置为100~1000中的某个数值。但是，将sync_binlog设置为N，对应的风险是：如果主机发生异常重启，会丢失最近N个事务的</p>
<p>binlog日志。redo log的写入机制</p>
<p>接下来，我们再说说redo log的写入机制。在专栏的第15篇答疑文章中，我给你介绍了redo log buffer。事务在执行过程中，生成的redo</p>
<p>log是要先写到redo log buffer的。然后就有同学问了，redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢？答案是，不需要。如果事务执行期间MySQL发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这</p>
<p>时日志丢了也不会有损失。那么，另外一个问题是，事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久</p>
<p>化到磁盘呢？答案是，确实会有。这个问题，要从redo log可能存在的三种状态说起。这三种状态，对应的就是图2 中的三个颜色</p>
<p>块。图2 MySQL redo log存储状态</p>
<p>这三种状态分别是：</p>
<ol>
<li><p>存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分；</p>
</li>
<li><p>写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面，也就</p>
</li>
</ol>
<p>是图中的黄色部分；</p>
<ol start="3">
<li>持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。日志写到redo log buffer是很快的，wirte到page cache也差不多，但是持久化到磁盘的速度就慢</li>
</ol>
<p>多了。为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种</p>
<p>可能取值：</p>
<ol>
<li><p>设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中;</p>
</li>
<li><p>设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘；</p>
</li>
<li><p>设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的</p>
</li>
</ol>
<p>page cache，然后调用fsync持久化到磁盘。注意，事务执行中间过程的redo log也是直接写在redo log buffer中的，这些redo log也会被后台</p>
<p>线程一起持久化到磁盘。也就是说，一个没有提交的事务的redo log，也是可能已经持久化到磁</p>
<p>盘的。实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo</p>
<p>log写入到磁盘中。1. 一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，</p>
<p>后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是write，而</p>
<p>没有调用fsync，也就是只留在了文件系统的page cache。2. 另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁</p>
<p>盘。假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程</p>
<p>的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻</p>
<p>辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候，就会带上事务A在redo</p>
<p>log buffer里的日志一起持久化到磁盘。这里需要说明的是，我们介绍两阶段提交的时候说过，时序上redo log先prepare， 再写binlog，</p>
<p>最后再把redo log commit。如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次，</p>
<p>因为有一个崩溃恢复逻辑是要依赖于prepare 的redo log，再加上binlog来恢复的。（如果你印象</p>
<p>有点儿模糊了，可以再回顾下第15篇文章中的相关内容）。每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB就认为redo log在commit的时候就</p>
<p>不需要fsync了，只会write到文件系统的page cache中就够了。通常我们说MySQL的“双1”配置，指的就是sync_binlog和innodb_flush_log_at_trx_commit都设</p>
<p>置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是redo log（prepare 阶</p>
<p>段），一次是binlog。这时候，你可能有一个疑问，这意味着我从MySQL看到的TPS是每秒两万的话，每秒就会写四</p>
<p>万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的TPS？解释这个问题，就要用到组提交（group commit）机制了。这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN是单调</p>
<p>递增的，用来对应redo log的一个个写入点。每次写入长度为length的redo log， LSN的值就会加</p>
<p>上length。LSN也会写到InnoDB的数据页中，来确保数据页不会被多次执行重复的redo log。关于LSN和</p>
<p>redo log、checkpoint的关系，我会在后面的文章中详细展开。如图3所示，是三个并发事务(trx1, trx2, trx3)在prepare 阶段，都写完redo log buffer，持久化到</p>
<p>磁盘的过程，对应的LSN分别是50、120 和160。图3 redo log 组提交</p>
<p>从图中可以看到，</p>
<ol>
<li><p>trx1是第一个到达的，会被选为这组的 leader；</p>
</li>
<li><p>等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160；</p>
</li>
<li><p>trx1去写盘的时候，带的就是LSN&#x3D;160，因此等trx1返回时，所有LSN小于等于160的redo</p>
</li>
</ol>
<p>log，都已经被持久化到磁盘；</p>
<ol start="4">
<li>这时候trx2和trx3就可以直接返回了。所以，一次组提交里面，组员越多，节约磁盘IOPS的效果越好。但如果只有单线程压测，那就</li>
</ol>
<p>只能老老实实地一个事务对应一次持久化操作了。在并发更新场景下，第一个事务写完redo log buffer以后，接下来这个fsync越晚调用，组员可能</p>
<p>越多，节约IOPS的效果就越好。为了让一次fsync带的组员更多，MySQL有一个很有趣的优化：拖时间。在介绍两阶段提交的时</p>
<p>候，我曾经给你画了一个图，现在我把它截过来。图4 两阶段提交</p>
<p>图中，我把“写binlog”当成一个动作。但实际上，写binlog是分成两步的：</p>
<ol>
<li><p>先把binlog从binlog cache中写到磁盘上的binlog文件；</p>
</li>
<li><p>调用fsync持久化。MySQL为了让组提交的效果更好，把redo log做fsync的时间拖到了步骤1之后。也就是说，上面</p>
</li>
</ol>
<p>的图变成了这样：</p>
<p>图5 两阶段提交细化</p>
<p>这么一来，binlog也可以组提交了。在执行图5中第4步把binlog fsync到磁盘时，如果有多个事务</p>
<p>的binlog已经写完了，也是一起持久化的，这样也可以减少IOPS的消耗。不过通常情况下第3步执行得会很快，所以binlog的write和fsync间的间隔时间短，导致能集合到</p>
<p>一起持久化的binlog比较少，因此binlog的组提交的效果通常不如redo log的效果那么好。如果你想提升binlog组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和</p>
<p>binlog_group_commit_sync_no_delay_count来实现。1. binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync;</p>
<ol start="2">
<li>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。这两个条件是或的关系，也就是说只要有一个满足条件就会调用fsync。所以，当binlog_group_commit_sync_delay设置为0的时</li>
</ol>
<p>候，binlog_group_commit_sync_no_delay_count也无效了。之前有同学在评论区问到，WAL机制是减少磁盘写，可是每次提交事务都要写redo log和</p>
<p>binlog，这磁盘读写次数也没变少呀？现在你就能理解了，WAL机制主要得益于两个方面：</p>
<ol>
<li><p>redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快；</p>
</li>
<li><p>组提交机制，可以大幅度降低磁盘的IOPS消耗。分析到这里，我们再来回答这个问题：如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO</p>
</li>
</ol>
<p>上，可以通过哪些方法来提升性能呢？针对这个问题，可以考虑以下三种方法：</p>
<ol>
<li>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参</li>
</ol>
<p>数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加</p>
<p>语句的响应时间，但没有丢失数据的风险。2. 将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时</p>
<p>会丢binlog日志。3. 将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。我不建议你把innodb_flush_log_at_trx_commit 设置成0。因为把这个参数设置成0，表示redo</p>
<p>log只保存在内存中，这样的话MySQL本身异常重启也会丢数据，风险太大。而redo log写到文</p>
<p>件系统的page cache的速度也是很快的，所以将这个参数设置成2跟设置成0其实性能差不多，</p>
<p>但这样做MySQL异常重启时就不会丢数据了，相比之下风险会更小。小结</p>
<p>在专栏的第2篇和第15篇文章中，我和你分析了，如果redo log和binlog是完整的，MySQL是如</p>
<p>何保证crash-safe的。今天这篇文章，我着重和你介绍的是MySQL是“怎么保证redo log和binlog</p>
<p>是完整的”。希望这三篇文章串起来的内容，能够让你对crash-safe这个概念有更清晰的理解。之前的第15篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方</p>
<p>便你回顾、学习，我再集中回答一次这些问题。问题1：执行一个update语句以后，我再去执行hexdump命令直接查看ibd文件内容，为什么没</p>
<p>有看到数据有改变呢？回答：这可能是因为WAL机制的原因。update语句执行完成后，InnoDB只保证写完了redo</p>
<p>log、内存，可能还没来得及将数据写到磁盘。问题2：为什么binlog cache是每个线程自己维护的，而redo log buffer是全局共用的？回答：MySQL这么设计的主要原因是，binlog是不能“被打断的”。一个事务的binlog必须连续</p>
<p>写，因此要整个事务完成后，再一起写到文件里。而redo log并没有这个要求，中间有生成的日志可以写到redo log buffer中。redo log buffer中的</p>
<p>内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。问题3：事务执行期间，还没到提交阶段，如果发生crash的话，redo log肯定丢了，这会不会导</p>
<p>致主备不一致呢？回答：不会。因为这时候binlog 也还在binlog cache里，没发给备库。crash以后redo log和binlog</p>
<p>都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。问题4：如果binlog写完盘以后发生crash，这时候还没给客户端答复就重启了。等客户端再重连</p>
<p>进来，发现事务已经提交成功了，这是不是bug？回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit完成了，备库也收到</p>
<p>binlog并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端</p>
<p>也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是bug。实际上数据库的crash-safe保证的是：</p>
<ol>
<li><p>如果客户端收到事务成功的消息，事务就一定持久化了；</p>
</li>
<li><p>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；</p>
</li>
<li><p>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。最后，又到了课后问题时间。今天我留给你的思考题是：你的生产库设置的是“双1”吗？ 如果平时是的话，你有在什么场景下</p>
</li>
</ol>
<p>改成过“非双1”吗？你的这个操作又是基于什么决定的？另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？你可以把你的理解或者经验写在留言区，我会在下一篇文章的末尾选取有趣的评论和你一起分享</p>
<p>和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我在上篇文章最后，想要你分享的是线上“救火”的经验。@Long 同学，在留言中提到了几个很好的场景。其中第3个问题，“如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没</p>
<p>用的。”，说明他很好地思考了。这个问题是因为重启之后，业务请求还会再发。而且由于是重启，buffer pool被清空，可能会</p>
<p>导致语句执行得更慢。他提到的第4个问题也很典型。有时候一个表上会出现多个单字段索引（而且往往这是因为运</p>
<p>维工程师对索引原理不够清晰做的设计），这样就可能出现优化器选择索引合并算法的现</p>
<p>象。但实际上，索引合并算法的效率并不好。而通过将其中的一个索引改成联合索引的方</p>
<p>法，是一个很好的应对方案。还有其他几个同学提到的问题场景，也很好，很值得你一看。@Max 同学提到一个很好的例子：客户端程序的连接器，连接完成后会做一些诸如show</p>
<p>columns的操作，在短连接模式下这个影响就非常大了。这个提醒我们，在review项目的时候，不止要review我们自己业务的代码，也要review连接器</p>
<p>的行为。一般做法就是在测试环境，把general_log打开，用业务行为触发连接，然后通过</p>
<p>general log分析连接器的行为。@Manjusaka 同学的留言中，第二点提得非常好：如果你的数据库请求模式直接对应于客户</p>
<p>请求，这往往是一个危险的设计。因为客户行为不可控，可能突然因为你们公司的一个运营推</p>
<p>广，压力暴增，这样很容易把数据库打挂。在设计模型里面设计一层，专门负责管理请求和数据库服务资源，对于比较重要和大流量的业</p>
<p>务，是一个好的设计方向。锅子   2</p>
<p>老师好，有一个疑问：当设置sync_binlog&#x3D;0时，每次commit都只时write到page cache，并不</p>
<p>会fsync。但是做实验时binlog文件中还是会有记录，这是什么原因呢？是不是后台线程每秒一</p>
<p>次的轮询也会将binlog cache持久化到磁盘？还是有其他的参数控制呢？2019-01-04</p>
<p> 作者回复</p>
<p>你看到的“binlog的记录”，也是从page cache读的哦。Page cache是操作系统文件系统上的 </p>
<p>好问题</p>
<p>2019-01-04</p>
<p>倪大人   4</p>
<p>老师求解sync_binlog和binlog_group_commit_sync_no_delay_count这两个参数区别</p>
<p>如果</p>
<p>@Vincent 同学提了一个好问题，用文中提到的DDL方案，会导致binlog里面少了这个DDL语</p>
<p>句，后续影响备份恢复的功能。由于需要另一个知识点（主备同步协议），我放在后面的文章</p>
<p>中说明。精选留言</p>
<p>sync_binlog &#x3D; N</p>
<p>binlog_group_commit_sync_no_delay_count &#x3D; M</p>
<p>binlog_group_commit_sync_delay &#x3D; 很大值</p>
<p>这种情况fsync什么时候发生呀，min(N,M)吗？感觉sync_binlog搭配binlog_group_commit_sync_delay也可以实现组提交？如果</p>
<p>sync_binlog &#x3D; 0</p>
<p>binlog_group_commit_sync_no_delay_count &#x3D; 10</p>
<p>这种情况下是累计10个事务fsync一次？2019-01-04</p>
<p> 作者回复</p>
<p>好问题，我写这篇文章的时候也为了这个问题去翻了代码，是这样的：</p>
<p>达到N次以后，可以刷盘了，然后再进入(sync_delay和no_delay_count)这个逻辑；</p>
<p>Sync_delay如果很大，就达到no_delay_count才刷；</p>
<p>只要sync_binlog&#x3D;0,也会有前面的等待逻辑，但是等完后还是不调fsync </p>
<p>2019-01-06</p>
<p>WilliamX   3</p>
<p>为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？这个问题，感觉还有一点，binlog存储是以statement或者row格式存储的，而redo log是以page</p>
<p>页格式存储的。page格式，天生就是共有的，而row格式，只跟当前事务相关</p>
<p>2019-01-04</p>
<p> 作者回复</p>
<p>嗯，这个解释也很好。  </p>
<p>2019-01-04</p>
<p>一大只    2</p>
<p>你是怎么验证的？等于0的时候虽然有走这个逻辑，但是最后调用fsync之前判断是0，就啥也没</p>
<p>做就走了</p>
<p>回复老师:</p>
<p>老师，我说的sync_binlog&#x3D;0或&#x3D;1效果一样，就是看语句实际执行的效果，参数binlog_group_c</p>
<p>ommit_sync_delay我设置成了500000微秒，在&#x3D;1或&#x3D;0时，对表进行Insert，然后都会有0.5秒的</p>
<p>等待，也就是执行时间都是0.51 sec，关闭binlog_group_commit_sync_delay，insert执行会飞</p>
<p>快，所以我认为&#x3D;1或&#x3D;0都是受组提交参数的影响的。2019-01-05</p>
<p> 作者回复</p>
<p>  </p>
<p>非常好</p>
<p>然后再补上我回答的这个逻辑，就完备了</p>
<p>2019-01-05</p>
<p>alias cd&#x3D;rm -rf   1</p>
<p>事务A是当前事务，这时候事务B提交了。事务B的redolog持久化时候，会顺道把A产生的redol</p>
<p>og也持久化，这时候A的redolog状态是prepare状态么？2019-01-28</p>
<p> 作者回复</p>
<p>不是。说明一下哈，所谓的 redo log prepare，是“当前事务提交”的一个阶段，也就是说，在事务A提</p>
<p>交的时候，我们才会走到事务A的redo log prepare这个阶段。事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A还没有进入提交阶段，是无</p>
<p>所谓“redo log prepare”的。好问题</p>
<p>2019-01-28</p>
<p>某、人   1</p>
<p>有调到非双1的时候,在大促时非核心库和从库延迟较多的情况。设置的是sync_binlog&#x3D;0和innodb_flush_log_at_trx_commit&#x3D;2</p>
<p>针对0和2,在mysql crash时不会出现异常,在主机挂了时，会有几种风险:</p>
<p>1.如果事务的binlog和redo log都还未fsync,则该事务数据丢失</p>
<p>2.如果事务binlog fsync成功,redo log未fsync,则该事务数据丢失。虽然binlog落盘成功,但是binlog没有恢复redo log的能力,所以redo log不能恢复.</p>
<p>不过后续可以解析binlog来恢复这部分数据</p>
<p>3.如果事务binlog fsync未成功,redo log成功。由于redo log恢复数据是在引擎层,所以重新启动数据库,redo log能恢复数据,但是不能恢复serve</p>
<p>r层的binlog,则binlog丢失。如果该事务还未从FS page cache里发送给从库,那么主从就会出现不一致的情况</p>
<p>4.如果binlog和redo log都成功fsync,那么皆大欢喜。老师我有几个问题:</p>
<p>1.因为binlog不能被打断,那么binlog做fsync是单线程吧?</p>
<p>如果是的话,那么binlog的write到fsync的时间,就应该是redo log fsync+上一个事务的binlog fsync</p>
<p>时间。但是测试到的现象,一个超大事务做fsync时,对其它事务的提交影响也不大。如果是多线程做fsync,怎么保证的一个事务binlog在磁盘上的连续性？2. 5.7的并行复制是基于binlog组成员并行的,为什么很多文章说是表级别的并行复制？2019-01-06</p>
<p> 作者回复</p>
<ol>
<li>Write的时候只要写进去了，fsync其实很快的。连续性是write的时候做的（写的时候保证了</li>
</ol>
<p>连续）</p>
<ol start="2">
<li>你的理解应该是对的。不是表级</li>
</ol>
<p>2019-01-06</p>
<p>永恒记忆   1</p>
<p>主从模式下，内网从库如果设置双1，刚还原的数据发现根本追不上主库，所以从库设置了0，</p>
<p>老师后面章节会讲关于mysql包括主从监控这块的内容吗。2019-01-04</p>
<p> 作者回复</p>
<p>会讲到</p>
<p>2019-01-04</p>
<p>往事随风，顺其自然   1</p>
<p>redolog 里面有已经提交事物日志，还有未提交事物日志都持久化到磁盘，此时异常重启，binl</p>
<p>og 里面不是多余记录的未提交事物，干嘛不设计不添加未提交事物不更好</p>
<p>2019-01-04</p>
<p>miu   0</p>
<p>老师，关于BINLOG_GROUP_COMMIT_SYNC_DELAY，</p>
<p>BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT，</p>
<p>SYNC_BINLOG三个参数，我的理解是：</p>
<p>若SYNC_BINLOG&gt;1时，且设置了BINLOG_GROUP_COMMIT_SYNC_DELAY和BINLOG_GR</p>
<p>OUP_COMMIT_SYNC_NO_DELAY_COUNT两个参数。例如 </p>
<p>sync_binlog&#x3D;2，</p>
<p>BINLOG_GROUP_COMMIT_SYNC_DELAY&#x3D;1000000，</p>
<p>BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT&#x3D;3，</p>
<p>那么在执行完第1个事务后，在第2个事务提交时，会根据后续的事务提交来判断fsync等待的时</p>
<p>间，</p>
<p>若后续在1秒内没有累积3个事务的提交，则会等待1秒后再做fsync，从SQL语句来看，执行第</p>
<p>一个语句很快，第二个语句需要等待1秒才成功。这时延时等待的时间是BINLOG_GROUP_C</p>
<p>OMMIT_SYNC_DELAY所设置的值。若执行完第1个事务后，并行执行3个事务（1秒内完成），则后续3个事务会同时做fsync，这时</p>
<p>延时等待的时间是BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT设置的数量的事</p>
<p>务提交的间隔时间。也就是sync_binlog+BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT-1 个事务做一</p>
<p>次fsync。我测试的版本是MySQL官方5.7.24，请老师点评。2019-02-01</p>
<p> 作者回复</p>
<p>这两个逻辑不建议放到一起算</p>
<p>就是按照这样：</p>
<ol>
<li>有设置 BINLOG_GROUP_COMMIT_SYNC_NO_DELAY_COUNT这个值，（假设SYNC_D</li>
</ol>
<p>ELAY很大），提交的时候就得等这么多次才能过；</p>
<ol start="2">
<li>到了提交阶段，又要按照sync_binlog来判断是否刷盘。新春快乐~</li>
</ol>
<p>2019-02-04</p>
<p>alias cd&#x3D;rm -rf   0</p>
<p>老师不好意思，我接着刚才的问题问哈</p>
<p>并发事务的redolog持久化，会把当前事务的redolog持久化，当前事务的redolog持久化后prepa</p>
<p>re状态么？redolog已经被持久化到磁盘了，那么当前事务提交时候，redolog变为prepare状态</p>
<p>，这时候是从redologbuffer加载还是从磁盘加载？2019-01-28</p>
<p> 作者回复</p>
<p>每个事务在提交过程的prepare阶段，会把redolog持久化； “当前事务的redolog持久化后prepar</p>
<p>e状态么”这个描述还是不清楚，你用事务A、事务B这样来描述吧 </p>
<p>redolog已经被持久化到磁盘了，那么当前事务提交时候，</p>
<p>（其实这里只是“部分”被持久化，因为这个事务自己在执行的过程中，还会产生新的日志），</p>
<p>只需要继续持久化剩下的redo log</p>
<p>2019-01-28</p>
<p>alias cd&#x3D;rm -rf   0</p>
<p>您好，我看文章后有俩点疑问，前提条件如果mysql设置双1</p>
<p>1、这时候磁盘中的redolog的状态是什么状态呢？是prepare么？2、如果一个事务在进行中的时候redolog已经被持久化，在事务提交时候，这条redolog还在re</p>
<p>dolog-buffer中么？2019-01-27</p>
<p> 作者回复</p>
<ol>
<li><p>“这时候磁盘中的redolog的状态是什么状态呢？是prepare么？”这个“这时候”是什么意思 </p>
</li>
<li><p>还在，不过随时可以被覆盖</p>
</li>
</ol>
<p>2019-01-28</p>
<p>嘻嘻   0</p>
<ol>
<li>如果客户端收到事务成功的消息，事务就一定持久化了；</li>
</ol>
<p>commit是在什么阶段返回的？如果写完page cache就返回也没有持久化吧？2019-01-25</p>
<p> 作者回复</p>
<p>第一个问题没看懂。“如果写完page cache就返回也没有持久化吧”， 是的，</p>
<p>“客户端收到事务成功的消息，事务就一定持久化了”是建立在双1基础上的。2019-01-26</p>
<p>Geek_527020   0</p>
<p>您好，老师，我有一个以后，组提交，把为提交事务的redo log写入磁盘，如果有查询，岂不</p>
<p>是查到未提交事务的更新内容了?</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>不会啊，有MVCC的， 08篇再看下</p>
<p>2019-01-25</p>
<p>J!   0</p>
<p>共同写一个binlog文件，这个过程应该需要锁来维持提交的时序吧，写文件的时候是不是可能</p>
<p>会变成瓶颈点？2019-01-23</p>
<p> 作者回复</p>
<p>不会的，大家分头写，然后一起持久化到磁盘</p>
<p>2019-01-23</p>
<p>Komine   0</p>
<p>为什么binlog 是不能“被打断的”的呢？主要出于什么考虑？2019-01-22</p>
<p> 作者回复</p>
<p>好问题</p>
<p>我觉得一个比较重要的原因是，一个线程只能同时有一个事务在执行。由于这个设定，所以每当执行一个begin&#x2F;start transaction的时候，就会默认提交上一个事务；</p>
<p>这样如果一个事务的binlog被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破</p>
<p>坏了原子性，是有问题的。2019-01-22</p>
<p>就是个渣渣    0</p>
<p>林老师，你好！超过了binlog_cache_size，暂存到磁盘，那如果超过了max_binlog_cache_siz</p>
<p>e 就直接报错了呢，这两个参数的关联是什么呢？2019-01-19</p>
<p> 作者回复</p>
<p>max_binlog_cache_size只是用来限制设置binlog_cache_size的时候的上限 </p>
<p>并不参与执行语句的逻辑的</p>
<p>2019-01-19</p>
<p>似水流年   0</p>
<p>我网上查pagecache是在内存里的，这与您讲的一样吗？2019-01-15</p>
<p> 作者回复</p>
<p>就是文件系统的page cache，是属于操作系统的内存的一部分</p>
<p>2019-01-15</p>
<p>猪哥哥   0</p>
<p>老师好, 能说下innodb_log_buffer_size参数的作用吗</p>
<p>2019-01-10</p>
<p>roaming   0</p>
<p>看了几遍，终于看明白了</p>
<p>2019-01-10</p>
<p> 作者回复</p>
<p> </p>
<p>2019-01-10</p>
<p>猪哥哥   0</p>
<p>老师 我想问下文件系统的page cache还是不是内存, 是不是文件系统向内核申请的一块的内存?</p>
<p>2019-01-10</p>
<p> 作者回复</p>
<p>你理解的是对的</p>
<p>2019-01-10</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/84d0671b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/84d0671b.html" class="post-title-link" itemprop="url">mysql-MySQL有哪些“饮鸩止渴”提高性能的方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-27 06:11:42" itemprop="dateCreated datePublished" datetime="2019-11-27T06:11:42+08:00">2019-11-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>38 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>22 | MySQL有哪些“饮鸩止渴”提高性能的方法？2019-01-02 林晓斌</p>
<p>不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的MySQL压力太</p>
<p>大，没法正常响应，需要短期内、临时性地提升一些性能。我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，</p>
<p>让业务先跑起来再说。但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，</p>
<p>并着重说一说它们可能存在的风险。短连接风暴</p>
<p>正常的短连接模式就是连接到数据库后，执行很少的SQL语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。我在第1篇文章《基础架构：一条SQL查询语句是如何执行的？》中说过，MySQL建立连接的过</p>
<p>程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的</p>
<p>数据读写权限。在数据库压力比较小的时候，这些额外的成本并不明显。但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections参数，用来控制一个MySQL实例同时存在的连接数的上限，超过这个值，系统</p>
<p>就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来</p>
<p>说，从业务角度看就是数据库不可用。在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有</p>
<p>新建连接的话，就可能会超过max_connections的限制。碰到这种情况时，一个比较自然的想法，就是调高max_connections的值。但这样做是有风险</p>
<p>的。因为设计max_connections这个参数的目的是想保护MySQL，如果我们把它改得太大，让更</p>
<p>多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑</p>
<p>上，结果可能是适得其反，已经连接的线程拿不到CPU资源去执行业务的SQL请求。那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损</p>
<p>的。第一种方法：先处理掉那些占着连接但是不工作的线程。max_connections的计算，不是看谁在running，是只要连着就占用一个计数位置。对于那些不需</p>
<p>要保持的连接，我们可以通过kill connection主动踢掉。这个行为跟事先设置wait_timeout的效果</p>
<p>是一样的。设置wait_timeout参数表示的是，一个线程空闲wait_timeout这么多秒之后，就会被</p>
<p>MySQL直接断开连接。但是需要注意，在show processlist的结果里，踢掉显示为sleep的线程，可能是有损的。我们来</p>
<p>看下面这个例子。图1 sleep线程的两种状态</p>
<p>在上面这个例子里，如果断开session A的连接，因为这时候session A还没有提交，所以MySQL</p>
<p>只能按照回滚事务来处理；而断开session B的连接，就没什么大影响。所以，如果按照优先级</p>
<p>来说，你应该优先断开像session B这样的事务外空闲的连接。但是，怎么判断哪些是事务外空闲的呢？session C在T时刻之后的30秒执行show processlist，</p>
<p>看到的结果是这样的。图2 sleep线程的两种状态，show processlist结果</p>
<p>图中id&#x3D;4和id&#x3D;5的两个会话都是Sleep 状态。而要看事务具体状态的话，你可以查</p>
<p>information_schema库的innodb_trx表。图3 从information_schema.innodb_trx查询事务状态</p>
<p>这个结果里，trx_mysql_thread_id&#x3D;4，表示id&#x3D;4的线程还处在事务中。因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断</p>
<p>开事务内空闲太久的连接。从服务端断开连接使用的是kill connection + id的命令， 一个客户端处于sleep状态时，它的连接</p>
<p>被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会</p>
<p>收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是</p>
<p>直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL一直没恢复”。你可能觉得这是一个冷笑话，但实际上我碰到过不下10次。所以，如果你是一个支持业务的DBA，不要假设所有的应用代码都会被正确地处理。即使只是</p>
<p>一个断开连接的操作，也要确保通知到业务开发团队。第二种方法：减少连接过程的消耗。有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打</p>
<p>挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables参数启动。这样，整个MySQL会</p>
<p>跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。但是，这种方法特别符合我们标题里说的“饮鸩止渴”，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。在MySQL 8.0版本里，如果你启用–skip-grant-tables参数，MySQL会默认把 –skip-networking参</p>
<p>数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL官方对skip-grant-tables这</p>
<p>个参数的安全问题也很重视。除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句</p>
<p>导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是</p>
<p>由QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展</p>
<p>开说明。慢查询性能问题</p>
<p>在MySQL中，会引发性能问题的慢查询，大体有以下三种可能：</p>
<ol>
<li><p>索引没有设计好；</p>
</li>
<li><p>SQL语句没写好；</p>
</li>
<li><p>MySQL选错了索引。接下来，我们就具体分析一下这三种可能，以及对应的解决方案。导致慢查询的第一种可能是，索引没有设计好。这种场景一般就是通过紧急创建索引来解决。MySQL 5.6版本以后，创建索引都支持Online DDL</p>
</li>
</ol>
<p>了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行alter</p>
<p>table 语句。比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库A、备库B，这个方案的</p>
<p>大致流程是这样的：</p>
<ol>
<li>在备库B上执行 set sql_log_bin&#x3D;off，也就是不写binlog，然后执行alter table 语句加上索</li>
</ol>
<p>引；</p>
<ol start="2">
<li><p>执行主备切换；</p>
</li>
<li><p>这时候主库是B，备库是A。在A上执行 set sql_log_bin&#x3D;off，然后执行alter table 语句加上</p>
</li>
</ol>
<p>索引。这是一个“古老”的DDL方案。平时在做变更的时候，你应该考虑类似gh-ost这样的方案，更加稳</p>
<p>妥。但是在需要紧急处理时，上面这个方案的效率是最高的。导致慢查询的第二种可能是，语句没写好。比如，我们犯了在第18篇文章《为什么这些SQL语句逻辑相同，性能却差异巨大？》中提到的</p>
<p>那些错误，导致语句没有使用上索引。这时，我们可以通过改写SQL语句来处理。MySQL 5.7提供了query_rewrite功能，可以把输入的</p>
<p>一种语句改写成另外一种模式。比如，语句被错误地写成了 select * from t where id + 1 &#x3D; 10000，你可以通过下面的方式，增加</p>
<p>一个语句改写规则。这里，call query_rewrite.flush_rewrite_rules()这个存储过程，是让插入的新规则生效，也就是我</p>
<p>们说的“查询重写”。你可以用图4中的方法来确认改写规则是否生效。图4 查询重写效果</p>
<p>mysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (“select * from t where id + 1 &#x3D; ?”, “select * from t where id &#x3D; ? - 1”, “db1”);</p>
<p>call query_rewrite.flush_rewrite_rules();</p>
<p>导致慢查询的第三种可能，就是碰上了我们在第10篇文章《MySQL为什么有时候会选错索</p>
<p>引？》中提到的情况，MySQL选错了索引。这时候，应急方案就是给这个语句加上force index。同样地，使用查询重写功能，给原来的语句加上force index，也可以解决这个问题。上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索</p>
<p>引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，</p>
<p>我们就可以预先发现问题。1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，</p>
<p>确保每个语句都会被记录入慢查询日志；</p>
<ol start="2">
<li><p>在测试表里插入模拟线上的数据，做一遍回归测试；</p>
</li>
<li><p>观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。（我</p>
</li>
</ol>
<p>们在前面文章中已经多次用到过Rows_examined方法了，相信你已经动手尝试过了。如果</p>
<p>还有不明白的，欢迎给我留言，我们一起讨论）。不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。如果新增的SQL语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的</p>
<p>表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的SQL语句的返回结</p>
<p>果。比如，你可以使用开源工具pt-query-digest(<a target="_blank" rel="noopener" href="https://www.percona.com/doc/percona-">https://www.percona.com/doc/percona-</a></p>
<p>toolkit&#x2F;3.0&#x2F;pt-query-digest.html)。QPS突增问题</p>
<p>有时候由于业务突然出现高峰，或者应用程序bug，导致某个语句的QPS突然暴涨，也可能导致</p>
<p>MySQL压力过大，影响服务。我之前碰到过一类情况，是由一个新功能的bug导致的。当然，最理想的情况是让业务把这个功</p>
<p>能下掉，服务自然就会恢复。而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再</p>
<p>和你展开说明一下。1. 一种是由全新业务的bug导致的。假设你的DB运维是比较规范的，也就是说白名单是一个个</p>
<p>加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就</p>
<p>可以从数据库端直接把白名单去掉。2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开</p>
<p>现有连接。这样，这个新功能的连接不成功，由它引发的QPS就会变成0。3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这</p>
<p>时，我们可以使用上面提到的查询重写功能，把压力最大的SQL语句直接重写成”select 1”返</p>
<p>回。当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：</p>
<ol>
<li><p>如果别的功能里面也用到了这个SQL语句模板，会有误伤；</p>
</li>
<li><p>很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以select 1的结</p>
</li>
</ol>
<p>果返回的话，可能会导致后面的业务逻辑一起失败。所以，方案3是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低</p>
<p>的一个方案。同时你会发现，其实方案1和2都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分</p>
<p>离。由此可见，更多的准备，往往意味着更稳定的系统。小结</p>
<p>今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方</p>
<p>法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你</p>
<p>做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机</p>
<p>制。DBA虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好SQL审计</p>
<p>可以减少需要这类操作的机会。其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在server层。在下一篇文章</p>
<p>中，我会继续和你讨论一些跟InnoDB有关的处理方法。最后，又到了我们的思考题时间了。今天，我留给你的课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么</p>
<p>处理的呢？你可以把你的经历和经验写在留言区，我会在下一篇文章的末尾选取有趣的评论跟大家一起分享</p>
<p>和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>前两期我给你留的问题是，下面这个图的执行序列中，为什么session B的insert语句会被堵住。我们用上一篇的加锁规则来分析一下，看看session A的select语句加了哪些锁：</p>
<ol>
<li>由于是order by c desc，第一个要定位的是索引c上“最右边的”c&#x3D;20的行，所以会加上间隙锁</li>
</ol>
<p>(20,25)和next-key lock (15,20]。2. 在索引c上向左遍历，要扫描到c&#x3D;10才停下来，所以next-key lock会加到(5,10]，这正是阻塞</p>
<p>session B的insert语句的原因。3. 在扫描过程中，c&#x3D;20、c&#x3D;15、c&#x3D;10这三行都存在值，由于是select *，所以会在主键id上加</p>
<p>三个行锁。因此，session A 的select语句锁的范围就是：</p>
<ol>
<li><p>索引c上 (5, 25)；</p>
</li>
<li><p>主键索引上id&#x3D;15、20两个行锁。这里，我再啰嗦下，你会发现我在文章中，每次加锁都会说明是加在“哪个索引上”的。因为，锁</p>
</li>
</ol>
<p>就是加在索引上的，这是InnoDB的一个基础设定，需要你在分析问题的时候要一直记得。评论区留言点赞板：</p>
<p>@HuaMax 给出了正确的解释。@Justin 同学提了个好问题，&lt;&#x3D;到底是间隙锁还是行锁？其实，这个问题，你要跟“执行过</p>
<p>程”配合起来分析。在InnoDB要去找“第一个值”的时候，是按照等值去找的，用的是等值判断</p>
<p>的规则；找到第一个值以后，要在索引内找“下一个值”，对应于我们规则中说的范围查找。@信信 提了一个不错的问题，要知道最终的加锁是根据实际执行情况来的。所以，如果一个</p>
<p>select * from … for update 语句，优化器决定使用全表扫描，那么就会把主键索引上next-key</p>
<p>lock全加上。最后，我要为元旦期间还坚持学习的同学们，点个赞 ^_^</p>
<p>某、人   4</p>
<p>最近才发生了个案列:</p>
<p>由于一个delete大事务导致磁盘空间满了,数据库hang住,连接不上,所以无法kill掉该大事务</p>
<p>当时的观察到的现象是:</p>
<p>binlog有一个文件已经达到50多G</p>
<p>lsof | grep delete 该tmp文件100多G</p>
<p>redo log还是只有4个组,每个文件1G</p>
<p>undo log大概有100来G</p>
<p>由于数据库连不上,只有把连接切到从库,kill掉主库的进程。过了几分钟,binlog文件才缩小为原来</p>
<p>的大小。把主库启起来,但是recovery非常慢。后面kill掉,又以innodb_force_recovery&#x3D;3恢复,rec</p>
<p>overy也是半天没反应。由于这个库也不是重要的库,就把新的主库的备份文件重做了之前的主</p>
<p>库,以从库启起来</p>
<p>@nero 同学的问题，提示我需要提醒大家注意，“有行”才会加行锁。如果查询条件没有命中</p>
<p>行，那就加next-key lock。当然，等值判断的时候，需要加上优化2（即：索引上的等值查</p>
<p>询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。）。@小李子、@发条橙子同学，都提了很好的问题，这期高质量评论很多，你也都可以去看看。精选留言</p>
<p>通过最近的学习+测试分析了下,为什么binlog达到了50多G。tmp文件100多G.</p>
<p>由于binlog_cache不够用,把binlog写进了tmp文件中,binlog文件50多G,说明事务已经执行完成,</p>
<p>是binlog在fsync阶段,把空间占满了。fsync并不是一个move而是相当于copy。要等binlog完全</p>
<p>落盘以后,才会删除之前的tmp文件。redo log由于是循环写,而且在事务执行过程中,就会把redo l</p>
<p>og分为mtx落地到磁盘上。所以没有一次性暴增,还是以1G的大小持续写.</p>
<p>我也是后续做测试,观察在事务进行中,redo log文件一直都有变化。binlog没有变化</p>
<p>binlog是在事务执行完以后,才一次性fsync到磁盘</p>
<p>但是为什么recovery&#x3D;3的情况下,还比较耗时。我估计是之前脏页较多,而redo log又全部被覆盖</p>
<p>掉,</p>
<p>需要先通过binlog来恢复redo log,然后再通过redo log来恢复数据页。请问老师有没有更好的办法来处理这种hang住的情况?</p>
<p>如果在操作系统层面kill掉执行的线程,就好了。昨天提到的问题3,我也没有测试出来Sending to client这个状态.是之前别人问到的,我也挺懵</p>
<p>2019-01-03</p>
<p> 作者回复</p>
<p>先说明下，binlog是没有“恢复redolog”的能力的哈。其它部分分析得很好  </p>
<p>Binlog 这么大，说明是大事务，崩溃恢复的时候要处理的redolog 很多，估计耗时间耗在这。这种磁盘空间满的情况，以前我的处理方法是把最老的binlog移动到别的盘（如果确定日志已</p>
<p>经备份到备份系统了就删掉），目的是腾出空间让这个事务执行完成。后面可以考虑这种方案，强制重启还是有点伤的，不过核心还是做好监控，不让出现磁盘100%</p>
<p>写满的情况</p>
<p>2019-01-03</p>
<p>Long   9</p>
<p>不是专业DBA，遇到过几次数据库问题，有的能解决，有的好像除了重启或者干等着没啥好办</p>
<p>法。MySQL5.6版本遇到的部分问题：</p>
<ol>
<li>几个线程处于killed状态一直kill不掉（1天），然后备份的时候MySQL backup flush all tables</li>
</ol>
<p>with read lock的时候被阻塞，后面的线程只能等待flush table, kill backup以后也没有办法kill那</p>
<p>几个killed状态的语句（processlist显示的killed状态的语句的就是show columns, show create t</p>
<p>able这样的），后面没办法，重启了server。（看到老师后面第25讲有关于kill的解释，非常期</p>
<p>待新知识）</p>
<ol start="2">
<li>一个非常大（大几百万行）的表truncate，结果后面所有的线程都阻塞了，类似于下面这个M</li>
</ol>
<p>ySQL bug的场景，结果就是等这个truncate结束。没有继续干预。<a target="_blank" rel="noopener" href="https://bugs.mysql.com/bug.php?id=80060">https://bugs.mysql.com/bug.php?id=80060</a></p>
<ol start="3">
<li>某个新功能上线以后，一个记录操作人员操作页面操作时间KPI的功能，由于sql性能不好，</li>
</ol>
<p>在业务上线跑了3天后数据量增多到临界值，突然影响了整个系统性能。数据库发现是大量的s</p>
<p>ql执行状态是converting heap to MyISAM，sql写法类似 select (select * from table) where id(有</p>
<p>索引)&#x3D; xxxx order by yyyy</p>
<p>DBA以及他们团队要求重启。但是分析了几分钟后提供了几个意见给”DBA”，并解释重启解决</p>
<p>不了问题：首先这个问题重启是解决不了，因为每次这个sql查询全表，查询分配的临时表空间</p>
<p>不足了，需要把结果集转到磁盘上，重启了sql动作没变，参数没变所以重启解决不了问题。页面查询也没法屏蔽，页面查询也无法过滤条件，</p>
<p>（1）和研发确认后，表数据删除不影响功能，只影响客户的KPI报表，先备份表，然后删除，</p>
<p>后面等功能修复了再补回去。（2）调整max_heap_table_size，tmp_table_size，扩大几倍</p>
<p>（3）给这个sql的唯一的一个order by字段加个索引。同时催促研发提供hotfix。最终选择了最简单有效的（1）问题解决，研发迅速后面也发了hotfix</p>
<p>解决了。4. 某个消费高峰时间段，高频查询被触发，一天几十万次执行，由于存量数据越来越多，查询</p>
<p>性能越来越慢，主要是索引没有很好规划，导致CPU资源使用飙升，后面的sql执行越来越慢。最后尝试了给2个字段添加单独的索引，解决了50%的问题，看到执行计划，extra里面，索引</p>
<p>合并使用了intersect，性能还是慢，然后立马drop原先的2个单独索引，创建两个字段的联合索</p>
<p>引，问题解决了。5. 死锁回滚，导致的MySQL hang住了，当时刚入门，只能简单复现死锁，没有保留所有的日</p>
<p>志，现在想查也查不了了。。。感觉大部分都是慢sql和高频事务导致的。（当然后面的慢sql监控分析，项目上就很重视了。。）</p>
<p>今天看了这期专栏，发现5.7的这个功能，query_rewrite，受教了。等我们升到5.7以后，可以实</p>
<p>际操练下。上面的问题3，也可以用这个功能了（因为是新业务，新表，特殊sql，完全可以起</p>
<p>到hotfix的作用）。请老师帮忙看下上面几次故障是否有更好，更专业的解决方案。多谢</p>
<p>2019-01-02</p>
<p> 作者回复</p>
<ol>
<li>Kill 掉备份线程在当时是最好的办法了。不过我之前确实也没碰到过show create table 不能kil</li>
</ol>
<p>l的情况，我看下代码，如果能复现出来加入那篇文章中</p>
<ol start="2">
<li>嗯，80060这个问题是因为要truncate，所以要回收脏页导致慢，不过这个问题在5.5.23就优</li>
</ol>
<p>化掉了哦，看你使用的是5.6，可能是别的原因。truncate如果不是被锁，而是已经在执行了，</p>
<p>确实还是别做别的事情，等结束最好；</p>
<ol start="3">
<li>这个语句是因为子查询要用临时表，跟order by 无关的（你看到的阶段还没开始order by 操</li>
</ol>
<p>作）。这个语句的临时表都能多到把磁盘打满，增加tmp_table_size是没用的。就是说这三个方法里面2和3其实都无效。你们当时的选择很精准呀。而且前面提出“重启无效”的这个人值得团队内大力表扬（是不是就是你 ）</p>
<p>另外这个语句，看着像有机会优化的样子，核心方向是去掉临时表</p>
<p>4.可以只删掉其中一个独立索引，再加一个联合索引，就是变成(a,b)和(b)这两种索引，也就是</p>
<p>把(a)改成(a,b)，这样是加法，相对比较安全。删除索引是一个要很小心的操作，少删一个多一</p>
<p>份安全，之后再通过观察索引b的使用情况，确定没必要再删。interset确实一般都比较慢。5. 正常回滚很快的，是不是大事务回滚？这种还是得从消除大事务入手</p>
<p>2019-01-02</p>
<p>某、人   4</p>
<p>老师,我有几个问题:</p>
<p>1.如果把order by去掉或者order by c asc,往右扫描,为什么没有加[25,30)next-key lock?</p>
<p>2.执行session A,为什么slow log里的Rows_examined为2?按照答案来讲不应该是为3嘛</p>
<p>3.thread states里sending data包括sending data to the client,</p>
<p>另外还有一种state是Sending to client(5.7.8之前叫Writing to net)是writing a packet to the client.</p>
<p>请问针对发送数据给客户端,这两种状态有什么区别？2019-01-02</p>
<p> 作者回复</p>
<ol>
<li><p>Next-key lock是前开后闭区间呀，有扫描到25，所以(20,25]</p>
</li>
<li><p>Rows_examined 是server层统计的，这个不满足的值没返回给server</p>
</li>
<li><p>你show processlist 结果发我看下，代码中没搜到 </p>
</li>
</ol>
<p>2019-01-02</p>
<p>Tony Du   4</p>
<p>对于上期问题的解答，有一点不是特别理解，</p>
<p>因为order by desc，在索引c上向左遍历，对于（15， 25）这段区间没有问题，</p>
<p>然后，扫描到c&#x3D;10才停下来，理论上把（10，15]这个区间锁上就应该是完备的了呀。（5，10]</p>
<p>这段区间是否锁上对结果应该没有影响呀，为什么会需要（5，10] 这段的next-key lock ?</p>
<p>2019-01-02</p>
<p> 作者回复</p>
<p>就是这么实现的 </p>
<p>C&#x3D;10还是要锁的，如果不锁可能被删除</p>
<p>2019-01-02</p>
<p>Tony Du   2</p>
<p>对于上期问题的解答，有一点不是特别理解，</p>
<p>因为order by desc，在索引c上向左遍历，对于（15， 25）这段区间没有问题，</p>
<p>然后，扫描到c&#x3D;10才停下来，理论上把（10，15]这个区间锁上就应该是完备的了呀。（5，10]</p>
<p>这段区间是否锁上对结果应该没有影响呀，为什么会需要（5，10] 这段的next-key lock ?</p>
<p>2019-01-02</p>
<p>  作者回复</p>
<p>就是这么实现的 </p>
<p>C&#x3D;10还是要锁的，如果不锁可能被删除</p>
<p>我的回复：</p>
<p>所以，如果把sql改成</p>
<p>select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c asc lock in share mode;</p>
<p>那锁的范围就应该是索引c上（10，25）了吧。同样查询条件，不同的order顺序，锁的范围不一样，稍微感觉有一点奇怪…</p>
<p>2019-01-03</p>
<p> 作者回复</p>
<p>嗯，因为执行索引遍历的顺序不一样，其实锁范围不一样也算合理啦 </p>
<p>2019-01-03</p>
<p>Long   1</p>
<p>老师好，看到有的同学在讨论锁的释放问题。之前分析过一个锁表异常，很多用workbench或者类似客户端的同学可能会遇到，</p>
<p>复现方式：</p>
<p>Step 1：显示的打开一个事务，或者把autocommit&#x3D;0，或者mysql workbench中把自动提交的</p>
<p>置灰按钮打开以后</p>
<p>Step 2: 执行一个sql（比如，update或者delete之类的），然后sql还没有返回执行结果的中途点</p>
<p>击workbench 自带的那个stop的红色的按钮。这个时候很多人可能就不再做其他操作，大多会认为执行已经结束了。但是实际上，锁还在继</p>
<p>续锁着的并不会释放。系统日志记录：</p>
<p>（1）processlist的状态是sleep，info为null</p>
<p>（2）innodb_trx的状态是running，trx_query为null</p>
<p>（3）performance_schema.events_statements_current表中的，</p>
<p>sql_text，digest_text：是有正确的sql的。—这个5.6以后就有了，如果ps打开的话，应该是可</p>
<p>以看到的。message_text ：Query execution was interrupted</p>
<p>（4）inoodb_locks，lock_waits，以及show engine innodb status，只有出现锁等待的时候才</p>
<p>会记录，如果只有一个事务的记录行锁，或者表锁，是不会记录的。（不知道是否有参考控制</p>
<p>，还是默认的）</p>
<p>（5）关于行锁记录数的问题，从测试的结果看，inoodb_trx的locked rows，当我点停止的时候</p>
<p>，锁定行数保持不变了，当我继续点击执行的时候，锁定记录行数会在之前的记录上向上累加</p>
<p>，并不是从0开始。然后查了audit log以后发现，客户端（mysqlworkbench）送给server端的是KILL QUERY threa</p>
<p>d_id，而不是Kill thread_id，</p>
<p>所以MySQL只是终止了事务中的statement执行，但是并不会释放锁，因为目前的琐的获取和</p>
<p>释放都是基于事务结束的（提交或者回滚）。这里面关于kill query&#x2F; thread_id的区别解释</p>
<p><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.6/en/kill.html">https://dev.mysql.com/doc/refman/5.6/en/kill.html</a></p>
<p>解决方法：</p>
<p>自己解决：kill 对应的thread_id，或者关闭执行窗口（这个时候会送个quit给server端）。别人解决：有super权限的人kill thread_id。关于kill的那个文章，其实对所有DDL，DML的操作释放过程，还没有全部搞清楚，期待老师的</p>
<p>第25讲。2019-01-02</p>
<p> 作者回复</p>
<p>总结的非常好，而且现象很全面。核心的一个点是：kill query 只是终止当前执行语句，并不会让事务回滚  </p>
<p>2019-01-03</p>
<p>曾剑   1</p>
<p>老师，关于上期遗留问题的解答，我有一点疑惑：</p>
<p>解答中的1中，第一个要定位的是索引 c 上“最右边的”c&#x3D;20 的行，为啥只会加上间隙锁（20,25</p>
<p>）和next-key lock(15,20]呢，为啥不是两个next-key lock(15,20]和(20,25]呢？25上的行锁难道</p>
<p>是退化的？老师上一篇文章中说到加锁的基本原则中第一点是加锁的基本单位是next-key lock</p>
<p>，而退化都是基于索引上的等值查询才会发生呀？盼老师指点迷津。2019-01-02</p>
<p> 作者回复</p>
<p>就是优化2，找第一个值的时候是等值查询</p>
<p>2019-01-02</p>
<p>Invictus_CD     0</p>
<p>老师好，这个课后题c≥15加锁和上一课的例子4的c≥10解释的不太一样啊。例子4的直接在10上</p>
<p>面加的间隙锁啊，这个为啥要在5上面加呢？2019-02-08</p>
<p> 作者回复</p>
<p>上一篇的案例4，session A的select语句没有order by c desc</p>
<p>区别就是在 “order by c desc”上</p>
<p>看一下30篇哈</p>
<p>2019-02-09</p>
<p>刘昆   0</p>
<p>老师你好，上期问题里面我遇到一下问题：</p>
<p>insert into t values(6,5,6) &#x3D;&gt; block</p>
<p>insert into t values(4,5,6) &#x3D;&gt; no block</p>
<p>insert into t values(6,4,6) &#x3D;&gt; no block</p>
<p>insert into t values(7,5,6) &#x3D;&gt; block</p>
<p>insert into t values(7,4,6) &#x3D;&gt; no block</p>
<p>根据你的解答，c 上面的 next-key lock 在 (5, 10]，那么上面的情况应该都不会阻塞还对呀？Server version: 5.7.24-log MySQL Community Server (GPL)</p>
<p>2019-02-02</p>
<p> 作者回复</p>
<p>是这样的，我们只是简写成(5,10],</p>
<p>这个是索引c上的next-key lock，</p>
<p>所以这个范围的左边界是 (c&#x3D;5,id&#x3D;5), 右边界是(c&#x3D;10,id&#x3D;10)</p>
<p>你举例里面，</p>
<p>insert into t values(6,5,6) 是（c&#x3D;5, id&#x3D;6);</p>
<p>insert into t values(7,5,6) 是（c&#x3D;5, id&#x3D;7);</p>
<p>这两个都落在上面的next-key lock的区间，所以是会被锁住的哦</p>
<p>好问题， 新年快乐</p>
<p>2019-02-03</p>
<p>Moby   0</p>
<p>谢谢谢谢谢谢老师的回答！“作者回复</p>
<p>这没问题呀</p>
<p>begin; select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc lock in share mode;</p>
<p>锁的范围是这样的：</p>
<p>索引c上，next-key lock: (5，10],(10,15],(15,20];</p>
<p>索引id上，行锁: id&#x3D;15和id&#x3D;20”</p>
<p>不过在文末（二十二：MySQL有哪些”饮鸩止渴“提高性能的方法）上写的是“</p>
<p>因此，session A 的 select 语句锁的范围就是：1.索引c上(5,25); 2. 主键索引上id&#x3D;10、15、20</p>
<p>三个行锁”（写错了吧？）</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>嗯嗯，你说的对，我这里弄错了，应该是“主键索引上id&#x3D;15、20两个行锁”</p>
<p>勘误啦 多谢</p>
<p>2019-01-23</p>
<p>Moby   0</p>
<p>丁奇老师好，不好意思，学渣看得比较慢。关于前两期的问题，我有一点没搞懂。就是你说的</p>
<p>：”session A 在 select 语句锁的范围是 1…. ; 2.在主键索引上id&#x3D;10、15、20三个行锁”，经我测</p>
<p>试(MySQL版本：5.7.17-log; 隔离级别：可重复读)：“session </p>
<p>A: begin; select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc lock in share mode;”、”sessi</p>
<p>on B: update t set c&#x3D;1010 where id&#x3D;10; Query ok”、”session C: update t set c&#x3D;1515 where id&#x3D;</p>
<p>15;block…“。即：为什么id&#x3D;10这一行可以更新数据？而id&#x3D;15、20这两行更新数据就被阻塞？2019-01-21</p>
<p> 作者回复</p>
<p>这没问题呀</p>
<p>begin; select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc lock in share mode;</p>
<p>锁的范围是这样的：</p>
<p>索引c上，next-key lock: (5，10],(10,15],(15,20];</p>
<p>索引id上，行锁: id&#x3D;15和id&#x3D;20</p>
<p>2019-01-21</p>
<p>unlock   0</p>
<p>老师，对于这句话“锁就是加在索引上的”，如果一个表没有主键、没有索引，还会加锁吗。如果会加，加到哪</p>
<p>2019-01-18</p>
<p> 作者回复</p>
<p>InnoDB可不存在“没有索引的表”哦</p>
<p>没有主键，系统会给创建一个的（隐藏的</p>
<p>2019-01-18</p>
<p>往事随风，顺其自然   0</p>
<p>为什么我的电脑上没有慢查询的日志文件，mysql5.7</p>
<p>ysql&gt; show VARIABLES like ‘%slow%’;</p>
<p>+—————————+————————–+</p>
<p>| Variable_name | Value |</p>
<p>+—————————+————————–+</p>
<p>| log_slow_admin_statements | OFF |</p>
<p>| log_slow_slave_statements | OFF |</p>
<p>| slow_launch_time | 2 |</p>
<p>| slow_query_log | ON |</p>
<p>| slow_query_log_file | DESKTOP-76FNKS3-slow.log |</p>
<p>+—————————+————————–+</p>
<p>DESKTOP-76FNKS3-slow.log 这个文件再本地磁盘找不到</p>
<p>2019-01-04</p>
<p> 作者回复</p>
<p>Show variables like “output”</p>
<p>2019-01-04</p>
<p>往事随风，顺其自然   0</p>
<p>mysql5.7为什么不存在下面的数据库和表 </p>
<p>mysql&gt; use query_rewrite;</p>
<p>ERROR 1049 (42000): Unknown database ‘query_rewrite’</p>
<p>mysql&gt;</p>
<p>2019-01-04</p>
<p> 作者回复</p>
<p>搜一下用法吧 </p>
<p>2019-01-04</p>
<p>堕落天使   0</p>
<p>老师，您好：</p>
<p>我引用一下 Ryoma 的留言，如下：</p>
<p>Ryoma</p>
<p>我之前的描述有点问题，其实想问的是：为什么加了 order by c desc，第一个定位c&#x3D;20 的行，</p>
<p>会加上间隙锁 (20,25) 和 next-key lock (15,20]？如果没有order by c desc，第一次命中c&#x3D;15时，只会加上next-key lock(10.15]；</p>
<p>而有了order by c desc，我的理解是第一次命中c&#x3D;20只需要加上next-key lock (15,20]</p>
<p>当然最后(20,25)还是加上了锁，老师的结论是对的，我也测试过了，但是我不知道如何解释。唯一能想到的解释是order by c desc 并不会改变优化2这个原则：即等值查询时，会向右遍历</p>
<p>且最后一个值不满足等值条件；同时order by c desc 带来一个类似于优化2的向左遍历原则。进而导致最后的锁范围是(5,25)；而没有order by c desc的范围是(10,25]。2019-01-03</p>
<p>  作者回复</p>
<p>因为执行c&#x3D;20的时候，由于要order by c desc, 就要先找到“最右边第一个c&#x3D;20的行”，</p>
<p>这个怎么找呢，只能向右找到25，才能知道它左边那个20是“最右的20”</p>
<p>我的问题是：</p>
<ol>
<li>按照老师您说的，先找c&#x3D;20，由于是order by c desc，所以要找最右边的20，即找到25。那</li>
</ol>
<p>如果c是唯一索引呢？是不是就不会找到25了（是否会加 (20,25) 的gap lock）？我把语句改造</p>
<p>了一下，“select * from t_20 where id &gt;&#x3D; 15 and id&lt;&#x3D;20 ORDER BY id desc lock in share mode</p>
<p>;”。发现当 session A 执行完这行语句不提交的时候，session B 执行 “insert into t_20 values(2</p>
<p>4,24,24);” 是阻塞的。也就是说也加了(20,25)的间隙锁。这又是为什么呢？2. 间隙锁本身不冲突，但和插入语句冲突。那么delete语句呢?</p>
<p>我做了个如下实验（以下语句按时间顺序排序）：</p>
<p>session A</p>
<p>begin;</p>
<p>select * from t_20 where c&#x3D;10 lock in share mode;</p>
<p>session B</p>
<p>delete from t_20 where c&#x3D;15;</p>
<p>insert into t_20 values(16,16,16); </p>
<p>(blocked)</p>
<p>session B 中第一条delete语句执行正常，第二条insert语句被阻塞。我的分析是：session A在索引c上的锁是：(5,10] (10,15)；当session B把(15,15,15)这条记录删</p>
<p>了之后，(10,15)的间隙就不存在了，所以此时session A在索引c上的锁变为：(5,10] (10,20)。这时再在session B中插入(16,16,16)就被阻塞了。这个分析正确吗？2019-01-04</p>
<p> 作者回复</p>
<p>对，我在第30篇会说到这个问题哈</p>
<p>2019-01-10</p>
<p>不二   0</p>
<p>老师，曾剑同学的问题</p>
<p>关于上期遗留问题的解答，我有一点疑惑：</p>
<p>解答中的1中，第一个要定位的是索引 c 上“最右边的”c&#x3D;20 的行，为啥只会加上间隙锁（20,25</p>
<p>）和next-key lock(15,20]呢，为啥不是两个next-key lock(15,20]和(20,25]呢？25上的行锁难道</p>
<p>是退化的？老师上一篇文章中说到加锁的基本原则中第一点是加锁的基本单位是next-key lock</p>
<p>，而退化都是基于索引上的等值查询才会发生呀？盼老师指点迷津。您给回答是定位到c&#x3D;20的时候，是等值查询，所以加的是(20,25)的间隙锁，25的行锁退化了，</p>
<p>那么在上一期中的案例五：唯一索引范围锁 bug，那id&lt;&#x3D;15,不也是先定位到id&#x3D;15，然后向右扫</p>
<p>描，那应该也是等值查询，那么应该加的是（15，20）间隙锁，那为啥你说的加的是（15，20]</p>
<p>,为啥这个id&#x3D;20的行锁也加上了呢，为啥同样是范围查询，一个行锁退化了，一个没有退化呢</p>
<p>，求老师指点迷津</p>
<p>2019-01-04</p>
<p> 作者回复</p>
<ol>
<li><p>第一次就是找c&#x3D;20,这个就是一次等值查找</p>
</li>
<li><p>案例5那个，等值查的是id&#x3D;10,然后向右遍历。这两个，一个是有order by desc,索引的扫描方</p>
</li>
</ol>
<p>向不一样，“找第一个”的值也是不一样的</p>
<p>2019-01-04</p>
<p>张永志   0</p>
<p>说一个锁全库(schema)的案例，数据库晚间定时任务执行CTAS操作，由于需要执行十几分钟</p>
<p>，导致严重会话阻塞，全库所有表上的增删改查全被阻塞。后改为先建表再插数解决。2019-01-04</p>
<p> 作者回复</p>
<p>嗯嗯。看来你也是趟过好多坑啦，</p>
<p>CTAS不是好用法 </p>
<p>2019-01-04</p>
<p>张永志   0</p>
<p>我是从Oracle转到MySQL来的，先接触的Oracle再看MySQL就经常喜欢拿两者对比，包括表数</p>
<p>据存储结构，二级索引的异同，redo，binlog，锁机制，以及默认隔离级别。研究锁后，根据自己的理解得出一个结论，MySQL默认隔离级别选为RR也是无奈之举！</p>
<p>因为当时binlog还是语句格式，为了保证binlog事务顺序正确就得有gap和next key锁。而对开发人员来说，他们未必清楚事务隔离级别，且大多数开发都是从Oracle转向MySQL的，</p>
<p>故果断将隔离级别全部调整为RC。2019-01-04</p>
<p> 作者回复</p>
<p>是的，以前有很多oracle专家，然后大家就觉得RC够用。不过他们不是“以为够用”，他们是真的分析过业务场景，分析业务的用法，确认够用。这种是</p>
<p>很好的实践</p>
<p>2019-01-04</p>
<p>张永志   0</p>
<p>分享一个主从切换时遇到的问题，主从切换前主库要改为只读，设置只读后，show master sta</p>
<p>tus发现binlog一直在变化，当时应用没断开。主库并不是其他库的从库，怎么搞的呢？检查业务用户权限发现拥有super权限，查看授权语句原来是grant all on <em>.</em> to user，这里要说</p>
<p>的是*.* 权限就太大了，而且这个也很容易被误解，需要特别注意。2019-01-04</p>
<p> 作者回复</p>
<p>对的，readonly对super无效；</p>
<p>一方面是尽量不要给业务super</p>
<p>一方面你做完readonly还会去确认binlog有没有变，这个意识很好哦</p>
<p>2019-01-04</p>
<p>张永志   0</p>
<p>小系统，昨天一直报CPU使用率高，报警阈值设定为CPU平均使用率0.8。登录看进程都在执行同一条SQL，活动会话有40个，主机逻辑CPU只有4个，这负载能不高吗</p>
<p>？检查SQL，表很小不到两万行，创建一个复合索引后，负载立刻就消失不见啦 </p>
<p>2019-01-04</p>
<p> 作者回复</p>
<p>   立竿见影</p>
<p>2019-01-04</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/e1607c99.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/e1607c99.html" class="post-title-link" itemprop="url">mysql-为什么我只改一行的语句锁这么多</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-26 06:13:30" itemprop="dateCreated datePublished" datetime="2019-11-26T06:13:30+08:00">2019-11-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>28 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>21 | 为什么我只改一行的语句，锁这么多？2018-12-31 林晓斌</p>
<p>在上一篇文章中，我和你介绍了间隙锁和next-key lock的概念，但是并没有说明加锁规则。间隙</p>
<p>锁的概念理解起来确实有点儿难，尤其在配合上行锁以后，很容易在判断是否会出现锁等待的问</p>
<p>题上犯错。所以今天，我们就先从这个加锁规则开始吧。首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是</p>
<p>想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷</p>
<p>了代码临时总结出来的。所以，这个规则有以下两条前提说明：</p>
<ol>
<li>MySQL后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即</li>
</ol>
<p>5.x系列&lt;&#x3D;5.7.24，8.0系列 &lt;&#x3D;8.0.13。2. 如果大家在验证中有发现bad case的话，请提出来，我会再补充进这篇文章，使得一起学习</p>
<p>本专栏的所有同学都能受益。因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认</p>
<p>是可重复读隔离级别。我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。1. 原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。2. 原则2：查找过程中访问到的对象才会加锁。3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key</p>
<p>lock退化为间隙锁。5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。我还是以上篇文章的表t为例，和你解释一下这些规则。表t的建表语句和初始化语句如下。接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能</p>
<p>会“毁三观”，也建议你读完文章后亲手实践一下。案例一：等值查询间隙锁</p>
<p>第一个例子是关于等值条件操作间隙：</p>
<p>图1 等值查询的间隙锁</p>
<p>由于表t中没有id&#x3D;7的记录，所以用我们上面提到的加锁规则判断一下的话：</p>
<p>CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  &#96;d  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  KEY &#96;c  ̀(̀ c )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t values(0,0,0),(5,5,5),</p>
<p>(10,10,10),(15,15,15),(20,20,20),(25,25,25);</p>
<ol>
<li><p>根据原则1，加锁单位是next-key lock，session A加锁范围就是(5,10]；</p>
</li>
<li><p>同时根据优化2，这是一个等值查询(id&#x3D;7)，而id&#x3D;10不满足查询条件，next-key lock退化成间</p>
</li>
</ol>
<p>隙锁，因此最终加锁的范围是(5,10)。所以，session B要往这个间隙里面插入id&#x3D;8的记录会被锁住，但是session C修改id&#x3D;10这行是可</p>
<p>以的。案例二：非唯一索引等值锁</p>
<p>第二个例子是关于覆盖索引上的锁：</p>
<p>图2 只加在非唯一索引上的锁</p>
<p>看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。这里session A要给索引c上c&#x3D;5的这一行加上读锁。1. 根据原则1，加锁单位是next-key lock，因此会给(0,5]加上next-key lock。2. 要注意c是普通索引，因此仅访问c&#x3D;5这一条记录是不能马上停下来的，需要向右遍历，查到</p>
<p>c&#x3D;10才放弃。根据原则2，访问到的都要加锁，因此要给(5,10]加next-key lock。3. 但是同时这个符合优化2：等值判断，向右遍历，最后一个值不满足c&#x3D;5这个等值条件，因此</p>
<p>退化成间隙锁(5,10)。4. 根据原则2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索</p>
<p>引，所以主键索引上没有加任何锁，这就是为什么session B的update语句可以执行完成。但session C要插入一个(7,7,7)的记录，就会被session A的间隙锁(5,10)锁住。需要注意，在这个例子中，lock in share mode只锁覆盖索引，但是如果是for update就不一样</p>
<p>了。 执行 for update时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的</p>
<p>行加上行锁。这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用lock in share mode</p>
<p>来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不</p>
<p>存在的字段。比如，将session A的查询语句改成select d from t where c&#x3D;5 lock in share mode。你可以自己验证一下效果。案例三：主键索引范围锁</p>
<p>第三个例子是关于范围查询的。举例之前，你可以先思考一下这个问题：对于我们这个表t，下面这两条查询语句，加锁范围相</p>
<p>同吗？你可能会想，id定义为int类型，这两个语句就是等价的吧？其实，它们并不完全等价。在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让</p>
<p>session A执行第二个查询语句，来看看加锁效果。图3 主键索引上范围查询的锁</p>
<p>现在我们就用前面提到的加锁规则，来分析一下session A 会加什么锁呢？mysql&gt; select * from t where id&#x3D;10 for update;</p>
<p>mysql&gt; select * from t where id&gt;&#x3D;10 and id&lt;11 for update;</p>
<ol>
<li>开始执行的时候，要找到第一个id&#x3D;10的行，因此本该是next-key lock(5,10]。 根据优化1，</li>
</ol>
<p>主键id上的等值条件，退化成行锁，只加了id&#x3D;10这一行的行锁。2. 范围查找就往后继续找，找到id&#x3D;15这一行停下来，因此需要加next-key lock(10,15]。所以，session A这时候锁的范围就是主键索引上，行锁id&#x3D;10和next-key lock(10,15]。这</p>
<p>样，session B和session C的结果你就能理解了。这里你需要注意一点，首次session A定位查找id&#x3D;10的行的时候，是当做等值查询来判断的，而</p>
<p>向右扫描到id&#x3D;15的时候，用的是范围查询判断。案例四：非唯一索引范围锁</p>
<p>接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。需要注意的是，与案例三不同的是，案例四中查询语句的where部分用的是字段c。图4 非唯一索引范围锁</p>
<p>这次session A用字段c来判断，加锁规则跟案例三唯一的不同是：在第一次用c&#x3D;10定位记录的时</p>
<p>候，索引c上加了(5,10]这个next-key lock后，由于索引c是非唯一索引，没有优化规则，也就是</p>
<p>说不会蜕变为行锁，因此最终sesion A加的锁是，索引c上的(5,10] 和(10,15] 这两个next-key</p>
<p>lock。所以从结果上来看，sesson B要插入（8,8,8)的这个insert语句时就被堵住了。这里需要扫描到c&#x3D;15才停止扫描，是合理的，因为InnoDB要扫到c&#x3D;15，才知道不需要继续往后</p>
<p>找了。案例五：唯一索引范围锁bug</p>
<p>前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁</p>
<p>规则中bug的案例。图5 唯一索引范围锁的bug</p>
<p>session A是一个范围查询，按照原则1的话，应该是索引id上只加(10,15]这个next-key lock，并</p>
<p>且因为id是唯一键，所以循环判断到id&#x3D;15这一行就应该停止了。但是实现上，InnoDB会往前扫描到第一个不满足条件的行为止，也就是id&#x3D;20。而且由于这是个</p>
<p>范围扫描，因此索引id上的(15,20]这个next-key lock也会被锁上。所以你看到了，session B要更新id&#x3D;20这一行，是会被锁住的。同样地，session C要插入id&#x3D;16</p>
<p>的一行，也会被锁住。照理说，这里锁住id&#x3D;20这一行的行为，其实是没有必要的。因为扫描到id&#x3D;15，就可以确定不用</p>
<p>往后再找了。但实现上还是这么做了，因此我认为这是个bug。我也曾找社区的专家讨论过，官方bug系统上也有提到，但是并未被verified。所以，认为这是</p>
<p>bug这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。案例六：非唯一索引上存在”等值”的例子</p>
<p>接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表t插入一条新记录。新插入的这一行c&#x3D;10，也就是说现在表里有两个c&#x3D;10的行。那么，这时候索引c上的间隙是什么</p>
<p>状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。mysql&gt; insert into t values(30,10,30);</p>
<p>图6 非唯一索引等值的例子</p>
<p>可以看到，虽然有两个c&#x3D;10，但是它们的主键值id是不同的（分别是10和30），因此这两个</p>
<p>c&#x3D;10的记录之间，也是有间隙的。图中我画出了索引c上的主键id。为了跟间隙锁的开区间形式进行区别，我用(c&#x3D;10,id&#x3D;30)这样的</p>
<p>形式，来表示索引上的一行。现在，我们来看一下案例六。这次我们用delete语句来验证。注意，delete语句加锁的逻辑，其实跟select … for update 是类</p>
<p>似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。图7 delete 示例</p>
<p>这时，session A在遍历的时候，先访问第一个c&#x3D;10的记录。同样地，根据原则1，这里加的是</p>
<p>(c&#x3D;5,id&#x3D;5)到(c&#x3D;10,id&#x3D;10)这个next-key lock。然后，session A向右查找，直到碰到(c&#x3D;15,id&#x3D;15)这一行，循环才结束。根据优化2，这是一个</p>
<p>等值查询，向右查找到了不满足条件的行，所以会退化成(c&#x3D;10,id&#x3D;10) 到 (c&#x3D;15,id&#x3D;15)的间隙</p>
<p>锁。也就是说，这个delete语句在索引c上的加锁范围，就是下图中蓝色区域覆盖的部分。图8 delete加锁效果示例</p>
<p>这个蓝色区域左右两边都是虚线，表示开区间，即(c&#x3D;5,id&#x3D;5)和(c&#x3D;15,id&#x3D;15)这两行上都没有锁。案例七：limit 语句加锁</p>
<p>例子6也有一个对照案例，场景如下所示：</p>
<p>图9 limit 语句加锁</p>
<p>这个例子里，session A的delete语句加了 limit 2。你知道表t里c&#x3D;10的记录其实只有两条，因此</p>
<p>加不加limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B的insert</p>
<p>语句执行通过了，跟案例六的结果不同。这是因为，案例七里的delete语句明确加了limit 2的限制，因此在遍历到(c&#x3D;10, id&#x3D;30)这一行之</p>
<p>后，满足条件的语句已经有两条，循环就结束了。因此，索引c上的加锁范围就变成了从（c&#x3D;5,id&#x3D;5)到（c&#x3D;10,id&#x3D;30)这个前开后闭区间，如下图所</p>
<p>示：</p>
<p>图10 带limit 2的加锁效果</p>
<p>可以看到，(c&#x3D;10,id&#x3D;30）之后的这个间隙并没有在加锁范围里，因此insert语句插入c&#x3D;12是可以</p>
<p>执行成功的。这个例子对我们实践的指导意义就是，在删除数据的时候尽量加limit。这样不仅可以控制删除</p>
<p>数据的条数，让操作更安全，还可以减小加锁的范围。案例八：一个死锁的例子</p>
<p>前面的例子中，我们在分析的时候，是按照next-key lock的逻辑来分析的，因为这样分析比较方</p>
<p>便。最后我们再看一个案例，目的是说明：next-key lock实际上是间隙锁和行锁加起来的结果。你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：</p>
<p>图11 案例八的操作序列</p>
<p>现在，我们按时间顺序来分析一下为什么是这样的结果。1. session A 启动事务后执行查询语句加lock in share mode，在索引c上加了next-key</p>
<p>lock(5,10] 和间隙锁(10,15)；</p>
<ol start="2">
<li><p>session B 的update语句也要在索引c上加next-key lock(5,10] ，进入锁等待；</p>
</li>
<li><p>然后session A要再插入(8,8,8)这一行，被session B的间隙锁锁住。由于出现了死</p>
</li>
</ol>
<p>锁，InnoDB让session B回滚。你可能会问，session B的next-key lock不是还没申请成功吗？其实是这样的，session B的“加next-key lock(5,10] ”操作，实际上分成了两步，先是加(5,10)的间</p>
<p>隙锁，加锁成功；然后加c&#x3D;10的行锁，这时候才被锁住的。也就是说，我们在分析加锁规则的时候可以用next-key lock来分析。但是要知道，具体执行的时</p>
<p>候，是要分成间隙锁和行锁两段来执行的。小结</p>
<p>这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别(repeatable-read)下验证</p>
<p>的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的</p>
<p>时候才释放的。在最后的案例中，你可以清楚地知道next-key lock实际上是由间隙锁加行锁实现的。如果切换到</p>
<p>读提交隔离级别(read-committed)的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下</p>
<p>行锁的部分。其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成</p>
<p>后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提</p>
<p>交隔离级别的原因。不过，我希望你学过今天的课程以后，可以对next-key lock的概念有更清晰的认识，并且会用加</p>
<p>锁规则去判断语句的加锁范围。在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题</p>
<p>的同时，最大限度地提升系统并行处理事务的能力。经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。我把题目重新描述和简化一下：还是我们在文章开头初始化的表t，里面有6条记录，图12的语句</p>
<p>序列中，为什么session B的insert操作，会被锁住呢？图12 锁分析思考题</p>
<p>另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然</p>
<p>后实际地验证结果是否跟你的分析一致。对于那些你自己无法解释的结果，可以发到评论区里，后面我争取挑一些有趣的案例在文章中分</p>
<p>析。你可以把你关于思考题的分析写在留言区，也可以分享你自己设计的锁验证方案，我会在下一篇</p>
<p>文章的末尾选取有趣的评论跟大家分享。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友</p>
<p>一起阅读。上期问题时间</p>
<p>上期的问题，我在本期继续作为了课后思考题，所以会在下篇文章再一起公布“答案”。这里，我展开回答一下评论区几位同学的问题。@令狐少侠 说，以前一直认为间隙锁只在二级索引上有。现在你知道了，有间隙的地方就可</p>
<p>能有间隙锁。@浪里白条 同学问，如果是varchar类型，加锁规则是什么样的。回答：实际上在判断间隙的时候，varchar和int是一样的，排好序以后，相邻两个值之间就有</p>
<p>间隙。有几位同学提到说，上一篇文章自己验证的结果跟案例一不同，就是在session A执行完这两</p>
<p>个语句：</p>
<p>以后，session B 的update 和session C的insert 都会被堵住。这是不是跟文章的结论矛盾？其实不是的，这个例子用的是反证假设，就是假设不堵住，会出现问题；然后，推导出session</p>
<p>A需要锁整个表所有的行和所有间隙。评论区留言点赞板：</p>
<p>begin;</p>
<p>select * from t where d&#x3D;5 for update; &#x2F;<em>Q1</em>&#x2F;</p>
<p>@ 某、人 、@郭江伟 两位同学尝试分析了上期问题，并给了有启发性的解答。堕落天使   1</p>
<p>老师，您好。假期的没跟上，今天补到了这节课，看了之后有几点不是太明白。望能解答一下</p>
<p>。1. 索引c上的锁算不算是行锁。假如索引c上的next-key lock为(0,5] (5,10]，那么5算不算是c上</p>
<p>的行锁？2. 在案例六中，执行 “delete from t where c&#x3D;10;” 语句，索引c上的next-key lock是(5,10],(10,10]</p>
<p>,(10,15)。那么主键索引上的锁是什么呢？是只有行锁，锁住的是 (10,10,10) 和 (30,10,30) 两行</p>
<p>吗？3. 也是在案例六中，session A不变，在session B中执行 “update t_20 set d&#x3D;50 where c&#x3D;5;”、“</p>
<p>update t_20 set d&#x3D;50 where c&#x3D;15;”、“insert into t_20 values(40,15,40);”均执行成功，但执行“ins</p>
<p>ert into t_20 values(50,5,50);” 时，却被阻塞。为什么呢？具体执行语句如下</p>
<p>session A</p>
<p>mysql&gt; begin;</p>
<p>mysql&gt; explain delete from t_20 where c&#x3D;10;</p>
<p>id select_type table partitions type possible_keys key key_len ref rows filtered Extra</p>
<p>1 DELETE t_20 range c c 5 const 2 100 Using where</p>
<p>mysql&gt; delete from t_20 where c&#x3D;10;</p>
<p>session B</p>
<p>mysql&gt; update t_20 set d&#x3D;50 where c&#x3D;5;</p>
<p>Query OK, 1 row affected (0.01 sec)</p>
<p>Rows matched: 1 Changed: 1 Warnings: 0</p>
<p>mysql&gt; update t_20 set d&#x3D;50 where c&#x3D;15;</p>
<p>Query OK, 1 row affected (0.00 sec)</p>
<p>Rows matched: 1 Changed: 1 Warnings: 0</p>
<p>mysql&gt; insert into t_20 values(40,15,40);</p>
<p>Query OK, 1 row affected (0.00 sec)</p>
<p>mysql&gt; explain insert into t_20 values(50,5,50);</p>
<p>+—-+————-+——-+————+——+—————+——+———+——+——+———-+——-+</p>
<p>| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | </p>
<p>Extra |</p>
<p>+—-+————-+——-+————+——+—————+——+———+——+——+———-+——-+</p>
<p>| 1 | INSERT | t_20 | NULL | ALL | c | NULL | NULL | NULL | NULL | NULL | NULL |</p>
<p>+—-+————-+——-+————+——+—————+——+———+——+——+———-+——-+</p>
<p>1 row in set (0.00 sec)</p>
<p>mysql&gt; insert into t_20 values(50,5,50);</p>
<p>（block）</p>
<p>精选留言</p>
<p>我使用的mysql版本是：5.7.23-0ubuntu0.16.04.1</p>
<p>show variables的结果太多，我截取了一部分，或许对您分析有帮助：</p>
<p>innodb_version 5.7.23</p>
<p>protocol_version 10</p>
<p>slave_type_conversions </p>
<p>tls_version TLSv1,TLSv1.1</p>
<p>version 5.7.23-0ubuntu0.16.04.1</p>
<p>version_comment (Ubuntu)</p>
<p>version_compile_machine x86_64</p>
<p>version_compile_os Linux</p>
<p>2019-01-03</p>
<p> 作者回复</p>
<ol>
<li><p>Next-key lock 就是间隙锁 行锁，所以包含&#x3D;5这一行</p>
</li>
<li><p>对</p>
</li>
<li><p>(c&#x3D;5,id&#x3D;50)是在这个gap里哦，你试试插入(1,5,50)对比一下。好问题</p>
</li>
</ol>
<p>2019-01-03</p>
<p>张三   25</p>
<p>Happy New Year !这个专栏绝对是极客时间最好我买过最值的专栏。2018-12-31</p>
<p>约书亚   12</p>
<p>早晨睡不着打开极客时间一看，竟然更新了。今天是周日而且在假期中哎…</p>
<p>2018-12-31</p>
<p> 作者回复</p>
<p>风雨无阻 节假日不休，包括元旦和春节 </p>
<p>2018-12-31</p>
<p>HuaMax   4</p>
<p>首先老师新年快乐，学习专栏受益良多！</p>
<p>上期问过老师的问题已了解答案，锁是加在索引上的。再尝试回答问题。c上是普通索引，根据</p>
<p>原则2，访问到的都要加锁，在查询c&gt;&#x3D;15这个条件时，在查找到15后加锁（10，15］，继续往</p>
<p>右查找，按理说不会锁住6这个索引值，但查询语句中加了order by c desc，我猜想会优化为使</p>
<p>用c&lt;&#x3D;20这条语句，查找到20后往左查找，这样会访问到15左边的值10，从而加锁（5，10］</p>
<p>，不知我理解对否？2019-01-01</p>
<p> 作者回复</p>
<p>新年好</p>
<p>对的  </p>
<p>2019-01-01</p>
<p>郭江伟   4</p>
<p>郭江伟   4</p>
<p>老师这次的留下的问题，语句跟上次不一样，上期问题语句是select id from t where c&gt;&#x3D;15 and</p>
<p>c&lt;&#x3D;20 order by c desc for update;；这次缺少了 order by c desc ，不加desc的话insert into t val</p>
<p>ues(6,6,6);不会被堵塞；</p>
<p>根据优化3：索引上的等值查询，在向右遍历时且最后一个值不满足等值条件的时候next-key lo</p>
<p>ck退化为间隙锁；</p>
<p>问题中的sql语句加了desc ，是向左扫描，该优化用不上，所以下限10是闭区间，为了防止c为</p>
<p>10的行加入，需要锁定到索引c键（5,5）</p>
<p>此例中insert into t values(6,5,6) 会堵塞，insert into t values(4,5,6) 不会堵塞，</p>
<p>2018-12-31</p>
<p> 作者回复</p>
<p>嗯你说的对</p>
<p>不过是我少打一个词了，加上去了，要desc哦</p>
<p>重新分析下 </p>
<p>2018-12-31</p>
<p>undifined   3</p>
<p>遇到一个有趣的问题，在老师的解答下终于弄明白了：</p>
<p>CREATE TABLE z (</p>
<p>id INT PRIMARY KEY AUTO_INCREMENT,</p>
<p>b INT,</p>
<p>KEY b(b)</p>
<p>)</p>
<p>ENGINE &#x3D; InnoDB</p>
<p>DEFAULT CHARSET &#x3D; utf8;</p>
<p>INSERT INTO z (id, b)</p>
<p>VALUES (1, 2),</p>
<p>(3, 4),</p>
<p>(5, 6),</p>
<p>(7, 8),</p>
<p>(9, 10);</p>
<p>session A</p>
<p>BEGIN;</p>
<p>SELECT *</p>
<p>FROM z</p>
<p>WHERE b &#x3D; 6 FOR UPDATE;</p>
<p>session B </p>
<p>INSERT INTO z VALUES (0, 4);</p>
<p>这里为什么会被锁住</p>
<p>答案比较长，写在我自己的笔记里了，地址是 <a target="_blank" rel="noopener" href="https://helloworlde.github.io/blog/blog/MySQL/M">https://helloworlde.github.io/blog/blog/MySQL/M</a></p>
<p>ySQL-%E4%B8%AD%E5%85%B3%E4%BA%8Egap-lock-next-key-lock-%E7%9A%84%E4%B</p>
<p>8%80%E4%B8%AA%E9%97%AE%E9%A2%98.html</p>
<p>大家可以看看</p>
<p>2019-01-07</p>
<p> 作者回复</p>
<p>好问题，质量很高的笔记</p>
<p>2019-01-10</p>
<p>乾坤   3</p>
<p>您好，关于”优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，ne</p>
<p>xt-key lock 退化为间隙锁。”，我觉得改为”从第一个满足等值条件的索引记录开始向右遍历到</p>
<p>第一个不满足等值条件记录，并将第一个不满足等值条件记录上的next-key lock 退化为间隙锁”</p>
<p>更明确些</p>
<p>2019-01-01</p>
<p> 作者回复</p>
<p>感觉没大差别，嗯嗯，理解就好 </p>
<p>2019-01-02</p>
<p>Geek_9ca34e   2</p>
<p>老师，你好：</p>
<p>我练习实例的时候发现一个问题：如 案例五：唯一索引范围锁 bug</p>
<p>begin;</p>
<p>select * from t where id&gt;10 and id&lt;&#x3D;15 for update;</p>
<p>1、执行如上语句加锁范围(10,15]和(15,20]；</p>
<p>2、因为10未加锁，所以我单独再开一个连接，执行delete from t where id&#x3D;10;不会锁等待，能</p>
<p>正常删除；</p>
<p>3、但是我再执行insert into t values(10,10,10); 语句会等待，无法正常执行；</p>
<p>4、经过分析我发现第一个连接执行的语句的加锁范围已经变成(5,15]和(15,20]，代表锁蔓延了</p>
<p>；这是什么原因呢？2019-01-09</p>
<p> 作者回复</p>
<p>好问题，我会加到答疑文章中，</p>
<p>Gap是一个动态的概念</p>
<p>2019-01-09</p>
<p>往事随风，顺其自然   2</p>
<p>这和分两步有什么关系？(5,10]已经是被锁住，分不分两步来加锁，这个间隙和行锁都被锁住了，session b应该是拿不</p>
<p>到锁才对。2019-01-01</p>
<p>happy涛   1</p>
<p>老师：同上一个问题。 还是案例2. select id from t where c&#x3D;6 for update;</p>
<p>ID为[0,9)都不可以添加，包括-1都可以。为啥会锁这么多。而c锁的是[5,10),大于等于5，小于1</p>
<p>0</p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p>select id from t where c&#x3D;6 for update;</p>
<p>这个在c上的锁是（5，10）这个间隙</p>
<p>2019-01-23</p>
<p>往事随风，顺其自然   1</p>
<p>session A</p>
<p>mysql&gt; select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc lock in share mode;</p>
<p>+—-+——+——+</p>
<p>| id | c | d |</p>
<p>+—-+——+——+</p>
<p>| 20 | 20 | 20 |</p>
<p>| 15 | 15 | 15 |</p>
<p>+—-+——+——+</p>
<p>2 rows in set (0.00 sec)</p>
<p>session b</p>
<p>mysql&gt; insert into t values(6,6,6);</p>
<p>Query OK, 1 row affected (0.00 sec)</p>
<p>可以插入成功，没有被锁住</p>
<p>2019-01-01</p>
<p> 作者回复</p>
<p>Explain结果发一下，还有show variables 结果也发下</p>
<p>2019-01-02</p>
<p>是我的海   0</p>
<p>全是干货赞赞赞，以后出去面试再也不怕面试官装X问锁的问题了</p>
<p>2019-01-31</p>
<p> 作者回复</p>
<p>一定要低调哈 </p>
<p>如果面试的时候能够让大家回答更有底气，那就太好啦 </p>
<p>2019-01-31</p>
<p>时隐时现   0</p>
<p>不好意思，这次又来晚了，看这种连载技术文章，和看小说一样，养肥了集中看~~</p>
<p>这次的问题如下，希望丁老师有空解答一下。版本：mysql 5.6.39</p>
<p>CREATE TABLE <code>t</code> (</p>
<p><code>a</code> int(11) NOT NULL,</p>
<p><code>b</code> int(11) DEFAULT NULL</p>
<p>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;</p>
<p>insert into t values(1,1),(2,2),(3,3),(4,4),(5,5);</p>
<p>采用READ-COMMITTED隔离级别</p>
<p>案例1、</p>
<p>session A：</p>
<p>begin;</p>
<p>update t set a&#x3D;6 where b&#x3D;1;</p>
<p>session B：</p>
<p>begin;</p>
<p>update t set a&#x3D;7 where b&#x3D;2;</p>
<p>A和B均能执行成功</p>
<p>问题1：官档上说对于RC且全表扫描的update，先逐行添加行锁然后释放掉不符合where条件</p>
<p>的，那么session A成功对(1,1)加锁，理论上session B在扫描(1,1)并尝试加锁时会被阻塞，为</p>
<p>何还能执行成功？官档链接：<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isol">https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isol</a></p>
<p>ation-levels.html</p>
<p>案例2：</p>
<p>session A：</p>
<p>begin;</p>
<p>update t set a&#x3D;6 where b&#x3D;1;</p>
<p>session B：</p>
<p>begin;</p>
<p>delete from t where b&#x3D;2; – 被阻塞</p>
<p>问题2：为何案例1 中的session B不会被阻塞，而案例2的却被session A的行数阻塞，update和</p>
<p>delete都是全部扫描，难道加锁机制不一样？2019-01-30</p>
<p> 作者回复</p>
<p>好问题，在read-commited隔离级别下，update语句</p>
<p>有一个“semi-consistent” read优化，</p>
<p>意思是，如果update语句碰到一个已经被锁了的行，会读入最新的版本，然后判断一下是不是</p>
<p>满足查询条件，</p>
<p>a)如果不满足，就直接跳过；</p>
<p>b) 如果满足，才进入锁等待</p>
<p>你的第二个问题：这个策略，只对update有效，delete无效</p>
<p>新春快乐~</p>
<p>2019-02-04</p>
<p>Leon    0</p>
<p>老师，案例八session B的操作语句update t set d &#x3D; d + 1 where c &#x3D;10; 由于c是非唯一键索引，</p>
<p>锁（5，10」可以理解</p>
<p>，为什么不锁(10,15} 呢，不是应该继续向后扫描直到第一个不满足条件的值为止吗</p>
<p>2019-01-29</p>
<p> 作者回复</p>
<p>好问题，新年快乐</p>
<p>会锁的，只是因为在(5,10]就被锁住了，所以后面的锁加不上去了 </p>
<p>2019-02-01</p>
<p>happy涛   0</p>
<p>老师：</p>
<p>环境同上. QQ466096028</p>
<p>案二：案三也不对。案例五：b事物也可以执行成功， 16，16，16我也可以写入 ，id（10,15）不可以。案例六：我没有添加C10,ID30的数。还是用0，5，10，15，20，25这几条数据， 案例六中的</p>
<p>代码执行结果是ID（10，15），c(5,15) .. </p>
<p>头好疼，感觉理不清，规则太乱了。2019-01-23</p>
<p> 作者回复</p>
<p>啊 已经是我简化过的规则了。。需要再理解一下。。你用session A、sessionB这种模式列一下复现步骤，哪个不清楚的，我们一个个来看吧</p>
<p>2019-01-23</p>
<p>happy涛   0</p>
<p>老师：</p>
<p>案例二：非唯一索引等值锁，这个文章中，事物A加读取之后， 按您的文章走，最后结果加的</p>
<p>是（5，10）间隙锁， 但我这里为什么插入，c从[0,9)都不能插入。mysql版本是8.0.12,隔离级别是RR，表用的是您的例子，数据也是。2019-01-23</p>
<p> 作者回复</p>
<p>不是哦</p>
<p>案例二的语句是 where c&#x3D;5 lock in share mode, 这个在c上的加锁范围是(5,10)</p>
<p>2019-01-23</p>
<p>alias cd&#x3D;rm -rf   0</p>
<p>思考题：</p>
<p>order by desc优化器会向左遍历</p>
<p>1、先判断条件c&lt;&#x3D;20，普通索引等值c&#x3D;20，所以next-key-lock:（25，20]</p>
<p>2、20到15，所以next-key-lock:（20，15]</p>
<p>3、判断c&gt;&#x3D;15，普通索引c&#x3D;15，继续向左遍历到c&#x3D;5不符合条件，并且优化2等值第一个不符</p>
<p>合条件的数据降为间隙锁(5,15)</p>
<p>所以锁的范围是(5,15)+[15,20)+[20,25)</p>
<p>2019-01-16</p>
<p> 作者回复</p>
<p>3、判断c&gt;&#x3D;15，普通索引c&#x3D;15，继续向左遍历到c&#x3D;5不符合条件，并且优化2等值第一个不符</p>
<p>合条件的数据降为间隙锁(5,15)</p>
<p>所以锁的范围是(5,15)+[15,20)+[20,25)</p>
<p>这个不太对哈（或者说跟我文章里面说的规则不匹配）。c&gt;&#x3D;15这个条件，只会向左匹配到c&#x3D;10这个记录，</p>
<p>只是因为next-key lock是前开后闭区间，所以就是(5,10].</p>
<p>结论的范围也确实是(5,15)+[15,20)+[20,25)  </p>
<p>2019-01-17</p>
<p>J!   0</p>
<p>select max(id) from tb1 和 select id from tb1 order by id desc limit 1; id 为主键，这个两个的加</p>
<p>索过程都是一样的吗</p>
<p>2019-01-16</p>
<p> 作者回复</p>
<p>都不加锁。。如果你说的是后面加 for update, 加索范围一样的</p>
<p>2019-01-16</p>
<p>任洋   0</p>
<p>老师你好，最近在线上遇到一个问题如下：执行一个简单的update语句更新数据库，where后</p>
<p>面的字段没有索引，这个字段的数据库中值可能有重复，在并发的情况下，会偶发出现数据库</p>
<p>死锁的情况。后面通过，查询出主键，再通过主键进行更新，解决了这个问题，但不明白为什</p>
<p>么会出现死锁的情况，能麻发解释下吗？2019-01-15</p>
<p> 作者回复</p>
<p>update 没索引就是锁住主键索引上所有的行和间隙</p>
<p>锁的内容太多了， 这样确实容易出现死锁哦</p>
<p>2019-01-15</p>
<p>陈   0</p>
<p>老师在案列一中update t set d&#x3D;d+1 where id&#x3D;7 中id是主键也是唯一索引，按优化1应该退化成</p>
<p>行锁才对，为什么insert into t values(8,8,8)会被锁住，我是那儿理解错了?</p>
<p>2019-01-11</p>
<p> 作者回复</p>
<p>这一行存在的时候是行锁，这一行不存在，那就是间隙锁啦。insert into t values(8,8,8)是被主键上(5,10)的间隙锁锁住的</p>
<p>2019-01-11</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/97b6038b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/97b6038b.html" class="post-title-link" itemprop="url">mysql-幻读是什么幻读有什么问题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-25 06:13:13" itemprop="dateCreated datePublished" datetime="2019-11-25T06:13:13+08:00">2019-11-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>8.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>31 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>20 | 幻读是什么，幻读有什么问题？2018-12-28 林晓斌</p>
<p>在上一篇文章最后，我给你留了一个关于加锁规则的问题。今天，我们就从这个问题说起吧。为了便于说明问题，这一篇文章，我们就先使用一个小一点儿的表。建表和初始化语句如下（为</p>
<p>了便于本期的例子说明，我把上篇文章中用到的表结构做了点儿修改）：</p>
<p>这个表除了主键id外，还有一个索引c，初始化语句在表中插入了6行数据。上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  &#96;d  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  KEY &#96;c  ̀(̀ c )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t values(0,0,0),(5,5,5),</p>
<p>(10,10,10),(15,15,15),(20,20,20),(25,25,25);</p>
<p>比较好理解的是，这个语句会命中d&#x3D;5的这一行，对应的主键id&#x3D;5，因此在select 语句执行完成</p>
<p>后，id&#x3D;5这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行commit语句的时候释</p>
<p>放。由于字段d上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足</p>
<p>条件的5行记录上，会不会被加锁呢？我们知道，InnoDB的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都</p>
<p>是设定在可重复读隔离级别下。幻读是什么？现在，我们就来分析一下，如果只在id&#x3D;5这一行加锁，而其他行的不加锁的话，会怎么样。下面先来看一下这个场景（注意：这是我假设的一个场景）：</p>
<p>图 1 假设只在id&#x3D;5这一行加行锁</p>
<p>可以看到，session A里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是</p>
<p>select * from t where d&#x3D;5 for update。这个语句的意思你应该很清楚了，查所有d&#x3D;5的行，而且</p>
<p>使用的是当前读，并且加上写锁。现在，我们来看一下这三条SQL语句，分别会返回什么结果。1. Q1只返回id&#x3D;5这一行；</p>
<p>begin;</p>
<p>select * from t where d&#x3D;5 for update;</p>
<p>commit;</p>
<ol start="2">
<li>在T2时刻，session B把id&#x3D;0这一行的d值改成了5，因此T3时刻Q2查出来的是id&#x3D;0和id&#x3D;5这</li>
</ol>
<p>两行；</p>
<ol start="3">
<li>在T4时刻，session C又插入一行（1,1,5），因此T5时刻Q3查出来的是id&#x3D;0、id&#x3D;1和id&#x3D;5的</li>
</ol>
<p>这三行。其中，Q3读到id&#x3D;1这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查</p>
<p>询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。这里，我需要对“幻读”做一个说明：</p>
<ol>
<li>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，</li>
</ol>
<p>幻读在“当前读”下才会出现。2. 上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。如果只从第8篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的</p>
<p>话，上面这三条SQL语句的返回结果都没有问题。因为这三个查询都是加了for update，都是当前读。而当前读的规则，就是要能读到所有已经提</p>
<p>交的记录的最新值。并且，session B和sessionC的两条语句，执行后就会提交，所以Q2和Q3就</p>
<p>是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。但是，这是不是真的没问题呢？不，这里还真就有问题。幻读有什么问题？首先是语义上的。session A在T1时刻就声明了，“我要把所有d&#x3D;5的行锁住，不准别的事务进行</p>
<p>读写操作”。而实际上，这个语义被破坏了。如果现在这样看感觉还不明显的话，我再往session B和session C里面分别加一条SQL语句，你</p>
<p>再看看会出现什么现象。图 2 假设只在id&#x3D;5这一行加行锁–语义被破坏</p>
<p>session B的第二条语句update t set c&#x3D;5 where id&#x3D;0，语义是“我把id&#x3D;0、d&#x3D;5这一行的c值，改成</p>
<p>了5”。由于在T1时刻，session A 还只是给id&#x3D;5这一行加了行锁， 并没有给id&#x3D;0这行加上锁。因</p>
<p>此，session B在T2时刻，是可以执行这两条update语句的。这样，就破坏了 session A 里Q1语</p>
<p>句要锁住所有d&#x3D;5的行的加锁声明。session C也是一样的道理，对id&#x3D;1这一行的修改，也是破坏了Q1的加锁声明。其次，是数据一致性的问题。我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此</p>
<p>刻的一致性，还包含了数据和日志在逻辑上的一致性。为了说明这个问题，我给session A在T1时刻再加一个更新语句，即：update t set d&#x3D;100 where</p>
<p>d&#x3D;5。图 3 假设只在id&#x3D;5这一行加行锁–数据一致性问题</p>
<p>update的加锁语义和select …for update 是一致的，所以这时候加上这条update语句也很合理。session A声明说“要给d&#x3D;5的语句加上锁”，就是为了要更新数据，新加的这条update语句就是把</p>
<p>它认为加上了锁的这一行的d值修改成了100。现在，我们来分析一下图3执行完成后，数据库里会是什么结果。1. 经过T1时刻，id&#x3D;5这一行变成 (5,5,100)，当然这个结果最终是在T6时刻正式提交的;</p>
<ol start="2">
<li><p>经过T2时刻，id&#x3D;0这一行变成(0,5,5);</p>
</li>
<li><p>经过T4时刻，表里面多了一行(1,5,5);</p>
</li>
<li><p>其他行跟这个执行序列无关，保持不变。这样看，这些数据也没啥问题，但是我们再来看看这时候binlog里面的内容。1. T2时刻，session B事务提交，写入了两条语句；</p>
</li>
<li><p>T4时刻，session C事务提交，写入了两条语句；</p>
</li>
<li><p>T6时刻，session A事务提交，写入了update t set d&#x3D;100 where d&#x3D;5 这条语句。我统一放到一起的话，就是这样的：</p>
</li>
</ol>
<p>好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用binlog来克隆一个</p>
<p>库，这三行的结果，都变成了 (0,5,100)、(1,5,100)和(5,5,100)。也就是说，id&#x3D;0和id&#x3D;1这两行，发生了数据不一致。这个问题很严重，是不行的。到这里，我们再回顾一下，这个数据不一致到底是怎么引入的？我们分析一下可以知道，这是我们假设“select * from t where d&#x3D;5 for update这条语句只给d&#x3D;5这</p>
<p>一行，也就是id&#x3D;5的这一行加锁”导致的。所以我们认为，上面的设定不合理，要改。那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。update t set d&#x3D;5 where id&#x3D;0; &#x2F;<em>(0,0,5)</em>&#x2F;</p>
<p>update t set c&#x3D;5 where id&#x3D;0; &#x2F;<em>(0,5,5)</em>&#x2F;</p>
<p>insert into t values(1,1,5); &#x2F;<em>(1,1,5)</em>&#x2F;</p>
<p>update t set c&#x3D;5 where id&#x3D;1; &#x2F;<em>(1,5,5)</em>&#x2F;</p>
<p>update t set d&#x3D;100 where d&#x3D;5;&#x2F;<em>所有d&#x3D;5的行，d改成100</em>&#x2F;</p>
<p>图 4 假设扫描到的行都被加上了行锁</p>
<p>由于session A把所有的行都加了写锁，所以session B在执行第一个update语句的时候就被锁住</p>
<p>了。需要等到T6时刻session A提交以后，session B才能继续执行。这样对于id&#x3D;0这一行，在数据库里的最终结果还是 (0,5,5)。在binlog里面，执行序列是这样的：</p>
<p>可以看到，按照日志顺序执行，id&#x3D;0这一行的最终结果也是(0,5,5)。所以，id&#x3D;0这一行的问题解</p>
<p>决了。但同时你也可以看到，id&#x3D;1这一行，在数据库里面的结果是(1,5,5)，而根据binlog的执行结果是</p>
<p>(1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都</p>
<p>上了锁，还是阻止不了id&#x3D;1这一行的插入和更新呢？原因很简单。在T3时刻，我们给所有行加锁的时候，id&#x3D;1这一行还不存在，不存在也就加不上</p>
<p>锁。也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻</p>
<p>读”会被单独拿出来解决的原因。到这里，其实我们刚说明完文章的标题 ：幻读的定义和幻读有什么问题。接下来，我们再看看InnoDB怎么解决幻读的问题。如何解决幻读？现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记</p>
<p>录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap</p>
<p>Lock)。顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表t，初始化插入了6个记录，</p>
<p>这就产生了7个间隙。insert into t values(1,1,5); &#x2F;<em>(1,1,5)</em>&#x2F;</p>
<p>update t set c&#x3D;5 where id&#x3D;1; &#x2F;<em>(1,5,5)</em>&#x2F;</p>
<p>update t set d&#x3D;100 where d&#x3D;5;&#x2F;<em>所有d&#x3D;5的行，d改成100</em>&#x2F;</p>
<p>update t set d&#x3D;5 where id&#x3D;0; &#x2F;<em>(0,0,5)</em>&#x2F;</p>
<p>update t set c&#x3D;5 where id&#x3D;0; &#x2F;<em>(0,5,5)</em>&#x2F;</p>
<p>图 5 表t主键索引上的行锁和间隙锁</p>
<p>这样，当你执行 select * from t where d&#x3D;5 for update的时候，就不止是给数据库中已有的6个记</p>
<p>录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上</p>
<p>了间隙锁。现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是</p>
<p>间隙锁跟我们之前碰到过的锁都不太一样。比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。图6 两种行锁间的冲突关系</p>
<p>也就是说，跟行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操</p>
<p>作。间隙锁之间都不存在冲突关系。这句话不太好理解，我给你举个例子：</p>
<p>图7 间隙锁之间不互锁</p>
<p>这里session B并不会被堵住。因为表t里并没有c&#x3D;7这个记录，因此session A加的是间隙锁</p>
<p>(5,10)。而session B也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允</p>
<p>许插入值。但，它们之间是不冲突的。间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。也就是说，我们的表t初始</p>
<p>化以后，如果用select * from t for update要把整个表所有记录锁起来，就形成了7个next-key</p>
<p>lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。你可能会问说，这个supremum从哪儿来的呢？这是因为+∞是开区间。实现上，InnoDB给每个索引加了一个不存在的最大值supremum，这样</p>
<p>才符合我们前面说的“都是前开后闭区间”。间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。在前面的文章中，就有同学提到了这个问题。我把他的问题转述一下，对应到我们这个例子的表</p>
<p>来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新</p>
<p>它的数据，代码如下：</p>
<p>备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把next-key lock记为前开</p>
<p>后闭区间。begin;</p>
<p>select * from t where id&#x3D;N for update;</p>
<p>&#x2F;<em>如果行不存在</em>&#x2F;</p>
<p>insert into t values(N,N,N);</p>
<p>&#x2F;<em>如果行存在</em>&#x2F;</p>
<p>update t set d&#x3D;N set id&#x3D;N;</p>
<p>commit;</p>
<p>可能你会说，这个不是insert … on duplicate key update 就能解决吗？但其实在有多个唯一键的时</p>
<p>候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说</p>
<p>明。现在，我们就只讨论这个逻辑。这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每</p>
<p>次操作前用for update锁起来，已经是最严格的模式了，怎么还会有死锁呢？这里，我用两个session来模拟并发，并假设N&#x3D;9。图8 间隙锁导致的死锁</p>
<p>你看到了，其实都不需要用到后面的update语句，就已经形成死锁了。我们按语句执行顺序来</p>
<p>分析一下：</p>
<ol>
<li>session A 执行select … for update语句，由于id&#x3D;9这一行并不存在，因此会加上间隙锁</li>
</ol>
<p>(5,10);</p>
<ol start="2">
<li>session B 执行select … for update语句，同样会加上间隙锁(5,10)，间隙锁之间不会冲突，因</li>
</ol>
<p>此这个语句可以执行成功；</p>
<ol start="3">
<li><p>session B 试图插入一行(9,9,9)，被session A的间隙锁挡住了，只好进入等待；</p>
</li>
<li><p>session A试图插入一行(9,9,9)，被session B的间隙锁挡住了。至此，两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对</p>
</li>
</ol>
<p>死锁关系，让session A的insert语句报错返回了。你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并</p>
<p>发度的。其实，这还只是一个简单的例子，在下一篇文章中我们还会碰到更多、更复杂的例</p>
<p>子。你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法</p>
<p>呢。我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下</p>
<p>的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，</p>
<p>就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置</p>
<p>为row。这，也是现在不少公司使用的配置组合。前面文章的评论区有同学留言说，他们公司就使用的是读提交隔离级别加binlog_format&#x3D;row的</p>
<p>组合。他曾问他们公司的DBA说，你为什么要这么配置。DBA直接答复说，因为大家都这么用</p>
<p>呀。所以，这个同学在评论区就问说，这个配置到底合不合理。关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保</p>
<p>证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。但其实我想说的是，配置是否合理，跟业务场景有关，需要具体问题具体分析。但是，如果DBA认为之所以这么用的原因是“大家都这么用”，那就有问题了，或者说，迟早会出</p>
<p>问题。比如说，大家都用读提交，可是逻辑备份的时候，mysqldump为什么要把备份线程设置成可重复</p>
<p>读呢？（这个我在前面的文章中已经解释过了，你可以再回顾下第6篇文章《全局锁和表锁 ：给</p>
<p>表加个字段怎么有这么多阻碍？》的内容）</p>
<p>然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔</p>
<p>离级别，会不会有问题？进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这</p>
<p>个结论是怎么得到的？如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。小结</p>
<p>今天我们从上一篇文章的课后问题说起，提到了全表扫描的加锁方式。我们发现即使给所有的行</p>
<p>都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。我碰到过很多对数据库有一定了解的业务开发人员，他们在设计数据表结构和业务SQL语句的时</p>
<p>候，对行锁有很准确的认识，但却很少考虑到间隙锁。最后的结果，就是生产库上会经常出现由</p>
<p>于间隙锁导致的死锁现象。行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析</p>
<p>的复杂度，但也有章可循。下一篇文章，我就会为你讲解InnoDB的加锁规则，帮你理顺这其中</p>
<p>的“章法”。作为对下一篇文章的预习，我给你留下一个思考题。图9 事务进入锁等待状态</p>
<p>如果你之前没有了解过本篇文章的相关内容，一定觉得这三个语句简直是风马牛不相及。但实际</p>
<p>上，这里session B和session C的insert 语句都会进入锁等待状态。你可以试着分析一下，出现这种情况的原因是什么？这里需要说明的是，这其实是我在下一篇文章介绍加锁规则后才能回答的问题，是留给你作为预</p>
<p>习的，其中session C被锁住这个分析是有点难度的。如果你没有分析出来，也不要气馁，我会</p>
<p>在下一篇文章和你详细说明。你也可以说说，你的线上MySQL配置的是什么隔离级别，为什么会这么配置？你有没有碰到什</p>
<p>么场景，是必须使用可重复读隔离级别的呢？你可以把你的碰到的场景和分析写在留言区里，我会在下一篇文章选取有趣的评论跟大家一起分</p>
<p>享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我们在本文的开头回答了上期问题。有同学的回答中还说明了读提交隔离级别下，在语句执行完</p>
<p>成后，是只有行锁的。而且语句执行完成后，InnoDB就会把不满足条件的行行锁去掉。当然了，c&#x3D;5这一行的行锁，还是会等到commit的时候才释放的。评论区留言点赞板：</p>
<p>@薛畅 、@张永志同学给出了正确答案。而且提到了在读提交隔离级别下，是只有行锁的。@帆帆帆帆帆帆帆帆、@欧阳成 对上期的例子做了验证，需要说明一下，需要在启动配置里</p>
<p>令狐少侠   5</p>
<p>老师，今天的文章对我影响很大，发现之前掌握的知识有些错误的地方，课后我用你的表结构</p>
<p>根据以前不清楚的地方实践了一遍，现在有两个问题，麻烦您解答下</p>
<p>1.我在事务1中执行 begin;select * from t where c&#x3D;5 for update;事务未提交，然后事务2中begin;</p>
<p>update t set c&#x3D;5 where id&#x3D;0;执行阻塞，替换成update t set c&#x3D;11 where id&#x3D;0;执行不阻塞，我觉</p>
<p>得原因是事务1执行时产生next-key lock范围是(0,5].(5,10]。我想问下update set操作c&#x3D;xxx是会</p>
<p>加锁吗？以及加锁的原理。2.一直以为gap只会在二级索引上，看了你的死锁案例，发现主键索引上也会有gap锁？2018-12-28</p>
<p> 作者回复</p>
<ol>
<li>好问题。你可以理解为要在索引c上插入一个(c&#x3D;5,id&#x3D;0)这一行，是落在(0,5],(5,10]里面的，1</li>
</ol>
<p>1可以对吧</p>
<ol start="2">
<li>嗯，主键索引的间隙上也要有Gap lock保护的</li>
</ol>
<p>2018-12-28</p>
<p>xuery   0</p>
<p>老师之前的留言说错了，重新梳理下：</p>
<p>面增加performance_schema&#x3D;on，才能用上这个功能，performance_schema库里的表才有</p>
<p>数据。精选留言</p>
<p>图8：间隙锁导致的死锁；我把innodb_locks_unsafe_for_binlog设置为1之后，session B并不</p>
<p>会blocked，session A insert会阻塞住，但是不会提示死锁；然后session B提交执行成功，ses</p>
<p>sion A提示主键冲突</p>
<p>这个是因为将innodb_locks_unsafe_for_binlog设置为1之后，什么原因造成的？2019-01-28</p>
<p> 作者回复</p>
<p>对， innodb_locks_unsafe_for_binlog 这个参数就是这个意思 “不加gap lock”，</p>
<p>这个已经要被废弃了（8.0就没有了），所以不建议设置哈，容易造成误会。如果真的要去掉gap lock，可以考虑改用RC隔离级别+binlog_format&#x3D;row</p>
<p>2019-02-01</p>
<p>薛畅   8</p>
<p>可重复读隔离级别下，经试验：</p>
<p>SELECT * FROM t where c&gt;&#x3D;15 and c&lt;&#x3D;20 for update; 会加如下锁：</p>
<p>next-key lock:(10, 15], (15, 20]</p>
<p>gap lock:(20, 25)</p>
<p>SELECT * FROM t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc for update; 会加如下锁：</p>
<p>next-key lock:(5, 10], (10, 15], (15, 20]</p>
<p>gap lock:(20, 25)</p>
<p>session C 被锁住的原因就是根据索引 c 逆序排序后多出的 next-key lock:(5, 10]</p>
<p>同时我有个疑问：加不加 next-key lock:(5, 10] 好像都不会影响到 session A 可重复读的语义，</p>
<p>那么为什么要加这个锁呢？2018-12-29</p>
<p> 作者回复</p>
<p>是的，这个其实就是为啥总结规则有点麻烦，有时候只是因为代码是这么写的 </p>
<p>2018-12-29</p>
<p>AI杜嘉嘉   7</p>
<p>说真的，这一系列文章实用性真的很强，老师非常负责，想必牵扯到老师大量精力，希望老师</p>
<p>再出好文章，谢谢您了，辛苦了</p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>精力花了没事，睡一觉醒来还是一条好汉 </p>
<p>主要还是得大家有收获，我就值了 </p>
<p>2018-12-28</p>
<p>郭江伟   7</p>
<p>郭江伟   7</p>
<p>insert into t values(0,0,0),(5,5,5),</p>
<p>(10,10,10),(15,15,15),(20,20,20),(25,25,25);</p>
<p>运行mysql&gt; begin;</p>
<p>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc for update;</p>
<p>c 索引会在最右侧包含主键值，c索引的值为(0,0) (5,5) (10,10) (15,15) (20,20) (25,25)</p>
<p>此时c索引上锁的范围其实还要匹配主键值 。思考题答案是，上限会扫到c索引(20,20) 上一个键，为了防止c为20 主键值小于25 的行插入，</p>
<p>需要锁定(20,20) (25,25) 两者的间隙；开启另一会话(26,25,25)可以插入，而(24,25,25)会被堵塞</p>
<p>。下限会扫描到(15,15)的下一个键也就是(10,10),测试语句会继续扫描一个键就是(5,5) ，此时会</p>
<p>锁定，(5,5) 到(15,15)的间隙，由于id是主键不可重复所以下限也是闭区间；</p>
<p>在本例的测试数据中添加(21,25,25)后就可以正常插入(24,25,25)</p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>感觉你下一篇看起来会很轻松了哈  </p>
<p>2018-12-28</p>
<p>沉浮   5</p>
<p>通过打印锁日志帮助理解问题</p>
<p>锁信息见括号里的说明。TABLE LOCK table <code>guo_test</code>.<code>t</code> trx id 105275 lock mode IX</p>
<p>RECORD LOCKS space id 31 page no 4 n bits 80 index c of table <code>guo_test</code>.<code>t</code> trx id 105275 lo</p>
<p>ck_mode X</p>
<p>Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 —-(Next-</p>
<p>Key Lock，索引锁c（5，10])</p>
<p>0: len 4; hex 8000000a; asc ;;</p>
<p>1: len 4; hex 8000000a; asc ;;</p>
<p>Record lock, heap no 5 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 —-(Next-</p>
<p>Key Lock，索引锁c (10,15]) </p>
<p>0: len 4; hex 8000000f; asc ;;</p>
<p>1: len 4; hex 8000000f; asc ;;</p>
<p>Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 —-(Next-</p>
<p>Key Lock，索引锁c (15,20]) </p>
<p>0: len 4; hex 80000014; asc ;;</p>
<p>1: len 4; hex 80000014; asc ;;</p>
<p>Record lock, heap no 7 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 —-(Next-</p>
<p>Key Lock，索引锁c (20,25]) </p>
<p>0: len 4; hex 80000019; asc ;;</p>
<p>1: len 4; hex 80000019; asc ;;</p>
<p>RECORD LOCKS space id 31 page no 3 n bits 80 index PRIMARY of table <code>guo_test</code>.<code>t</code> trx id </p>
<p>105275 lock_mode X locks rec but not gap</p>
<p>Record lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0 </p>
<p>—-(记录锁 锁c&#x3D;15对应的主键）</p>
<p>0: len 4; hex 8000000f; asc ;;</p>
<p>1: len 6; hex 0000000199e3; asc ;;</p>
<p>2: len 7; hex ca000001470134; asc G 4;;</p>
<p>3: len 4; hex 8000000f; asc ;;</p>
<p>4: len 4; hex 8000000f; asc ;;</p>
<p>Record lock, heap no 6 PHYSICAL RECORD: n_fields 5; compact format; info bits 0</p>
<p>0: len 4; hex 80000014; asc ;;</p>
<p>—-(记录锁 锁c&#x3D;20对应的主键）</p>
<p>1: len 6; hex 0000000199e3; asc ;;</p>
<p>2: len 7; hex ca000001470140; asc G @;;</p>
<p>3: len 4; hex 80000014; asc ;;</p>
<p>4: len 4; hex 80000014; asc ;;</p>
<p>由于字数限制，正序及无排序的日志无法帖出，倒序日志比这两者，多了范围(Next-Key Lock</p>
<p>，索引锁c（5，10])，个人理解是，加锁分两次，第一次，即正序的锁，第二次为倒序的锁，</p>
<p>即多出的(5,10],在RR隔离级别，</p>
<p>innodb在加锁的过程中会默认向后锁一个记录，加上Next-Key Lock,第一次加锁的时候10已经</p>
<p>在范围，由于倒序，向后，即向5再加Next-key Lock,即多出的(5,10]范围</p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>优秀</p>
<p>2018-12-28</p>
<p>慧鑫coming   4</p>
<p>这篇需要多读几遍，again</p>
<p>2018-12-28</p>
<p>往事随风，顺其自然   2</p>
<p>总结：for update 是锁住所有行还有间隙锁，但是间隙 之间互不冲突，但是互不冲突，为什么</p>
<p>插入9这一行会被间隙锁等待，原来没有这一行，这和查询9这一行不是一样？2018-12-28</p>
<p>en   1</p>
<p>老师您好，我mysql的隔离级别是可重复读，数据是(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,</p>
<p>20),(25,25,25)，使用了begin;select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc for update</p>
<p>;然后sessionB的11阻塞了，但是(6,6,6)的插入成功了这是什么原因呢？2018-12-31</p>
<p>郭健   1</p>
<p>老师，想请教您几个问题。1.在第六章MDL锁的时候，您说给大表增加字段和增加索引的时候</p>
<p>要小心，之前做过测试，给一个一千万的数据增加索引有时需要40分钟，但是增加索引不会对</p>
<p>表增加MDL锁吧。除了增加索引慢，还会对数据库有什么影响吗，我问我们dba，他说就开始</p>
<p>和结束的时候上一下锁，没什么影响，我个人是持怀疑态度的。2，老师讲到表锁除了MDL锁</p>
<p>，还有显示命令lock table的命令的表锁，老师我可以认为，在mysql中如果不显示使用lock tabl</p>
<p>e表锁的话，那么mysql是永远不会使用表锁的，如果锁的条件没有索引，使用的是锁住行锁+</p>
<p>间隙控制并发。2018-12-30</p>
<p> 作者回复</p>
<ol>
<li>在锁方面你们dba说的基本是对的。一开始和结束有写锁，执行中间40分钟只有读锁</li>
</ol>
<p>但是1000万的表要做40分钟，可能意味着系统压力大（或者配置偏小），这样可能不是没影响</p>
<p>对，比较这个操作还是要吃IO和CPU的</p>
<ol start="2">
<li>嗯，innodb引擎是这样的。2018-12-30</li>
</ol>
<p>滔滔   1</p>
<p>老师，听了您的课收获满满～～感谢您的付出！您可不可以在分析死锁的时候讲一下如何分析</p>
<p>死锁日志，期待～～ </p>
<p>2018-12-29</p>
<p> 作者回复</p>
<p>谢谢你的肯定。嗯死锁分析会有一篇专门说。不过你可以提前说一下碰到的疑问 </p>
<p>2018-12-29</p>
<p>胡月    1</p>
<p>老师，今天线上遇上了一个死锁的问题，您能帮我分析下吗。根据前面文章的理解：死锁产生的原因如下</p>
<p>线程1：update语句where c&#x3D; 1 然后 update语句where c&#x3D;2</p>
<p>线程2：update语句where c&#x3D;2然后 update语句where c&#x3D;1</p>
<p>如果线程1获取c&#x3D;1的锁，等待c&#x3D;2的锁，线程2获取了c&#x3D;2的锁，等待c&#x3D;1的锁，就会产生死锁</p>
<p>。但是线上的情况是</p>
<p>线程1：update语句where c&#x3D; 1 然后 update语句where c&#x3D;2</p>
<p>线程2：update语句where c&#x3D;1然后 update语句where c&#x3D;2</p>
<p>按说不会产生死锁啊，因为如果线程1获取了c&#x3D;1的锁，线程2就阻塞了。线程1执行完之后，线</p>
<p>程2执行就可以了死锁日志如下：</p>
<p>(1) TRANSACTION:</p>
<p>TRANSACTION 9418928, ACTIVE 0.088 sec fetching rows</p>
<p>mysql tables in use 1, locked 1</p>
<p>LOCK WAIT 66 lock struct(s), heap size 13864, 8 row lock(s)</p>
<p>LOCK BLOCKING MySQL thread id: 11495130 block 11105198</p>
<p>MySQL thread id 11105198, OS thread handle 0x2b086bf45700, query id 88822589 39.106.161.</p>
<p>89 daogou Searching rows for update</p>
<p>UPDATE union_pid</p>
<p>SET USE_TIMES &#x3D; USE_TIMES + 1</p>
<p>WHERE PID &#x3D; ‘mm_128160800_40474215_33107450401’</p>
<p>(1) WAITING FOR THIS LOCK TO BE GRANTED:</p>
<p>RECORD LOCKS space id 134 page no 93 n bits 192 index <code>PRIMARY</code> of table <code>shanfan</code>.&#96;uni</p>
<p>on_pid&#96; trx id 9418928 lock_mode X locks rec but not gap waiting</p>
<p>Record lock, heap no 86 PHYSICAL RECORD: n_fields 12; compact format; info bits 0</p>
<p>(2) TRANSACTION:</p>
<p>TRANSACTION 9418929, ACTIVE 0.088 sec fetching rows</p>
<p>mysql tables in use 1, locked 1</p>
<p>280 lock struct(s), heap size 46632, 17 row lock(s), undo log entries 1</p>
<p>MySQL thread id 11495130, OS thread handle 0x2b086be41700, query id 88822594 39.106.161.</p>
<p>89 daogou Searching rows for update</p>
<p>UPDATE union_pid</p>
<p>SET USE_TIMES &#x3D; USE_TIMES + 1</p>
<p>WHERE PID &#x3D; ‘1000501132_0_1432392817’</p>
<p>(2) HOLDS THE LOCK(S):</p>
<p>RECORD LOCKS space id 134 page no 93 n bits 192 index <code>PRIMARY</code> of table <code>shanfan</code>.&#96;uni</p>
<p>on_pid&#96; trx id 9418929 lock_mode X locks rec but not gap</p>
<p>Record lock, heap no 86 PHYSICAL RECORD: n_fields 12; compact format; info bits 0</p>
<p>(2) WAITING FOR THIS LOCK TO BE GRANTED:</p>
<p>RECORD LOCKS space id 134 page no 68 n bits 264 index <code>PRIMARY</code> of table <code>shanfan</code>.&#96;uni</p>
<p>on_pid&#96; trx id 9418929 lock_mode X locks rec but not gap waiting</p>
<p>Record lock, heap no 116 PHYSICAL RECORD: n_fields 12; compact format; info bits 0</p>
<p>WE ROLL BACK TRANSACTION (1)</p>
<p>2018-12-29</p>
<p> 作者回复</p>
<p>PID是唯一索引吗？ 给一下表结构。这两个语句分别对应的主键ID如果单独查出来分别是多少</p>
<p>2018-12-29</p>
<p>高枕   1</p>
<p>林老师，今天我又回头看第四节 深入浅出谈索引（上），里面有这样一段话：为了让一个查询</p>
<p>尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，</p>
<p>而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。我想问的是，</p>
<p>一 mysql是以page为最小单位的，mysql一次磁盘io能只读一个块吗？还是多个块组成的page？二 若一次只能读一个page，也就是多个块的话，这个N的大小是不是应该取决于page的大小呢</p>
<p>？三 主键索引叶子结点存放的实际数据，应该是通过指针跟叶子结点连接的吗？还是直接存在叶</p>
<p>子结点所在的页里吗？2018-12-29</p>
<p>信信   1</p>
<p>老师你好，如果图1的字段d有索引，按前面说的T1时刻后，只有id等于5这一行加了写锁。那么</p>
<p>session B 操作的是id等于0这一行，应该不会被阻断吧？如果没阻断的话，仍然会产生语义问</p>
<p>题及数据不一致的情况啊。想不明白。。。2018-12-29</p>
<p> 作者回复</p>
<p>如果d有索引，而且写法是d&#x3D;5，那么其他语句要把其他行的d改成5，也是不行的哦</p>
<p>2018-12-29</p>
<p>某、人   1</p>
<p>按照我的理解select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc for update;</p>
<p>这条语句的加锁顺序的以及范围应该是[25,20),[20,15],(15,10],但是通过实验得出来多了(10,5)ga</p>
<p>p锁</p>
<p>而且不管是用二级索引还是用主键索引,都会加这段gap锁.</p>
<p>有点不太清楚为什么倒序扫描就需要加上了这段gap锁,目的又是为了什么?</p>
<p>不会气磊,期待老师下一期的答案。 </p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>嗯嗯下周一见 </p>
<p>2018-12-28</p>
<p>可凡不凡   1</p>
<p>老师</p>
<p>update tab1 set name &#x3D;(select name from tab2 where status &#x3D;2)…</p>
<p>tab2.status 上有二级非唯一索引,rr 隔离级别</p>
<p>上述情况</p>
<p>tab2.id 上的的索引会被锁吗?</p>
<p>实际开发 看到的死锁情况 是这条语句在等待 s 锁 但是没有 gap 锁,也没有设置 semi-consistent</p>
<p>read</p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>Tab2满足条件的航上会加读锁</p>
<p>2018-12-28</p>
<p>小新   1</p>
<p>这篇文章真的需要多啃几遍，</p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>嗯嗯，而且这篇是下篇的基础 </p>
<p>2018-12-28</p>
<p>Justin   1</p>
<p>下一章老师会不会讲走普通索引，锁普通索引的时候，主键索引，以及其他索引的加锁顺序或</p>
<p>者规则呢？很是好奇</p>
<p>2018-12-28</p>
<p> 作者回复</p>
<p>嗯嗯，就是这些内容 </p>
<p>这篇文章末尾的问题如果一眼看懂的同学应该看起来就轻松的</p>
<p>2018-12-28</p>
<p>林   0</p>
<p>总结就是并发加可重复读引起了数据不一致，也就是幻读的产生，通过间隙锁解决。2019-02-01</p>
<p> 作者回复</p>
<p> </p>
<p>2019-02-02</p>
<p>胡楚坚   0</p>
<p>我对于左开右闭的意义(如果是数学那肯定造的)一直有点迷糊，闭和开有什么区别？然后自己</p>
<p>去搜索下:（a，b]代表着会锁住a跟b之间，不让插入数据，还会锁住数据b本身，但不会锁住数</p>
<p>据a(即开和闭对应着要不要锁住数据本身)。老师，我理解的对吗？至于为什么左开右闭，说是迎合自增主键特性，这就不是很理解了，希望老师有空能回答下。2019-01-31</p>
<p> 作者回复</p>
<p>非常正确，就是gap 再加上它右边的那个记录。要让整个区间连续，总要有一边闭区间哈，二选一。然后MySQL 一直支持的是升序索引 </p>
<p>2019-01-31</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/649145f1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/649145f1.html" class="post-title-link" itemprop="url">mysql-为什么我只查一行的语句，也执行这么慢</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-24 06:19:33" itemprop="dateCreated datePublished" datetime="2019-11-24T06:19:33+08:00">2019-11-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>19 | 为什么我只查一行的语句，也执行这么慢？2018-12-26 林晓斌</p>
<p>一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大</p>
<p>量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话</p>
<p>题，看看什么情况下，会出现这个现象。需要说明的是，如果MySQL数据库本身就有很大的压力，导致数据库服务器CPU占用率很高或</p>
<p>ioutil（IO利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范</p>
<p>围。为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段id和c，</p>
<p>并且我在里面插入了10万行记录。接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看</p>
<p>能不能一眼看穿，来检验一下吧。第一类：查询长时间不返回</p>
<p>如图1所示，在表t执行下面的SQL语句：</p>
<p>查询结果长时间不返回。图1 查询长时间不返回</p>
<p>一般碰到这种情况的话，大概率是表t被锁住了。接下来分析原因的时候，一般都是首先执行一</p>
<p>下show processlist命令，看看当前语句处于什么状态。mysql&gt; CREATE TABLE <code>t</code> (</p>
<p>  <code>id</code> int(11) NOT NULL,</p>
<p>  <code>c</code> int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (<code>id</code>)</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>delimiter ;;</p>
<p>create procedure idata()</p>
<p>begin</p>
<p>  declare i int;</p>
<p>  set i&#x3D;1;</p>
<p>  while(i&lt;&#x3D;100000)do</p>
<pre><code>insert into t values(i,i)

set i=i+1;
</code></pre>
<p>  end while;</p>
<p>end;;</p>
<p>delimiter ;</p>
<p>call idata();</p>
<p>mysql&gt; select * from t where id&#x3D;1;</p>
<p>然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。等MDL锁</p>
<p>如图2所示，就是使用show processlist命令查看Waiting for table metadata lock的示意图。图2 Waiting for table metadata lock状态示意图</p>
<p>出现这个状态表示的是，现在有一个线程正在表t上请求或者持有MDL写锁，把select语句</p>
<p>堵住了。在第6篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现</p>
<p>方法。但需要说明的是，那个复现过程是基于MySQL 5.6版本的。而MySQL 5.7版本修改了MDL</p>
<p>的加锁策略，所以就不能复现这个场景了。不过，在MySQL 5.7版本下复现这个场景，也很容易。如图3所示，我给出了简单的复现步骤。图3 MySQL 5.7中Waiting for table metadata lock的复现步骤</p>
<p>session A 通过lock table命令持有表t的MDL写锁，而session B的查询需要获取MDL读锁。所</p>
<p>以，session B进入等待状态。这类问题的处理方式，就是找到谁持有MDL写锁，然后把它kill掉。但是，由于在show processlist的结果里面，session A的Command列是“Sleep”，导致查找起来</p>
<p>很不方便。不过有了performance_schema和sys系统库以后，就方便多了。（MySQL启动时需</p>
<p>要设置performance_schema&#x3D;on)</p>
<p>通过查询sys.schema_table_lock_waits这张表，我们就可以直接找出造成阻塞的process id，把</p>
<p>这个连接用kill 命令断开即可。图4 查获加表锁的线程id</p>
<p>等flush</p>
<p>接下来，我给你举另外一种查询被堵住的情况。我在表t上，执行下面的SQL语句：</p>
<p>这里，我先卖个关子。你可以看一下图5。我查出来这个线程的状态是Waiting for table flush，你可以设想一下这是什</p>
<p>么原因。图5 Waiting for table flush状态示意图</p>
<p>这个状态表示的是，现在有一个线程正要对表t做flush操作。MySQL里面对表做flush操作的用</p>
<p>法，一般有以下两个：</p>
<p>这两个flush语句，如果指定表t的话，代表的是只关闭表t；如果没有指定具体的表名，则表示关</p>
<p>闭MySQL里所有打开的表。但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。所以，出现Waiting for table flush状态的可能情况是：有一个flush tables命令被别的语句堵住</p>
<p>mysql&gt; select * from information_schema.processlist where id&#x3D;1;</p>
<p>flush tables t with read lock;</p>
<p>flush tables with read lock;</p>
<p>了，然后它又堵住了我们的select语句。现在，我们一起来复现一下这种情况，复现步骤如图6所示：</p>
<p>图6 Waiting for table flush的复现步骤</p>
<p>在session A中，我故意每行都调用一次sleep(1)，这样这个语句默认要执行10万秒，在这期间表</p>
<p>t一直是被session A“打开”着。然后，session B的flush tables t命令再要去关闭表t，就需要等</p>
<p>session A的查询结束。这样，session C要再次查询的话，就会被flush 命令堵住了。图7是这个复现步骤的show processlist结果。这个例子的排查也很简单，你看到这个show</p>
<p>processlist的结果，肯定就知道应该怎么做了。图 7 Waiting for table flush的show processlist 结果</p>
<p>等行锁</p>
<p>现在，经过了表级锁的考验，我们的select 语句终于来到引擎里了。上面这条语句的用法你也很熟悉了，我们在第8篇《事务到底是隔离的还是不隔离的？》文章介</p>
<p>绍当前读时提到过。由于访问id&#x3D;1这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我</p>
<p>们的select语句就会被堵住。复现步骤和现场如下：</p>
<p>mysql&gt; select * from t where id&#x3D;1 lock in share mode; </p>
<p>图 8 行锁复现</p>
<p>图 9 行锁show processlist 现场</p>
<p>显然，session A启动了事务，占有写锁，还不提交，是导致session B被堵住的原因。这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是MySQL 5.7版本，可</p>
<p>以通过sys.innodb_lock_waits 表查到。查询方法是：</p>
<p>mysql&gt; select * from t sys.innodb_lock_waits where locked_table&#x3D;<code>&#39;test&#39;.&#39;t&#39;</code>\G</p>
<p>图10 通过sys.innodb_lock_waits 查行锁</p>
<p>可以看到，这个信息很全，4号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是</p>
<p>KILL QUERY 4或KILL 4。不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止4号线程当前正在执行的语句，而这</p>
<p>个方法其实是没有用的。因为占有行锁的是update语句，这个语句已经是之前执行完成了的，</p>
<p>现在执行KILL QUERY，无法让这个事务去掉id&#x3D;1上的行锁。实际上，KILL 4才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的</p>
<p>时候，会自动回滚这个连接里面正在执行的线程，也就释放了id&#x3D;1上的行锁。第二类：查询慢</p>
<p>经过了重重封“锁”，我们再来看看一些查询慢的例子。先来看一条你一定知道原因的SQL语句：</p>
<p>mysql&gt; select * from t where c&#x3D;50000 limit 1;</p>
<p>由于字段c上没有索引，这个语句只能走id主键顺序扫描，因此需要扫描5万行。作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到slow log里，我在连接</p>
<p>后先执行了 set long_query_time&#x3D;0，将慢查询日志的时间阈值设置为0。图11 全表扫描5万行的slow log</p>
<p>Rows_examined显示扫描了50000行。你可能会说，不是很慢呀，11.5毫秒就返回了，我们线上</p>
<p>一般都配置超过1秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只</p>
<p>有10万行记录，数据量大起来的话，执行时间就线性涨上去了。扫描行数多，所以执行慢，这个很好理解。但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。如图12所示，是这个例子的slow log。可以看到，执行的语句是</p>
<p>虽然扫描行数是1，但执行时间却长达800毫秒。图12 扫描一行却执行得很慢</p>
<p>是不是有点奇怪呢，这些时间都花在哪里了？如果我把这个slow log的截图再往下拉一点，你可以看到下一个语句，select * from t where id&#x3D;1</p>
<p>lock in share mode，执行时扫描行数也是1行，执行时间是0.2毫秒。图 13 加上lock in share mode的slow log</p>
<p>看上去是不是更奇怪了？按理说lock in share mode还要加锁，时间应该更长才对啊。可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图14是这两个</p>
<p>mysql&gt; select * from t where id&#x3D;1；</p>
<p>语句的执行输出结果。图14 两个语句的输出结果</p>
<p>第一个语句的查询结果里c&#x3D;1，带lock in share mode的语句返回的是c&#x3D;1000001。看到这里应该</p>
<p>有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，</p>
<p>再分析原因。图15 复现步骤</p>
<p>你看到了，session A先用start transaction with consistent snapshot命令启动了一个事务，之后</p>
<p>session B才开始执行update 语句。session B执行完100万次update语句后，id&#x3D;1这一行处于什么状态呢？你可以从图16中找到答</p>
<p>案。图16 id&#x3D;1的数据状态</p>
<p>session B更新完100万次，生成了100万个回滚日志(undo log)。带lock in share mode的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很</p>
<p>快；而select * from t where id&#x3D;1这个语句，是一致性读，因此需要从1000001开始，依次执行</p>
<p>undo log，执行了100万次以后，才将1这个结果返回。注意，undo log里记录的其实是“把2改成1”，“把3改成2”这样的操作逻辑，画成减1的目的是方</p>
<p>便你看图。小结</p>
<p>今天我给你举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其</p>
<p>中涉及到了表锁、行锁和一致性读的概念。在实际使用中，碰到的场景会更复杂。但大同小异，你可以按照我在文章中介绍的定位方法，来</p>
<p>定位并解决问题。最后，我给你留一个问题吧。我们在举例加锁读的时候，用的是这个语句，select * from t where id&#x3D;1 lock in share mode。由</p>
<p>于id上有索引，所以可以直接定位到id&#x3D;1这一行，因此读锁也是只加在了这一行上。但如果是下面的SQL语句，</p>
<p>这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？你可以把你的观点和验证方法写在留言区里，我会在下一篇文章的末尾给出我的参考答案。感谢</p>
<p>你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>在上一篇文章最后，我留给你的问题是，希望你可以分享一下之前碰到过的、与文章中类似的场</p>
<p>景。@封建的风 提到一个有趣的场景，值得一说。我把他的问题重写一下，表结构如下：</p>
<p>假设现在表里面，有100万行数据，其中有10万行数据的b的值是’1234567890’， 假设现在执行</p>
<p>语句是这么写的:</p>
<p>这时候，MySQL会怎么执行呢？最理想的情况是，MySQL看到字段b定义的是varchar(10)，那肯定返回空呀。可惜，MySQL并没</p>
<p>有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树b上</p>
<p>并没有这个值，也很快就能返回空结果。begin;</p>
<p>select * from t where c&#x3D;5 for update;</p>
<p>commit;</p>
<p>mysql&gt; CREATE TABLE <code>table_a</code> (</p>
<p>  <code>id</code> int(11) NOT NULL,</p>
<p>  <code>b</code> varchar(10) DEFAULT NULL,</p>
<p>  PRIMARY KEY (<code>id</code>),</p>
<p>  KEY <code>b</code> (<code>b</code>)</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>mysql&gt; select * from table_a where b&#x3D;’1234567890abcd’;</p>
<p>但实际上，MySQL也不是这么做的。这条SQL语句的执行很慢，流程是这样的：</p>
<ol>
<li>在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是10，所以只截</li>
</ol>
<p>了前10个字节，就是’1234567890’进去做匹配；</p>
<ol start="2">
<li><p>这样满足条件的数据有10万行；</p>
</li>
<li><p>因为是select *， 所以要做10万次回表；</p>
</li>
<li><p>但是每次回表以后查出整行，到server层一判断，b的值都不是’1234567890abcd’;</p>
</li>
<li><p>返回结果是空。这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在</p>
</li>
</ol>
<p>拿到结果后，server层还是要做一轮判断的。评论区留言点赞板：</p>
<p>@赖阿甘 提到了等号顺序问题，时间上MySQL优化器执行过程中，where 条件部分， a&#x3D;b和</p>
<p>b&#x3D;a的写法是一样的。@沙漠里的骆驼 提到了一个常见的问题。相同的模板语句，但是匹配行数不同，语句执行时</p>
<p>间相差很大。这种情况，在语句里面有order by这样的操作时会更明显。@Justin 回答了我们正文中的问题，如果id 的类型是整数，传入的参数类型是字符串的时候，</p>
<p>可以用上索引。</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/f5203c05.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/f5203c05.html" class="post-title-link" itemprop="url">mysql-为什么我只查一行的语句也执行这么慢</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-23 06:15:35" itemprop="dateCreated datePublished" datetime="2019-11-23T06:15:35+08:00">2019-11-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>6.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>19 | 为什么我只查一行的语句，也执行这么慢？2018-12-26 林晓斌</p>
<p>一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大</p>
<p>量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话</p>
<p>题，看看什么情况下，会出现这个现象。需要说明的是，如果MySQL数据库本身就有很大的压力，导致数据库服务器CPU占用率很高或</p>
<p>ioutil（IO利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范</p>
<p>围。为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段id和c，</p>
<p>并且我在里面插入了10万行记录。接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看</p>
<p>能不能一眼看穿，来检验一下吧。第一类：查询长时间不返回</p>
<p>如图1所示，在表t执行下面的SQL语句：</p>
<p>查询结果长时间不返回。图1 查询长时间不返回</p>
<p>一般碰到这种情况的话，大概率是表t被锁住了。接下来分析原因的时候，一般都是首先执行一</p>
<p>下show processlist命令，看看当前语句处于什么状态。mysql&gt; CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>delimiter ;;</p>
<p>create procedure idata()</p>
<p>begin</p>
<p>  declare i int;</p>
<p>  set i&#x3D;1;</p>
<p>  while(i&lt;&#x3D;100000)do</p>
<pre><code>insert into t values(i,i);

set i=i+1;
</code></pre>
<p>  end while;</p>
<p>end;;</p>
<p>delimiter ;</p>
<p>call idata();</p>
<p>mysql&gt; select * from t where id&#x3D;1;</p>
<p>然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。等MDL锁</p>
<p>如图2所示，就是使用show processlist命令查看Waiting for table metadata lock的示意图。图2 Waiting for table metadata lock状态示意图</p>
<p>出现这个状态表示的是，现在有一个线程正在表t上请求或者持有MDL写锁，把select语句</p>
<p>堵住了。在第6篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现</p>
<p>方法。但需要说明的是，那个复现过程是基于MySQL 5.6版本的。而MySQL 5.7版本修改了MDL</p>
<p>的加锁策略，所以就不能复现这个场景了。不过，在MySQL 5.7版本下复现这个场景，也很容易。如图3所示，我给出了简单的复现步骤。图3 MySQL 5.7中Waiting for table metadata lock的复现步骤</p>
<p>session A 通过lock table命令持有表t的MDL写锁，而session B的查询需要获取MDL读锁。所</p>
<p>以，session B进入等待状态。这类问题的处理方式，就是找到谁持有MDL写锁，然后把它kill掉。但是，由于在show processlist的结果里面，session A的Command列是“Sleep”，导致查找起来</p>
<p>很不方便。不过有了performance_schema和sys系统库以后，就方便多了。（MySQL启动时需</p>
<p>要设置performance_schema&#x3D;on，相比于设置为off会有10%左右的性能损失)</p>
<p>通过查询sys.schema_table_lock_waits这张表，我们就可以直接找出造成阻塞的process id，把</p>
<p>这个连接用kill 命令断开即可。图4 查获加表锁的线程id</p>
<p>等flush</p>
<p>接下来，我给你举另外一种查询被堵住的情况。我在表t上，执行下面的SQL语句：</p>
<p>这里，我先卖个关子。你可以看一下图5。我查出来这个线程的状态是Waiting for table flush，你可以设想一下这是什</p>
<p>么原因。图5 Waiting for table flush状态示意图</p>
<p>这个状态表示的是，现在有一个线程正要对表t做flush操作。MySQL里面对表做flush操作的用</p>
<p>法，一般有以下两个：</p>
<p>这两个flush语句，如果指定表t的话，代表的是只关闭表t；如果没有指定具体的表名，则表示关</p>
<p>闭MySQL里所有打开的表。但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。所以，出现Waiting for table flush状态的可能情况是：有一个flush tables命令被别的语句堵住</p>
<p>mysql&gt; select * from information_schema.processlist where id&#x3D;1;</p>
<p>flush tables t with read lock;</p>
<p>flush tables with read lock;</p>
<p>了，然后它又堵住了我们的select语句。现在，我们一起来复现一下这种情况，复现步骤如图6所示：</p>
<p>图6 Waiting for table flush的复现步骤</p>
<p>在session A中，我故意每行都调用一次sleep(1)，这样这个语句默认要执行10万秒，在这期间表</p>
<p>t一直是被session A“打开”着。然后，session B的flush tables t命令再要去关闭表t，就需要等</p>
<p>session A的查询结束。这样，session C要再次查询的话，就会被flush 命令堵住了。图7是这个复现步骤的show processlist结果。这个例子的排查也很简单，你看到这个show</p>
<p>processlist的结果，肯定就知道应该怎么做了。图 7 Waiting for table flush的show processlist 结果</p>
<p>等行锁</p>
<p>现在，经过了表级锁的考验，我们的select 语句终于来到引擎里了。上面这条语句的用法你也很熟悉了，我们在第8篇《事务到底是隔离的还是不隔离的？》文章介</p>
<p>绍当前读时提到过。由于访问id&#x3D;1这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我</p>
<p>们的select语句就会被堵住。复现步骤和现场如下：</p>
<p>mysql&gt; select * from t where id&#x3D;1 lock in share mode; </p>
<p>图 8 行锁复现</p>
<p>图 9 行锁show processlist 现场</p>
<p>显然，session A启动了事务，占有写锁，还不提交，是导致session B被堵住的原因。这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是MySQL 5.7版本，可</p>
<p>以通过sys.innodb_lock_waits 表查到。查询方法是：</p>
<p>mysql&gt; select * from t sys.innodb_lock_waits where locked_table&#x3D; ‘̀test’.’t’̀ \G</p>
<p>图10 通过sys.innodb_lock_waits 查行锁</p>
<p>可以看到，这个信息很全，4号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是</p>
<p>KILL QUERY 4或KILL 4。不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止4号线程当前正在执行的语句，而这</p>
<p>个方法其实是没有用的。因为占有行锁的是update语句，这个语句已经是之前执行完成了的，</p>
<p>现在执行KILL QUERY，无法让这个事务去掉id&#x3D;1上的行锁。实际上，KILL 4才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的</p>
<p>时候，会自动回滚这个连接里面正在执行的线程，也就释放了id&#x3D;1上的行锁。第二类：查询慢</p>
<p>经过了重重封“锁”，我们再来看看一些查询慢的例子。先来看一条你一定知道原因的SQL语句：</p>
<p>mysql&gt; select * from t where c&#x3D;50000 limit 1;</p>
<p>由于字段c上没有索引，这个语句只能走id主键顺序扫描，因此需要扫描5万行。作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到slow log里，我在连接</p>
<p>后先执行了 set long_query_time&#x3D;0，将慢查询日志的时间阈值设置为0。图11 全表扫描5万行的slow log</p>
<p>Rows_examined显示扫描了50000行。你可能会说，不是很慢呀，11.5毫秒就返回了，我们线上</p>
<p>一般都配置超过1秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只</p>
<p>有10万行记录，数据量大起来的话，执行时间就线性涨上去了。扫描行数多，所以执行慢，这个很好理解。但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。如图12所示，是这个例子的slow log。可以看到，执行的语句是</p>
<p>虽然扫描行数是1，但执行时间却长达800毫秒。图12 扫描一行却执行得很慢</p>
<p>是不是有点奇怪呢，这些时间都花在哪里了？如果我把这个slow log的截图再往下拉一点，你可以看到下一个语句，select * from t where id&#x3D;1</p>
<p>lock in share mode，执行时扫描行数也是1行，执行时间是0.2毫秒。图 13 加上lock in share mode的slow log</p>
<p>看上去是不是更奇怪了？按理说lock in share mode还要加锁，时间应该更长才对啊。可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图14是这两个</p>
<p>mysql&gt; select * from t where id&#x3D;1；</p>
<p>语句的执行输出结果。图14 两个语句的输出结果</p>
<p>第一个语句的查询结果里c&#x3D;1，带lock in share mode的语句返回的是c&#x3D;1000001。看到这里应该</p>
<p>有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，</p>
<p>再分析原因。图15 复现步骤</p>
<p>你看到了，session A先用start transaction with consistent snapshot命令启动了一个事务，之后</p>
<p>session B才开始执行update 语句。session B执行完100万次update语句后，id&#x3D;1这一行处于什么状态呢？你可以从图16中找到答</p>
<p>案。图16 id&#x3D;1的数据状态</p>
<p>session B更新完100万次，生成了100万个回滚日志(undo log)。带lock in share mode的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很</p>
<p>快；而select * from t where id&#x3D;1这个语句，是一致性读，因此需要从1000001开始，依次执行</p>
<p>undo log，执行了100万次以后，才将1这个结果返回。注意，undo log里记录的其实是“把2改成1”，“把3改成2”这样的操作逻辑，画成减1的目的是方</p>
<p>便你看图。小结</p>
<p>今天我给你举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其</p>
<p>中涉及到了表锁、行锁和一致性读的概念。在实际使用中，碰到的场景会更复杂。但大同小异，你可以按照我在文章中介绍的定位方法，来</p>
<p>定位并解决问题。最后，我给你留一个问题吧。我们在举例加锁读的时候，用的是这个语句，select * from t where id&#x3D;1 lock in share mode。由</p>
<p>于id上有索引，所以可以直接定位到id&#x3D;1这一行，因此读锁也是只加在了这一行上。但如果是下面的SQL语句，</p>
<p>这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？你可以把你的观点和验证方法写在留言区里，我会在下一篇文章的末尾给出我的参考答案。感谢</p>
<p>你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>在上一篇文章最后，我留给你的问题是，希望你可以分享一下之前碰到过的、与文章中类似的场</p>
<p>景。@封建的风 提到一个有趣的场景，值得一说。我把他的问题重写一下，表结构如下：</p>
<p>假设现在表里面，有100万行数据，其中有10万行数据的b的值是’1234567890’， 假设现在执行</p>
<p>语句是这么写的:</p>
<p>这时候，MySQL会怎么执行呢？最理想的情况是，MySQL看到字段b定义的是varchar(10)，那肯定返回空呀。可惜，MySQL并没</p>
<p>有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树b上</p>
<p>并没有这个值，也很快就能返回空结果。begin;</p>
<p>select * from t where c&#x3D;5 for update;</p>
<p>commit;</p>
<p>mysql&gt; CREATE TABLE t̀able_a  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;b  ̀varchar(10) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  KEY &#96;b  ̀(̀ b )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>mysql&gt; select * from table_a where b&#x3D;’1234567890abcd’;</p>
<p>但实际上，MySQL也不是这么做的。这条SQL语句的执行很慢，流程是这样的：</p>
<ol>
<li>在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是10，所以只截</li>
</ol>
<p>了前10个字节，就是’1234567890’进去做匹配；</p>
<ol start="2">
<li><p>这样满足条件的数据有10万行；</p>
</li>
<li><p>因为是select *， 所以要做10万次回表；</p>
</li>
<li><p>但是每次回表以后查出整行，到server层一判断，b的值都不是’1234567890abcd’;</p>
</li>
<li><p>返回结果是空。这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在</p>
</li>
</ol>
<p>拿到结果后，server层还是要做一轮判断的。评论区留言点赞板：</p>
<p>@赖阿甘 提到了等号顺序问题，时间上MySQL优化器执行过程中，where 条件部分， a&#x3D;b和</p>
<p>b&#x3D;a的写法是一样的。@沙漠里的骆驼 提到了一个常见的问题。相同的模板语句，但是匹配行数不同，语句执行时</p>
<p>间相差很大。这种情况，在语句里面有order by这样的操作时会更明显。@Justin 回答了我们正文中的问题，如果id 的类型是整数，传入的参数类型是字符串的时候，</p>
<p>可以用上索引。某、人   15</p>
<p>最近几张干货越来越多了,很实用,收获不少.先回答今天的问题</p>
<p>版本5.7.13</p>
<p>rc模式下:</p>
<p>session 1:</p>
<p>begin;</p>
<p>select * from t where c&#x3D;5 for update; </p>
<p>session 2:</p>
<p>delete from t where c&#x3D;10 –等待</p>
<p>session 3:</p>
<p>insert into t values(100001,8) –成功</p>
<p>session 1:</p>
<p>commit</p>
<p>session 2:事务执行成功</p>
<p>rr模式下:</p>
<p>begin;</p>
<p>select * from t where c&#x3D;5 for update; </p>
<p>session 2:</p>
<p>delete from t where c&#x3D;10 –等待</p>
<p>session 3:</p>
<p>insert into t values(100001,8) –等待</p>
<p>session 1:</p>
<p>commit</p>
<p>session 2:事务执行成功</p>
<p>session 3：事务执行成功</p>
<p>从上面这两个简单的例子,可以大概看出上锁的流程.</p>
<p>不管是rr模式还是rc模式,这条语句都会先在server层对表加上MDL S锁,然后进入到引擎层。rc模式下,由于数据量不大只有10W。通过实验可以证明session 1上来就把该表的所有行都锁住</p>
<p>了。导致其他事务要对该表的所有现有记录做更新,是阻塞状态。为什么insert又能成功?</p>
<p>说明rc模式下for update语句没有上gap锁,所以不阻塞insert对范围加插入意向锁,所以更新成功</p>
<p>。session 1commit后,session 2执行成功。表明所有行的x锁是在事务提交完成以后才释放。rr模式下,session 1和session 2与rc模式下都一样,说明rr模式下也对所有行上了X锁。唯一的区别是insert也等待了,是因为rr模式下对没有索引的更新,聚簇索引上的所有记录，都被</p>
<p>加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。由于gap锁阻</p>
<p>精选留言</p>
<p>塞了insert要加的插入意向锁,导致insert也处于等待状态。只有当session 1 commit完成以后。s</p>
<p>ession 1上的所有锁才会释放,S2,S3执行成功</p>
<p>由于例子中的数据量还比较小,如果数据量达到千万级别,就比较直观的能看出,上锁是逐行上锁</p>
<p>的一个过程.扫描一条上一条,直到所有行扫描完,rc模式下对所有行上x锁。rr模式下不仅对所有</p>
<p>行上X锁,还对所有区间上gap锁.直到事务提交或者回滚完成后,上的锁才会被释放。2018-12-26</p>
<p> 作者回复</p>
<p>分析得非常好。两个模式下，各增加一个session 4 : update t set c&#x3D;100 where id&#x3D;10看看哦</p>
<p>基本就全了  </p>
<p>2018-12-26</p>
<p>薛畅   9</p>
<p>回来老师的问题：</p>
<p>在 Read Committed 隔离级别下，会锁上聚簇索引中的所有记录；</p>
<p>在 Repeatable Read 隔离级别下，会锁上聚簇索引中的所有记录，并且会锁上聚簇索引内的所</p>
<p>有 GAP；</p>
<p>在上面两个隔离级别的情况下，如果设置了 innodb_locks_unsafe_for_binlog 开启 semi-consis</p>
<p>tent read 的话，对于不满足查询条件的记录，MySQL 会提前放锁，不过加锁的过程是不可避</p>
<p>免的。2018-12-26</p>
<p>似水流年   4</p>
<p>请问老师，为什么select blocking_pid from sys.schema_table_lock_waits;查不到mdl锁的进程i</p>
<p>d，显示为空。2018-12-28</p>
<p>沙漠里的骆驼   4</p>
<p>@高枕</p>
<p>这里有些资料提供给你参考: </p>
<ol>
<li><p>何登成的技术博客: 加锁分析 <a target="_blank" rel="noopener" href="http://hedengcheng.com/?p=771">http://hedengcheng.com/?p=771</a></p>
</li>
<li><p>锁的常见种类: <a target="_blank" rel="noopener" href="http://www.aneasystone.com/archives/2017/11/solving-dead-locks-two.html">http://www.aneasystone.com/archives/2017/11/solving-dead-locks-two.html</a></p>
</li>
</ol>
<p>2018-12-26</p>
<p>尘封   3</p>
<p>课后问题：d这一列不存在，但是还是要加MDL锁，释放时间应该是事务提交时。2018-12-26</p>
<p> 作者回复</p>
<p>抱歉，是要写成where c&#x3D;5 , 发起堪误了</p>
<p>2018-12-26</p>
<p>尘封   3</p>
<p>尘封   3</p>
<p>老师，有没有遇到过select语句一直处于killed状态的情况？2018-12-26</p>
<p> 作者回复</p>
<p>有  这个是在后面的文章中会用到的例子</p>
<p>2018-12-26</p>
<p>蠢蠢欲动的腹肌   2</p>
<p>老师，您好</p>
<p>我的mysql版本5.7.24，尝试的时候发现了如下问题</p>
<p>锁住了表T</p>
<p>mysql&gt; lock table T write;</p>
<p>Query OK, 0 rows affected (0.00 sec)</p>
<p>另一个terminal查询时被阻塞，但是查不到blocking_pid ，这是什么情况呢</p>
<p>mysql&gt; select blocking_pid from sys.schema_table_lock_waits;</p>
<p>Empty set (0.00 sec)</p>
<p>ps:发现查询schema_table_lock_waits表与lock table的语句不能放在一个terminal执行，否则会</p>
<p>报</p>
<p>Table ‘schema_table_lock_waits’ was not locked with LOCK TABLES</p>
<p>自行尝试的同学要注意下，老师有空的话也可以帮看看为什么。。。2018-12-28</p>
<p>小李子   2</p>
<p>老师，为什么session B 执行了 select in share mode ，在等行锁的时候，session C 执行 </p>
<p>select * from sys.innodb_lock_waits where locked_table&#x3D;’<code>test</code>.<code>t</code>‘ 会报这个错 </p>
<p>[Err] 1356 - View ‘sys.innodb_lock_waits’ references invalid table(s) or column(s) or function(s) </p>
<p>or definer&#x2F;invoker of view lack rights to use them，而超时之后，又可以查了？另外，\G 参数会</p>
<p>报语法错误？2018-12-27</p>
<p>Tony Du   2</p>
<p>对于课后问题，select * from t where c&#x3D;5 for update，</p>
<p>当级别为RR时，因为字段c上没有索引，会扫主键索引，这时会把表中的记录都加上X锁。同</p>
<p>时，因为对于innodb来说，当级别为RR时，是可以解决幻读的，此时对于每条记录的间隙还要</p>
<p>加上GAP锁。也就是说，表上每一条记录和每一个间隙都锁上了。当级别为RC时，因为字段c上没有索引，会扫主键索引，这时会把表中的记录都加上X锁。另外，之前看过相关文章，MySQL在实际实现中有些优化措施，比如当RC时，在MySQL serv</p>
<p>er过滤条件，发现不满足后，会把不满足条件的记录释放锁（这里就是把 c!&#x3D;5的记录释放锁）</p>
<p>，这里会违背两阶段的约束。当然，之前每条记录的加锁操作还是不能省略的。还有，对于semi consistent read开启的情况下，也会提前释放锁。2018-12-27</p>
<p>信信   2</p>
<p>老师你好，图3上方提到MySQL 5.7 版本修改了 MDL 的加锁策略，不能复现第六章的场景。但</p>
<p>我认为只要仍然满足：DML操作加MDL读锁，DDL操作加MDL写锁，并且事务提交才释放锁，</p>
<p>那么就可以复现啊。。。所以5.7到底是改了什么导致无法复现的呢？2018-12-27</p>
<p>某、人   2</p>
<p>老师我请教一个问题:</p>
<p>flush tables中close table的意思是说的把open_tables里的表全部关闭掉?下次如果有关于某张表</p>
<p>的操作</p>
<p>又把frm file缓存进Open_table_definitions,把表名缓存到open_tables,还是open_table只是一个计</p>
<p>数?</p>
<p>不是特别明白flush table和打开表是个什么流程</p>
<p>2018-12-26</p>
<p> 作者回复</p>
<p>Flush tables是会关掉表，然后下次请求重新读表信息的</p>
<p>第一次打开表其实就是open_table_definitions，包括读表信息一类的</p>
<p>之后再有查询就是拷贝一个对象，加一个计数这样的</p>
<p>2018-12-26</p>
<p>老杨同志   2</p>
<p>愉快的做一下思考题</p>
<p>begin;</p>
<p>select * from t where c&#x3D;5 for update;</p>
<p>commit;</p>
<p>历史知识的结论是，innodb先锁全表的所有行，返回server层，判断c是否等于5，然后释放c！</p>
<p>&#x3D;5的行锁。验证方法：</p>
<p>事务A执行 锁住一行c！&#x3D;5的记录 比如id &#x3D;3 c&#x3D;3</p>
<p>select * from t where id &#x3D; 3 for update 或者 update t set c&#x3D;4 where id &#x3D;3</p>
<p>然后启动新事务B执行上面的语句select * from t where c&#x3D;5 for update; 看看有没有被阻塞。用于判断事务B的语句会不会试图锁不满足条件的记录。然后把事务A和事务B的执行顺序对调一下，也就是先执行B在执行A。看看有没有阻塞，</p>
<p>判断在事务B加锁成功的情况下会不会释放不满足查询条件记录的行锁。2018-12-26</p>
<p> 作者回复</p>
<p>   思路清晰</p>
<p>隔离级别再愉快地改成RR试试 </p>
<p>2018-12-26</p>
<p>小确幸   1</p>
<p>问一下：索引扫描与全表扫描，有什么异同点？2018-12-26</p>
<p> 作者回复</p>
<p>一般说全表扫描默认是值“扫瞄主键索引”</p>
<p>2018-12-26</p>
<p>陈旭   1</p>
<p>老师，最近遇到了一个问题，看您有什么建议。业务场景是这样的：</p>
<p>1.开启事务</p>
<p>2.在表a插入一条记录</p>
<p>3.在表b更新一条记录</p>
<p>4.在表c更新一条记录</p>
<p>5.提交事务</p>
<p>看程序日志所有sql都没问题（没看数据库日志），但是结果是2的那条插入了，3和4都没更新</p>
<p>，这个问题有哪几种情况？2018-12-26</p>
<p> 作者回复</p>
<p>这是被别的并发事务又改回去了吗 </p>
<p>要么是update的值跟原值相同</p>
<p>要么是update条件没有匹配到行</p>
<p>额，最好给一下每个语句执行后的affacted rows , 还有binlog里的日志内容，才好分析</p>
<p>2018-12-26</p>
<p>杰之7   0</p>
<p>通过这一节的阅读学习，老师讲述了一个查询语句被锁住和查询慢的两种情况。在被锁住中，通过等MDL锁，堵住了select查询语句，可以通过kiss掉持有MDL写锁。第二种</p>
<p>是flush被别的语句堵住，然后flush堵住select语句。第三种是等行锁，通过sys.innodb_lock_w</p>
<p>ait查到，然后kill。在查询慢中，lock in sharde mode直接读1000001</p>
<p>而select * from t where id&#x3D;1需要从1000001执行100百万行，所以查询就慢了。老师昨天给我了学习的建议，每个事例在Mysql中去运行做，有不懂的问老师。真的非常感动</p>
<p>，也给我了会一直跟随老师学习的动力和勇气。学了专栏的一半，需要把之前学的内容复习，</p>
<p>接下来我会跟进老师的课程同时动手做之前的案例，不懂有我的思考之后，会及时请教老师。2019-01-21</p>
<p>唐名之   0</p>
<p>show VARIABLES LIKE ‘performance%’;</p>
<p>performance_schema ON</p>
<p>配置已经是打开的</p>
<p>2019-01-11</p>
<p> 作者回复</p>
<p>诶。。那奇怪了</p>
<p>执行</p>
<p>select * from performance_schema.metadata_locks; 看看？2019-01-11</p>
<p>唐名之   0</p>
<p>环境：mysql-5.7.24</p>
<p>show VARIABLES LIKE ‘performance%’;</p>
<p>performance_schema ON</p>
<p>A窗口执行：lock table t WRITE;</p>
<p>B窗口执行：select * from t where id&#x3D;1;</p>
<p>C窗口执行：show PROCESSLIST;</p>
<p>53 slave_user DESKTOP-00HHFO4:63064 Binlog Dump 3027 Master has sent all binlog to sla</p>
<p>ve; waiting for more updates </p>
<p>54 root localhost:64572 Sleep 157 </p>
<p>55 root localhost:64573 mysql_action Sleep 158 </p>
<p>56 root localhost:64575 mysql_action Sleep 156 </p>
<p>57 root localhost:64576 mysql_action Sleep 156 </p>
<p>58 root localhost:64577 mysql_action Sleep 156 </p>
<p>59 root localhost:64578 mysql_action Sleep 156 </p>
<p>60 root localhost:64579 mysql_action Sleep 144 </p>
<p>61 root localhost:64581 mysql_action Query 140 Waiting for table metadata lock select * from t</p>
<p>where id&#x3D;1</p>
<p>62 root localhost:64583 mysql_action Query 0 starting </p>
<p>show PROCESSLIST</p>
<p>已出现：“Waiting for table metadata ” 但这三张表都查不出数据，求解；</p>
<p>SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;</p>
<p>SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS；</p>
<p>SELECT * from sys.schema_table_lock_waits;</p>
<p>2019-01-11</p>
<p> 作者回复</p>
<p>SELECT * from sys.schema_table_lock_waits; 是需要配置里面把performance_schema打开的</p>
<p>；</p>
<p>前面两个语句是只会显示跟innodb的行锁相关的，表级的锁不会显示在这两个表</p>
<p>2019-01-11</p>
<p>M   0</p>
<p>老师讲的很好</p>
<p>2019-01-09</p>
<p> 作者回复</p>
<p>多谢鼓励</p>
<p>看文章的同学都很细致，不敢不认真 </p>
<p>2019-01-09</p>
<p>alias cd&#x3D;rm -rf   0</p>
<p>思考题</p>
<p>c无索引x锁应该是锁表。解锁我觉得应该是sessionb的事物提交之后</p>
<p>2019-01-08</p>
<p> 作者回复</p>
<p>不是锁表哈，innodb里面除非明确写lock table，不会锁表；</p>
<p>解锁时机对的</p>
<p>2019-01-10</p>
<p>ʘᴗʘ小白帽ʘᴗʘ   0</p>
<p>涨知识了</p>
<p>2019-01-04</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/14/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><a class="extend next" rel="next" href="/page/16/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meng Qi</p>
  <div class="site-description" itemprop="description">recording</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">342</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Meng Qi</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">390k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">23:40</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">loading...</span><span id="times">loading...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("1/1/2018 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>

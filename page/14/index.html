<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.fastolf.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="recording">
<meta property="og:type" content="website">
<meta property="og:title" content="Qi">
<meta property="og:url" content="https://www.fastolf.com/page/14/index.html">
<meta property="og:site_name" content="Qi">
<meta property="og:description" content="recording">
<meta property="og:locale">
<meta property="article:author" content="Meng Qi">
<meta property="article:tag" content="Tech;Data;Vision">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.fastolf.com/page/14/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <title>Qi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
<a target="_blank" rel="noopener" href="https://github.com/gitmmq" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Qi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Cogito ergo sum</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/b0b7112a.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/b0b7112a.html" class="post-title-link" itemprop="url">mysql-为什么临时表可以重名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-11 06:18:39" itemprop="dateCreated datePublished" datetime="2019-12-11T06:18:39+08:00">2019-12-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:39" itemprop="dateModified" datetime="2023-01-18T23:34:39+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>为什么临时表可以重名？在上一篇文章中，我们在优化join查询的时候使用到了临时表。</p>
<p>当时，我们是这么用的：<br>你可能会有疑问，为什么要用临时表呢？直接用普通表是不是也可以呢？今天我们就从这个问题说起：临时表有哪些特征，为什么它适合这个场景？这里，我需要先帮你厘清一个容易误解的问题：有的人可能会认为，临时表就是内存表。</p>
<p>但是，这两个概念可是完全不同的。</p>
<p>内存表，指的是使用Memory引擎的表，建表语法是create table … engine&#x3D;memory。</p>
<p>这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。</p>
<p>除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。</p>
<p>而临时表，可以使用各种引擎类型 。</p>
<p>如果是使用InnoDB引擎或者MyISAM引擎的临时表，写create temporary table temp_t like t1;alter table temp_t add index(b);insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000;select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);数据的时候是写到磁盘上的。</p>
<p>当然，临时表也可以使用Memory引擎。</p>
<p>弄清楚了内存表和临时表的区别以后，我们再来看看临时表有哪些特征。</p>
<p>临时表的特性为了便于理解，我们来看下下面这个操作序列：<br>图1 临时表特性示例可以看到，临时表在使用上有以下几个特点：</p>
<ol>
<li><p>建表语法是create temporary table …。</p>
</li>
<li><p>一个临时表只能被创建它的session访问，对其他线程不可见。</p>
</li>
</ol>
<p>所以，图中session A创建的临时表t，对于session B就是不可见的。</p>
<ol start="3">
<li><p>临时表可以与普通表同名。</p>
</li>
<li><p>session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的是临时表。</p>
</li>
<li><p>show tables命令不显示临时表。</p>
</li>
</ol>
<p>由于临时表只能被创建它的session访问，所以在这个session结束的时候，会自动删除临时表。</p>
<p>也正是由于这个特性，临时表就特别适合我们文章开头的join优化这种场景。</p>
<p>为什么呢？原因主要包括以下两个方面：</p>
<ol>
<li><p>不同session的临时表是可以重名的，如果有多个session同时执行join优化，不需要担心表名重复导致建表失败的问题。</p>
</li>
<li><p>不需要担心数据删除问题。</p>
</li>
</ol>
<p>如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。</p>
<p>而临时表由于会自动回收，所以不需要这个额外的操作。</p>
<p>临时表的应用由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。</p>
<p>其中，分库分表系统的跨库查询就是一个典型的使用场景。</p>
<p>一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。</p>
<p>比如。</p>
<p>将一个大表ht，按照字段f，拆分成1024个分表，然后分布到32个数据库实例上。</p>
<p>如下图所示：<br>图2 分库分表简图一般情况下，这种分库分表系统都有一个中间层proxy。</p>
<p>不过，也有一些方案会让客户端直接连接数据库，也就是没有proxy这一层。</p>
<p>在这个架构中，分区key的选择是以“减少跨库和跨表查询”为依据的。</p>
<p>如果大部分的语句都会包含f的等值条件，那么就要用f做分区键。</p>
<p>这样，在proxy这一层解析完SQL语句以后，就能确定将这条语句路由到哪个分表做查询。</p>
<p>比如下面这条语句：<br>这时，我们就可以通过分表规则（比如，N%1024)来确认需要的数据被放在了哪个分表上。</p>
<p>这种语句只需要访问一个分表，是分库分表方案最欢迎的语句形式了。</p>
<p>但是，如果这个表上还有另外一个索引k，并且查询语句是这样的：<br>这时候，由于查询条件里面没有用到分区字段f，只能到所有的分区中去查找满足条件的所有行，然后统一做order by 的操作。</p>
<p>这种情况下，有两种比较常用的思路。</p>
<p>第一种思路是，在proxy层的进程代码中实现排序。</p>
<p>这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。</p>
<p>不过，这个方案的缺点也比较明显：</p>
<ol>
<li>需要的开发工作量比较大。</li>
</ol>
<p>我们举例的这条语句还算是比较简单的，如果涉及到复杂的操作，比如group by，甚至join这样的操作，对中间层的开发能力要求比较高；<br>2. 对proxy端的压力比较大，尤其是很容易出现内存不够用和CPU瓶颈的问题。</p>
<p>另一种思路就是，把各个分库拿到的数据，汇总到一个MySQL实例的一个表中，然后在这个汇总实例上做逻辑操作。</p>
<p>比如上面这条语句，执行流程可以类似这样：<br>在汇总库上创建一个临时表temp_ht，表里包含三个字段v、k、t_modified；<br>在各个分库上执行select v from ht where f&#x3D;N;select v from ht where k &gt;&#x3D; M order by t_modified desc limit 100;select v,k,t_modified from ht_x where k &gt;&#x3D; M order by t_modified desc limit 100;把分库执行的结果插入到temp_ht表中；<br>执行得到结果。</p>
<p>这个过程对应的流程图如下所示：<br>图3 跨库查询流程示意图在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表temp_ht放到32个分库中的某一个上。</p>
<p>这时的查询逻辑与图3类似，你可以自己再思考一下具体的流程。</p>
<p>为什么临时表可以重名？你可能会问，不同线程可以创建同名的临时表，这是怎么做到的呢？接下来，我们就看一下这个问题。</p>
<p>我们在执行select v from temp_ht order by t_modified desc limit 100; 这个语句的时候，MySQL要给这个InnoDB表创建一个frm文件保存表结构定义，还要有地方保存表数据。</p>
<p>这个frm文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程id}_{线程id}_序列号”。</p>
<p>你可以使用select @@tmpdir命令，来显示实例的临时文件目录。</p>
<p>而关于表中数据的存放方式，在不同的MySQL版本中有着不同的处理方式：<br>在5.6以及之前的版本里，MySQL会在临时文件目录下创建一个相同前缀、以.ibd为后缀的文件，用来存放数据文件；<br>而从 5.7版本开始，MySQL引入了一个临时文件表空间，专门用来存放临时文件的数据。</p>
<p>因此，我们就不需要再创建ibd文件了。</p>
<p>从文件名的前缀规则，我们可以看到，其实创建一个叫作t1的InnoDB临时表，MySQL在存储上认为我们创建的表名跟普通表t1是不同的，因此同一个库下面已经有普通表t1的情况下，还是可以再创建一个临时表t1的。</p>
<p>为了便于后面讨论，我先来举一个例子。</p>
<p>图4 临时表的表名这个进程的进程号是1234，session A的线程id是4，session B的线程id是5。</p>
<p>所以你看到了，session A和session B创建的临时表，在磁盘上的文件不会重名。</p>
<p>MySQL维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个table_def_key。</p>
<p>一个普通表的table_def_key的值是由“库名+表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现table_def_key已经存在了。</p>
<p>而对于临时表，table_def_key在“库名+表名”基础上，又加入了“server_id+thread_id”。</p>
<p>create temporary table temp_t(id int primary key)engine&#x3D;innodb;也就是说，session A和sessionB创建的两个临时表t1，它们的table_def_key不同，磁盘文件名也不同，因此可以并存。</p>
<p>在实现上，每个线程都维护了自己的临时表链表。</p>
<p>这样每次session内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在session结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE +表名”操作。</p>
<p>这时候你会发现，binlog中也记录了DROP TEMPORARY TABLE这条命令。</p>
<p>你一定会觉得奇怪，临时表只在线程内自己可以访问，为什么需要写到binlog里面？这，就需要说到主备复制了。</p>
<p>临时表和主备复制既然写binlog，就意味着备库需要。</p>
<p>你可以设想一下，在主库上执行下面这个语句序列：<br>如果关于临时表的操作都不记录，那么在备库就只有create table t_normal表和insert intot_normal select * from temp_t这两个语句的binlog日志，备库在执行到insert into t_normal的时候，就会报错“表temp_t不存在”。</p>
<p>你可能会说，如果把binlog设置为row格式就好了吧？因为binlog是row格式时，在记录insert intot_normal的binlog时，记录的是这个操作的数据，即：write_row event里面记录的逻辑是“插入一行数据（1,1)”。</p>
<p>确实是这样。</p>
<p>如果当前的binlog_format&#x3D;row，那么跟临时表有关的语句，就不会记录到binlog里。</p>
<p>也就是说，只在binlog_format&#x3D;statment&#x2F;mixed 的时候，binlog中才会记录临时表的操作。</p>
<p>这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。</p>
<p>主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。</p>
<p>所以，这时候我们就需要在主库上再写一个DROP TEMPORARY TABLE传给备库执行。</p>
<p>之前有人问过我一个有趣的问题：MySQL在记录binlog的时候，不论是create table还是altertable语句，都是原样记录，甚至于连空格都不变。</p>
<p>但是如果执行drop table t_normal，系统记录binlog就会写成：<br>create table t_normal(id int primary key, c int)engine&#x3D;innodb;&#x2F;<em>Q1</em>&#x2F;create temporary table temp_t like t_normal;&#x2F;<em>Q2</em>&#x2F;insert into temp_t values(1,1);&#x2F;<em>Q3</em>&#x2F;insert into t_normal select * from temp_t;&#x2F;<em>Q4</em>&#x2F;也就是改成了标准的格式。</p>
<p>为什么要这么做呢 ？现在你知道原因了，那就是：drop table命令是可以一次删除多个表的。</p>
<p>比如，在上面的例子中，设置binlog_format&#x3D;row，如果主库上执行 “drop table t_normal, temp_t”这个命令，那么binlog中就只能记录：<br>因为备库上并没有表temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止。</p>
<p>所以，drop table命令记录binlog的时候，就必须对语句做改写。</p>
<p>“&#x2F;* generated by server *&#x2F;”说明了这是一个被服务端改写过的命令。</p>
<p>说到主备复制，还有另外一个问题需要解决：主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？现在，我给你举个例子，下面的序列中实例S是M的备库。</p>
<p>图5 主备关系中的临时表操作主库M上的两个session创建了同名的临时表t1，这两个create temporary table t1 语句都会被传到备库S上。</p>
<p>但是，备库的应用日志线程是共用的，也就是说要在应用线程里面先后执行这个create 语句两次。</p>
<p>（即使开了多线程复制，也可能被分配到从库的同一个worker中执行）。</p>
<p>那么，这会不会导致同步线程报错 ？显然是不会的，否则临时表就是一个bug了。</p>
<p>也就是说，备库线程在执行的时候，要把这两个t1DROP TABLE t̀_normal  ̀&#x2F;* generated by server <em>&#x2F;DROP TABLE t̀_normal  ̀&#x2F;</em> generated by server *&#x2F;表当做两个不同的临时表来处理。</p>
<p>这，又是怎么实现的呢？MySQL在记录binlog的时候，会把主库执行这个语句的线程id写到binlog中。</p>
<p>这样，在备库的应用线程就能够知道执行每个语句的主库线程id，并利用这个线程id来构造临时表的table_def_key：</p>
<ol>
<li>session A的临时表t1，在备库的table_def_key就是：库名+t1+“M的serverid”+“session A的thread_id”;2. session B的临时表t1，在备库的table_def_key就是 ：库名+t1+“M的serverid”+“session B的thread_id”。</li>
</ol>
<p>由于table_def_key不同，所以这两个表在备库的应用线程里面是不会冲突的。</p>
<p>小结今天这篇文章，我和你介绍了临时表的用法和特性。</p>
<p>在实际应用中，临时表一般用于处理比较复杂的计算逻辑。</p>
<p>由于临时表是每个线程自己可见的，所以不需要考虑多个线程执行同一个处理逻辑时，临时表的重名问题。</p>
<p>在线程退出的时候，临时表也能自动删除，省去了收尾和异常处理的工作。</p>
<p>在binlog_format&#x3D;’row’的时候，临时表的操作不记录到binlog中，也省去了不少麻烦，这也可以成为你选择binlog_format时的一个考虑因素。</p>
<p>需要注意的是，我们上面说到的这种临时表，是用户自己创建的 ，也可以称为用户临时表。</p>
<p>与它相对应的，就是内部临时表，在第17篇文章中我已经和你介绍过。</p>
<p>最后，我给你留下一个思考题吧。</p>
<p>下面的语句序列是创建一个临时表，并将其改名：<br>图6 关于临时表改名的思考题可以看到，我们可以使用alter table语法修改临时表的表名，而不能使用rename语法。</p>
<p>你知道这是什么原因吗？你可以把你的分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期的问题是，对于下面这个三个表的join语句，如果改写成straight_join，要怎么指定连接顺序，以及怎么给三个表创建索引。</p>
<p>第一原则是要尽量使用BKA算法。</p>
<p>需要注意的是，使用BKA算法的时候，并不是“先计算两个表join的结果，再跟第三个表join”，而是直接嵌套查询的。</p>
<p>具体实现是：在t1.c&gt;&#x3D;X、t2.c&gt;&#x3D;Y、t3.c&gt;&#x3D;Z这三个条件里，选择一个经过过滤以后，数据最少的那个表，作为第一个驱动表。</p>
<p>此时，可能会出现如下两种情况。</p>
<p>第一种情况，如果选出来是表t1或者t3，那剩下的部分就固定了。</p>
<ol>
<li>如果驱动表是t1，则连接顺序是t1-&gt;t2-&gt;t3，要在被驱动表字段创建上索引，也就是t2.a 和t3.b上创建索引；</li>
<li>如果驱动表是t3，则连接顺序是t3-&gt;t2-&gt;t1，需要在t2.b 和 t1.a上创建索引。</li>
</ol>
<p>同时，我们还需要在第一个驱动表的字段c上创建索引。</p>
<p>第二种情况是，如果选出来的第一个驱动表是表t2的话，则需要评估另外两个条件的过滤效果。</p>
<p>总之，整体的思路就是，尽量让每一次参与join的驱动表的数据集，越小越好，因为这样我们的驱动表就会越小。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/6651e679.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/6651e679.html" class="post-title-link" itemprop="url">mysql-join语句怎么优化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-10 06:03:35" itemprop="dateCreated datePublished" datetime="2019-12-10T06:03:35+08:00">2019-12-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:26:04" itemprop="dateModified" datetime="2023-01-18T23:26:04+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/object-Object/" itemprop="url" rel="index"><span itemprop="name">[object Object]</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/object-Object/object-Object/" itemprop="url" rel="index"><span itemprop="name">[object Object]</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析join语句怎么优化？join语句的两种算法，分别是Index-Nested-Loop-Join-NLJ-和-Block-Nested-Loop-Join-BNL-。"><a href="#问题解析join语句怎么优化？join语句的两种算法，分别是Index-Nested-Loop-Join-NLJ-和-Block-Nested-Loop-Join-BNL-。" class="headerlink" title="问题解析join语句怎么优化？join语句的两种算法，分别是Index Nested-Loop Join(NLJ)和 Block Nested-Loop Join(BNL)。"></a>问题解析join语句怎么优化？join语句的两种算法，分别是Index Nested-Loop Join(NLJ)和 Block Nested-Loop Join(BNL)。</h1><p>我们发现在使用NLJ算法的时候，其实效果还是不错的，比通过应用层拆分成多个语句然后再拼接查询结果更方便，而且性能也不会差。</p>
<p>但是，BNL算法在大表join的时候性能就差多了，比较次数等于两个表参与join的行数的乘积，很消耗CPU资源。</p>
<p>当然了，这两个算法都还有继续优化的空间，我们今天就来聊聊这个话题。</p>
<p>为了便于分析，我还是创建两个表t1、t2来和你展开今天的问题。</p>
<p>为了便于后面量化说明，我在表t1里，插入了1000行数据，每一行的a&#x3D;1001-id的值。</p>
<p>也就是说，表t1中字段a是逆序的。</p>
<p>同时，我在表t2中插入了100万行数据。</p>
<p>Multi-Range Read优化在介绍join语句的优化方案之前，我需要先和你介绍一个知识点，即：Multi-Range Read优化(MRR)。</p>
<p>这个优化的主要目的是尽量使用顺序读盘。</p>
<p>在第4篇文章中，我和你介绍InnoDB的索引结构时，提到了“回表”的概念。</p>
<p>我们先来回顾一下这个概念。</p>
<p>回表是指，InnoDB在普通索引a上查到主键id的值后，再根据一个个主键id的值到主键索引上去查整行数据的过程。</p>
<p>然后，有同学在留言区问到，回表过程是一行行地查数据，还是批量地查数据？我们先来看看这个问题。</p>
<p>假设，我执行这个语句：<br>create table t1(id int primary key, a int, b int, index(a));create table t2 like t1;drop procedure idata;delimiter ;;create procedure idata()begin  declare i int;  set i&#x3D;1;  while(i&lt;&#x3D;1000)do    insert into t1 values(i, 1001-i, i);    set i&#x3D;i+1;  end while;    set i&#x3D;1;  while(i&lt;&#x3D;1000000)do    insert into t2 values(i, i, i);    set i&#x3D;i+1;  end while;end;;delimiter ;call idata();主键索引是一棵B+树，在这棵树上，每次只能根据一个主键id查到一行数据。</p>
<p>因此，回表肯定是一行行搜索主键索引的。</p>
<p>如果随着a的值递增顺序查询的话，id的值就变成随机的，那么就会出现随机访问，性能相对较差。</p>
<p>虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。</p>
<p>因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</p>
<p>这就是MRR优化的设计思路。</p>
<p>此时，语句的执行流程变成了这样：</p>
<ol>
<li>根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;2. 将read_rnd_buffer中的id进行递增排序；</li>
<li>排序后的id数组，依次到主键id索引中查记录，并作为结果返回。</li>
</ol>
<p>select * from t1 where a&gt;&#x3D;1 and a&lt;&#x3D;100;这里，read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。</p>
<p>read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。</p>
<p>之后继续找索引a的下个记录，并继续循环。</p>
<p>另外需要说明的是，如果你想要稳定地使用MRR优化的话，需要设置set optimizer_switch&#x3D;”mrr_cost_based&#x3D;off”。</p>
<p>（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用MRR，把mrr_cost_based设置为off，就是固定使用MRR了。</p>
<p>）下面两幅图就是使用了MRR优化后的执行流程和explain结果。</p>
<p>从explain结果中，我们可以看到Extra字段多了Using MRR，表示的是用上了MRR优化。</p>
<p>而且，由于我们在read_rnd_buffer中按照id做了排序，所以最后得到的结果集也是按照主键id递增顺序的，也就是与图1结果集中行的顺序相反。</p>
<p>到这里，我们小结一下。</p>
<p>MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。</p>
<p>这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。</p>
<p>Batched Key Access理解了MRR性能提升的原理，我们就能理解MySQL在5.6版本后开始引入的Batched KeyAcess(BKA)算法了。</p>
<p>这个BKA算法，其实就是对NLJ算法的优化。</p>
<p>我们再来看看上一篇文章中用到的NLJ算法的流程图：<br>图4 Index Nested-Loop Join流程图NLJ算法执行的逻辑是：从驱动表t1，一行行地取出a的值，再到被驱动表t2去做join。</p>
<p>也就是说，对于表t2来说，每次都是匹配一个值。</p>
<p>这时，MRR的优势就用不上了。</p>
<p>那怎么才能一次性地多传些值给表t2呢？方法就是，从表t1里一次性地多拿些行出来，一起传给表t2。</p>
<p>既然如此，我们就把表t1的数据取出来一部分，先放到一个临时内存。</p>
<p>这个临时内存不是别人，就是join_buffer。</p>
<p>通过上一篇文章，我们知道join_buffer 在BNL算法里的作用，是暂存驱动表的数据。</p>
<p>但是在NLJ算法里并没有用。</p>
<p>那么，我们刚好就可以复用join_buffer到BKA算法中。</p>
<p>如图5所示，是上面的NLJ算法优化后的BKA算法的流程。</p>
<p>图5 Batched Key Acess流程图中，我在join_buffer中放入的数据是P1~P100，表示的是只会取查询需要的字段。</p>
<p>当然，如果join buffer放不下P1~P100的所有数据，就会把这100行数据分成多段执行上图的流程。</p>
<p>那么，这个BKA算法到底要怎么启用呢？如果要使用BKA优化算法的话，你需要在执行SQL语句之前，先设置其中，前两个参数的作用是要启用MRR。</p>
<p>这么做的原因是，BKA算法的优化要依赖于MRR。</p>
<p>set optimizer_switch&#x3D;’mrr&#x3D;on,mrr_cost_based&#x3D;off,batched_key_access&#x3D;on’;BNL算法的性能问题说完了NLJ算法的优化，我们再来看BNL算法的优化。</p>
<p>我在上一篇文章末尾，给你留下的思考题是，使用Block Nested-Loop Join(BNL)算法时，可能会对被驱动表做多次扫描。</p>
<p>如果这个被驱动表是一个大的冷数据表，除了会导致IO压力大以外，还会对系统有什么影响呢？在第33篇文章中，我们说到InnoDB的LRU算法的时候提到，由于InnoDB对Bufffer Pool的LRU算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。</p>
<p>如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。</p>
<p>但是，如果一个使用BNL算法的join语句，多次扫描一个冷表，而且这个语句执行时间超过1秒，就会在再次扫描冷表的时候，把冷表的数据页移到LRU链表头部。</p>
<p>这种情况对应的，是冷表的数据量小于整个Buffer Pool的3&#x2F;8，能够完全放入old区域的情况。</p>
<p>如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入young区域。</p>
<p>由于优化机制的存在，一个正常访问的数据页，要进入young区域，需要隔1秒后再次被访问到。</p>
<p>但是，由于我们的join语句在循环读磁盘和淘汰内存页，进入old区域的数据页，很可能在1秒之内就被淘汰了。</p>
<p>这样，就会导致这个MySQL实例的Buffer Pool在这段时间内，young区域的数据页没有被合理地淘汰。</p>
<p>也就是说，这两种情况都会影响Buffer Pool的正常运作。</p>
<p>大表join操作虽然对IO有影响，但是在语句执行结束后，对IO的影响也就结束了。</p>
<p>但是，对Buffer Pool的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。</p>
<p>为了减少这种影响，你可以考虑增大join_buffer_size的值，减少对被驱动表的扫描次数。</p>
<p>也就是说，BNL算法对系统的影响主要包括三个方面：</p>
<ol>
<li>可能会多次扫描被驱动表，占用磁盘IO资源；</li>
<li>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；</li>
<li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。</li>
</ol>
<p>我们执行语句之前，需要通过理论分析和查看explain结果的方式，确认是否要使用BNL算法。</p>
<p>如果确认优化器会使用BNL算法，就需要做优化。</p>
<p>优化的常见做法是，给被驱动表的join字段加上索引，把BNL算法转成BKA算法。</p>
<p>接下来，我们就具体看看，这个优化怎么做？BNL转BKA一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成BKA算法了。</p>
<p>但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。</p>
<p>比如下面这个语句：<br>我们在文章开始的时候，在表t2中插入了100万行数据，但是经过where条件过滤后，需要参与join的只有2000行数据。</p>
<p>如果这条语句同时是一个低频的SQL语句，那么再为这个语句在表t2的字段b上创建一个索引就很浪费了。</p>
<p>但是，如果使用BNL算法来join的话，这个语句的执行流程是这样的：</p>
<ol>
<li>把表t1的所有字段取出来，存入join_buffer中。</li>
</ol>
<p>这个表只有1000行，join_buffer_size默认值是256k，可以完全存入。</p>
<ol start="2">
<li>扫描表t2，取出每一行数据跟join_buffer中的数据进行对比，如果不满足t1.b&#x3D;t2.b，则跳过；<br>如果满足t1.b&#x3D;t2.b, 再判断其他条件，也就是是否满足t2.b处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。</li>
</ol>
<p>我在上一篇文章中说过，对于表t2的每一行，判断join是否满足的时候，都需要遍历join_buffer中的所有行。</p>
<p>因此判断等值条件的次数是1000*100万&#x3D;10亿次，这个判断的工作量很大。</p>
<p>图6 explain结果图7 语句执行时间可以看到，explain结果里Extra字段显示使用了BNL算法。</p>
<p>在我的测试环境里，这条语句需要执select * from t1 join t2 on (t1.b&#x3D;t2.b) where t2.b&gt;&#x3D;1 and t2.b&lt;&#x3D;2000;行1分11秒。</p>
<p>在表t2的字段b上创建索引会浪费资源，但是不创建索引的话这个语句的等值条件要判断10亿次，想想也是浪费。</p>
<p>那么，有没有两全其美的办法呢？这时候，我们可以考虑使用临时表。</p>
<p>使用临时表的大致思路是：</p>
<ol>
<li>把表t2中满足条件的数据放在临时表tmp_t中；</li>
<li>为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；</li>
<li>让表t1和tmp_t做join操作。</li>
</ol>
<p>此时，对应的SQL语句的写法如下：<br>图8就是这个语句序列的执行效果。</p>
<p>图8 使用临时表的执行效果可以看到，整个过程3个语句执行时间的总和还不到1秒，相比于前面的1分11秒，性能得到了大幅提升。</p>
<p>接下来，我们一起看一下这个过程的消耗：</p>
<ol>
<li>执行insert语句构造temp_t表并插入数据的过程中，对表t2做了全表扫描，这里扫描行数是100万。</li>
</ol>
<p>create temporary table temp_t(id int primary key, a int, b int, index(b))engine&#x3D;innodb;insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000;select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);2. 之后的join语句，扫描表t1，这里的扫描行数是1000；join比较过程中，做了1000次带索引的查询。</p>
<p>相比于优化前的join语句需要做10亿次条件判断来说，这个优化效果还是很明显的。</p>
<p>总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让join语句能够用上被驱动表上的索引，来触发BKA算法，提升查询性能。</p>
<p>扩展-hash join看到这里你可能发现了，其实上面计算10亿次那个操作，看上去有点儿傻。</p>
<p>如果join_buffer里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，而是100万次hash查找。</p>
<p>这样的话，整条语句的执行速度就快多了吧？确实如此。</p>
<p>这，也正是MySQL的优化器和执行器一直被诟病的一个原因：不支持哈希join。</p>
<p>并且，MySQL官方的roadmap，也是迟迟没有把这个优化排上议程。</p>
<p>实际上，这个优化思路，我们可以自己实现在业务端。</p>
<p>实现流程大致如下：</p>
<ol>
<li><p>select * from t1;取得表t1的全部1000行数据，在业务端存入一个hash结构，比如C++里的set、PHP的dict这样的数据结构。</p>
</li>
<li><p>select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; 获取表t2中满足条件的2000行数据。</p>
</li>
<li><p>把这2000行数据，一行一行地取到业务端，到hash结构的数据表中寻找匹配的数据。</p>
</li>
</ol>
<p>满足匹配的条件的这行数据，就作为结果集的一行。</p>
<p>理论上，这个过程会比临时表方案的执行速度还要快一些。</p>
<p>如果你感兴趣的话，可以自己验证一下。</p>
<p>小结今天，我和你分享了Index Nested-Loop Join（NLJ）和Block Nested-Loop Join（BNL）的优化方法。</p>
<p>在这些优化方法中：</p>
<ol>
<li>BKA优化是MySQL已经内置支持的，建议你默认使用；</li>
<li>BNL算法效率低，建议你都尽量转成BKA算法。</li>
</ol>
<p>优化的方向就是给被驱动表的关联字段加上索引；<br>3. 基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的；<br>4. MySQL目前的版本还不支持hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。</p>
<p>最后，我给你留下一道思考题吧。</p>
<p>我们在讲join语句的这两篇文章中，都只涉及到了两个表的join。</p>
<p>那么，现在有一个三个表join的需求，假设这三个表的表结构如下：<br>语句的需求实现如下的join逻辑：<br>现在为了得到最快的执行速度，如果让你来设计表t1、t2、t3上的索引，来支持这个join语句，你会加哪些索引呢？同时，如果我希望你用straight_join来重写这个语句，配合你创建的索引，你就需要安排连接顺序，你主要考虑的因素是什么呢？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/db4372f3.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/db4372f3.html" class="post-title-link" itemprop="url">mysql-使用join</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-09 06:12:07" itemprop="dateCreated datePublished" datetime="2019-12-09T06:12:07+08:00">2019-12-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:39" itemprop="dateModified" datetime="2023-01-18T23:34:39+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>到底可不可以使用join？在实际生产中，关于join语句使用的问题，一般会集中在以下两类：</p>
<ol>
<li>我们DBA不让使用join，使用join有什么问题呢？2. 如果有两个大小不同的表做join，应该用哪个表做驱动表呢？今天这篇文章，我就先跟你说说join语句到底是怎么执行的，然后再来回答这两个问题。</li>
</ol>
<p>为了便于量化分析，我还是创建两个表t1和t2来和你说明。</p>
<p>可以看到，这两个表都有一个主键索引id和一个索引a，字段b上无索引。</p>
<p>存储过程idata()往表t2里插入了1000行数据，在表t1里插入的是100行数据。</p>
<p>Index Nested-Loop Join我们来看一下这个语句：</p>
<p>如果直接使用join语句，MySQL优化器可能会选择表t1或t2作为驱动表，这样会影响我们分析SQL语句的执行过程。</p>
<p>所以，为了便于分析执行过程中的性能问题，我改用straight_join让MySQL使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去join。</p>
<p>在这个语句CREATE TABLE t̀2  ̀(  ìd  ̀int(11) NOT NULL,  <code>a  ̀int(11) DEFAULT NULL,  </code>b  ̀int(11) DEFAULT NULL,  PRIMARY KEY (̀ id )̀,  KEY &#96;a  ̀(̀ a )̀) ENGINE&#x3D;InnoDB;drop procedure idata;delimiter ;;create procedure idata()begin  declare i int;  set i&#x3D;1;  while(i&lt;&#x3D;1000)do    insert into t2 values(i, i, i);    set i&#x3D;i+1;  end while;end;;delimiter ;call idata();create table t1 like t2;insert into t1 (select * from t2 where id&lt;&#x3D;100)select * from t1 straight_join t2 on (t1.a&#x3D;t2.a);里，t1 是驱动表，t2是被驱动表。</p>
<p>现在，我们来看一下这条语句的explain结果。</p>
<p>图1 使用索引字段join的 explain结果可以看到，在这条语句里，被驱动表t2的字段a上有索引，join过程用上了这个索引，因此这个语句的执行流程是这样的：</p>
<ol>
<li><p>从表t1中读入一行数据 R；</p>
</li>
<li><p>从数据行R中，取出a字段到表t2里去查找；</p>
</li>
<li><p>取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；</p>
</li>
<li><p>重复执行步骤1到3，直到表t1的末尾循环结束。</p>
</li>
</ol>
<p>这个过程是先遍历表t1，然后根据从表t1中取出的每行数据中的a值，去表t2中查找满足条件的记录。</p>
<p>在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称NLJ。</p>
<p>它对应的流程图如下所示：</p>
<p>图2 Index Nested-Loop Join算法的执行流程在这个流程里：</p>
<ol>
<li><p>对驱动表t1做了全表扫描，这个过程需要扫描100行；</p>
</li>
<li><p>而对于每一行R，根据a字段去表t2查找，走的是树搜索过程。</p>
</li>
</ol>
<p>由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描100行；</p>
<ol start="3">
<li>所以，整个执行流程，总扫描行数是200。</li>
</ol>
<p>现在我们知道了这个过程，再试着回答一下文章开头的两个问题。</p>
<p>先看第一个问题：能不能使用join?假设不使用join，那我们就只能用单表查询。</p>
<p>我们看看上面这条语句的需求，用单表查询怎么实现。</p>
<ol>
<li><p>执行select * from t1，查出表t1的所有数据，这里有100行；</p>
</li>
<li><p>循环遍历这100行数据：</p>
</li>
</ol>
<p>从每一行R取出字段a的值$R.a；</p>
<p>执行select * from t2 where a&#x3D;$R.a；</p>
<p>把返回的结果和R构成结果集的一行。</p>
<p>可以看到，在这个查询过程，也是扫描了200行，但是总共执行了101条语句，比直接join多了100次交互。</p>
<p>除此之外，客户端还要自己拼接SQL语句和结果。</p>
<p>显然，这么做还不如直接join好。</p>
<p>我们再来看看第二个问题：怎么选择驱动表？在这个join语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。</p>
<p>假设被驱动表的行数是M。</p>
<p>每次在被驱动表查一行数据，要先搜索索引a，再搜索主键索引。</p>
<p>每次搜索一棵树近似复杂度是以2为底的M的对数，记为log M，所以在被驱动表上查一行的时间复杂度是 2*log M。</p>
<p>假设驱动表的行数是N，执行过程就要扫描驱动表N行，然后对于每一行，到被驱动表上匹配一次。</p>
<p>因此整个执行过程，近似复杂度是 N + N<em>2</em>log M。</p>
<p>显然，N对扫描行数的影响更大，因此应该让小表来做驱动表。</p>
<p>到这里小结一下，通过上面的分析我们得到了两个结论：</p>
<ol>
<li><p>使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好；</p>
</li>
<li><p>如果使用join语句的话，需要让小表做驱动表。</p>
</li>
</ol>
<p>但是，你需要注意，这个结论的前提是“可以使用被驱动表的索引”。</p>
<p>接下来，我们再看看被驱动表用不上索引的情况。</p>
<p>Simple Nested-Loop Join现在，我们把SQL语句改成这样：</p>
<p>由于表t2的字段b上没有索引，因此再用图2的执行流程时，每次到t2去匹配的时候，就要做一次222如果你没觉得这个影响有那么“显然”， 可以这么理解：N扩大1000倍的话，扫描行数就会扩大1000倍；而M扩大1000倍，扫描行数扩大不到10倍。</p>
<p>select * from t1 straight_join t2 on (t1.a&#x3D;t2.b);全表扫描。</p>
<p>你可以先设想一下这个问题，继续使用图2的算法，是不是可以得到正确的结果呢？如果只看结果的话，这个算法是正确的，而且这个算法也有一个名字，叫做“Simple Nested-Loop Join”。</p>
<p>但是，这样算来，这个SQL请求就要扫描表t2多达100次，总共扫描100*1000&#x3D;10万行。</p>
<p>这还只是两个小表，如果t1和t2都是10万行的表（当然了，这也还是属于小表的范围），就要扫描100亿行，这个算法看上去太“笨重”了。</p>
<p>当然，MySQL也没有使用这个Simple Nested-Loop Join算法，而是使用了另一个叫作“BlockNested-Loop Join”的算法，简称BNL。</p>
<p>Block Nested-Loop Join这时候，被驱动表上没有可用的索引，算法的流程是这样的：</p>
<ol>
<li><p>把表t1的数据读入线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整个表t1放入了内存；</p>
</li>
<li><p>扫描表t2，把表t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回。</p>
</li>
</ol>
<p>这个过程的流程图如下：</p>
<p>图3 Block Nested-Loop Join 算法的执行流程对应地，这条SQL语句的explain结果如下所示：</p>
<p>图4 不使用索引字段join的 explain结果可以看到，在这个过程中，对表t1和t2都做了一次全表扫描，因此总的扫描行数是1100。</p>
<p>由于join_buffer是以无序数组的方式组织的，因此对表t2中的每一行，都要做100次判断，总共需要在内存中做的判断次数是：100*1000&#x3D;10万次。</p>
<p>前面我们说过，如果使用Simple Nested-Loop Join算法进行查询，扫描行数也是10万行。</p>
<p>因此，从时间复杂度上来说，这两个算法是一样的。</p>
<p>但是，Block Nested-Loop Join算法的这10万次判断是内存操作，速度上会快很多，性能也更好。</p>
<p>接下来，我们来看一下，在这种情况下，应该选择哪个表做驱动表。</p>
<p>假设小表的行数是N，大表的行数是M，那么在这个算法里：</p>
<ol>
<li><p>两个表都做一次全表扫描，所以总的扫描行数是M+N；</p>
</li>
<li><p>内存中的判断次数是M*N。</p>
</li>
</ol>
<p>可以看到，调换这两个算式中的M和N没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。</p>
<p>然后，你可能马上就会问了，这个例子里表t1才100行，要是表t1是一个大表，join_buffer放不下怎么办呢？join_buffer的大小是由参数join_buffer_size设定的，默认值是256k。</p>
<p>如果放不下表t1的所有数据话，策略很简单，就是分段放。</p>
<p>我把join_buffer_size改成1200，再执行：</p>
<p>执行过程就变成了：</p>
<ol>
<li><p>扫描表t1，顺序读取数据行放入join_buffer中，放完第88行join_buffer满了，继续第2步；</p>
</li>
<li><p>扫描表t2，把t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回；</p>
</li>
<li><p>清空join_buffer；</p>
</li>
<li><p>继续扫描表t1，顺序读取最后的12行数据放入join_buffer中，继续执行第2步。</p>
</li>
</ol>
<p>执行流程图也就变成这样：</p>
<p>select * from t1 straight_join t2 on (t1.a&#x3D;t2.b);图5 Block Nested-Loop Join – 两段图中的步骤4和5，表示清空join_buffer再复用。</p>
<p>这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去join”。</p>
<p>可以看到，这时候由于表t1被分成了两次放入join_buffer中，导致表t2会被扫描两次。</p>
<p>虽然分成两次放入join_buffer，但是判断等值条件的次数还是不变的，依然是(88+12)*1000&#x3D;10万次。</p>
<p>我们再来看下，在这种情况下驱动表的选择问题。</p>
<p>假设，驱动表的数据行数是N，需要分K段才能完成算法流程，被驱动表的数据行数是M。</p>
<p>注意，这里的K不是常数，N越大K就会越大，因此把K表示为λ*N，显然λ的取值范围是(0,1)。</p>
<p>所以，在这个算法的执行过程中：</p>
<ol>
<li><p>扫描行数是 N+λ<em>N</em>M；</p>
</li>
<li><p>内存判断 N*M次。</p>
</li>
</ol>
<p>显然，内存判断次数是不受选择哪个表作为驱动表影响的。</p>
<p>而考虑到扫描行数，在M和N大小确定的情况下，N小一些，整个算式的结果会更小。</p>
<p>所以结论是，应该让小表当驱动表。</p>
<p>当然，你会发现，在N+λ<em>N</em>M这个式子里，λ才是影响扫描行数的关键因素，这个值越小越好。</p>
<p>刚刚我们说了N越大，分段数K越大。</p>
<p>那么，N固定的时候，什么参数会影响K的大小呢？（也就是λ的大小）答案是join_buffer_size。</p>
<p>join_buffer_size越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。</p>
<p>这就是为什么，你可能会看到一些建议告诉你，如果你的join语句很慢，就把join_buffer_size改大。</p>
<p>理解了MySQL执行join的两种算法，现在我们再来试着回答文章开头的两个问题。</p>
<p>第一个问题：能不能使用join语句？1. 如果可以使用Index Nested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是没问题的；</p>
<ol start="2">
<li>如果使用Block Nested-Loop Join算法，扫描行数就会过多。</li>
</ol>
<p>尤其是在大表上的join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。</p>
<p>所以这种join尽量不要用。</p>
<p>所以你在判断要不要使用join语句时，就是看explain结果里面，Extra字段里面有没有出现“BlockNested Loop”字样。</p>
<p>第二个问题是：如果要使用join，应该选择大表做驱动表还是选择小表做驱动表？1. 如果是Index Nested-Loop Join算法，应该选择小表做驱动表；</p>
<ol start="2">
<li>如果是Block Nested-Loop Join算法：</li>
</ol>
<p>在join_buffer_size足够大的时候，是一样的；</p>
<p>在join_buffer_size不够大的时候（这种情况更常见），应该选择小表做驱动表。</p>
<p>所以，这个问题的结论就是，总是应该使用小表做驱动表。</p>
<p>当然了，这里我需要说明下，什么叫作“小表”。</p>
<p>我们前面的例子是没有加条件的。</p>
<p>如果我在语句的where条件加上 t2.id&lt;&#x3D;50这个限定条件，再来看下这两条语句：</p>
<p>select * from t1 straight_join t2 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;50;select * from t2 straight_join t1 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;50;注意，为了让两条语句的被驱动表都用不上索引，所以join字段都使用了没有索引的字段b。</p>
<p>但如果是用第二个语句的话，join_buffer只需要放入t2的前50行，显然是更好的。</p>
<p>所以这里，“t2的前50行”是那个相对小的表，也就是“小表”。</p>
<p>我们再来看另外一组例子：</p>
<p>这个例子里，表t1 和 t2都是只有100行参加join。</p>
<p>但是，这两条语句每次查询放入join_buffer中的数据是不一样的：</p>
<p>表t1只查字段b，因此如果把t1放到join_buffer中，则join_buffer中只需要放入b的值；</p>
<p>表t2需要查所有的字段，因此如果把表t2放到join_buffer中的话，就需要放入三个字段id、a和b。</p>
<p>这里，我们应该选择表t1作为驱动表。</p>
<p>也就是说在这个例子里，“只需要一列参与join的表t1”是那个相对小的表。</p>
<p>所以，更准确地说，在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。</p>
<p>小结今天，我和你介绍了MySQL执行join语句的两种可能算法，这两种算法是由能否使用被驱动表的索引决定的。</p>
<p>而能否用上被驱动表的索引，对join语句的性能影响很大。</p>
<p>通过对Index Nested-Loop Join和Block Nested-Loop Join两个算法执行过程的分析，我们也得到了文章开头两个问题的答案：</p>
<ol>
<li><p>如果可以使用被驱动表的索引，join语句还是有其优势的；</p>
</li>
<li><p>不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法，这样的语句就尽量不要使用；</p>
</li>
<li><p>在使用join的时候，应该让小表做驱动表。</p>
</li>
</ol>
<p>最后，又到了今天的问题时间。</p>
<p>我们在上文说到，使用Block Nested-Loop Join算法，可能会因为join_buffer不够大，需要对被select t1.b,t2.* from  t1  straight_join t2 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;100;select t1.b,t2.* from  t2  straight_join t1 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;100;驱动表做多次全表扫描。</p>
<p>我的问题是，如果被驱动表是一个大表，并且是一个冷数据表，除了查询过程中可能会导致IO压力大以外，你觉得对这个MySQL服务还有什么更严重的影响吗？（这个问题需要结合上一篇文章的知识点）你可以把你的结论和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间我在上一篇文章最后留下的问题是，如果客户端由于压力过大，迟迟不能接收数据，会对服务端造成什么严重的影响。</p>
<p>这个问题的核心是，造成了“长事务”。</p>
<p>至于长事务的影响，就要结合我们前面文章中提到的锁、MVCC的知识点了。</p>
<p>如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；</p>
<p>当然读的事务也有问题，就是会导致undo log不能被回收，导致回滚段空间膨胀。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/f0491e2a.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/f0491e2a.html" class="post-title-link" itemprop="url">mysql-我查这么多数据会不会把数据库内存打爆</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-08 06:03:33" itemprop="dateCreated datePublished" datetime="2019-12-08T06:03:33+08:00">2019-12-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:39" itemprop="dateModified" datetime="2023-01-18T23:34:39+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>我查这么多数据，会不会把数据库内存打爆？我经常会被问到这样一个问题：我的主机内存只有100G，现在要对一个200G的大表做全表扫描，会不会把数据库主机的内存用光了？这个问题确实值得担心，被系统OOM（out of memory）可不是闹着玩的。</p>
<p>但是，反过来想想，逻辑备份的时候，可不就是做整库扫描吗？如果这样就会把内存吃光，逻辑备份不是早就挂了？所以说，对大表做全表扫描，看来应该是没问题的。</p>
<p>但是，这个流程到底是怎么样的呢？全表扫描对server层的影响假设，我们现在要对一个200G的InnoDB表db1. t，执行一个全表扫描。</p>
<p>当然，你要把扫描结果保存在客户端，会使用类似这样的命令：</p>
<p>你已经知道了，InnoDB的数据是保存在主键索引上的，所以全表扫描实际上是直接扫描表t的主键索引。</p>
<p>这条查询语句由于没有其他的判断条件，所以查到的每一行都可以直接放到结果集里面，然后返回给客户端。</p>
<p>那么，这个“结果集”存在哪里呢？mysql -h$host -P$port -u$user -p$pwd -e “select * from db1.t” &gt; $target_file实际上，服务端并不需要保存一个完整的结果集。</p>
<p>取数据和发数据的流程是这样的：</p>
<ol>
<li>获取一行，写到net_buffer中。</li>
</ol>
<p>这块内存的大小是由参数net_buffer_length定义的，默认是16k。</p>
<ol start="2">
<li><p>重复获取行，直到net_buffer写满，调用网络接口发出去。</p>
</li>
<li><p>如果发送成功，就清空net_buffer，然后继续取下一行，并写入net_buffer。</p>
</li>
<li><p>如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket sendbuffer）写满了，进入等待。</p>
</li>
</ol>
<p>直到网络栈重新可写，再继续发送。</p>
<p>这个过程对应的流程图如下所示。</p>
<p>图1 查询结果发送流程从这个流程中，你可以看到：</p>
<ol>
<li><p>一个查询在发送过程中，占用的MySQL内部的内存最大就是net_buffer_length这么大，并不会达到200G；</p>
</li>
<li><p>socket send buffer 也不可能达到200G（默认定义&#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;wmem_default），如果socket send buffer被写满，就会暂停读数据的流程。</p>
</li>
</ol>
<p>也就是说，MySQL是“边读边发的”，这个概念很重要。</p>
<p>这就意味着，如果客户端接收得慢，会导致MySQL服务端由于结果发不出去，这个事务的执行时间变长。</p>
<p>比如下面这个状态，就是我故意让客户端不去读socket receive buffer中的内容，然后在服务端show processlist看到的结果。</p>
<p>图2 服务端发送阻塞如果你看到State的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。</p>
<p>我在上一篇文章中曾提到，如果客户端使用–quick参数，会使用mysql_use_result方法。</p>
<p>这个方法是读一行处理一行。</p>
<p>你可以想象一下，假设有一个业务的逻辑比较复杂，每读一行数据以后要处理的逻辑如果很慢，就会导致客户端要过很久才会去取下一行数据，可能就会出现如图2所示的这种情况。</p>
<p>因此，对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，我都建议你使用mysql_store_result这个接口，直接把查询结果保存到本地内存。</p>
<p>当然前提是查询返回结果不多。</p>
<p>在第30篇文章评论区，有同学说到自己因为执行了一个大查询导致客户端占用内存近20G，这种情况下就需要改用mysql_use_result接口了。</p>
<p>另一方面，如果你在自己负责维护的MySQL里看到很多个线程都处于“Sending to client”这个状态，就意味着你要让业务开发同学优化查询结果，并评估这么多的返回结果是否合理。</p>
<p>而如果要快速减少处于这个状态的线程的话，将net_buffer_length参数设置为一个更大的值是一个可选方案。</p>
<p>与“Sending to client”长相很类似的一个状态是“Sending data”，这是一个经常被误会的问题。</p>
<p>有同学问我说，在自己维护的实例上看到很多查询语句的状态是“Sending data”，但查看网络也没什么问题啊，为什么Sending data要这么久？实际上，一个查询语句的状态变化是这样的（注意：这里，我略去了其他无关的状态）：</p>
<p>MySQL查询语句进入执行阶段后，首先把状态设置成“Sending data”；</p>
<p>然后，发送执行结果的列相关的信息（meta data) 给客户端；</p>
<p>再继续执行语句的流程；</p>
<p>执行完成后，把状态设置成空字符串。</p>
<p>也就是说，“Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。</p>
<p>比如，你可以构造一个锁等待的场景，就能看到Sending data状态。</p>
<p>图3 读全表被锁图 4 Sending data状态可以看到，session B明显是在等锁，状态显示为Sending data。</p>
<p>也就是说，仅当一个线程处于“等待客户端接收结果”的状态，才会显示”Sending to client”；而如果显示成“Sending data”，它的意思只是“正在执行”。</p>
<p>现在你知道了，查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。</p>
<p>在server层的处理逻辑我们都清楚了，在InnoDB引擎里面又是怎么处理的呢？ 扫描全表会不会对引擎系统造成影响呢？全表扫描对InnoDB的影响在第2和第15篇文章中，我介绍WAL机制的时候，和你分析了InnoDB内存的一个作用，是保存更新的结果，再配合redo log，就避免了随机写盘。</p>
<p>内存的数据页是在Buffer Pool (BP)中管理的，在WAL里Buffer Pool 起到了加速更新的作用。</p>
<p>而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。</p>
<p>在第2篇文章的评论区有同学问道，由于有WAL机制，当事务提交的时候，磁盘上的数据页是旧的，那如果这时候马上有一个查询要来读这个数据页，是不是要马上把redo log应用到数据页呢？答案是不需要。</p>
<p>因为这时候内存数据页的结果是最新的，直接读内存页就可以了。</p>
<p>你看，这时候查询根本不需要读磁盘，直接从内存拿结果，速度是很快的。</p>
<p>所以说，Buffer Pool还有加速查询的作用。</p>
<p>而Buffer Pool对查询的加速效果，依赖于一个重要的指标，即：内存命中率。</p>
<p>你可以在show engine innodb status结果中，查看一个系统当前的BP命中率。</p>
<p>一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在99%以上。</p>
<p>执行show engine innodb status ，可以看到“Buffer pool hit rate”字样，显示的就是当前的命中率。</p>
<p>比如图5这个命中率，就是99.0%。</p>
<p>图5 show engine innodb status显示内存命中率如果所有查询需要的数据页都能够直接从内存得到，那是最好的，对应的命中率就是100%。</p>
<p>但，这在实际生产上是很难做到的。</p>
<p>InnoDB Buffer Pool的大小是由参数 innodb_buffer_pool_size确定的，一般建议设置成可用物理内存的60%~80%。</p>
<p>在大约十年前，单机的数据量是上百个G，而物理内存是几个G；现在虽然很多服务器都能有128G甚至更高的内存，但是单机的数据量却达到了T级别。</p>
<p>所以，innodb_buffer_pool_size小于磁盘的数据量是很常见的。</p>
<p>如果一个 Buffer Pool满了，而又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。</p>
<p>InnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是淘汰最久未使用的数据。</p>
<p>下图是一个LRU算法的基本模型。</p>
<p>图6 基本LRU算法InnoDB管理Buffer Pool的LRU算法，是用链表来实现的。</p>
<ol>
<li><p>在图6的状态1里，链表头部是P1，表示P1是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；</p>
</li>
<li><p>这时候有一个读请求访问P3，因此变成状态2，P3被移到最前面；</p>
</li>
<li><p>状态3表示，这次访问的数据页是不存在于链表中的，所以需要在Buffer Pool中新申请一个数据页Px，加到链表头部。</p>
</li>
</ol>
<p>但是由于内存已经满了，不能申请新的内存。</p>
<p>于是，会清空链表末尾Pm这个数据页的内存，存入Px的内容，然后放到链表头部。</p>
<ol start="4">
<li>从效果上看，就是最久没有被访问的数据页Pm，被淘汰了。</li>
</ol>
<p>这个算法乍一看上去没什么问题，但是如果考虑到要做一个全表扫描，会不会有问题呢？假设按照这个算法，我们要扫描一个200G的表，而这个表是一个历史数据表，平时没有业务访问它。</p>
<p>那么，按照这个算法扫描的话，就会把当前的Buffer Pool里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。</p>
<p>也就是说Buffer Pool里面主要放的是这个历史数据表的数据。</p>
<p>对于一个正在做业务服务的库，这可不妙。</p>
<p>你会看到，Buffer Pool的内存命中率急剧下降，磁盘压力增加，SQL语句响应变慢。</p>
<p>所以，InnoDB不能直接使用这个LRU算法。</p>
<p>实际上，InnoDB对LRU算法做了改进。</p>
<p>图 7 改进的LRU算法在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。</p>
<p>图中LRU_old指向的就是old区域的第一个位置，是整个链表的5&#x2F;8处。</p>
<p>也就是说，靠近链表头部的5&#x2F;8是young区域，靠近链表尾部的3&#x2F;8是old区域。</p>
<p>改进后的LRU算法执行流程变成了下面这样。</p>
<ol>
<li><p>图7中状态1，要访问数据页P3，由于P3在young区域，因此和优化前的LRU算法一样，将其移到链表头部，变成状态2。</p>
</li>
<li><p>之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。</p>
</li>
<li><p>处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p>
</li>
</ol>
<p>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</p>
<p>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。</p>
<p>1秒这个时间，是由参数innodb_old_blocks_time控制的。</p>
<p>其默认值是1000，单位毫秒。</p>
<p>这个策略，就是为了处理类似全表扫描的操作量身定制的。</p>
<p>还是以刚刚的扫描200G的历史数据表为例，我们看看改进后的LRU算法的操作逻辑：</p>
<ol>
<li><p>扫描过程中，需要新插入的数据页，都被放到old区域;2. 一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过1秒，因此还是会被保留在old区域；</p>
</li>
<li><p>再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是young区域），很快就会被淘汰出去。</p>
</li>
</ol>
<p>可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了Buffer Pool，但是对young区域完全没有影响，从而保证了Buffer Pool响应正常业务的查询命中率。</p>
<p>小结今天，我用“大查询会不会把内存用光”这个问题，和你介绍了MySQL的查询结果，发送给客户端的过程。</p>
<p>由于MySQL采用的是边算边发的逻辑，因此对于数据量很大的查询结果来说，不会在server端保存完整的结果集。</p>
<p>所以，如果客户端读结果不及时，会堵住MySQL的查询过程，但是不会把内存打爆。</p>
<p>而对于InnoDB引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。</p>
<p>并且，由于InnoDB对LRU算法做了改进，冷数据的全表扫描，对Buffer Pool的影响也能做到可控。</p>
<p>当然，我们前面文章有说过，全表扫描还是比较耗费IO资源的，所以业务高峰期还是不能直接在线上主库执行全表扫描的。</p>
<p>最后，我给你留一个思考题吧。</p>
<p>我在文章中说到，如果由于客户端压力太大，迟迟不能接收结果，会导致MySQL无法发送结果而影响语句执行。</p>
<p>但，这还不是最糟糕的情况。</p>
<p>你可以设想出由于客户端的性能问题，对数据库影响更严重的例子吗？或者你是否经历过这样的场景？你又是怎么优化的？你可以把你的经验和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期的问题是，如果一个事务被kill之后，持续处于回滚状态，从恢复速度的角度看，你是应该重启等它执行结束，还是应该强行重启整个MySQL进程。</p>
<p>因为重启之后该做的回滚动作还是不能少的，所以从恢复速度的角度来说，应该让它自己结束。</p>
<p>当然，如果这个语句可能会占用别的锁，或者由于占用IO资源过多，从而影响到了别的语句执行的话，就需要先做主备切换，切到新主库提供服务。</p>
<p>切换之后别的线程都断开了连接，自动停止执行。</p>
<p>接下来还是等它自己执行完成。</p>
<p>这个操作属于我们在文章中说到的，减少系统压力，加速终止逻辑。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/11e721ea.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/11e721ea.html" class="post-title-link" itemprop="url">mysql-为什么还有kill不掉的语句</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-07 06:12:12" itemprop="dateCreated datePublished" datetime="2019-12-07T06:12:12+08:00">2019-12-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:26:04" itemprop="dateModified" datetime="2023-01-18T23:26:04+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>6.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>25 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>为什么还有kill不掉的语句？在MySQL中有两个kill命令：一个是kill query +线程id，表示终止这个线程中正在执行的语句；一个是kill connection +线程id，这里connection可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。</p>
<p>不知道你在使用MySQL的时候，有没有遇到过这样的现象：使用了kill命令，却没能断开这个连接。</p>
<p>再执行show processlist命令，看到这条语句的Command列显示的是Killed。</p>
<p>你一定会奇怪，显示为Killed是什么意思，不是应该直接在show processlist的结果里看不到这个线程了吗？今天，我们就来讨论一下这个问题。</p>
<p>其实大多数情况下，kill query&#x2F;connection命令是有效的。</p>
<p>比如，执行一个查询的过程中，发现执行时间太久，要放弃继续查询，这时我们就可以用kill query命令，终止这条查询语句。</p>
<p>还有一种情况是，语句处于锁等待的时候，直接使用kill命令也是有效的。</p>
<p>我们一起来看下这个例子：</p>
<p>图1 kill query 成功的例子可以看到，session C 执行kill query以后，session B几乎同时就提示了语句被中断。</p>
<p>这，就是我们预期的结果。</p>
<p>收到kill以后，线程做什么？但是，这里你要停下来想一下：session B是直接终止掉线程，什么都不管就直接退出吗？显然，这是不行的。</p>
<p>我在第6篇文章中讲过，当对一个表做增删改查操作时，会在表上加MDL读锁。</p>
<p>所以，session B虽然处于blocked状态，但还是拿着一个MDL读锁的。</p>
<p>如果线程被kill的时候，就直接终止，那之后这个MDL读锁就没机会被释放了。</p>
<p>这样看来，kill并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。</p>
<p>实现上，当用户执行kill query thread_id_B时，MySQL里处理kill命令的线程做了两件事：</p>
<ol>
<li><p>把session B的运行状态改成THD::KILL_QUERY(将变量killed赋值为THD::KILL_QUERY)；</p>
</li>
<li><p>给session B的执行线程发一个信号。</p>
</li>
</ol>
<p>为什么要发信号呢？因为像图1的我们例子里面，session B处于锁等待状态，如果只是把session B的线程状态设置THD::KILL_QUERY，线程B并不知道这个状态变化，还是会继续等待。</p>
<p>发一个信号的目的，就是让session B退出等待，来处理这个THD::KILL_QUERY状态。</p>
<p>其实，这跟Linux的kill命令类似，kill -N pid并不是让进程直接停止，而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑。</p>
<p>只是对于MySQL的kill命令来说，不需要传信号量参数，就只有“停止”这个命令。</p>
<p>上面的分析中，隐含了这么三层意思：</p>
<ol>
<li><p>一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是THD::KILL_QUERY，才开始进入语句终止逻辑；</p>
</li>
<li><p>如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；</p>
</li>
<li><p>语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。</p>
</li>
</ol>
<p>到这里你就知道了，原来不是“说停就停的”。</p>
<p>接下来，我们再看一个kill不掉的例子，也就是我们在前面第29篇文章中提到的innodb_thread_concurrency 不够用的例子。</p>
<p>首先，执行set global innodb_thread_concurrency&#x3D;2，将InnoDB的并发线程上限数设置为2；然后，执行下面的序列：</p>
<p>图2 kill query 无效的例子可以看到：</p>
<ol>
<li><p>sesssion C执行的时候被堵住了；</p>
</li>
<li><p>但是session D执行的kill query C命令却没什么效果，3. 直到session E执行了kill connection命令，才断开了session C的连接，提示“Lostconnection to MySQL server during query”，4. 但是这时候，如果在session E中执行show processlist，你就能看到下面这个图。</p>
</li>
</ol>
<p>图3 kill connection之后的效果这时候，id&#x3D;12这个线程的Commnad列显示的是Killed。</p>
<p>也就是说，客户端虽然断开了连接，但实际上服务端上这条语句还在执行过程中。</p>
<p>为什么在执行kill query命令时，这条语句不像第一个例子的update语句一样退出呢？在实现上，等行锁时，使用的是pthread_cond_timedwait函数，这个等待状态可以被唤醒。</p>
<p>但是，在这个例子里，12号线程的等待逻辑是这样的：每10毫秒判断一下是否可以进入InnoDB执行，如果不行，就调用nanosleep函数进入sleep状态。</p>
<p>也就是说，虽然12号线程的状态已经被设置成了KILL_QUERY，但是在这个等待进入InnoDB的循环过程中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。</p>
<p>而当session E执行kill connection 命令时，是这么做的，1. 把12号线程状态设置为KILL_CONNECTION；</p>
<ol start="2">
<li>关掉12号线程的网络连接。</li>
</ol>
<p>因为有这个操作，所以你会看到，这时候session C收到了断开连接的提示。</p>
<p>那为什么执行show processlist的时候，会看到Command列显示为killed呢？其实，这就是因为在执行show processlist的时候，有一个特别的逻辑：</p>
<p>所以其实，即使是客户端退出了，这个线程的状态仍然是在等待中。</p>
<p>那这个线程什么时候会退出呢？答案是，只有等到满足进入InnoDB的条件后，session C的查询语句继续执行，然后才有可能判断到线程状态已经变成了KILL_QUERY或者KILL_CONNECTION，再进入终止逻辑阶段。</p>
<p>到这里，我们来小结一下。</p>
<p>这个例子是kill无效的第一类情况，即：线程没有执行到判断线程状态的逻辑。</p>
<p>跟这种情况相同的，还有由于IO压力过大，读写IO的函数一直无法返回，导致不能及时判断线程的状态。</p>
<p>如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed。</p>
<p>另一类情况是，终止逻辑耗时较长。</p>
<p>这时候，从show processlist结果上看也是Command&#x3D;Killed，需要等到终止逻辑完成，语句才算真正完成。</p>
<p>这类情况，比较常见的场景有以下几种：</p>
<ol>
<li>超大事务执行期间被kill。</li>
</ol>
<p>这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。</p>
<ol start="2">
<li>大查询回滚。</li>
</ol>
<p>如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待IO资源，导致耗时较长。</p>
<ol start="3">
<li>DDL命令执行到最后阶段，如果被kill，需要删除中间过程的临时文件，也可能受IO资源影响耗时较久。</li>
</ol>
<p>之前有人问过我，如果直接在客户端通过Ctrl+C命令，是不是就可以直接终止线程呢？答案是，不可以。</p>
<p>这里有一个误解，其实在客户端的操作只能操作到客户端的线程，客户端和服务端只能通过网络交互，是不可能直接操作服务端线程的。</p>
<p>而由于MySQL是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继续发命令也是没有用的。</p>
<p>实际上，执行Ctrl+C的时候，是MySQL客户端另外启动一个连接，然后发送一个kill query 命令。</p>
<p>所以，你可别以为在客户端执行完Ctrl+C就万事大吉了。</p>
<p>因为，要kill掉一个线程，还涉及到后端的很多操作。</p>
<p>另外两个关于客户端的误解在实际使用中，我也经常会碰到一些同学对客户端的使用有误解。</p>
<p>接下来，我们就来看看两个最常见的误解。</p>
<p>第一个误解是：如果库里面的表特别多，连接就会很慢。</p>
<p>有些线上的库，会包含很多表（我见过最多的一个库里有6万个表）。</p>
<p>这时候，你就会发现，每次用客户端连接都会卡在下面这个界面上。</p>
<p>图4 连接等待而如果db1这个库里表很少的话，连接起来就会很快，可以很快进入输入命令的状态。</p>
<p>因此，有同学会认为是表的数目影响了连接性能。</p>
<p>从第一篇文章你就知道，每个客户端在和服务端建立连接的时候，需要做的事情就是TCP握手、用户校验、获取权限。</p>
<p>但这几个操作，显然跟库里面表的个数无关。</p>
<p>但实际上，正如图中的文字提示所说的，当使用默认参数连接的时候，MySQL客户端会提供一个本地库名和表名补全的功能。</p>
<p>为了实现这个功能，客户端在连接成功后，需要多做一些操作：</p>
<ol>
<li><p>执行show databases；</p>
</li>
<li><p>切到db1库，执行show tables；</p>
</li>
<li><p>把这两个命令的结果用于构建一个本地的哈希表。</p>
</li>
</ol>
<p>在这些操作中，最花时间的就是第三步在本地构建哈希表的操作。</p>
<p>所以，当一个库中的表个数非常多的时候，这一步就会花比较长的时间。</p>
<p>也就是说，我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。</p>
<p>图中的提示也说了，如果在连接命令中加上-A，就可以关掉这个自动补全的功能，然后客户端就可以快速返回了。</p>
<p>这里自动补全的效果就是，你在输入库名或者表名的时候，输入前缀，可以使用Tab键自动补全表名或者显示提示。</p>
<p>实际使用中，如果你自动补全功能用得并不多，我建议你每次使用的时候都默认加-A。</p>
<p>其实提示里面没有说，除了加-A以外，加–quick(或者简写为-q)参数，也可以跳过这个阶段。</p>
<p>但是，这个–quick是一个更容易引起误会的参数，也是关于客户端常见的一个误解。</p>
<p>你看到这个参数，是不是觉得这应该是一个让服务端加速的参数？但实际上恰恰相反，设置了这个参数可能会降低服务端的性能。</p>
<p>为什么这么说呢？MySQL客户端发送请求后，接收服务端返回结果的方式有两种：</p>
<ol>
<li>一种是本地缓存，也就是在本地开一片内存，先把结果存起来。</li>
</ol>
<p>如果你用API开发，对应的就是mysql_store_result 方法。</p>
<ol start="2">
<li>另一种是不缓存，读一个处理一个。</li>
</ol>
<p>如果你用API开发，对应的就是mysql_use_result方法。</p>
<p>MySQL客户端默认采用第一种方式，而如果加上–quick参数，就会使用第二种不缓存的方式。</p>
<p>采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。</p>
<p>关于服务端的具体行为，我会在下一篇文章再和你展开说明。</p>
<p>那你会说，既然这样，为什么要给这个参数取名叫作quick呢？这是因为使用这个参数可以达到以下三点效果：</p>
<p>第一点，就是前面提到的，跳过表名自动补全功能。</p>
<p>第二点，mysql_store_result需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存，可能会影响客户端本地机器的性能；</p>
<p>第三点，是不会把执行命令记录到本地的命令历史文件。</p>
<p>所以你看到了，–quick参数的意思，是让客户端变得更快。</p>
<p>小结在今天这篇文章中，我首先和你介绍了MySQL中，有些语句和连接“kill不掉”的情况。</p>
<p>这些“kill不掉”的情况，其实是因为发送kill命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。</p>
<p>而被kill的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。</p>
<p>并且，终止逻辑本身也是需要耗费时间的。</p>
<p>所以，如果你发现一个线程处于Killed状态，你可以做的事情就是，通过影响系统环境，让这个Killed状态尽快结束。</p>
<p>比如，如果是第一个例子里InnoDB并发度的问题，你就可以临时调大innodb_thread_concurrency的值，或者停掉别的线程，让出位子给这个线程执行。</p>
<p>而如果是回滚逻辑由于受到IO资源限制执行得比较慢，就通过减少系统压力让它加速。</p>
<p>做完这些操作后，其实你已经没有办法再对它做什么了，只能等待流程自己完成。</p>
<p>最后，我给你留下一个思考题吧。</p>
<p>如果你碰到一个被killed的事务一直处于回滚状态，你认为是应该直接把MySQL进程强行重启，还是应该让它自己执行完成呢？为什么呢？你可以把你的结论和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间我在上一篇文章末尾，给你留下的问题是，希望你分享一下误删数据的处理经验。</p>
<p>@苍茫 同学提到了一个例子，我觉得值得跟大家分享一下。</p>
<p>运维的同学直接拷贝文本去执行，SQL语句截断，导致数据库执行出错。</p>
<p>从浏览器拷贝文本执行，是一个非常不规范的操作。</p>
<p>除了这个例子里面说的SQL语句截断问题，还可能存在乱码问题。</p>
<p>一般这种操作，如果脚本的开发和执行不是同一个人，需要开发同学把脚本放到git上，然后把git地址，以及文件的md5发给运维同学。</p>
<p>这样就要求运维同学在执行命令之前，确认要执行的文件的md5，跟之前开发同学提供的md5相同才能继续执行。</p>
<p>另外，我要特别点赞一下@苍茫 同学复现问题的思路和追查问题的态度。</p>
<p>@linhui0705 同学提到的“四个脚本”的方法，我非常推崇。</p>
<p>这四个脚本分别是：备份脚本、执行脚本、验证脚本和回滚脚本。</p>
<p>如果能够坚持做到，即使出现问题，也是可以很快恢复的，一定能降低出现故障的概率。</p>
<p>不过，这个方案最大的敌人是这样的思想：这是个小操作，不需要这么严格。</p>
<p>@Knight²º¹  给了一个保护文件的方法，我之前没有用过这种方法，不过这确实是一个不错的思路。</p>
<p>为了数据安全和服务稳定，多做点预防方案的设计讨论，总好过故障处理和事后复盘。</p>
<p>方案设计讨论会和故障复盘会，这两种会议的会议室气氛完全不一样。</p>
<p>经历过的同学一定懂的。</p>
<p>Leon    2kill connection本质上只是把客户端的sql连接断开，后面的执行流程还是要走kill query的，是这样理解吧2019-01-30 作者回复这个理解非常到位 额外的一个不同就是show processlist的时候，kill connection会显示“killed”这两句加起来可以用来替换我们文中的描述 2019-01-30Mr.sylar   2老师，我想问下这些原理的”渔”的方法除了看源码，还有别的建议吗2019-01-25 作者回复不同的知识点不太一样哈，有些可以看文档；</p>
<p>有些可以自己验证；</p>
<p>还有就是看其他人文章，加验证；（就是我们这个专栏的方法^_^）2019-01-25夹心面包   2对于结尾的问题,我觉得肯定是等待,即便是mysql重启,也是需要对未提交的事务进行回滚操作的,保证数据库的一致性2019-01-25Ryoma   1想得简单点：既然事务处于回滚状态了，重启MySQL这部分事务还是需要回滚。</p>
<p>私以为让它执行完成比较好。</p>
<p>2019-01-25斜面镜子 Bill   0“采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢” 这个怎么理解？2019-01-28 作者回复堵住了不就变慢了 2019-01-28700   0精选留言 0老师，您好。</p>
<p>客户端版本如下：</p>
<p>mysql Ver 14.14 Distrib 5.7.24, for linux-glibc2.12 (x86_64) using EditLine wrapper老师，再请教另一个问题。</p>
<p>并非所有的 DDL 操作都可以通过主从切换来实现吧？不适用的场景有哪些呢？2019-01-27 作者回复对，其实只有 改索引、 加最后一列、删最后一列其他的大多数不行，比如删除中间一列这种2019-01-28千年孤独   0可能不是本章讨论的问题，我想请问老师“MySQL使用自增ID和UUID作为主键的优劣”，基于什么样的业务场景用哪种好?2019-01-27 作者回复后面会有文章会提到这个问题哈：）2019-01-27Geek_a67865   0老师好，我猜发条橙子的问题 因为很多日志监控会统计error日志，这样并不很优雅，觉得他是想有什么办法规避这种并发引起的问题，2019-01-26 作者回复嗯嗯 不过我也确实没有想到更好的方法毕竟两个线程要同时发起一个insert操作，这个服务端也拦不住呀 2019-01-26路过   0老师，kill语法是：</p>
<p>KILL [CONNECTION | QUERY] processlist_idprocesslist_id是conn_id，不是thd_id.通过对比sys.processlist表中的信息就可以知道了。</p>
<p>通过查询官方文档也说明了：</p>
<p>thd_id：The thread ID.conn_id：The connection ID.所以，这篇文章开头的：</p>
<p>在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id感觉有点不对。</p>
<p>请老师指正。</p>
<p>谢谢！2019-01-26 作者回复这两个是一样的吧？都是对应show processlist这个命令结果里的第一列2019-01-26HuaMax   0课后题。</p>
<p>我认为需要看当时的业务场景。</p>
<p>重启会导致其他的连接也断开，返回给其他业务连接丢失的错误。</p>
<p>如果有很多事务在等待该事务的锁，则应该重启，让其他事务快速重试获取锁。</p>
<p>另外如果是RR的事务隔离级别，长事务会因为数据可见性的问题，对于多版本的数据需要找到正确的版本，对读性能是不是也会有影响，这时候重启也更好。</p>
<p>个人理解，请老师指正。</p>
<p>2019-01-26 作者回复有考虑到对其他线程的影响，这个 其实这种时候往往是要先考虑切换（当然重启也是切换的）如果只看恢复时间的话，等待会更快 2019-01-26Geek_a67865   0也遇到@发条橙子一样的问题，例如队列两个消息同时查询库存，发现都不存在，然后就都执行插入语句，一条成功，一条报唯一索引异常，这样程序日志会一直显示一个唯一索引报错，然后重试执行更新，我暂时是强制查主库2019-01-26 作者回复“我暂时是强制查主库” 从这就看你是因为读是读的备库，才出现这个问题的是吧。</p>
<p>发条橙子的问题是，他都是操作主库。</p>
<p>其实如果索引有唯一键，就直接上insert。</p>
<p>然后碰到违反唯一键约束就报错，这个应该就是唯一键约束正常的用法吧 2019-01-26gaohueric   0老师您好，一个表中 1个主键，2个唯一索引，1个普通索引 4个普通字段，当插入一条全部字段不为空的数据时，此时假设有4个索引文件，分别对应 主键 唯一性索引，普通索引，假设内存中没有这个数据页，那么server是直接调用innodb的接口，然后依次校验 （读取磁盘数据，验证唯一性）主键，唯一性索引，然后确认无误A时刻之后，吧主键和唯一性索引的写入内存，再把普通索引写入change buffer？那普通数据呢，是不是跟着主键一块写入内存了？2019-01-26 作者回复1. 是的，如果普通索引上的数据页这时候没有在内存中，就会使用change buffer2. “那普通数据呢，是不是跟着主键一块写入内存了？” 你说的是无索引的字段是吧，这些数据就在主键索引上，其实改的就是主键索引。</p>
<p>2019-01-26700   0老师，您好。</p>
<p>我继续接着我上条留言。</p>
<p>关于2），因为是测试机，我是直接 tail -0f 观察 general log 输出的。</p>
<p>确实没看到 KILL QUERY 等字眼。</p>
<p>数据库版本是 MySQL 5.7.24。</p>
<p>关于4），文中您不是这样说的吗？2.但是 session D 执行的 kill query C 命令却没什么效果， 3.直到 session E 执行了 kill connection 命令，才断开了 session C 的连接，提示“Lost connection to MySQL server during query”， 感谢您的解答。</p>
<p>2019-01-26 作者回复1. 你的客户端版本是什么 mysql –version 看看3. 嗯，是的，连接会断开，但是这个语句在server端还是会继续执行 （如果kill query 无效的话）2019-01-26700   0老师，请教。</p>
<p>1）文中开头说“当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的”。</p>
<p>我个人在平时使用中就是按默认的执行，不管这个线程有无正在执行语句。</p>
<p>不知这样会有什么潜在问题？2）文中说“实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 kill query 命令“。</p>
<p>这个怎么解释呢？我开启 general log 的时候执行 Ctrl+C 或 Ctrl+D 并没有看到有另外启动一个连接，也没有看到 kill query 命令。</p>
<p>general log 中仅看到对应线程 id 和 Quit。</p>
<p>3）MySQL 为什么要同时存在 kill query 和 kill connection，既然 kill query 有无效的场景，干嘛不直接存在一个 kill connection 命令就好了？那它俩分别对应的适用场景是什么，什么时候考虑 kill query，什么时候考虑 kill connection？我个人觉得连接如果直接被 kill 掉大不了再重连一次好了。</p>
<p>也没啥损失。</p>
<p>4）小小一个总结，不知对否？kill query - 会出现无法 kill 掉的情况，只能再次执行 kill connection。</p>
<p>kill connection - 会出现 Command 列显示成 Killed 的情况。</p>
<p>2019-01-25 作者回复1. 一般你执行kill就是要停止正在执行的语句，所以问题不大 2. 不应该呀， KILL QUERY 是大写哦，你再grep一下日志；</p>
<ol start="3">
<li>多提供一种方法嘛。</li>
</ol>
<p>kill query是指你只是想停止这个语句，但是事务不会回滚。</p>
<p>一般kill query是发生在客户端执行ctrl+c的时候啦。</p>
<p>平时紧急处理确实直接用kill + thread_id。</p>
<p> 好问题4. 对，另外，在kill query无效的时候，其实kill connection也是无效的2019-01-26Justin   0想咨询一个问题 如果走索引找寻比如age&#x3D;11的人的时候是只会锁age&#x3D;10到age&#x3D;12吗 如果那个索引页包含了从5到13的数据 是只会锁离11最近的还是说二分查找时候每一个访问到的都会锁呢2019-01-25 作者回复只会锁左右。</p>
<p>2019-01-26往事随风，顺其自然   012 号线程的等待逻辑是这样的：每 10 毫秒判断一下是否可以进入 InnoDB 执行，如果不行，如果不行，就调用 nanosleep 函数进入 sleep状态。</p>
<p>这里为什么是10毫秒判断一下？怎么查看和设置这个参数？2019-01-25发条橙子 。</p>
<p>   0老师我这里问一下唯一索引的问题 ，希望老师能给点思路背景 ： 一张商品库存表 ， 如果表里没这个商品则插入 ，如果已经存在就更新库存 。</p>
<p>同步这个库存表是异步的 ，每次添加商品库存成功后会发消息 ， 收到消息后会去表里新增&#x2F;更新库存问题 ： 商品库存表会有一个 商品的唯一索引。</p>
<p>当我们批量添加同一商品库存后会批量发消息 ，消息同时生效后去处理就有了并发的问题 。</p>
<p>这时候两个消息都判断表里没有该商品记录， 但是插入的时候就会有一个消息插入成功，另一个消息执行失败报唯一索引的错误， 之后消息重试走更新的逻辑。</p>
<p>这个这样做对业务没有影响 ，但是现在批量添加的需求量上来了 ，线上一直报这种错误日志也不是个办法， 我能想到的除了 catch 掉这个异常就没什么其他思路了。</p>
<p> 老师能给一些其他的思路么2019-01-25 作者回复有唯一索引了，就直接插入，然后出现唯一性约束就放弃，这个逻辑的问题是啥，我感觉挺好的呀 是不是我没有get到问题的点2019-01-25AI杜嘉嘉   0我想请问下老师，一个事务执行很长时间，我去kill。</p>
<p>那么，执行这个事务过程中的数据会不会回滚？2019-01-25 作者回复这个事务执行过程中新生成的数据吗？ 会回滚的2019-01-25曾剑   0曾剑  0今天的问题，我觉得得让他自己执行完成后自动恢复。</p>
<p>因为强制重启后该做的回滚还是会继续做。</p>
<p>2019-01-25Dkey   0老师，请教一个 第八章 的问题。</p>
<p>关于可见性判断，文中都是说事务id大于高水位都不可见。</p>
<p>如果等于是不是也不可见。</p>
<p>还有一个，readview中是否不包含当前事务id。</p>
<p>谢谢老师2019-01-25 作者回复代码实现上，事务生成trxid后，trxid的分配器会+1，以这个加1以后的数作为高水位，所以“等于”是不算的。</p>
<p>其实有没有包含是一样的，实现上没有包含。</p>
<p>2019-01-25&#96;&#96;&#96;</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/3ffe231f.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3ffe231f.html" class="post-title-link" itemprop="url">mysql-误删数据后除了跑路还能怎么办</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-06 06:02:07" itemprop="dateCreated datePublished" datetime="2019-12-06T06:02:07+08:00">2019-12-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>误删数据后除了跑路，还能怎么办？今天我要和你讨论的是一个沉重的话题：误删数据。</p>
<p>在前面几篇文章中，我们介绍了MySQL的高可用架构。</p>
<p>当然，传统的高可用架构是不能预防误删数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。</p>
<p>虽然我们之前遇到的大多数的数据被删，都是运维同学或者DBA背锅的。</p>
<p>但实际上，只要有数据操作权限的同学，都有可能踩到误删数据这条线。</p>
<p>今天我们就来聊聊误删数据前后，我们可以做些什么，减少误删数据的风险，和由误删数据带来的损失。</p>
<p>为了找到解决误删数据的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：</p>
<ol>
<li><p>使用delete语句误删数据行；</p>
</li>
<li><p>使用drop table或者truncate table语句误删数据表；</p>
</li>
<li><p>使用drop database语句误删数据库；</p>
</li>
<li><p>使用rm命令误删整个MySQL实例。</p>
</li>
</ol>
<p>误删行在第24篇文章中，我们提到如果是使用delete语句误删了数据行，可以用Flashback工具通过闪回把数据恢复回来。</p>
<p>Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。</p>
<p>而能够使用这个方案的前提是，需要确保binlog_format&#x3D;row 和 binlog_row_image&#x3D;FULL。</p>
<p>具体恢复数据时，对单个事务做如下处理：</p>
<ol>
<li><p>对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event即可；</p>
</li>
<li><p>同理，对于delete语句，也是将Delete_rows event改为Write_rows event；</p>
</li>
<li><p>而如果是Update_rows的话，binlog里面记录了数据行修改前和修改后的值，对调这两行的位置即可。</p>
</li>
</ol>
<p>如果误操作不是一个，而是多个，会怎么样呢？比如下面三个事务：</p>
<p>现在要把数据库恢复回这三个事务操作之前的状态，用Flashback工具解析binlog后，写回主库的命令是：</p>
<p>也就是说，如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。</p>
<p>需要说明的是，我不建议你直接在主库上执行这些操作。</p>
<p>恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。</p>
<p>为什么要这么做呢？这是因为，一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。</p>
<p>可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。</p>
<p>所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破(A)delete …(B)insert …(C)update …(reverse C)update …(reverse B)delete …(reverse A)insert …坏。</p>
<p>当然，我们不止要说误删数据的事后处理办法，更重要是要做到事前预防。</p>
<p>我有以下两个建议：</p>
<ol>
<li>把sql_safe_updates参数设置为on。</li>
</ol>
<p>这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。</p>
<ol start="2">
<li>代码上线前，必须经过SQL审计。</li>
</ol>
<p>你可能会说，设置了sql_safe_updates&#x3D;on，如果我真的要把一个小表的数据全部删掉，应该怎么办呢？如果你确定这个删除操作没问题的话，可以在delete语句中加上where条件，比如where id&gt;&#x3D;0。</p>
<p>但是，delete全表是很慢的，需要生成回滚日志、写redo、写binlog。</p>
<p>所以，从性能角度考虑，你应该优先考虑使用truncate table或者drop table命令。</p>
<p>使用delete命令删除的数据，你还可以用Flashback来恢复。</p>
<p>而使用truncate &#x2F;drop table和dropdatabase命令删除的数据，就没办法通过Flashback来恢复了。</p>
<p>为什么呢？这是因为，即使我们配置了binlog_format&#x3D;row，执行这三个命令时，记录的binlog还是statement格式。</p>
<p>binlog里面就只有一个truncate&#x2F;drop 语句，这些信息是恢复不出数据的。</p>
<p>那么，如果我们真的是使用这几条命令误删数据了，又该怎么办呢？误删库&#x2F;表这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。</p>
<p>这个方案要求线上有定期的全量备份，并且实时备份binlog。</p>
<p>在这两个条件都具备的情况下，假如有人中午12点误删了一个库，恢复数据的流程如下：</p>
<ol>
<li><p>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</p>
</li>
<li><p>用备份恢复出一个临时库；</p>
</li>
<li><p>从日志备份里面，取出凌晨0点之后的日志；</p>
</li>
<li><p>把这些日志，除了误删除数据的语句外，全部应用到临时库。</p>
</li>
</ol>
<p>这个流程的示意图如下所示：</p>
<p>图1 数据恢复流程-mysqlbinlog方法关于这个过程，我需要和你说明如下几点：</p>
<ol>
<li>为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用mysqlbinlog命令时，加上一个–database参数，用来指定误删表所在的库。</li>
</ol>
<p>这样，就避免了在恢复数据时还要应用其他库日志的情况。</p>
<ol start="2">
<li>在应用日志的时候，需要跳过12点误操作的那个语句的binlog：</li>
</ol>
<p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用–stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；</p>
<p>如果实例使用了GTID模式，就方便多了。</p>
<p>假设误操作命令的GTID是gtid1，那么只需要执行set gtid_next&#x3D;gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后按顺序执行binlog的时候，就会自动跳过误操作的语句。</p>
<p>不过，即使这样，使用mysqlbinlog方法恢复数据还是不够快，主要原因有两个：</p>
<ol>
<li><p>如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog工具并不能指定只解析一个表的日志；</p>
</li>
<li><p>用mysqlbinlog解析出日志应用，应用日志的过程就只能是单线程。</p>
</li>
</ol>
<p>我们在第26篇文章中介绍的那些并行复制的方法，在这里都用不上。</p>
<p>一种加速的方法是，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样：</p>
<ol>
<li><p>在start slave之前，先通过执行change replication filter replicate_do_table &#x3D; (tbl_name) 命令，就可以让临时库只同步误操作的表；</p>
</li>
<li><p>这样做也可以用上并行复制技术，来加速整个数据恢复过程。</p>
</li>
</ol>
<p>这个过程的示意图如下所示。</p>
<p>图2 数据恢复流程-master-slave方法可以看到，图中binlog备份系统到线上备库有一条虚线，是指如果由于时间太久，备库上已经删除了临时实例需要的binlog的话，我们可以从binlog备份系统中找到需要的binlog，再放回备库中。</p>
<p>假设，我们发现当前临时实例需要的binlog是从master.000005开始的，但是在备库上执行showbinlogs 显示的最小的binlog文件是master.000007，意味着少了两个binlog文件。</p>
<p>这时，我们就需要去binlog备份系统中找到这两个文件。</p>
<p>把之前删掉的binlog放回备库的操作步骤，是这样的：</p>
<ol>
<li><p>从备份系统下载master.000005和master.000006这两个文件，放到备库的日志目录下；</p>
</li>
<li><p>打开日志目录下的master.index文件，在文件开头加入两行，内容分别是“.&#x2F;master.000005”和“.&#x2F;master.000006”;3. 重启备库，目的是要让备库重新识别这两个日志文件；</p>
</li>
<li><p>现在这个备库上就有了临时库需要的所有binlog了，建立主备关系，就可以正常同步了。</p>
</li>
</ol>
<p>不论是把mysqlbinlog工具解析出的binlog文件应用到临时库，还是把临时库接到备库上，这两个方案的共同点是：误删库或者表后，恢复数据的思路主要就是通过备份，再加上应用binlog的方式。</p>
<p>也就是说，这两个方案都要求备份系统定期备份全量日志，而且需要确保binlog在被从本地删除之前已经做了备份。</p>
<p>但是，一个系统不可能备份无限的日志，你还需要根据成本和磁盘空间资源，设定一个日志保留的天数。</p>
<p>如果你的DBA团队告诉你，可以保证把某个实例恢复到半个月内的任意时间点，这就表示备份系统保留的日志时间就至少是半个月。</p>
<p>另外，我建议你不论使用上述哪种方式，都要把这个数据恢复功能做成自动化工具，并且经常拿出来演练。</p>
<p>为什么这么说呢？这里的原因，主要包括两个方面：</p>
<ol>
<li><p>虽然“发生这种事，大家都不想的”，但是万一出现了误删事件，能够快速恢复数据，将损失降到最小，也应该不用跑路了。</p>
</li>
<li><p>而如果临时再手忙脚乱地手动操作，最后又误操作了，对业务造成了二次伤害，那就说不过去了。</p>
</li>
</ol>
<p>延迟复制备库虽然我们可以通过利用并行复制来加速恢复数据的过程，但是这个方案仍然存在“恢复时间不可控”的问题。</p>
<p>如果一个库的备份特别大，或者误操作的时间距离上一个全量备份的时间较长，比如一周一备的实例，在备份之后的第6天发生误操作，那就需要恢复6天的日志，这个恢复时间可能是要按天来计算的。</p>
<p>那么，我们有什么方法可以缩短恢复数据需要的时间呢？如果有非常核心的业务，不允许太长的恢复时间，我们可以考虑搭建延迟复制的备库。</p>
<p>这个功能是MySQL 5.6版本引入的。</p>
<p>一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。</p>
<p>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY &#x3D; N命令，可以指定这个备库持续保持跟主库有N秒的延迟。</p>
<p>比如你把N设置为3600，这就代表了如果主库上有数据被误删了，并且在1小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。</p>
<p>这时候到这个备库上执行stopslave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。</p>
<p>这样的话，你就随时可以得到一个，只需要最多再追1小时，就可以恢复出数据的临时实例，也就缩短了整个数据恢复需要的时间。</p>
<p>预防误删库&#x2F;表的方法虽然常在河边走，很难不湿鞋，但终究还是可以找到一些方法来避免的。</p>
<p>所以这里，我也会给你一些减少误删操作风险的建议。</p>
<p>第一条建议是，账号分离。</p>
<p>这样做的目的是，避免写错命令。</p>
<p>比如：</p>
<p>我们只给业务开发同学DML权限，而不给truncate&#x2F;drop权限。</p>
<p>而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。</p>
<p>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。</p>
<p>第二条建议是，制定操作规范。</p>
<p>这样做的目的，是避免写错要删除的表名。</p>
<p>比如：</p>
<p>在删除数据表之前，必须先对表做改名操作。</p>
<p>然后，观察一段时间，确保对业务无影响以后再删除这张表。</p>
<p>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。</p>
<p>并且，管理系删除表的时候，只能删除固定后缀的表。</p>
<p>rm删除数据其实，对于一个有高可用机制的MySQL集群来说，最不怕的就是rm删除数据了。</p>
<p>只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。</p>
<p>这时，你要做的就是在这个节点上把数据恢复回来，再接入整个集群。</p>
<p>当然了，现在不止是DBA有自动化系统，SA（系统管理员）也有自动化系统，所以也许一个批量下线机器的操作，会让你整个MySQL集群的所有节点都全军覆没。</p>
<p>应对这种情况，我的建议只能是说尽量把你的备份跨机房，或者最好是跨城市保存。</p>
<p>小结今天，我和你讨论了误删数据的几种可能，以及误删后的处理方法。</p>
<p>但，我要强调的是，预防远比处理的意义来得大。</p>
<p>另外，在MySQL的集群方案中，会时不时地用到备份来恢复实例，因此定期检查备份的有效性也很有必要。</p>
<p>如果你是业务开发同学，你可以用show grants命令查看账户的权限，如果权限过大，可以建议DBA同学给你分配权限低一些的账号；你也可以评估业务的重要性，和DBA商量备份的周期、是否有必要创建延迟复制的备库等等。</p>
<p>数据和服务的可靠性不止是运维团队的工作，最终是各个环节一起保障的结果。</p>
<p>今天的课后话题是，回忆下你亲身经历过的误删数据事件吧，你用了什么方法来恢复数据呢？你在这个过程中得到的经验又是什么呢？你可以把你的经历和经验写在留言区，我会在下一篇文章的末尾选取有趣的评论和你一起讨论。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间我在上一篇文章给你留的问题，是关于空表的间隙的定义。</p>
<p>一个空表就只有一个间隙。</p>
<p>比如，在空表上执行：</p>
<p>这个查询语句加锁的范围就是next-key lock (-∞, supremum]。</p>
<p>验证方法的话，你可以使用下面的操作序列。</p>
<p>你可以在图4中看到显示的结果。</p>
<p>begin;select * from t where id&gt;1 for update;图3 复现空表的next-key lock图4 show engine innodb status </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/90c350b7.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/90c350b7.html" class="post-title-link" itemprop="url">mysql-答疑文章（二）：用动态的观点看加锁</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-05 06:11:28" itemprop="dateCreated datePublished" datetime="2019-12-05T06:11:28+08:00">2019-12-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:26:04" itemprop="dateModified" datetime="2023-01-18T23:26:04+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>27 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>答疑文章（二）：用动态的观点看加锁<br>在第20和21篇文章中，我和你介绍了InnoDB的间隙锁、next-key lock，以及加锁规则。</p>
<p>在这两篇文章的评论区，出现了很多高质量的留言。</p>
<p>我觉得通过分析这些问题，可以帮助你加深对加锁规则的理解。</p>
<p>所以，我就从中挑选了几个有代表性的问题，构成了今天这篇答疑文章的主题，即：用动态的观点看加锁。</p>
<p>为了方便你理解，我们再一起复习一下加锁规则。</p>
<p>这个规则中，包含了两个“原则”、两个“优化”和一个“bug”：</p>
<p>原则1：加锁的基本单位是next-key lock。</p>
<p>希望你还记得，next-key lock是前开后闭区间。</p>
<p>原则2：查找过程中访问到的对象才会加锁。</p>
<p>优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。</p>
<p>优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。</p>
<p>一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</p>
<p>接下来，我们的讨论还是基于下面这个表t：</p>
<p>不等号条件里的等值查询有同学对“等值查询”提出了疑问：等值查询和“遍历”有什么区别？为什么我们文章的例子里面，where条件是不等号，这个过程里也有等值查询？我们一起来看下这个例子，分析一下这条查询语句的加锁范围：</p>
<p>利用上面的加锁规则，我们知道这个语句的加锁范围是主键索引上的 (0,5]、(5,10]和(10, 15)。</p>
<p>也就是说，id&#x3D;15这一行，并没有被加上行锁。</p>
<p>为什么呢？我们说加锁单位是next-key lock，都是前开后闭区间，但是这里用到了优化2，即索引上的等值查询，向右遍历的时候id&#x3D;15不满足条件，所以next-key lock退化为了间隙锁 (10, 15)。</p>
<p>但是，我们的查询语句中where条件是大于号和小于号，这里的“等值查询”又是从哪里来的呢？要知道，加锁动作是发生在语句执行过程中的，所以你在分析加锁行为的时候，要从索引上的数据结构开始。</p>
<p>这里，我再把这个过程拆解一下。</p>
<p>如图1所示，是这个表的索引id的示意图。</p>
<p>CREATE TABLE t̀  ̀(  ìd  ̀int(11) NOT NULL,  <code>c  ̀int(11) DEFAULT NULL,  </code>d  ̀int(11) DEFAULT NULL,  PRIMARY KEY (̀ id )̀,  KEY &#96;c  ̀(̀ c )̀) ENGINE&#x3D;InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);begin;select * from t where id&gt;9 and id&lt;12 order by id desc for update;图1 索引id示意图1. 首先这个查询语句的语义是order by id desc，要拿到满足条件的所有行，优化器必须先找到“第一个id&lt;12的值”。</p>
<ol start="2">
<li><p>这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到id&#x3D;12的这个值，只是最终没找到，但找到了(10,15)这个间隙。</p>
</li>
<li><p>然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到id&#x3D;5这一行，所以会加一个next-key lock (0,5]。</p>
</li>
</ol>
<p>也就是说，在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法。</p>
<p>等值查询的过程与上面这个例子对应的，是@发条橙子同学提出的问题：下面这个语句的加锁范围是什么？这条查询语句里用的是in，我们先来看这条语句的explain结果。</p>
<p>begin;select id from t where c in(5,20,10) lock in share mode;图2 in语句的explain结果可以看到，这条in语句使用了索引c并且rows&#x3D;3，说明这三个值都是通过B+树搜索定位的。</p>
<p>在查找c&#x3D;5的时候，先锁住了(0,5]。</p>
<p>但是因为c不是唯一索引，为了确认还有没有别的记录c&#x3D;5，就要向右遍历，找到c&#x3D;10才确认没有了，这个过程满足优化2，所以加了间隙锁(5,10)。</p>
<p>同样的，执行c&#x3D;10这个逻辑的时候，加锁的范围是(5,10] 和 (10,15)；执行c&#x3D;20这个逻辑的时候，加锁的范围是(15,20] 和 (20,25)。</p>
<p>通过这个分析，我们可以知道，这条语句在索引c上加的三个记录锁的顺序是：先加c&#x3D;5的记录锁，再加c&#x3D;10的记录锁，最后加c&#x3D;20的记录锁。</p>
<p>你可能会说，这个加锁范围，不就是从(5,25)中去掉c&#x3D;15的行锁吗？为什么这么麻烦地分段说呢？因为我要跟你强调这个过程：这些锁是“在执行过程中一个一个加的”，而不是一次性加上去的。</p>
<p>理解了这个加锁过程之后，我们就可以来分析下面例子中的死锁问题了。</p>
<p>如果同时有另外一个语句，是这么写的：</p>
<p>此时的加锁范围，又是什么呢？我们现在都知道间隙锁是不互锁的，但是这两条语句都会在索引c上的c&#x3D;5、10、20这三行记录上加记录锁。</p>
<p>这里你需要注意一下，由于语句里面是order by c desc， 这三个记录锁的加锁顺序，是先锁c&#x3D;20，然后c&#x3D;10，最后是c&#x3D;5。</p>
<p>也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。</p>
<p>当这两条语句并发执行的时候，就可能出现死锁。</p>
<p>关于死锁的信息，MySQL只保留了最后一个死锁的现场，但这个现场还是不完备的。</p>
<p>有同学在评论区留言到，希望我能展开一下怎么看死锁。</p>
<p>现在，我就来简单分析一下上面这个例子的死锁现场。</p>
<p>select id from t where c in(5,20,10) order by c desc for update;怎么看死锁？图3是在出现死锁后，执行show engine innodb status命令得到的部分输出。</p>
<p>这个命令会输出很多信息，有一节LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息。</p>
<p>图3 死锁现场我们来看看这图中的几个关键信息。</p>
<ol>
<li>这个结果分成三部分：</li>
</ol>
<p>(1) TRANSACTION，是第一个事务的信息；</p>
<p>(2) TRANSACTION，是第二个事务的信息；</p>
<p>WE ROLL BACK TRANSACTION (1)，是最终的处理结果，表示回滚了第一个事务。</p>
<ol start="2">
<li>第一个事务的信息中：</li>
</ol>
<p>WAITING FOR THIS LOCK TO BE GRANTED，表示的是这个事务在等待的锁信息；</p>
<p>index c of table t̀est .̀̀ t&#96;，说明在等的是表t的索引c上面的锁；</p>
<p>lock mode S waiting 表示这个语句要自己加一个读锁，当前的状态是等待中；</p>
<p>Record lock说明这是一个记录锁；</p>
<p>n_fields 2表示这个记录是两列，也就是字段c和主键字段id；</p>
<p>0: len 4; hex 0000000a; asc ;;是第一个字段，也就是c。</p>
<p>值是十六进制a，也就是10；</p>
<p>1: len 4; hex 0000000a; asc ;;是第二个字段，也就是主键id，值也是10；</p>
<p>这两行里面的asc表示的是，接下来要打印出值里面的“可打印字符”，但10不是可打印字符，因此就显示空格。</p>
<p>第一个事务信息就只显示出了等锁的状态，在等待(c&#x3D;10,id&#x3D;10)这一行的锁。</p>
<p>当然你是知道的，既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出来。</p>
<p>别着急，我们从第二个事务的信息中推导出来。</p>
<ol start="3">
<li>第二个事务显示的信息要多一些：</li>
</ol>
<p>“ HOLDS THE LOCK(S)”用来显示这个事务持有哪些锁；</p>
<p>index c of table t̀est .̀̀ t  ̀表示锁是在表t的索引c上；</p>
<p>hex 0000000a和hex 00000014表示这个事务持有c&#x3D;10和c&#x3D;20这两个记录锁；</p>
<p>WAITING FOR THIS LOCK TO BE GRANTED，表示在等(c&#x3D;5,id&#x3D;5)这个记录锁。</p>
<p>从上面这些信息中，我们就知道：</p>
<ol>
<li><p>“lock in share mode”的这条语句，持有c&#x3D;5的记录锁，在等c&#x3D;10的锁；</p>
</li>
<li><p>“for update”这个语句，持有c&#x3D;20和c&#x3D;10的记录锁，在等c&#x3D;5的记录锁。</p>
</li>
</ol>
<p>因此导致了死锁。</p>
<p>这里，我们可以得到两个结论：</p>
<ol>
<li><p>由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；</p>
</li>
<li><p>在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以InnoDB选择了回滚成本更小的lock in share mode语句，来回滚。</p>
</li>
</ol>
<p>怎么看锁等待？看完死锁，我们再来看一个锁等待的例子。</p>
<p>在第21篇文章的评论区，@Geek_9ca34e 同学做了一个有趣验证，我把复现步骤列出来：</p>
<p>图4 delete导致间隙变化可以看到，由于session A并没有锁住c&#x3D;10这个记录，所以session B删除id&#x3D;10这一行是可以的。</p>
<p>但是之后，session B再想insert id&#x3D;10这一行回去就不行了。</p>
<p>现在我们一起看一下此时show engine innodb status的结果，看看能不能给我们一些提示。</p>
<p>锁信息是在这个命令输出结果的TRANSACTIONS这一节。</p>
<p>你可以在文稿中看到这张图片图 5 锁等待信息我们来看几个关键信息。</p>
<ol>
<li><p>index PRIMARY of table t̀est .̀̀ t  ̀，表示这个语句被锁住是因为表t主键上的某个锁。</p>
</li>
<li><p>lock_mode X locks gap before rec insert intention waiting 这里有几个信息：</p>
</li>
</ol>
<p>insert intention表示当前线程准备插入一个记录，这是一个插入意向锁。</p>
<p>为了便于理解，你可以认为它就是这个插入动作本身。</p>
<p>gap before rec 表示这是一个间隙锁，而不是记录锁。</p>
<ol start="3">
<li><p>那么这个gap是在哪个记录之前的呢？接下来的0~4这5行的内容就是这个记录的信息。</p>
</li>
<li><p>n_fields 5也表示了，这一个记录有5列：</p>
</li>
</ol>
<p>0: len 4; hex 0000000f; asc ;;第一列是主键id字段，十六进制f就是id&#x3D;15。</p>
<p>所以，这时我们就知道了，这个间隙就是id&#x3D;15之前的，因为id&#x3D;10已经不存在了，它表示的就是(5,15)。</p>
<p>1: len 6; hex 000000000513; asc ;;第二列是长度为6字节的事务id，表示最后修改这一行的是trx id为1299的事务。</p>
<p>2: len 7; hex b0000001250134; asc % 4;; 第三列长度为7字节的回滚段信息。</p>
<p>可以看到，这里的acs后面有显示内容(%和4)，这是因为刚好这个字节是可打印字符。</p>
<p>后面两列是c和d的值，都是15。</p>
<p>因此，我们就知道了，由于delete操作把id&#x3D;10这一行删掉了，原来的两个间隙(5,10)、(10,15）变成了一个(5,15)。</p>
<p>说到这里，你可以联合起来再思考一下这两个现象之间的关联：</p>
<ol>
<li><p>session A执行完select语句后，什么都没做，但它加锁的范围突然“变大”了；</p>
</li>
<li><p>第21篇文章的课后思考题，当我们执行select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by cdesc lock in share mode; 向左扫描到c&#x3D;10的时候，要把(5, 10]锁起来。</p>
</li>
</ol>
<p>也就是说，所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。</p>
<p>update的例子看过了insert和delete的加锁例子，我们再来看一个update语句的案例。</p>
<p>在留言区中@信信 同学做了这个试验：</p>
<p>图 6 update 的例子你可以自己分析一下，session A的加锁范围是索引c上的 (5,10]、(10,15]、(15,20]、(20,25]和(25,supremum]。</p>
<p>之后session B的第一个update语句，要把c&#x3D;5改成c&#x3D;1，你可以理解为两步：</p>
<ol>
<li><p>插入(c&#x3D;1, id&#x3D;5)这个记录；</p>
</li>
<li><p>删除(c&#x3D;5, id&#x3D;5)这个记录。</p>
</li>
</ol>
<p>按照我们上一节说的，索引c上(5,10)间隙是由这个间隙右边的记录，也就是c&#x3D;10定义的。</p>
<p>所以通过这个操作，session A的加锁范围变成了图7所示的样子：</p>
<p>注意：根据c&gt;5查到的第一个记录是c&#x3D;10，因此不会加(0,5]这个next-key lock。</p>
<p>图 7 session B修改后， session A的加锁范围好，接下来session B要执行 update t set c &#x3D; 5 where c &#x3D; 1这个语句了，一样地可以拆成两步：</p>
<ol>
<li><p>插入(c&#x3D;5, id&#x3D;5)这个记录；</p>
</li>
<li><p>删除(c&#x3D;1, id&#x3D;5)这个记录。</p>
</li>
</ol>
<p>第一步试图在已经加了间隙锁的(1,10)中插入数据，所以就被堵住了。</p>
<p>小结今天这篇文章，我用前面第20和第21篇文章评论区的几个问题，再次跟你复习了加锁规则。</p>
<p>并且，我和你重点说明了，分析加锁范围时，一定要配合语句执行逻辑来进行。</p>
<p>在我看来，每个想认真了解MySQL原理的同学，应该都要能够做到：通过explain的结果，就能够脑补出一个SQL语句的执行流程。</p>
<p>达到这样的程度，才算是对索引组织表、索引、锁的概念有了比较清晰的认识。</p>
<p>你同样也可以用这个方法，来验证自己对这些知识点的掌握程度。</p>
<p>在分析这些加锁规则的过程中，我也顺便跟你介绍了怎么看show engine innodb status输出结果中的事务信息和死锁信息，希望这些内容对你以后分析现场能有所帮助。</p>
<p>老规矩，即便是答疑文章，我也还是要留一个课后问题给你的。</p>
<p>上面我们提到一个很重要的点：所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。</p>
<p>那么，一个空表有间隙吗？这个间隙是由谁定义的？你怎么验证这个结论呢？你可以把你关于分析和验证方法写在留言区，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间我在上一篇文章最后留给的问题，是分享一下你关于业务监控的处理经验。</p>
<p>在这篇文章的评论区，很多同学都分享了不错的经验。</p>
<p>这里，我就选择几个比较典型的留言，和你分享吧：</p>
<p>@老杨同志 回答得很详细。</p>
<p>他的主要思路就是关于服务状态和服务质量的监控。</p>
<p>其中，服务状态的监控，一般都可以用外部系统来实现；而服务的质量的监控，就要通过接口的响应时间来统计。</p>
<p>@Ryoma 同学，提到服务中使用了healthCheck来检测，其实跟我们文中提到的select 1的模式类似。</p>
<p>@强哥 同学，按照监控的对象，将监控分成了基础监控、服务监控和业务监控，并分享了每种监控需要关注的对象。</p>
<p>这些都是很好的经验，你也可以根据具体的业务场景借鉴适合自己的方案。</p>
<p>令狐少侠   2有个问题想确认下，在死锁日志里，lock_mode X waiting是间隙锁+行锁，lock_mode X locks rec but not gap这种加but not gap才是行锁？老师你后面能说下group by的原理吗，我看目录里面没有2019-01-22 作者回复对， 好问题lock_mode X waiting表示next-key lock；</p>
<p>lock_mode X locks rec but not gap是只有行锁；</p>
<p>还有一种 “locks gap before rec”，就是只有间隙锁；</p>
<p>2019-01-23Ryoma   2删除数据，导致锁扩大的描述：“因此，我们就知道了，由于 delete 操作把 id&#x3D;10 这一行删掉了，原来的两个间隙 (5,10)、(10,15）变成了一个 (5,15)。</p>
<p>”我觉得这个提到的(5, 10) 和 (10, 15)两个间隙会让人有点误解，实际上在删除之前间隙锁只有一个(10, 15)，删除了数据之后，导致间隙锁左侧扩张成了5，间隙锁成为了(5, 15)。</p>
<p>2019-01-22 作者回复嗯 所以我这里特别小心地没有写“锁“这个字。</p>
<p>间隙 (5,10)、(10,15）是客观存在的。</p>
<p>你提得也很对，“锁”是执行过程中才加的，是一个动态的概念。</p>
<p>这个问题也能够让大家更了解我们标题的意思，置顶了哈  2019-01-22    1老师好：</p>
<p>select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc for update;为什么这种c&#x3D;20就是用来查数据的就不是向右遍历select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 这种就是向右遍历怎么去判断合适是查找数据，何时又是遍历呢，是因为第一个有order by desc，然后反向向左遍历了吗？所以只需要[20,25)来判断已经是最后一个20就可以了是吧2019-01-22 作者回复索引搜索就是 “找到第一个值，然后向左或向右遍历”，order by desc 就是要用最大的值来找第一个；</p>
<p>精选留言order by就是要用做小的值来找第一个；</p>
<p>“所以只需要[20,25)来判断已经是最后一个20就可以了是吧”，你描述的意思是对的，但是在MySQL里面不建议写这样的前闭后开区间哈，容易造成误解。</p>
<p>可以描述为：</p>
<p>“取第一个id&#x3D;20后，向右遍历(25,25)这个间隙”^_^2019-01-22老杨同志   1先说结论：空表锁 (-supernum，supernum],老师提到过mysql的正无穷是supernum，在没有数据的情况下，next-key lock 应该是supernum前面的间隙加 supernum的行锁。</p>
<p>但是前开后闭的区间，前面的值是什么我也不知道，就写了一个-supernum。</p>
<p>稍微验证一下session 1）begin;select * from t where id&gt;9 for update;session 2）begin;insert into t values(0,0,0),(5,5,5);（block）2019-01-21 作者回复赞show engine innodb status 有惊喜 2019-01-21Long   0感觉这篇文章以及前面加锁的文章，提升了自己的认知。</p>
<p>还有，谢谢老师讲解了日志的对应细节……还愿了2019-01-28 作者回复   2019-01-28滔滔   0老师，有个疑问，select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc lock in share mode; 向左扫描到 c&#x3D;10 的时候，为什么要把 (5, 10] 锁起来？不锁也不会出现幻读或者逻辑上的不一致吧 2019-01-23 作者回复会加锁，insert into t values (6,6,6) 被堵住了2019-01-23尘封   0尘封   0老师，咨询个问题，本来想在后面分区表的文章问，发现大纲里没有分区表这一讲。</p>
<p>1，timestamp类型为什么不支持分区？2，前面的文章讲过分区不要太多，这个多了会怎么样？比如一个表一千多个分区谢谢2019-01-23 作者回复会讲的哈<del>新春快乐</del>2019-02-04长杰   0老师，还是select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc in share mode与select * from t where id&gt;10 and id&lt;&#x3D;15 for update的问题，为何select * from t where id&gt;10 and id&lt;&#x3D;15 for update不能解释为：根据id&#x3D;15来查数据，加锁(15, 20]的时候，可以使用优化2，这个等值查询是根据什么规则来定的？ 如果select * from t where id&gt;10 and id&lt;&#x3D;15 for update加上order by id desc是否可以按照id&#x3D;15等值查询，利用优化2？多谢指教。</p>
<p>2019-01-22 作者回复1. 代码实现上，传入的就是id&gt;10里面的这个102. 可以的，不过因为id是主键，而且id&#x3D;15这一行存在，我觉得用优化1解释更好哦2019-01-23堕落天使   0老师，您好：</p>
<p>我执行“explain select id from t where c in(5,20,10) lock in share mode;” 时，显示的rows对应的值是4。</p>
<p>为什么啊？我的mysql版本是：5.7.23-0ubuntu0.16.04.1，具体sql语句如下：</p>
<p>mysql&gt; select * from t;+—-+——+——+| id | c | d |+—-+——+——+| 0 | 0 | 0 || 5 | 5 | 5 || 10 | 10 | 10 || 15 | 15 | 15 || 20 | 20 | 20 || 25 | 25 | 25 || 30 | 10 | 30 |+—-+——+——+7 rows in set (0.00 sec)mysql&gt; explain select id from t where c in(5,20,10) lock in share mode;+—-+————-+——-+————+——-+—————+——+———+——+——+———-+————————–+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+—-+————-+——-+————+——-+—————+——+———+——+——+———-+————————–+| 1 | SIMPLE | t | NULL | range | c | c | 5 | NULL | 4 | 100.00 | Using where; Using index |+—-+————-+——-+————+——-+—————+——+———+——+——+———-+————————–+1 row in set, 1 warning (0.00 sec)2019-01-22 作者回复你这个例子里面有两行c&#x3D;102019-01-23Ivan   0Jan 17 23:52:27 prod-mysql-01 kernel: [ pid ] uid tgid total_vm rss cpu oom_adj oom_score_adjnameJan 17 23:52:27 prod-mysql-01 kernel: [125254] 0 125254 27087 5 0 0 0 mysqld_safeJan 17 23:52:27 prod-mysql-01 kernel: [126004] 498 126004 24974389 22439356 5 0 0 mysqldJan 17 23:52:27 prod-mysql-01 kernel: [ 5733] 0 5733 7606586 6077037 7 0 0 mysql—————————系统日志——————————————————————————–老师你好，请教一个问题 ，我在mysql服务器上本地登录，执行了一个SQL（select b.id,b.status from rb_bak b where id not in (select id from rb );该语句问了找不同数据， rb和 rb_bak 数据量均为500万左右），SQL很慢，30分钟也没结果；</p>
<p>在SQL语句执行期间，发生了OOM，mysql服务被kill。</p>
<p>查看系统日志发现 mysqld 占用内存基本没有变，但是本机连接mysql的客户端进程（5733）却占用了内存近20G，这很让人费解，SQL没有执行完，客户端怎么会占用这么多内存？用其他SQL查询查询不同数据，也就十几条数据，更不可能占用这么多内存呀。</p>
<p>还请老师帮忙分析一下，谢谢。</p>
<p>2019-01-22 作者回复好问题，第33篇会说到哈你可以在mysql客户端参数增加 –quick 再试试2019-01-23PengfeiWang   0老师，您好：</p>
<p>对文中以下语句感到有困惑：</p>
<p>我们说加锁单位是 next-key lock，都是前开后闭区，但是这里用到了优化 2，即索引上的等值查询，向右遍历的时候id&#x3D;15不满足条件，所以 next-key lock 退化为了间隙锁 (10, 15)。</p>
<p>SQL语句中条件中使用的是id字段（唯一索引），那么根据加锁规则这里不应该用的是优化 2，而是优化 1，因为优化1中明确指出给唯一索引加锁，从而优化 2的字面意思来理解，它适用于普通索引。</p>
<p>不知道是不是我理解的不到位？2019-01-22 作者回复主要是这里这一行不存在。</p>
<p>。</p>
<p>如果能够明确找到一行锁住的话，使用优化1就更准确些2019-01-23Justin   0想咨询一下 普通索引 如果索引中包括的元素都相同 在索引中顺序是怎么排解的呢 是按主键排列的吗 比如(name ,age ) 索引 name age都一样 那索引中会按照主键排序吗？2019-01-22 作者回复会的2019-01-23ServerCoder   0林老师我有个问题想请教一下，描述如下，望给予指点，先谢谢了！环境：虚拟机，CPU 4核，内存8G，系统CentOS7.4，MySQL版本5.6.40数据库配置：</p>
<p>bulk_insert_buffer_size &#x3D; 256Msql_mode&#x3D;NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESsecure_file_priv&#x3D;’’default-storage-engine&#x3D;MYISAM测试场景修改过的参数(以下这些参数得调整对加载效率没有实质的提升)：</p>
<p>myisam_repair_threads&#x3D;3myisam_sort_buffer_size&#x3D;256Mnet_buffer_length&#x3D;1Mmyisam_use_mmap&#x3D;ONkey_buffer_size&#x3D;256M测试场景：测试程序多线程，通过客户端API，执行load data infile语句加载数据文件三个线程，三个文件(每个文件100万条数据、150MB)，三张表(表结构相同，字段类型均为整形，没有定义主键，有一个字段加了非唯一索引)，一一对应进行数据加载，数据库没有使用多核，而是把一个核心的利用率均分给了三个线程。</p>
<p>单个线程加载一个文件大约耗时3秒单线程加载三个文件到三张表大约耗时9秒三个线程分别加载三个文件到三张表，则每个线程均耗时大约9秒。</p>
<p>从这个效果看，单线程顺序加载和三线程并发加载耗时相同，没有提升效果。</p>
<p>三线程加载过程中查看processlist发现时间主要耗费在了网络读取上。</p>
<p>问题：为啥这种场景下MySQL不利用多核？这种并行加载的情况要如何才能让其利用多核，提升加载速度2019-01-22 作者回复可以用到多核呀，你是怎么得到 “时间主要耗费在了网络读取上。</p>
<p>”这个结论的？另外，把这三个文件先拷贝到数据库本地，然后本地执行load看看什么效果？2019-01-23慕塔   0是这样的 假设只有一主一从 1)是集群只有一个sysbench实例，产生的数据流通过中间件，主机分全部写，和30%的读，另外70%的读全部分给从机。</p>
<p>2)有两个sysbench，一个读写加压到主机，另一个只有加压到从机。</p>
<p>主从复制之间通过binlog。</p>
<p>问题在1)的QPS累加与2)QPS累加 意义一样吗 1)的一条事务有读写，而2)的情况，主机与1)一样，从机的读事务与主机里的读不一样吧 2019-01-22 作者回复我觉得这两个对比不太公平^_^1）的测试可能会出现中间件瓶颈，a)网络环节中间增加了一跳；</p>
<p>b) 如果是小查询，可能proxy先打到瓶颈2)的测试结论一般会比1）好些但是有这个架构，你肯定是从中间件访问数据库的，所以应该以1的测试结果为准2019-01-23Jason_鹏   0最后一个update的例子，为没有加（0，5）的间隙呢？我理解应该是先拿c＝5去b+树搜索，按照间隙索最右原则，应该会加（0，5]的间隙，然后c＝5不满足大于5条件，根据优化2原则退化成（0，5）的间隙索，我是这样理解的2019-01-22 作者回复根据c&gt;5查到的第一个记录是c&#x3D;10，因此不会加(0,5]这个next-key lock。</p>
<p>你提醒得对，我应该多说明这句， 我加到文稿中啦 2019-01-22长杰   0老师，之前讲这个例子时，select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc in share mode;最右边加的是 (20, 25)的间隙锁，而这个例子select * from t where id&gt;10 and id&lt;&#x3D;15 for update中，最右边加的是(15,20]的next-key锁，这两个查询为何最后边一个加的gap锁，一个加的next-key锁，他们都是&lt;&#x3D;的等值范围查询，区别在哪里？2019-01-22 作者回复select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc in share mode;这个语句是根据 c&#x3D;20 来查数据的，所以加锁(20,25]的时候，可以使用优化2；</p>
<p>select * from t where id&gt;10 and id&lt;&#x3D;15 for update；</p>
<p>这里的id&#x3D;20，是用“向右遍历”的方式得到的，没有优化，按照“以next-key lock”为加锁单位来执行2019-01-22库淘淘   0对于问题 我理解是这样 session 1：</p>
<p>delete from t;begin; select * from t for update;session 2:insert into t values(1,1,1);发生等待show engine innodb status\G; …..——- TRX HAS BEEN WAITING 5 SEC FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 75 page no 3 n bits 72 index PRIMARY of table <code>test</code>.<code>t</code> trx id 752090 lock_mode X insert intention waitingRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 00: len 8; hex 73757072656d756d; asc supremum;;其中申请插入意向锁与间隙锁 冲突，supremum这个能否理解为 间隙右边的那个记录2019-01-21 作者回复发现了  2019-01-22慕塔   0大佬 请教下一主多从集群性能测试性能计算问题 如果使用基准测试工具sysbench。</p>
<p>数据流有两种1)sysbench—mycat—mysql主机(读写) TPS QPS1| |binlogmysql从机(只读)QPS2那性能指标 TPS QPS&#x3D;QPS1+QPS22)sysbench—mysql主机(读写) TPS QPS1| binlogsysbench—mysql从机(只读)TPS QPS2集群性能指标TPS QPS&#x3D;QPS1+QPS2这两种哪种严谨些啊？mycat的损失忽略。</p>
<p>生产中的集群性能怎么算的呢？？？(还是学生 谢谢！)2019-01-21 作者回复TPS就看主库的写入QPS就看所有从库的读能力加和不过没看懂你问题中1）和2）的区别 2019-01-22HuaMax   0删除导致锁范围扩大那个例子，id&gt;10 and id&lt;&#x3D;15，锁范围为什么没有10呢？不是应该（5，10]吗？2019-01-21 作者回复不是的，要找id&gt;10的，并没有命中id&#x3D;10哦，你可以理解成就是查到了(10,15)这个间隙2019-01-21llx   0回复@往事随风，顺其自然前面有解释为什么，这篇文章有更详细的解释。</p>
<p>Gap lock 由右值指定的，由于 c 不是唯一键，需要到10，遍历到10的时候，就把 5-10 锁了2019-01-21 作者回复 2019-01-21&#96;&#96;&#96;</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/e5c71a8.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/e5c71a8.html" class="post-title-link" itemprop="url">mysql-如何判断一个数据库是不是出问题了</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-04 06:04:41" itemprop="dateCreated datePublished" datetime="2019-12-04T06:04:41+08:00">2019-12-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:39" itemprop="dateModified" datetime="2023-01-18T23:34:39+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>如何判断一个数据库是不是出问题了？我在第25和27篇文章中，和你介绍了主备切换流程。</p>
<p>通过这些内容的讲解，你应该已经很清楚了：在一主一备的双M架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。</p>
<p>主备切换有两种场景，一种是主动切换，一种是被动切换。</p>
<p>而其中被动切换，往往是因为主库出问题了，由HA系统发起的。</p>
<p>这也就引出了我们今天要讨论的问题：怎么判断一个主库出问题了？你一定会说，这很简单啊，连上MySQL，执行个select 1就好了。</p>
<p>但是select 1成功返回了，就表示主库没问题吗？select 1判断实际上，select 1成功返回，只能说明这个库的进程还在，并不能说明主库没问题。</p>
<p>现在，我们来看一下这个场景。</p>
<p>图1 查询blocked我们设置innodb_thread_concurrency参数的目的是，控制InnoDB的并发线程上限。</p>
<p>也就是说，一旦并发线程数达到这个值，InnoDB在接收到新请求的时候，就会进入等待状态，直到有线程退出。</p>
<p>这里，我把innodb_thread_concurrency设置成3，表示InnoDB只允许3个线程并行执行。</p>
<p>而在我们的例子中，前三个session 中的sleep(100)，使得这三个语句都处于“执行”状态，以此来模拟大查询。</p>
<p>你看到了， session D里面，select 1是能执行成功的，但是查询表t的语句会被堵住。</p>
<p>也就是说，如果这时候我们用select 1来检测实例是否正常的话，是检测不出问题的。</p>
<p>在InnoDB中，innodb_thread_concurrency这个参数的默认值是0，表示不限制并发线程数量。</p>
<p>但是，不限制并发线程数肯定是不行的。</p>
<p>因为，一个机器的CPU核数有限，线程全冲进来，上下文切换的成本就会太高。</p>
<p>所以，通常情况下，我们建议把innodb_thread_concurrency设置为64~128之间的值。</p>
<p>这时，你一定会有疑问，并发线程上限数设置为128够干啥，线上的并发连接数动不动就上千了。</p>
<p>产生这个疑问的原因，是搞混了并发连接和并发查询。</p>
<p>set global innodb_thread_concurrency&#x3D;3;CREATE TABLE t̀  ̀(  ìd  ̀int(11) NOT NULL,  &#96;c  ̀int(11) DEFAULT NULL,  PRIMARY KEY (̀ id )̀) ENGINE&#x3D;InnoDB; insert into t values(1,1)并发连接和并发查询，并不是同一个概念。</p>
<p>你在show processlist的结果里，看到的几千个连接，指的就是并发连接。</p>
<p>而“当前正在执行”的语句，才是我们所说的并发查询。</p>
<p>并发连接数达到几千个影响并不大，就是多占一些内存而已。</p>
<p>我们应该关注的是并发查询，因为并发查询太高才是CPU杀手。</p>
<p>这也是为什么我们需要设置innodb_thread_concurrency参数的原因。</p>
<p>然后，你可能还会想起我们在第7篇文章中讲到的热点更新和死锁检测的时候，如果把innodb_thread_concurrency设置为128的话，那么出现同一行热点更新的问题时，是不是很快就把128消耗完了，这样整个系统是不是就挂了呢？实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在128里面的。</p>
<p>MySQL这样设计是非常有意义的。</p>
<p>因为，进入锁等待的线程已经不吃CPU了；更重要的是，必须这么设计，才能避免整个系统锁死。</p>
<p>为什么呢？假设处于锁等待的线程也占并发线程的计数，你可以设想一下这个场景：</p>
<ol>
<li>线程1执行begin; update t set c&#x3D;c+1 where id&#x3D;1, 启动了事务trx1， 然后保持这个状态。</li>
</ol>
<p>这时候，线程处于空闲状态，不算在并发线程里面。</p>
<ol start="2">
<li>线程2到线程129都执行 update t set c&#x3D;c+1 where id&#x3D;1; 由于等行锁，进入等待状态。</li>
</ol>
<p>这样就有128个线程处于等待状态；</p>
<ol start="3">
<li>如果处于锁等待状态的线程计数不减一，InnoDB就会认为线程数用满了，会阻止其他语句进入引擎执行，这样线程1不能提交事务。</li>
</ol>
<p>而另外的128个线程又处于锁等待状态，整个系统就堵住了。</p>
<p>下图2显示的就是这个状态。</p>
<p>图2 系统锁死状态（假设等行锁的语句占用并发计数）这时候InnoDB不能响应任何请求，整个系统被锁死。</p>
<p>而且，由于所有线程都处于等待状态，此时占用的CPU却是0，而这明显不合理。</p>
<p>所以，我们说InnoDB在设计时，遇到进程进入锁等待的情况时，将并发线程的计数减1的设计，是合理而且是必要的。</p>
<p>虽然说等锁的线程不算在并发线程计数里，但如果它在真正地执行查询，就比如我们上面例子中前三个事务中的select sleep(100) from t，还是要算进并发线程的计数的。</p>
<p>在这个例子中，同时在执行的语句超过了设置的innodb_thread_concurrency的值，这时候系统其实已经不行了，但是通过select 1来检测系统，会认为系统还是正常的。</p>
<p>因此，我们使用select 1的判断逻辑要修改一下。</p>
<p>查表判断为了能够检测InnoDB并发线程数过多导致的系统不可用情况，我们需要找一个访问InnoDB的场景。</p>
<p>一般的做法是，在系统库（mysql库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行：</p>
<p>mysql&gt; select * from mysql.health_check; 使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。</p>
<p>但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。</p>
<p>我们知道，更新事务要写binlog，而一旦binlog所在磁盘的空间占用率达到100%，那么所有的更新语句和事务提交的commit语句就都会被堵住。</p>
<p>但是，系统这时候还是可以正常读数据的。</p>
<p>因此，我们还是把这条监控语句再改进一下。</p>
<p>接下来，我们就看看把查询语句改成更新语句后的效果。</p>
<p>更新判断既然要更新，就要放个有意义的字段，常见做法是放一个timestamp字段，用来表示最后一次执行检测的时间。</p>
<p>这条更新语句类似于：</p>
<p>节点可用性的检测都应该包含主库和备库。</p>
<p>如果用更新来检测主库的话，那么备库也要进行更新检测。</p>
<p>但，备库的检测也是要写binlog的。</p>
<p>由于我们一般会把数据库A和B的主备关系设计为双M结构，所以在备库B上执行的检测命令，也要发回给主库A。</p>
<p>但是，如果主库A和备库B都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。</p>
<p>所以，现在看来mysql.health_check 这个表就不能只有一行数据了。</p>
<p>为了让主备之间的更新不产生冲突，我们可以在mysql.health_check表上存入多行数据，并用A、B的server_id做主键。</p>
<p>由于MySQL规定了主库和备库的server_id必须不同（否则创建主备关系的时候就会报错），这mysql&gt; update mysql.health_check set t_modified&#x3D;now();mysql&gt; CREATE TABLE &#96;health_check  ̀(  ìd  ̀int(11) NOT NULL,  t̀_modified  ̀timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,  PRIMARY KEY (̀ id )̀) ENGINE&#x3D;InnoDB;&#x2F;* 检测命令 *&#x2F;insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified&#x3D;now();样就可以保证主、备库各自的检测命令不会发生冲突。</p>
<p>更新判断是一个相对比较常用的方案了，不过依然存在一些问题。</p>
<p>其中，“判定慢”一直是让DBA头疼的问题。</p>
<p>你一定会疑惑，更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢？其实，这里涉及到的是服务器IO资源分配的问题。</p>
<p>首先，所有的检测逻辑都需要一个超时时间N。</p>
<p>执行一条update语句，超过N秒后还不返回，就认为系统不可用。</p>
<p>你可以设想一个日志盘的IO利用率已经是100%的场景。</p>
<p>这时候，整个系统响应非常慢，已经需要做主备切换了。</p>
<p>但是你要知道，IO利用率100%表示系统的IO是在工作的，每个请求都有机会获得IO资源，执行自己的任务。</p>
<p>而我们的检测使用的update命令，需要的资源很少，所以可能在拿到IO资源的时候就可以提交成功，并且在超时时间N秒未到达之前就返回给了检测系统。</p>
<p>检测系统一看，update命令没有超时，于是就得到了“系统正常”的结论。</p>
<p>也就是说，这时候在业务系统上正常的SQL语句已经执行得很慢了，但是DBA上去一看，HA系统还在正常工作，并且认为主库现在处于可用状态。</p>
<p>之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。</p>
<p>外部检测天然有一个问题，就是随机性。</p>
<p>因为，外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，我们才有可能发现问题。</p>
<p>而且，如果你的运气不够好的话，可能第一次轮询还不能发现，这就会导致切换慢的问题。</p>
<p>所以，接下来我要再和你介绍一种在MySQL内部发现数据库问题的方法。</p>
<p>内部统计针对磁盘利用率这个问题，如果MySQL可以告诉我们，内部每一次IO请求的时间，那我们判断数据库是否出问题的方法就可靠得多了。</p>
<p>其实，MySQL 5.6版本以后提供的performance_schema库，就在file_summary_by_event_name表里统计了每次IO请求的时间。</p>
<p>file_summary_by_event_name表里有很多行数据，我们先来看看event_name&#x3D;’wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file’这一行。</p>
<p>图3 performance_schema.file_summary_by_event_name的一行图中这一行表示统计的是redo log的写入时间，第一列EVENT_NAME 表示统计的类型。</p>
<p>接下来的三组数据，显示的是redo log操作的时间统计。</p>
<p>第一组五列，是所有IO类型的统计。</p>
<p>其中，COUNT_STAR是所有IO的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、平均值和最大值。</p>
<p>第二组六列，是读操作的统计。</p>
<p>最后一列SUM_NUMBER_OF_BYTES_READ统计的是，总共从redo log里读了多少个字节。</p>
<p>第三组六列，统计的是写操作。</p>
<p>最后的第四组数据，是对其他类型数据的统计。</p>
<p>在redo log里，你可以认为它们就是对fsync的统计。</p>
<p>在performance_schema库的file_summary_by_event_name表里，binlog对应的是event_name &#x3D;”wait&#x2F;io&#x2F;file&#x2F;sql&#x2F;binlog”这一行。</p>
<p>各个字段的统计逻辑，与redo log的各个字段完全相同。</p>
<p>这里，我就不再赘述了。</p>
<p>因为我们每一次操作数据库，performance_schema都需要额外地统计这些信息，所以我们打开这个统计功能是有性能损耗的。</p>
<p>我的测试结果是，如果打开所有的performance_schema项，性能大概会下降10%左右。</p>
<p>所以，我建议你只打开自己需要的项进行统计。</p>
<p>你可以通过下面的方法打开或者关闭某个具体项的统计。</p>
<p>如果要打开redo log的时间监控，你可以执行这个语句：</p>
<p>假设，现在你已经开启了redo log和binlog这两个统计信息，那要怎么把这个信息用在实例状态诊断上呢？很简单，你可以通过MAX_TIMER的值来判断数据库是否出问题了。</p>
<p>比如，你可以设定阈值，单次IO请求时间超过200毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。</p>
<p>发现异常后，取到你需要的信息，再通过下面这条语句：</p>
<p>把之前的统计信息清空。</p>
<p>这样如果后面的监控中，再次出现这个异常，就可以加入监控累积值了。</p>
<p>小结今天，我和你介绍了检测一个MySQL实例健康状态的几种方法，以及各种方法存在的问题和演进的逻辑。</p>
<p>你看完后可能会觉得，select 1这样的方法是不是已经被淘汰了呢，但实际上使用非常广泛的MHA（Master High Availability），默认使用的就是这个方法。</p>
<p>MHA中的另一个可选方法是只做连接，就是 “如果连接成功就认为主库没问题”。</p>
<p>不过据我所知，选择这个方法的很少。</p>
<p>其实，每个改进的方案，都会增加额外损耗，并不能用“对错”做直接判断，需要你根据业务实际情况去做权衡。</p>
<p>我个人比较倾向的方案，是优先考虑update系统表，然后再配合增加检测performance_schema的信息。</p>
<p>最后，又到了我们的思考题时间。</p>
<p>今天，我想问你的是：业务系统一般也有高可用的需求，在你开发和维护过的服务中，你是怎么判断服务有没有出问题的呢？mysql&gt; update setup_instruments set ENABLED&#x3D;’YES’, Timed&#x3D;’YES’ where name like ‘%wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file%’;mysql&gt; select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in (‘wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file’,’wait&#x2F;io&#x2F;file&#x2F;sql&#x2F;binlog’) and MAX_TIMER_WAIT&gt;200*1000000000;mysql&gt; truncate table performance_schema.file_summary_by_event_name;你可以把你用到的方法和分析写在留言区，我会在下一篇文章中选取有趣的方案一起来分享和分析。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期的问题是，如果使用GTID等位点的方案做读写分离，在对大表做DDL的时候会怎么样。</p>
<p>假设，这条语句在主库上要执行10分钟，提交后传到备库就要10分钟（典型的大事务）。</p>
<p>那么，在主库DDL之后再提交的事务的GTID，去备库查的时候，就会等10分钟才出现。</p>
<p>这样，这个读写分离机制在这10分钟之内都会超时，然后走主库。</p>
<p>这种预期内的操作，应该在业务低峰期的时候，确保主库能够支持所有业务查询，然后把读请求都切到主库，再在主库上做DDL。</p>
<p>等备库延迟追上以后，再把读请求切回备库。</p>
<p>通过这个思考题，我主要想让关注的是，大事务对等位点方案的影响。</p>
<p>当然了，使用gh-ost方案来解决这个问题也是不错的选择。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/5d62a522.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/5d62a522.html" class="post-title-link" itemprop="url">mysql-读写分离有哪些坑</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-03 06:13:35" itemprop="dateCreated datePublished" datetime="2019-12-03T06:13:35+08:00">2019-12-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>5.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>20 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>读写分离有哪些坑？在上一篇文章中，我和你介绍了一主多从的结构以及切换流程。</p>
<p>今天我们就继续聊聊一主多从架构的应用场景：读写分离，以及怎么处理主备延迟导致的读写分离问题。</p>
<p>我们在上一篇文章中提到的一主多从的结构，其实就是读写分离的基本结构了。</p>
<p>这里，我再把这张图贴过来，方便你理解。</p>
<p>图1 读写分离基本结构读写分离的主要目标就是分摊主库的压力。</p>
<p>图1中的结构是客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。</p>
<p>也就是说，由客户端来选择后端数据库进行查询。</p>
<p>还有一种架构是，在MySQL和客户端之间有一个中间代理层proxy，客户端只连接proxy， 由proxy根据请求类型和上下文决定请求的分发路由。</p>
<p>图2 带proxy的读写分离架构接下来，我们就看一下客户端直连和带proxy的读写分离架构，各有哪些特点。</p>
<ol>
<li>客户端直连方案，因为少了一层proxy转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。</li>
</ol>
<p>但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。</p>
<p>你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。</p>
<p>其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如Zookeeper，尽量让业务端只专注于业务逻辑开发。</p>
<ol start="2">
<li>带proxy的架构，对客户端比较友好。</li>
</ol>
<p>客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由proxy完成的。</p>
<p>但这样的话，对后端维护团队的要求会更高。</p>
<p>而且，proxy也需要有高可用架构。</p>
<p>因此，带proxy架构的整体就相对比较复杂。</p>
<p>理解了这两种方案的优劣，具体选择哪个方案就取决于数据库团队提供的能力了。</p>
<p>但目前看，趋势是往带proxy的架构方向发展的。</p>
<p>但是，不论使用哪种架构，你都会碰到我们今天要讨论的问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。</p>
<p>这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。</p>
<p>前面我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能100%避免的。</p>
<p>不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。</p>
<p>接下来，我们就来讨论怎么处理过期读问题。</p>
<p>这里，我先把文章中涉及到的处理过期读的方案汇总在这里，以帮助你更好地理解和掌握全文的知识脉络。</p>
<p>这些方案包括：</p>
<p>强制走主库方案；</p>
<p>sleep方案；</p>
<p>判断主备无延迟方案；</p>
<p>配合semi-sync方案；</p>
<p>等主库位点方案；</p>
<p>等GTID方案。</p>
<p>强制走主库方案强制走主库方案其实就是，将查询请求做分类。</p>
<p>通常情况下，我们可以将查询请求分为这么两类：</p>
<ol>
<li>对于必须要拿到最新结果的请求，强制将其发到主库上。</li>
</ol>
<p>比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。</p>
<p>那么，这个请求需要拿到最新的结果，就必须走主库。</p>
<ol start="2">
<li>对于可以读到旧数据的请求，才将其发到从库上。</li>
</ol>
<p>在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。</p>
<p>那么，这类请求就可以走从库。</p>
<p>你可能会说，这个方案是不是有点畏难和取巧的意思，但其实这个方案是用得最多的。</p>
<p>当然，这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。</p>
<p>这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。</p>
<p>因此接下来，我们来讨论的话题是：可以支持读写分离的场景下，有哪些解决过期读的方案，并分析各个方案的优缺点。</p>
<p>Sleep 方案主库更新后，读从库之前先sleep一下。</p>
<p>具体的方案就是，类似于执行一条select sleep(1)命令。</p>
<p>这个方案的假设是，大多数情况下主备延迟在1秒之内，做一个sleep可以有很大概率拿到最新的数据。</p>
<p>这个方案给你的第一感觉，很可能是不靠谱儿，应该不会有人用吧？并且，你还可能会说，直接在发起查询时先执行一条sleep语句，用户体验很不友好啊。</p>
<p>但，这个思路确实可以在一定程度上解决问题。</p>
<p>为了看起来更靠谱儿，我们可以换一种方式。</p>
<p>以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。</p>
<p>这样，卖家就可以通过这个显示，来确认产品已经发布成功了。</p>
<p>等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。</p>
<p>也就是说，这个sleep方案确实解决了类似场景下的过期读问题。</p>
<p>但，从严格意义上来说，这个方案存在的问题就是不精确。</p>
<p>这个不精确包含了两层意思：</p>
<ol>
<li><p>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</p>
</li>
<li><p>如果延迟超过1秒，还是会出现过期读。</p>
</li>
</ol>
<p>看到这里，你是不是有一种“你是不是在逗我”的感觉，这个改进方案虽然可以解决类似Ajax场景下的过期读问题，但还是怎么看都不靠谱儿。</p>
<p>别着急，接下来我就和你介绍一些更准确的方案。</p>
<p>判断主备无延迟方案要确保备库无延迟，通常有三种做法。</p>
<p>通过前面的第25篇文章，我们知道show slave status结果里的seconds_behind_master参数的值，可以用来衡量主备延迟时间的长短。</p>
<p>所以第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。</p>
<p>如果还不等于0 ，那就必须等到这个参数变为0才能执行查询请求。</p>
<p>seconds_behind_master的单位是秒，如果你觉得精度不够的话，还可以采用对比位点和GTID的方法来确保主备无延迟，也就是我们接下来要说的第二和第三种方法。</p>
<p>如图3所示，是一个show slave status结果的部分截图。</p>
<p>图3 show slave status结果现在，我们就通过这个结果，来看看具体如何通过对比位点和GTID来确保主备无延迟。</p>
<p>第二种方法，对比位点确保主备无延迟：</p>
<p>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；</p>
<p>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。</p>
<p>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成。</p>
<p>第三种方法，对比GTID集合确保主备无延迟：</p>
<p>Auto_Position&#x3D;1 ，表示这对主备关系使用了GTID协议。</p>
<p>Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；</p>
<p>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。</p>
<p>如果这两个集合相同，也表示备库接收到的日志都已经同步完成。</p>
<p>可见，对比位点和对比GTID这两种方法，都要比判断seconds_behind_master是否为0更准确。</p>
<p>在执行查询请求之前，先判断从库是否同步完成的方法，相比于sleep方案，准确度确实提升了不少，但还是没有达到“精确”的程度。</p>
<p>为什么这么说呢？我们现在一起来回顾下，一个事务的binlog在主备库之间的状态：</p>
<ol>
<li><p>主库执行完成，写入binlog，并反馈给客户端；</p>
</li>
<li><p>binlog被从主库发送给备库，备库收到；</p>
</li>
<li><p>在备库执行binlog完成。</p>
</li>
</ol>
<p>我们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。</p>
<p>但是，从binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</p>
<p>如图4所示就是这样的一个状态。</p>
<p>图4 备库还没收到trx3这时，主库上执行完成了三个事务trx1、trx2和trx3，其中：</p>
<ol>
<li><p>trx1和trx2已经传到从库，并且已经执行完成了；</p>
</li>
<li><p>trx3在主库执行完成，并且已经回复给客户端，但是还没有传到从库中。</p>
</li>
</ol>
<p>如果这时候你在从库B上执行查询请求，按照我们上面的逻辑，从库认为已经没有同步延迟，但还是查不到trx3的。</p>
<p>严格地说，就是出现了过期读。</p>
<p>那么，这个问题有没有办法解决呢？配合semi-sync要解决这个问题，就要引入半同步复制，也就是semi-sync replication。</p>
<p>semi-sync做了这样的设计：</p>
<ol>
<li><p>事务提交的时候，主库把binlog发给从库；</p>
</li>
<li><p>从库收到binlog以后，发回给主库一个ack，表示收到了；</p>
</li>
<li><p>主库收到这个ack以后，才能给客户端返回“事务完成”的确认。</p>
</li>
</ol>
<p>也就是说，如果启用了semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。</p>
<p>在第25篇文章的评论区，有同学问到：如果主库掉电的时候，有些binlog还来不及发给从库，会不会导致系统数据丢失？答案是，如果使用的是普通的异步复制模式，就可能会丢失，但semi-sync就可以解决这个问题。</p>
<p>这样，semi-sync配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。</p>
<p>但是，semi-sync+位点判断的方案，只对一主一备的场景是成立的。</p>
<p>在一主多从场景中，主库只要等到一个从库的ack，就开始给客户端返回确认。</p>
<p>这时，在从库上执行查询请求，就有两种情况：</p>
<ol>
<li><p>如果查询是落在这个响应了ack的从库上，是能够确保读到最新数据；</p>
</li>
<li><p>但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。</p>
</li>
</ol>
<p>其实，判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者GTID集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。</p>
<p>实际上，回到我们最初的业务逻辑里，当发起一个查询请求以后，我们要得到准确的结果，其实并不需要等到“主备完全同步”。</p>
<p>为什么这么说呢？我们来看一下这个时序图。</p>
<p>图5 主备持续延迟一个事务图5所示，就是等待位点方案的一个bad case。</p>
<p>图中备库B下的虚线框，分别表示relaylog和binlog中的事务。</p>
<p>可以看到，图5中从状态1 到状态4，一直处于延迟一个事务的状态。</p>
<p>备库B一直到状态4都和主库A存在延迟，如果用上面必须等到无延迟才能查询的方案，select语句直到状态4都不能被执行。</p>
<p>但是，其实客户端是在发完trx1更新后发起的select语句，我们只需要确保trx1已经执行完成就可以执行select语句了。</p>
<p>也就是说，如果在状态3执行查询请求，得到的就是预期结果了。</p>
<p>到这里，我们小结一下，semi-sync配合判断主备无延迟的方案，存在两个问题：</p>
<ol>
<li><p>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；</p>
</li>
<li><p>在持续延迟的情况下，可能出现过度等待的问题。</p>
</li>
</ol>
<p>接下来，我要和你介绍的等主库位点方案，就可以解决这两个问题。</p>
<p>等主库位点方案要理解等主库位点方案，我需要先和你介绍一条命令：</p>
<p>这条命令的逻辑如下：</p>
<ol>
<li><p>它是在从库执行的；</p>
</li>
<li><p>参数file和pos指的是主库上的文件名和位置；</p>
</li>
<li><p>timeout可选，设置为正整数N表示这个函数最多等待N秒。</p>
</li>
</ol>
<p>这个命令正常返回的结果是一个正整数M，表示从命令开始执行，到应用完file和pos表示的binlog位置，执行了多少事务。</p>
<p>当然，除了正常返回一个正整数M外，这条命令还会返回一些其他结果，包括：</p>
<ol>
<li><p>如果执行期间，备库同步线程发生异常，则返回NULL；</p>
</li>
<li><p>如果等待超过N秒，就返回-1；</p>
</li>
<li><p>如果刚开始执行的时候，就发现已经执行过这个位置了，则返回0。</p>
</li>
</ol>
<p>对于图5中先执行trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使用这个逻辑：</p>
<ol>
<li><p>trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；</p>
</li>
<li><p>选定一个从库执行查询语句；</p>
</li>
<li><p>在从库上执行select master_pos_wait(File, Position, 1)；</p>
</li>
<li><p>如果返回值是&gt;&#x3D;0的正整数，则在这个从库执行查询语句；</p>
</li>
<li><p>否则，到主库执行查询语句。</p>
</li>
</ol>
<p>我把上面这个流程画出来。</p>
<p>select master_pos_wait(file, pos[, timeout]);图6 master_pos_wait方案这里我们假设，这条select查询最多在从库上等待1秒。</p>
<p>那么，如果1秒内master_pos_wait返回一个大于等于0的整数，就确保了从库上执行的这个查询结果一定包含了trx1的数据。</p>
<p>步骤5到主库执行查询语句，是这类方案常用的退化机制。</p>
<p>因为从库的延迟时间不可控，不能无限等待，所以如果等待超时，就应该放弃，然后到主库去查。</p>
<p>你可能会说，如果所有的从库都延迟超过1秒了，那查询压力不就都跑到主库上了吗？确实是这样。</p>
<p>但是，按照我们设定不允许过期读的要求，就只有两种选择，一种是超时放弃，一种是转到主库查询。</p>
<p>具体怎么选择，就需要业务开发同学做好限流策略了。</p>
<p>GTID方案如果你的数据库开启了GTID模式，对应的也有等待GTID的方案。</p>
<p>MySQL中同样提供了一个类似的命令：</p>
<p> select wait_for_executed_gtid_set(gtid_set, 1);这条命令的逻辑是：</p>
<ol>
<li><p>等待，直到这个库执行的事务中包含传入的gtid_set，返回0；</p>
</li>
<li><p>超时返回1。</p>
</li>
</ol>
<p>在前面等位点的方案中，我们执行完事务后，还要主动去主库执行show master status。</p>
<p>而MySQL 5.7.6版本开始，允许在执行完更新类事务后，把这个事务的GTID返回给客户端，这样等GTID的方案就可以减少一次查询。</p>
<p>这时，等GTID的执行流程就变成了：</p>
<ol>
<li><p>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</p>
</li>
<li><p>选定一个从库执行查询语句；</p>
</li>
<li><p>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；</p>
</li>
<li><p>如果返回值是0，则在这个从库执行查询语句；</p>
</li>
<li><p>否则，到主库执行查询语句。</p>
</li>
</ol>
<p>跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。</p>
<p>我把这个流程图画出来。</p>
<p>图7 wait_for_executed_gtid_set方案在上面的第一步中，trx1事务更新完成后，从返回包直接获取这个事务的GTID。</p>
<p>问题是，怎么能够让MySQL在执行事务后，返回包中带上GTID呢？你只需要将参数session_track_gtids设置为OWN_GTID，然后通过API接口mysql_session_track_get_first从返回包解析出GTID的值即可。</p>
<p>在专栏的第一篇文章中，我介绍mysql_reset_connection的时候，评论区有同学留言问这类接口应该怎么使用。</p>
<p>这里我再回答一下。</p>
<p>其实，MySQL并没有提供这类接口的SQL用法，是提供给程序的API(<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/c-api-functions.html)%E3%80%82">https://dev.mysql.com/doc/refman/5.7/en/c-api-functions.html)。</a></p>
<p>比如，为了让客户端在事务提交后，返回的GITD能够在客户端显示出来，我对MySQL客户端代码做了点修改，如下所示：</p>
<p>图8 显示更新事务的GTID–代码这样，就可以看到语句执行完成，显示出GITD的值。</p>
<p>图9 显示更新事务的GTID–效果当然了，这只是一个例子。</p>
<p>你要使用这个方案的时候，还是应该在你的客户端代码中调用mysql_session_track_get_first这个函数。</p>
<p>小结在今天这篇文章中，我跟你介绍了一主多从做读写分离时，可能碰到过期读的原因，以及几种应对的方案。</p>
<p>这几种方案中，有的方案看上去是做了妥协，有的方案看上去不那么靠谱儿，但都是有实际应用场景的，你需要根据业务需求选择。</p>
<p>即使是最后等待位点和等待GTID这两个方案，虽然看上去比较靠谱儿，但仍然存在需要权衡的情况。</p>
<p>如果所有的从库都延迟，那么请求就会全部落到主库上，这时候会不会由于压力突然增大，把主库打挂了呢？其实，在实际应用中，这几个方案是可以混合使用的。</p>
<p>比如，先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期读；然后，对于不能接受过期读的语句，再使用等GTID或等位点的方案。</p>
<p>但话说回来，过期读在本质上是由一写多读导致的。</p>
<p>在实际应用中，可能会有别的不需要等待就可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中取权衡。</p>
<p>最后 ，我给你留下一个问题吧。</p>
<p>假设你的系统采用了我们文中介绍的最后一个方案，也就是等GTID的方案，现在你要对主库的一张大表做DDL，可能会出现什么情况呢？为了避免这种情况，你会怎么做呢？你可以把你的分析和方案设计写在评论区，我会在下一篇文章跟你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期给你留的问题是，在GTID模式下，如果一个新的从库接上主库，但是需要的binlog已经没了，要怎么做？@某、人同学给了很详细的分析，我把他的回答略做修改贴过来。</p>
<ol>
<li>如果业务允许主从不一致的情况，那么可以在主库上先执行show global variables like‘gtid_purged’，得到主库已经删除的GTID集合，假设是gtid_purged1；然后先在从库上执行reset master，再执行set global gtid_purged &#x3D;‘gtid_purged1’；最后执行start slave，就会从主库现存的binlog开始同步。</li>
</ol>
<p>binlog缺失的那一部分，数据在从库上就可能会有丢失，造成主从不一致。</p>
<ol start="2">
<li><p>如果需要主从数据一致的话，最好还是通过重新搭建从库来做。</p>
</li>
<li><p>如果有其他的从库保留有全量的binlog的话，可以把新的从库先接到这个保留了全量binlog的从库，追上日志以后，如果有需要，再接回主库。</p>
</li>
<li><p>如果binlog有备份的情况，可以先在从库上应用缺失的binlog，然后再执行start slave。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/fc93d163.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/fc93d163.html" class="post-title-link" itemprop="url">mysql-主库出问题了从库怎么办</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-02 06:01:31" itemprop="dateCreated datePublished" datetime="2019-12-02T06:01:31+08:00">2019-12-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>17 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>主库出问题了，从库怎么办？在前面的第24、25和26篇文章中，我和你介绍了MySQL主备复制的基础结构，但这些都是一主一备的结构。</p>
<p>大多数的互联网应用场景都是读多写少，因此你负责的业务，在发展过程中很可能先会遇到读性能的问题。</p>
<p>而在数据库层解决读性能问题，就要涉及到接下来两篇文章要讨论的架构：一主多从。</p>
<p>今天这篇文章，我们就先聊聊一主多从的切换正确性。</p>
<p>然后，我们在下一篇文章中再聊聊解决一主多从的查询逻辑正确性的方法。</p>
<p>如图1所示，就是一个基本的一主多从结构。</p>
<p>图1 一主多从基本结构图中，虚线箭头表示的是主备关系，也就是A和A’互为主备， 从库B、C、D指向的是主库A。</p>
<p>一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。</p>
<p>今天我们要讨论的就是，在一主多从架构下，主库故障后的主备切换问题。</p>
<p>如图2所示，就是主库发生故障，主备切换后的结果。</p>
<p>图2 一主多从基本结构–主备切换相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库B、C、D也要改接到A’。</p>
<p>正是由于多了从库B、C、D重新指向的这个过程，所以主备切换的复杂性也相应增加了。</p>
<p>接下来，我们再一起看看一个切换系统会怎么完成一主多从的主备切换过程。</p>
<p>基于位点的主备切换这里，我们需要先来回顾一个知识点。</p>
<p>当我们把节点B设置成节点A’的从库的时候，需要执行一条change master命令：</p>
<p>CHANGE MASTER TO MASTER_HOST&#x3D;$host_name MASTER_PORT&#x3D;$port MASTER_USER&#x3D;$user_name MASTER_PASSWORD&#x3D;$password MASTER_LOG_FILE&#x3D;$master_log_name MASTER_LOG_POS&#x3D;$master_log_pos  这条命令有这么6个参数：</p>
<p>MASTER_HOST、MASTER_PORT、MASTER_USER和MASTER_PASSWORD四个参数，分别代表了主库A’的IP、端口、用户名和密码。</p>
<p>最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示，要从主库的master_log_name文件的master_log_pos这个位置的日志继续同步。</p>
<p>而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。</p>
<p>那么，这里就有一个问题了，节点B要设置成A’的从库，就要执行change master命令，就不可避免地要设置位点的这两个参数，但是这两个参数到底应该怎么设置呢？原来节点B是A的从库，本地记录的也是A的位点。</p>
<p>但是相同的日志，A的位点和A’的位点是不同的。</p>
<p>因此，从库B要切换的时候，就需要先经过“找同步位点”这个逻辑。</p>
<p>这个位点很难精确取到，只能取一个大概位置。</p>
<p>为什么这么说呢？我来和你分析一下看看这个位点一般是怎么获取到的，你就清楚其中不精确的原因了。</p>
<p>考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。</p>
<p>一种取同步位点的方法是这样的：</p>
<ol>
<li><p>等待新主库A’把中转日志（relay log）全部同步完成；</p>
</li>
<li><p>在A’上执行show master status命令，得到当前A’上最新的File 和 Position；</p>
</li>
<li><p>取原主库A故障的时刻T；</p>
</li>
<li><p>用mysqlbinlog工具解析A’的File，得到T时刻的位点。</p>
</li>
</ol>
<p>图3 mysqlbinlog 部分输出结果图中，end_log_pos后面的值“123”，表示的就是A’这个实例，在T时刻写入新的binlog的位置。</p>
<p>然后，我们就可以把123这个值作为$master_log_pos ，用在节点B的change master命令里。</p>
<p>mysqlbinlog File –stop-datetime&#x3D;T –start-datetime&#x3D;T当然这个值并不精确。</p>
<p>为什么呢？你可以设想有这么一种情况，假设在T这个时刻，主库A已经执行完成了一个insert 语句插入了一行数据R，并且已经将binlog传给了A’和B，然后在传完的瞬间主库A的主机就掉电了。</p>
<p>那么，这时候系统的状态是这样的：</p>
<ol>
<li><p>在从库B上，由于同步了binlog， R这一行已经存在；</p>
</li>
<li><p>在新主库A’上， R这一行也已经存在，日志是写在123这个位置之后的；</p>
</li>
<li><p>我们在从库B上执行change master命令，指向A’的File文件的123位置，就会把插入R这一行数据的binlog又同步到从库B去执行。</p>
</li>
</ol>
<p>这时候，从库B的同步线程就会报告 Duplicate entry ‘id_of_R’ for key ‘PRIMARY’ 错误，提示出现了主键冲突，然后停止同步。</p>
<p>所以，通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。</p>
<p>一种做法是，主动跳过一个事务。</p>
<p>跳过命令的写法是：</p>
<p>因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库B刚开始接到新主库A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。</p>
<p>另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。</p>
<p>在执行主备切换时，有这么两类错误，是经常会遇到的：</p>
<p>1062错误是插入数据时唯一键冲突；</p>
<p>1032错误是删除数据时找不到行。</p>
<p>因此，我们可以把slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。</p>
<p>这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。</p>
<p>这个背景是，我们很清楚在主备切换过程中，直接跳过1032和1062这两类错误是无损的，所以set global sql_slave_skip_counter&#x3D;1;start slave;才可以这么设置slave_skip_errors参数。</p>
<p>等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。</p>
<p>GTID通过sql_slave_skip_counter跳过事务和通过slave_skip_errors忽略错误的方法，虽然都最终可以建立从库B和新主库A’的主备关系，但这两种操作都很复杂，而且容易出错。</p>
<p>所以，MySQL 5.6版本引入了GTID，彻底解决了这个困难。</p>
<p>那么，GTID到底是什么意思，又是如何解决找同步位点这个问题呢？现在，我就和你简单介绍一下。</p>
<p>GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。</p>
<p>它由两部分组成，格式是：</p>
<p>其中：</p>
<p>server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值；</p>
<p>gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。</p>
<p>这里我需要和你说明一下，在MySQL的官方文档里，GTID格式是这么定义的：</p>
<p>这里的source_id就是server_uuid；而后面的这个transaction_id，我觉得容易造成误导，所以我改成了gno。</p>
<p>为什么说使用transaction_id容易造成误解呢？因为，在MySQL里面我们说transaction_id就是指事务id，事务id是在事务执行过程中分配的，如果这个事务回滚了，事务id也会递增，而gno是在事务提交的时候才会分配。</p>
<p>从效果上看，GTID往往是连续的，因此我们用gno来表示更容易理解。</p>
<p>GTID模式的启动也很简单，我们只需要在启动一个MySQL实例的时候，加上参数gtid_mode&#x3D;on和enforce_gtid_consistency&#x3D;on就可以了。</p>
<p>在GTID模式下，每个事务都会跟一个GTID一一对应。</p>
<p>这个GTID有两种生成方式，而使用哪种方式取决于session变量gtid_next的值。</p>
<ol>
<li>如果gtid_next&#x3D;automatic，代表使用默认值。</li>
</ol>
<p>这时，MySQL就会把server_uuid:gno分配给GTID&#x3D;server_uuid:gnoGTID&#x3D;source_id:transaction_id这个事务。</p>
<p>a. 记录binlog的时候，先记录一行 SET @@SESSION.GTID_NEXT&#x3D;‘server_uuid:gno’;b. 把这个GTID加入本实例的GTID集合。</p>
<ol start="2">
<li>如果gtid_next是一个指定的GTID的值，比如通过set gtid_next&#x3D;’current_gtid’指定为current_gtid，那么就有两种可能：</li>
</ol>
<p>a. 如果current_gtid已经存在于实例的GTID集合中，接下来执行的这个事务会直接被系统忽略；</p>
<p>b. 如果current_gtid没有存在于实例的GTID集合中，就将这个current_gtid分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的GTID，因此gno也不用加1。</p>
<p>注意，一个current_gtid只能给一个事务使用。</p>
<p>这个事务提交后，如果要执行下一个事务，就要执行set 命令，把gtid_next设置成另外一个gtid或者automatic。</p>
<p>这样，每个MySQL实例都维护了一个GTID集合，用来对应“这个实例执行过的所有事务”。</p>
<p>这样看上去不太容易理解，接下来我就用一个简单的例子，来和你说明GTID的基本用法。</p>
<p>我们在实例X中创建一个表t。</p>
<p>图4 初始化数据的binlog可以看到，事务的BEGIN之前有一条SET @@SESSION.GTID_NEXT命令。</p>
<p>这时，如果实例X有从库，那么将CREATE TABLE和insert语句的binlog同步过去执行的话，执行事务之前就会先执行这两个SET命令， 这样被加入从库的GTID集合的，就是图中的这两个GTID。</p>
<p>CREATE TABLE t̀  ̀(  ìd  ̀int(11) NOT NULL,  &#96;c  ̀int(11) DEFAULT NULL,  PRIMARY KEY (̀ id )̀) ENGINE&#x3D;InnoDB;insert into t values(1,1);假设，现在这个实例X是另外一个实例Y的从库，并且此时在实例Y上执行了下面这条插入语句：</p>
<p>并且，这条语句在实例Y上的GTID是 “aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”。</p>
<p>那么，实例X作为Y的从库，就要同步这个事务过来执行，显然会出现主键冲突，导致实例X的同步线程停止。</p>
<p>这时，我们应该怎么处理呢？处理方法就是，你可以执行下面的这个语句序列：</p>
<p>其中，前三条语句的作用，是通过提交一个空事务，把这个GTID加到实例X的GTID集合中。</p>
<p>如图5所示，就是执行完这个空事务之后的show master status的结果。</p>
<p>图5 show master status结果可以看到实例X的Executed_Gtid_set里面，已经加入了这个GTID。</p>
<p>这样，我再执行start slave命令让同步线程执行起来的时候，虽然实例X上还是会继续执行实例Y传过来的事务，但是由于“aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”已经存在于实例X的GTID集合中了，所以实例X就会直接跳过这个事务，也就不会再出现主键冲突的错误。</p>
<p>在上面的这个语句序列中，start slave命令之前还有一句set gtid_next&#x3D;automatic。</p>
<p>这句话的作用是“恢复GTID的默认分配行为”，也就是说如果之后有新的事务再执行，就还是按照原来的分配方式，继续分配gno&#x3D;3。</p>
<p>insert into t values(1,1);set gtid_next&#x3D;’aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10’;begin;commit;set gtid_next&#x3D;automatic;start slave;基于GTID的主备切换现在，我们已经理解GTID的概念，再一起来看看基于GTID的主备复制的用法。</p>
<p>在GTID模式下，备库B要设置为新主库A’的从库的语法如下：</p>
<p>其中，master_auto_position&#x3D;1就表示这个主备关系使用的是GTID协议。</p>
<p>可以看到，前面让我们头疼不已的MASTER_LOG_FILE和MASTER_LOG_POS参数，已经不需要指定了。</p>
<p>我们把现在这个时刻，实例A’的GTID集合记为set_a，实例B的GTID集合记为set_b。</p>
<p>接下来，我们就看看现在的主备切换逻辑。</p>
<p>我们在实例B上执行start slave命令，取binlog的逻辑是这样的：</p>
<ol>
<li><p>实例B指定主库A’，基于主备协议建立连接。</p>
</li>
<li><p>实例B把set_b发给主库A’。</p>
</li>
<li><p>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。</p>
</li>
</ol>
<p>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；</p>
<p>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；</p>
<ol start="4">
<li>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。</li>
</ol>
<p>其实，这个逻辑里面包含了一个设计思想：在基于GTID的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。</p>
<p>因此，如果实例B需要的日志已经不存在，A’就拒绝把日志发给B。</p>
<p>这跟基于位点的主备协议不同。</p>
<p>基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。</p>
<p>基于上面的介绍，我们再来看看引入GTID后，一主多从的切换场景下，主备切换是如何实现的。</p>
<p>CHANGE MASTER TO MASTER_HOST&#x3D;$host_name MASTER_PORT&#x3D;$port MASTER_USER&#x3D;$user_name MASTER_PASSWORD&#x3D;$password master_auto_position&#x3D;1 由于不需要找位点了，所以从库B、C、D只需要分别执行change master命令指向实例A’即可。</p>
<p>其实，严谨地说，主备切换不是不需要找位点了，而是找位点这个工作，在实例A’内部就已经自动完成了。</p>
<p>但由于这个工作是自动的，所以对HA系统的开发人员来说，非常友好。</p>
<p>之后这个系统就由新主库A’写入，主库A’的自己生成的binlog中的GTID集合格式是：</p>
<p>server_uuid_of_A’:1-M。</p>
<p>如果之前从库B的GTID集合格式是 server_uuid_of_A:1-N， 那么切换之后GTID集合的格式就变成了server_uuid_of_A:1-N, server_uuid_of_A’:1-M。</p>
<p>当然，主库A’之前也是A的备库，因此主库A’和从库B的GTID集合是一样的。</p>
<p>这就达到了我们预期。</p>
<p>GTID和在线DDL接下来，我再举个例子帮你理解GTID。</p>
<p>之前在第22篇文章《MySQL有哪些“饮鸩止渴”提高性能的方法？》中，我和你提到业务高峰期的慢查询性能问题时，分析到如果是由于索引缺失引起的性能问题，我们可以通过在线加索引来解决。</p>
<p>但是，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再切换。</p>
<p>当时我说，在双M结构下，备库执行的DDL语句也会传给主库，为了避免传回后对主库造成影响，要通过set sql_log_bin&#x3D;off关掉binlog。</p>
<p>评论区有位同学提出了一个问题：这样操作的话，数据库里面是加了索引，但是binlog并没有记录下这一个更新，是不是会导致数据和日志不一致？这个问题提得非常好。</p>
<p>当时，我在留言的回复中就引用了GTID来说明。</p>
<p>今天，我再和你展开说明一下。</p>
<p>假设，这两个互为主备关系的库还是实例X和实例Y，且当前主库是X，并且都打开了GTID模式。</p>
<p>这时的主备切换流程可以变成下面这样：</p>
<p>在实例X上执行stop slave。</p>
<p>在实例Y上执行DDL语句。</p>
<p>注意，这里并不需要关闭binlog。</p>
<p>执行完成后，查出这个DDL语句对应的GTID，并记为 server_uuid_of_Y:gno。</p>
<p>到实例X上执行以下语句序列：</p>
<p>这样做的目的在于，既可以让实例Y的更新有binlog记录，同时也可以确保不会在实例X上执行这条更新。</p>
<p>接下来，执行完主备切换，然后照着上述流程再执行一遍即可。</p>
<p>小结在今天这篇文章中，我先和你介绍了一主多从的主备切换流程。</p>
<p>在这个过程中，从库找新主库的位点是一个痛点。</p>
<p>由此，我们引出了MySQL 5.6版本引入的GTID模式，介绍了GTID的基本概念和用法。</p>
<p>可以看到，在GTID模式下，一主多从切换就非常方便了。</p>
<p>因此，如果你使用的MySQL版本支持GTID的话，我都建议你尽量使用GTID模式来做一主多从的切换。</p>
<p>在下一篇文章中，我们还能看到GTID模式在读写分离场景的应用。</p>
<p>最后，又到了我们的思考题时间。</p>
<p>你在GTID模式下设置主从关系的时候，从库执行start slave命令后，主库发现需要的binlog已经被删除掉了，导致主备创建不成功。</p>
<p>这种情况下，你觉得可以怎么处理呢？你可以把你的方法写在留言区，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上一篇文章最后，我给你留的问题是，如果主库都是单线程压力模式，在从库追主库的过程中，binlog-transaction-dependency-tracking 应该选用什么参数？这个问题的答案是，应该将这个参数设置为WRITESET。</p>
<p>由于主库是单线程压力模式，所以每个事务的commit_id都不同，那么设置为COMMIT_ORDER模式的话，从库也只能单线程执行。</p>
<p>同样地，由于WRITESET_SESSION模式要求在备库应用日志的时候，同一个线程的日志必须set GTID_NEXT&#x3D;”server_uuid_of_Y:gno”;begin;commit;set gtid_next&#x3D;automatic;start slave;与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。</p>
<p>所以，应该将binlog-transaction-dependency-tracking 设置为WRITESET。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/34/">34</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meng Qi</p>
  <div class="site-description" itemprop="description">recording</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">337</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Meng Qi</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">288k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">17:26</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">loading...</span><span id="times">loading...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("1/1/2018 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>

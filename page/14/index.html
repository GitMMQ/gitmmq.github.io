<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.fastolf.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="recording">
<meta property="og:type" content="website">
<meta property="og:title" content="Qi">
<meta property="og:url" content="https://www.fastolf.com/page/14/index.html">
<meta property="og:site_name" content="Qi">
<meta property="og:description" content="recording">
<meta property="og:locale">
<meta property="article:author" content="Meng Qi">
<meta property="article:tag" content="Tech;Data;Vision">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.fastolf.com/page/14/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <title>Qi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
<a target="_blank" rel="noopener" href="https://github.com/gitmmq" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Qi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Cogito ergo sum</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/e01f4df8.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/e01f4df8.html" class="post-title-link" itemprop="url">mysql-什么时候会使用内部临时表</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-12 06:02:19" itemprop="dateCreated datePublished" datetime="2019-12-12T06:02:19+08:00">2019-12-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>18 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>37 | 什么时候会使用内部临时表？2019-02-06 林晓斌</p>
<p>今天是大年初二，在开始我们今天的学习之前，我要先和你道一声春节快乐！</p>
<p>在第16和第34篇文章中，我分别和你介绍了sort buffer、内存临时表和join buffer。这三个数据</p>
<p>结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的</p>
<p>时候用到了sort buffer，在使用join语句的时候用到了join buffer。然后，你可能会有这样的疑问，MySQL什么时候会使用内部临时表呢？今天这篇文章，我就先给你举两个需要用到内部临时表的例子，来看看内部临时表是怎么工作</p>
<p>的。然后，我们再来分析，什么情况下会使用内部临时表。union 执行流程</p>
<p>为了便于量化分析，我用下面的表t1来举例。然后，我们执行下面这条语句：</p>
<p>这条语句用到了union，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合</p>
<p>加起来，重复的行只保留一行。下图是这个语句的explain结果。图1 union语句explain 结果</p>
<p>可以看到：</p>
<p>第二行的key&#x3D;PRIMARY，说明第二个子句用到了索引id。第三行的Extra字段，表示在对子查询的结果集做union的时候，使用了临时表(Using</p>
<p>temporary)。这个语句的执行流程是这样的：</p>
<ol>
<li>创建一个内存临时表，这个临时表只有一个整型字段f，并且f是主键字段。create table t1(id int primary key, a int, b int, index(a));</li>
</ol>
<p>delimiter ;;</p>
<p>create procedure idata()</p>
<p>begin</p>
<p>  declare i int;</p>
<p>  set i&#x3D;1;</p>
<p>  while(i&lt;&#x3D;1000)do</p>
<pre><code>insert into t1 values(i, i, i);

set i=i+1;
</code></pre>
<p>  end while;</p>
<p>end;;</p>
<p>delimiter ;</p>
<p>call idata();</p>
<p>(select 1000 as f) union (select id from t1 order by id desc limit 2);</p>
<ol start="2">
<li>执行第一个子查询，得到1000这个值，并存入临时表中。3. 执行第二个子查询：</li>
</ol>
<p>拿到第一行id&#x3D;1000，试图插入临时表中。但由于1000这个值已经存在于临时表了，违</p>
<p>反了唯一性约束，所以插入失败，然后继续执行；</p>
<p>取到第二行id&#x3D;999，插入临时表成功。4. 从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是1000和</p>
<p>999。这个过程的流程图如下所示：</p>
<p>图 2 union 执行流程</p>
<p>可以看到，这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键id的唯</p>
<p>一性约束，实现了union的语义。顺便提一下，如果把上面这个语句中的union改成union all的话，就没有了“去重”的语义。这样执</p>
<p>行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不</p>
<p>需要临时表了。图3 union all的explain结果</p>
<p>可以看到，第二行的Extra字段显示的是Using index，表示只使用了覆盖索引，没有用临时表</p>
<p>了。group by 执行流程</p>
<p>另外一个常见的使用临时表的例子是group by，我们来看一下这个语句：</p>
<p>这个语句的逻辑是把表t1里的数据，按照 id%10 进行分组统计，并按照m的结果排序后输出。它</p>
<p>的explain结果如下：</p>
<p>图4 group by 的explain结果</p>
<p>在Extra字段里面，我们可以看到三个信息：</p>
<p>Using index，表示这个语句使用了覆盖索引，选择了索引a，不需要回表；</p>
<p>Using temporary，表示使用了临时表；</p>
<p>Using filesort，表示需要排序。这个语句的执行流程是这样的：</p>
<ol>
<li><p>创建内存临时表，表里有两个字段m和c，主键是m；</p>
</li>
<li><p>扫描表t1的索引a，依次取出叶子节点上的id值，计算id%10的结果，记为x；</p>
</li>
</ol>
<p>如果临时表中没有主键为x的行，就插入一个记录(x,1);</p>
<p>如果表中有主键为x的行，就将x这一行的c值加1；</p>
<ol start="3">
<li>遍历完成后，再根据字段m做排序，得到结果集返回给客户端。这个流程的执行图如下：</li>
</ol>
<p>select id%10 as m, count(*) as c from t1 group by m;</p>
<p>图5 group by执行流程</p>
<p>图中最后一步，对内存临时表的排序，在第17篇文章中已经有过介绍，我把图贴过来，方便你</p>
<p>回顾。图6 内存临时表排序流程</p>
<p>其中，临时表的排序过程就是图6中虚线框内的过程。接下来，我们再看一下这条语句的执行结果：</p>
<p>图 7 group by执行结果</p>
<p>如果你的需求并不需要对结果进行排序，那你可以在SQL语句末尾增加order by null，也就是改</p>
<p>成：</p>
<p>这样就跳过了最后排序的阶段，直接从临时表中取数据返回。返回的结果如图8所示。图8 group + order by null 的结果（内存临时表）</p>
<p>由于表t1中的id值是从1开始的，因此返回的结果集中第一行是id&#x3D;1；扫描到id&#x3D;10的时候才插入</p>
<p>m&#x3D;0这一行，因此结果集里最后一行才是m&#x3D;0。这个例子里由于临时表只有10行，内存可以放得下，因此全程只使用了内存临时表。但是，内</p>
<p>存临时表的大小是有限制的，参数tmp_table_size就是控制这个内存大小的，默认是16M。如果我执行下面这个语句序列：</p>
<p>把内存临时表的大小限制为最大1024字节，并把语句改成id % 100，这样返回结果里有100行数</p>
<p>据。但是，这时的内存临时表大小不够存下这100行数据，也就是说，执行过程中会发现内存临</p>
<p>时表大小到达了上限（1024字节）。那么，这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是InnoDB。 这</p>
<p>select id%10 as m, count(*) as c from t1 group by m order by null;</p>
<p>set tmp_table_size&#x3D;1024;</p>
<p>select id%100 as m, count(*) as c from t1 group by m order by null limit 10;</p>
<p>时，返回的结果如图9所示。图9 group + order by null 的结果（磁盘临时表）</p>
<p>如果这个表t1的数据量很大，很可能这个查询需要的磁盘临时表就会占用大量的磁盘空间。group by 优化方法 –索引</p>
<p>可以看到，不论是使用内存临时表还是磁盘临时表，group by逻辑都需要构造一个带唯一索引的</p>
<p>表，执行代价都是比较高的。如果表的数据量比较大，上面这个group by语句执行起来就会很</p>
<p>慢，我们有什么优化的方法呢？要解决group by语句的优化问题，你可以先想一下这个问题：执行group by语句为什么需要临时</p>
<p>表？group by的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的id%100的结果是无序</p>
<p>的，所以我们就需要有一个临时表，来记录并统计结果。那么，如果扫描过程中可以保证出现的数据是有序的，是不是就简单了呢？假设，现在有一个类似图10的这么一个数据结构，我们来看看group by可以怎么做。图10 group by算法优化-有序输入</p>
<p>可以看到，如果可以确保输入的数据是有序的，那么计算group by的时候，就只需要从左到右，</p>
<p>顺序扫描，依次累加。也就是下面这个过程：</p>
<p>当碰到第一个1的时候，已经知道累积了X个0，结果集里的第一行就是(0,X);</p>
<p>当碰到第一个2的时候，已经知道累积了Y个1，结果集里的第一行就是(1,Y);</p>
<p>按照这个逻辑执行的话，扫描到整个输入的数据结束，就可以拿到group by的结果，不需要临时</p>
<p>表，也不需要再额外排序。你一定想到了，InnoDB的索引，就可以满足这个输入有序的条件。在MySQL 5.7版本支持了generated column机制，用来实现列数据的关联更新。你可以用下面的</p>
<p>方法创建一个列z，然后在z列上创建一个索引（如果是MySQL 5.6及之前的版本，你也可以创建</p>
<p>普通列和索引，来解决这个问题）。这样，索引z上的数据就是类似图10这样有序的了。上面的group by语句就可以改成：</p>
<p>alter table t1 add column z int generated always as(id % 100), add index(z);</p>
<p>优化后的group by语句的explain结果，如下图所示：</p>
<p>图11 group by 优化的explain结果</p>
<p>从Extra字段可以看到，这个语句的执行不再需要临时表，也不需要排序了。group by优化方法 –直接排序</p>
<p>所以，如果可以通过加索引来完成group by逻辑就再好不过了。但是，如果碰上不适合创建索引</p>
<p>的场景，我们还是要老老实实做排序的。那么，这时候的group by要怎么优化呢？如果我们明明知道，一个group by语句中需要放到临时表上的数据量特别大，却还是要按照“先</p>
<p>放到内存临时表，插入一部分数据后，发现内存临时表不够用了再转成磁盘临时表”，看上去就</p>
<p>有点儿傻。那么，我们就会想了，MySQL有没有让我们直接走磁盘临时表的方法呢？答案是，有的。在group by语句中加入SQL_BIG_RESULT这个提示（hint），就可以告诉优化器：这个语句涉</p>
<p>及的数据量很大，请直接用磁盘临时表。MySQL的优化器一看，磁盘临时表是B+树存储，存储效率不如数组来得高。所以，既然你告诉</p>
<p>我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。因此，下面这个语句</p>
<p>的执行流程就是这样的：</p>
<ol>
<li><p>初始化sort_buffer，确定放入一个整型字段，记为m；</p>
</li>
<li><p>扫描表t1的索引a，依次取出里面的id值, 将 id%100的值存入sort_buffer中；</p>
</li>
<li><p>扫描完成后，对sort_buffer的字段m做排序（如果sort_buffer内存不够用，就会利用磁盘临</p>
</li>
</ol>
<p>时文件辅助排序）；</p>
<p>select z, count(*) as c from t1 group by z;</p>
<p>select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;</p>
<ol start="4">
<li>排序完成后，就得到了一个有序数组。根据有序数组，得到数组里面的不同值，以及每个值的出现次数。这一步的逻辑，你已经从前面</li>
</ol>
<p>的图10中了解过了。下面两张图分别是执行流程图和执行explain命令得到的结果。图12 使用 SQL_BIG_RESULT的执行流程图</p>
<p>图13 使用 SQL_BIG_RESULT的explain 结果</p>
<p>从Extra字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。基于上面的union、union all和group by语句的执行过程的分析，我们来回答文章开头的问题：</p>
<p>MySQL什么时候会使用内部临时表？1. 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要</p>
<p>额外的内存，来保存中间结果；</p>
<ol start="2">
<li><p>join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；</p>
</li>
<li><p>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union</p>
</li>
</ol>
<p>需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。小结</p>
<p>通过今天这篇文章，我重点和你讲了group by的几种实现算法，从中可以总结一些使用的指导原</p>
<p>则：</p>
<ol>
<li><p>如果对group by语句的结果没有排序要求，要在语句后面加 order by null；</p>
</li>
<li><p>尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using</p>
</li>
</ol>
<p>filesort；</p>
<ol start="3">
<li>如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大</li>
</ol>
<p>tmp_table_size参数，来避免用到磁盘临时表；</p>
<ol start="4">
<li>如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法</li>
</ol>
<p>得到group by的结果。最后，我给你留下一个思考题吧。文章中图8和图9都是order by null，为什么图8的返回结果里面，0是在结果集的最后一行，而图</p>
<p>9的结果里面，0是在结果集的第一行？你可以把你的分析写在留言区里，我会在下一篇文章和你讨论这个问题。感谢你的收听，也欢迎</p>
<p>你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期的问题是：为什么不能用rename修改临时表的改名。在实现上，执行rename table语句的时候，要求按照“库名&#x2F;表名.frm”的规则去磁盘找文件，但是</p>
<p>临时表在磁盘上的frm文件是放在tmpdir目录下的，并且文件名的规则是“#sql{进程id}<em>{线程id}</em></p>
<p>序列号.frm”，因此会报“找不到文件名”的错误。评论区留言点赞板：</p>
<p>@poppy 同学，通过执行语句的报错现象推测了这个实现过程。老杨同志   1</p>
<p>请教一个问题：如果只需要去重，不需要执行聚合函数，distinct 和group by那种效率高一些呢</p>
<p>？课后习题:</p>
<p>图8，把统计结果存内存临时表，不排序。id是从1到1000，模10的结果顺序就是1、2、3、4、</p>
<p>5。。。图9，老师把tmp_table_size改小了，内存临时表装不下，改用磁盘临时表。根据老师讲的流程</p>
<p>，id取模的结果，排序后存入临时表，临时的数据应该是0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,2,</p>
<p>……</p>
<p>从这个磁盘临时表读取数据汇总的结果的顺序就是0,1,2,3,4,5。。。2019-02-06</p>
<p> 作者回复</p>
<p>新年好</p>
<p>好问题，我加到后面文章中。简单说下结论，只需要去重的话，如果没有limit，是一样的；</p>
<p>有limit的话，distinct 快些。漂亮的回答 </p>
<p>精选留言</p>
<p>2019-02-07</p>
<p>Long   0</p>
<p>老师，新年好！ :-)</p>
<p>有几个版本差异的问题：</p>
<p>（1）图1中的执行计划应该是5.7版本以后的吧，貌似没找到说在哪个环境，我在5.6和5.7分别</p>
<p>测试了，id &#x3D; 2的那个rows，在5.6版本（5.6.26）是1000，在5.7版本是2行。应该是5.7做的优</p>
<p>化吧？（2）图 9 group + order by null 的结果（此盘临时表），这里面mysql5.6里面执行的结果是（1</p>
<p>，10），（2，10）…(10，10)，执行计划都是只有一样，没找到差异。跟踪下了下optimizer trace，发现问题应该是在临时表空间满的的时候，mysql5.7用的是：con</p>
<p>verting_tmp_table_to_ondisk “location”: “disk (InnoDB)”,，而mysql 5.6用的是converting_tmp_t</p>
<p>able_to_myisam “location”: “disk (MyISAM)”的原因导致的。查了下参数：</p>
<p>default_tmp_storage_engine。（5.6，5.7当前值都是innodb）</p>
<p>internal_tmp_disk_storage_engine（只有5.7有这个参数，当前值是innodb），5.6应该是默认磁</p>
<p>盘临时表就是MyISAM引擎的了，由于本地测试环境那个临时表的目录下找不到临时文件，也</p>
<p>没法继续分析了。。。至于为什么MySQL 5.6中结果展示m字段不是0-9而是1-10，还得请老师帮忙解答下了。还有几个小问题，为了方便解答，序号统一了：</p>
<p>（3）在阅读mysql执行计划的时候，看了网上有很多说法，也参考了mysql官网对id（select_id</p>
<p>）的解释：</p>
<p>id (JSON name: select_id)</p>
<p>The SELECT identifier. This is the sequential number of the SELECT within the query.（感觉这</p>
<p>个读起来也有点歧义，这个sequential字面解释感觉只有顺序的号码，并咩有说执行顺序）</p>
<p>比如图1，文中解释就是从ID小的往大的执行的，网上有很多其他说法，有的是说ID从大到小执</p>
<p>行，遇到ID一样的，就从上往下执行。有的说是从小往大顺序执行。不知道老师是否可以官方</p>
<p>讲解下。（4）我发现想搞懂一个原理，并且讲清楚让别人明白，真的是很有难度，非常感谢老师的分享</p>
<p>。这次专栏结束，还会推出的新的专栏吗？ 非常期待。2019-02-10</p>
<p>Laputa   0</p>
<p>老师好，文中说的不需要排序为什么不直接把orderby去掉而是写order by null</p>
<p>2019-02-08</p>
<p> 作者回复</p>
<p>MySQL 语义上这么定义的…</p>
<p>2019-02-08</p>
<p>HuaMax   0</p>
<p>课后题解答。图8是用内存临时表，文中已经提到，是按照表t1的索引a顺序取出数据，模10得0</p>
<p>的id是最后一行；图9是用硬盘临时表，默认用innodb 的索引，主键是id%10，因此存入硬盘后</p>
<p>再按主键树顺序取出，0就排到第一行了。2019-02-07</p>
<p>Li Shunduo   0</p>
<p>请问Group By部分的第一个语句 explain select id%10 as m, count(*) as c from t1 group by m；</p>
<p>为什么选择的是索引a，而不是primary key？如果字段a上有空值，使用索引a岂不是就不能取</p>
<p>到所有的id值了？2019-02-07</p>
<p> 作者回复</p>
<p>因为索引c的信息也足够，而且比主键索引小，使用索引c更会好。“如果字段a上有空值，使用索引a岂不是就不能取到所有的id值了？”，不会的</p>
<p>2019-02-07</p>
<p>牛牛   0</p>
<p>新年快乐～、感谢有您～^_^～</p>
<p>2019-02-06</p>
<p> 作者回复</p>
<p>新年快乐~ </p>
<p>2019-02-07</p>
<p>poppy   0</p>
<p>老师，春节快乐，过年还在更新，辛苦辛苦。关于思考题，我的理解是图8中的查询是使用了内存临时表，存储的顺序就是id%10的值的插入</p>
<p>顺序，而图9中的查询，由于内存临时表大小无法满足，所以使用了磁盘临时表，对于InnoDB</p>
<p>来说，就是对应B+树这种数据结构，这里会按照id%100(即m)的大小顺序来存储的，所以返回</p>
<p>的结果当然也是有序的</p>
<p>2019-02-06</p>
<p> 作者回复</p>
<p>新年好~ </p>
<p> </p>
<p>2019-02-07</p>
<p>张八百   0</p>
<p>春节快乐，老师。谢谢你让我学到不少知识</p>
<p>2019-02-06</p>
<p> 作者回复</p>
<p>新年快乐 </p>
<p>2019-02-06</p>
<p>某、人   0</p>
<p>老师春节快乐，辛苦了</p>
<p>2019-02-06</p>
<p> 作者回复</p>
<p>春节快乐， </p>
<p>2019-02-06</p>
<p>长杰   0</p>
<p>图九使用的是磁盘临时表，磁盘临时表使用的引擎是innodb，innodb是索引组织表，按主键顺</p>
<p>序存储数据，所以是按照m字段有序的。2019-02-06</p>
<p> 作者回复</p>
<p>  </p>
<p>春节快乐</p>
<p>2019-02-06</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/b0b7112a.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/b0b7112a.html" class="post-title-link" itemprop="url">mysql-为什么临时表可以重名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-11 06:18:39" itemprop="dateCreated datePublished" datetime="2019-12-11T06:18:39+08:00">2019-12-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>5.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>19 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>36 | 为什么临时表可以重名？2019-02-04 林晓斌</p>
<p>今天是大年三十，在开始我们今天的学习之前，我要先和你道一声春节快乐！</p>
<p>在上一篇文章中，我们在优化join查询的时候使用到了临时表。当时，我们是这么用的：</p>
<p>你可能会有疑问，为什么要用临时表呢？直接用普通表是不是也可以呢？今天我们就从这个问题说起：临时表有哪些特征，为什么它适合这个场景？这里，我需要先帮你厘清一个容易误解的问题：有的人可能会认为，临时表就是内存表。但是，</p>
<p>这两个概念可是完全不同的。内存表，指的是使用Memory引擎的表，建表语法是create table … engine&#x3D;memory。这种表的</p>
<p>数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去</p>
<p>比较“奇怪”外，从其他的特征上看，它就是一个正常的表。而临时表，可以使用各种引擎类型 。如果是使用InnoDB引擎或者MyISAM引擎的临时表，写</p>
<p>create temporary table temp_t like t1;</p>
<p>alter table temp_t add index(b);</p>
<p>insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000;</p>
<p>select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</p>
<p>数据的时候是写到磁盘上的。当然，临时表也可以使用Memory引擎。弄清楚了内存表和临时表的区别以后，我们再来看看临时表有哪些特征。临时表的特性</p>
<p>为了便于理解，我们来看下下面这个操作序列：</p>
<p>图1 临时表特性示例</p>
<p>可以看到，临时表在使用上有以下几个特点：</p>
<ol>
<li>建表语法是create temporary table …。2. 一个临时表只能被创建它的session访问，对其他线程不可见。所以，图中session A创建的</li>
</ol>
<p>临时表t，对于session B就是不可见的。3. 临时表可以与普通表同名。4. session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的</p>
<p>是临时表。5. show tables命令不显示临时表。由于临时表只能被创建它的session访问，所以在这个session结束的时候，会自动删除临时表。也正是由于这个特性，临时表就特别适合我们文章开头的join优化这种场景。为什么呢？原因主要包括以下两个方面：</p>
<ol>
<li>不同session的临时表是可以重名的，如果有多个session同时执行join优化，不需要担心表</li>
</ol>
<p>名重复导致建表失败的问题。2. 不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或</p>
<p>者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动</p>
<p>回收，所以不需要这个额外的操作。临时表的应用</p>
<p>由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分</p>
<p>表系统的跨库查询就是一个典型的使用场景。一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。比如。将一个大</p>
<p>表ht，按照字段f，拆分成1024个分表，然后分布到32个数据库实例上。如下图所示：</p>
<p>图2 分库分表简图</p>
<p>一般情况下，这种分库分表系统都有一个中间层proxy。不过，也有一些方案会让客户端直接连</p>
<p>接数据库，也就是没有proxy这一层。在这个架构中，分区key的选择是以“减少跨库和跨表查询”为依据的。如果大部分的语句都会包</p>
<p>含f的等值条件，那么就要用f做分区键。这样，在proxy这一层解析完SQL语句以后，就能确定将</p>
<p>这条语句路由到哪个分表做查询。比如下面这条语句：</p>
<p>这时，我们就可以通过分表规则（比如，N%1024)来确认需要的数据被放在了哪个分表上。这</p>
<p>种语句只需要访问一个分表，是分库分表方案最欢迎的语句形式了。但是，如果这个表上还有另外一个索引k，并且查询语句是这样的：</p>
<p>这时候，由于查询条件里面没有用到分区字段f，只能到所有的分区中去查找满足条件的所有</p>
<p>行，然后统一做order by 的操作。这种情况下，有两种比较常用的思路。第一种思路是，在proxy层的进程代码中实现排序。这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。不过，这个方案</p>
<p>的缺点也比较明显：</p>
<ol>
<li>需要的开发工作量比较大。我们举例的这条语句还算是比较简单的，如果涉及到复杂的操</li>
</ol>
<p>作，比如group by，甚至join这样的操作，对中间层的开发能力要求比较高；</p>
<ol start="2">
<li>对proxy端的压力比较大，尤其是很容易出现内存不够用和CPU瓶颈的问题。另一种思路就是，把各个分库拿到的数据，汇总到一个MySQL实例的一个表中，然后在这个汇</li>
</ol>
<p>总实例上做逻辑操作。比如上面这条语句，执行流程可以类似这样：</p>
<p>在汇总库上创建一个临时表temp_ht，表里包含三个字段v、k、t_modified；</p>
<p>在各个分库上执行</p>
<p>select v from ht where f&#x3D;N;</p>
<p>select v from ht where k &gt;&#x3D; M order by t_modified desc limit 100;</p>
<p>select v,k,t_modified from ht_x where k &gt;&#x3D; M order by t_modified desc limit 100;</p>
<p>把分库执行的结果插入到temp_ht表中；</p>
<p>执行</p>
<p>得到结果。这个过程对应的流程图如下所示：</p>
<p>图3 跨库查询流程示意图</p>
<p>在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表temp_ht放</p>
<p>到32个分库中的某一个上。这时的查询逻辑与图3类似，你可以自己再思考一下具体的流程。为什么临时表可以重名？你可能会问，不同线程可以创建同名的临时表，这是怎么做到的呢？接下来，我们就看一下这个问题。我们在执行</p>
<p>select v from temp_ht order by t_modified desc limit 100; </p>
<p>这个语句的时候，MySQL要给这个InnoDB表创建一个frm文件保存表结构定义，还要有地方保</p>
<p>存表数据。这个frm文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程id}<em>{线程id}</em></p>
<p>序列号”。你可以使用select @@tmpdir命令，来显示实例的临时文件目录。而关于表中数据的存放方式，在不同的MySQL版本中有着不同的处理方式：</p>
<p>在5.6以及之前的版本里，MySQL会在临时文件目录下创建一个相同前缀、以.ibd为后缀的文</p>
<p>件，用来存放数据文件；</p>
<p>而从 5.7版本开始，MySQL引入了一个临时文件表空间，专门用来存放临时文件的数据。因</p>
<p>此，我们就不需要再创建ibd文件了。从文件名的前缀规则，我们可以看到，其实创建一个叫作t1的InnoDB临时表，MySQL在存储上</p>
<p>认为我们创建的表名跟普通表t1是不同的，因此同一个库下面已经有普通表t1的情况下，还是可</p>
<p>以再创建一个临时表t1的。为了便于后面讨论，我先来举一个例子。图4 临时表的表名</p>
<p>这个进程的进程号是1234，session A的线程id是4，session B的线程id是5。所以你看到</p>
<p>了，session A和session B创建的临时表，在磁盘上的文件不会重名。MySQL维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都</p>
<p>对应一个table_def_key。一个普通表的table_def_key的值是由“库名+表名”得到的，所以如果你要在同一个库下创建两</p>
<p>个同名的普通表，创建第二个表的过程中就会发现table_def_key已经存在了。而对于临时表，table_def_key在“库名+表名”基础上，又加入了“server_id+thread_id”。create temporary table temp_t(id int primary key)engine&#x3D;innodb;</p>
<p>也就是说，session A和sessionB创建的两个临时表t1，它们的table_def_key不同，磁盘文件名</p>
<p>也不同，因此可以并存。在实现上，每个线程都维护了自己的临时表链表。这样每次session内操作表的时候，先遍历链</p>
<p>表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在</p>
<p>session结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE +表名”操作。这时候你会发现，binlog中也记录了DROP TEMPORARY TABLE这条命令。你一定会觉得奇</p>
<p>怪，临时表只在线程内自己可以访问，为什么需要写到binlog里面？这，就需要说到主备复制了。临时表和主备复制</p>
<p>既然写binlog，就意味着备库需要。你可以设想一下，在主库上执行下面这个语句序列：</p>
<p>如果关于临时表的操作都不记录，那么在备库就只有create table t_normal表和insert into</p>
<p>t_normal select * from temp_t这两个语句的binlog日志，备库在执行到insert into t_normal的时</p>
<p>候，就会报错“表temp_t不存在”。你可能会说，如果把binlog设置为row格式就好了吧？因为binlog是row格式时，在记录insert into</p>
<p>t_normal的binlog时，记录的是这个操作的数据，即：write_row event里面记录的逻辑是“插入一</p>
<p>行数据（1,1)”。确实是这样。如果当前的binlog_format&#x3D;row，那么跟临时表有关的语句，就不会记录到binlog</p>
<p>里。也就是说，只在binlog_format&#x3D;statment&#x2F;mixed 的时候，binlog中才会记录临时表的操作。这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主</p>
<p>库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我</p>
<p>们就需要在主库上再写一个DROP TEMPORARY TABLE传给备库执行。之前有人问过我一个有趣的问题：MySQL在记录binlog的时候，不论是create table还是alter</p>
<p>table语句，都是原样记录，甚至于连空格都不变。但是如果执行drop table t_normal，系统记录</p>
<p>binlog就会写成：</p>
<p>create table t_normal(id int primary key, c int)engine&#x3D;innodb;&#x2F;<em>Q1</em>&#x2F;</p>
<p>create temporary table temp_t like t_normal;&#x2F;<em>Q2</em>&#x2F;</p>
<p>insert into temp_t values(1,1);&#x2F;<em>Q3</em>&#x2F;</p>
<p>insert into t_normal select * from temp_t;&#x2F;<em>Q4</em>&#x2F;</p>
<p>也就是改成了标准的格式。为什么要这么做呢 ？现在你知道原因了，那就是：drop table命令是可以一次删除多个表的。比如，在上面的例子</p>
<p>中，设置binlog_format&#x3D;row，如果主库上执行 “drop table t_normal, temp_t”这个命令，那么</p>
<p>binlog中就只能记录：</p>
<p>因为备库上并没有表temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停</p>
<p>止。所以，drop table命令记录binlog的时候，就必须对语句做改写。“&#x2F;* generated by server *&#x2F;”说明</p>
<p>了这是一个被服务端改写过的命令。说到主备复制，还有另外一个问题需要解决：主库上不同的线程创建同名的临时表是没关系</p>
<p>的，但是传到备库执行是怎么处理的呢？现在，我给你举个例子，下面的序列中实例S是M的备库。图5 主备关系中的临时表操作</p>
<p>主库M上的两个session创建了同名的临时表t1，这两个create temporary table t1 语句都会被传</p>
<p>到备库S上。但是，备库的应用日志线程是共用的，也就是说要在应用线程里面先后执行这个create 语句两</p>
<p>次。（即使开了多线程复制，也可能被分配到从库的同一个worker中执行）。那么，这会不会导</p>
<p>致同步线程报错 ？显然是不会的，否则临时表就是一个bug了。也就是说，备库线程在执行的时候，要把这两个t1</p>
<p>DROP TABLE t̀_normal  ̀&#x2F;* generated by server *&#x2F;</p>
<p>DROP TABLE t̀_normal  ̀&#x2F;* generated by server *&#x2F;</p>
<p>表当做两个不同的临时表来处理。这，又是怎么实现的呢？MySQL在记录binlog的时候，会把主库执行这个语句的线程id写到binlog中。这样，在备库的应</p>
<p>用线程就能够知道执行每个语句的主库线程id，并利用这个线程id来构造临时表的</p>
<p>table_def_key：</p>
<ol>
<li>session A的临时表t1，在备库的table_def_key就是：库名+t1+“M的serverid”+“session A的</li>
</ol>
<p>thread_id”;</p>
<ol start="2">
<li>session B的临时表t1，在备库的table_def_key就是 ：库名+t1+“M的serverid”+“session B的</li>
</ol>
<p>thread_id”。由于table_def_key不同，所以这两个表在备库的应用线程里面是不会冲突的。小结</p>
<p>今天这篇文章，我和你介绍了临时表的用法和特性。在实际应用中，临时表一般用于处理比较复杂的计算逻辑。由于临时表是每个线程自己可见的，</p>
<p>所以不需要考虑多个线程执行同一个处理逻辑时，临时表的重名问题。在线程退出的时候，临时</p>
<p>表也能自动删除，省去了收尾和异常处理的工作。在binlog_format&#x3D;’row’的时候，临时表的操作不记录到binlog中，也省去了不少麻烦，这也可以</p>
<p>成为你选择binlog_format时的一个考虑因素。需要注意的是，我们上面说到的这种临时表，是用户自己创建的 ，也可以称为用户临时表。与</p>
<p>它相对应的，就是内部临时表，在第17篇文章中我已经和你介绍过。最后，我给你留下一个思考题吧。下面的语句序列是创建一个临时表，并将其改名：</p>
<p>图6 关于临时表改名的思考题</p>
<p>可以看到，我们可以使用alter table语法修改临时表的表名，而不能使用rename语法。你知道这</p>
<p>是什么原因吗？你可以把你的分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也</p>
<p>欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期的问题是，对于下面这个三个表的join语句，</p>
<p>如果改写成straight_join，要怎么指定连接顺序，以及怎么给三个表创建索引。第一原则是要尽量使用BKA算法。需要注意的是，使用BKA算法的时候，并不是“先计算两个表</p>
<p>join的结果，再跟第三个表join”，而是直接嵌套查询的。具体实现是：在t1.c&gt;&#x3D;X、t2.c&gt;&#x3D;Y、t3.c&gt;&#x3D;Z这三个条件里，选择一个经过过滤以后，数据最少</p>
<p>的那个表，作为第一个驱动表。此时，可能会出现如下两种情况。第一种情况，如果选出来是表t1或者t3，那剩下的部分就固定了。1. 如果驱动表是t1，则连接顺序是t1-&gt;t2-&gt;t3，要在被驱动表字段创建上索引，也就是t2.a 和</p>
<p>t3.b上创建索引；</p>
<ol start="2">
<li>如果驱动表是t3，则连接顺序是t3-&gt;t2-&gt;t1，需要在t2.b 和 t1.a上创建索引。同时，我们还需要在第一个驱动表的字段c上创建索引。第二种情况是，如果选出来的第一个驱动表是表t2的话，则需要评估另外两个条件的过滤效果。总之，整体的思路就是，尽量让每一次参与join的驱动表的数据集，越小越好，因为这样我们的</li>
</ol>
<p>驱动表就会越小。评论区留言点赞板：</p>
<p>select * from t1 join t2 on(t1.a&#x3D;t2.a) join t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;X and t2.c&gt;&#x3D;Y and t3.c&gt;&#x3D;Z;</p>
<p>@库淘淘 做了实验验证；</p>
<p>@poppy同学做了很不错的分析；</p>
<p>@dzkk 同学在评论中介绍了MariaDB支持的hash join，大家可以了解一下；</p>
<p>@老杨同志提了一个好问题，如果语句使用了索引a，结果还要对a排序，就不用MRR优化</p>
<p>了，否则回表完还要增加额外的排序过程，得不偿失。尘封   1</p>
<p>新年快乐</p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>新年快乐 </p>
<p>2019-02-04</p>
<p>亮   1</p>
<p>老师过年好呀，祝您猪年大吉，财源广进；老师咱们这个课结束后，再开一期好不好啊，没学</p>
<p>够啊，这是我的新年愿望哦</p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>新年快乐，共同进步 </p>
<p>2019-02-04</p>
<p>辣椒   0</p>
<p>老师，不同线程可以使用同名的临时表，这个没有问题。但是如果在程序中，用的是连接池中</p>
<p>的连接来操作的，而这些连接不会释放，和数据库保持长连接。这样使用临时表会有问题吗?。2019-02-07</p>
<p> 作者回复</p>
<p>会，“临时表会自动回收”这个功能，主要用于“应用程序异常断开、MySQL异常重启”后，不需</p>
<p>精选留言</p>
<p>要主动去删除表。而平时正常使用的时候，用完删除，还是应该有的好习惯。 </p>
<p>好问题，新年快乐~</p>
<p>2019-02-07</p>
<p>老杨同志   0</p>
<p>新年快乐，老师好勤奋！</p>
<p>有个问题，insert into select语句好像会给select的表加锁，如果没有索引，就锁全表，是不是</p>
<p>这样？什么时候可以大胆的用这类语句？2019-02-04</p>
<p> 作者回复</p>
<p>新年好！</p>
<p>“insert into select语句好像会给select的表加锁，如果没有索引，就锁全表”，是的。这类最好不要很大胆 ，如果不是业务急需的，从源表导出来再写到目标表也是好的。后面第40篇会说到哈。2019-02-05</p>
<p>慕塔   0</p>
<p>打卡 新年快乐   </p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>新年快乐、共同进步 </p>
<p>好勤奋呀 </p>
<p>2019-02-05</p>
<p>cheriston   0</p>
<p>老师辛苦了，大年三十还给我们分享技术，老师新年好 .</p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>同祝新年好，共同进步 </p>
<p>2019-02-05</p>
<p>长杰   0</p>
<p>老师，新年快乐，万事如意！</p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>新春快乐～</p>
<p>2019-02-05</p>
<p>杰   0</p>
<p>丁大大新春快乐</p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>新年快乐 工作顺利~</p>
<p>2019-02-04</p>
<p>某、人   0</p>
<p>老师，新年快乐。由于自身原因，错过几期精彩的内容，年后上班以后在好好补补。2019-02-04</p>
<p> 作者回复</p>
<p>春节快乐 新年身体健康哈</p>
<p>2019-02-04</p>
<p>poppy   0</p>
<p>老师，新年快乐。关于思考题，alter table temp_t rename to temp_t2,我的理解是mysql直接修改的是table_def_ke</p>
<p>y，而对于rename table temp_t2 to temp_t3,mysql直接去mysql的data目录下该数据库的目录(例</p>
<p>如老师实验用的应该是test数据库，所以对应的是test目录)下寻找名为temp_t2.frm的文件去修</p>
<p>改名称，所以就出现了”Can’t find file ‘.&#x2F;test&#x2F;temp_t2.frm’(errno: 2 - No such file or directory)</p>
<p>2019-02-04</p>
<p> 作者回复</p>
<p>春节快乐</p>
<p> </p>
<p>2019-02-04</p>
<p>亮   0</p>
<p>老师您好，在25课里面的置顶留言“6.表上无主键的情况(主库利用索引更改数据,备库回放只能</p>
<p>用全表扫描,这种情况可以调整slave_rows_search_algorithms参数适当优化下)”</p>
<p>为啥会存在无主键的表呢，就算dba没创建主键，Innodb可以用rowid给自动建一个虚拟主键呀</p>
<p>，这样不就是所有的表都有主键了吗？2019-02-04</p>
<p> 作者回复</p>
<p>用户没有显示指定主键的话，InnoDB引擎会自己创建一个隐藏的主键，但是这个主键对Server</p>
<p>层是透明的，优化器用不上。新年快乐~</p>
<p>2019-02-04</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/6651e679.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/6651e679.html" class="post-title-link" itemprop="url">mysql-join语句怎么优化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-10 06:03:35" itemprop="dateCreated datePublished" datetime="2019-12-10T06:03:35+08:00">2019-12-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>8.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>31 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>35 | join语句怎么优化？2019-02-01 林晓斌</p>
<p>在上一篇文章中，我和你介绍了join语句的两种算法，分别是Index Nested-Loop Join(NLJ)和</p>
<p>Block Nested-Loop Join(BNL)。我们发现在使用NLJ算法的时候，其实效果还是不错的，比通过应用层拆分成多个语句然后再拼</p>
<p>接查询结果更方便，而且性能也不会差。但是，BNL算法在大表join的时候性能就差多了，比较次数等于两个表参与join的行数的乘积，很</p>
<p>消耗CPU资源。当然了，这两个算法都还有继续优化的空间，我们今天就来聊聊这个话题。为了便于分析，我还是创建两个表t1、t2来和你展开今天的问题。为了便于后面量化说明，我在表t1里，插入了1000行数据，每一行的a&#x3D;1001-id的值。也就是</p>
<p>说，表t1中字段a是逆序的。同时，我在表t2中插入了100万行数据。Multi-Range Read优化</p>
<p>在介绍join语句的优化方案之前，我需要先和你介绍一个知识点，即：Multi-Range Read优化</p>
<p>(MRR)。这个优化的主要目的是尽量使用顺序读盘。在第4篇文章中，我和你介绍InnoDB的索引结构时，提到了“回表”的概念。我们先来回顾一下这</p>
<p>个概念。回表是指，InnoDB在普通索引a上查到主键id的值后，再根据一个个主键id的值到主键</p>
<p>索引上去查整行数据的过程。然后，有同学在留言区问到，回表过程是一行行地查数据，还是批量地查数据？我们先来看看这个问题。假设，我执行这个语句：</p>
<p>create table t1(id int primary key, a int, b int, index(a));</p>
<p>create table t2 like t1;</p>
<p>drop procedure idata;</p>
<p>delimiter ;;</p>
<p>create procedure idata()</p>
<p>begin</p>
<p>  declare i int;</p>
<p>  set i&#x3D;1;</p>
<p>  while(i&lt;&#x3D;1000)do</p>
<pre><code>insert into t1 values(i, 1001-i, i);

set i=i+1;
</code></pre>
<p>  end while;</p>
<p>  set i&#x3D;1;</p>
<p>  while(i&lt;&#x3D;1000000)do</p>
<pre><code>insert into t2 values(i, i, i);

set i=i+1;
</code></pre>
<p>  end while;</p>
<p>end;;</p>
<p>delimiter ;</p>
<p>call idata();</p>
<p>主键索引是一棵B+树，在这棵树上，每次只能根据一个主键id查到一行数据。因此，回表肯定是</p>
<p>一行行搜索主键索引的，基本流程如图1所示。图1 基本回表流程</p>
<p>如果随着a的值递增顺序查询的话，id的值就变成随机的，那么就会出现随机访问，性能相对较</p>
<p>差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键</p>
<p>的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。这，就是MRR优化的设计思路。此时，语句的执行流程变成了这样：</p>
<ol>
<li><p>根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;</p>
</li>
<li><p>将read_rnd_buffer中的id进行递增排序；</p>
</li>
<li><p>排序后的id数组，依次到主键id索引中查记录，并作为结果返回。select * from t1 where a&gt;&#x3D;1 and a&lt;&#x3D;100;</p>
</li>
</ol>
<p>这里，read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1</p>
<p>中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找</p>
<p>索引a的下个记录，并继续循环。另外需要说明的是，如果你想要稳定地使用MRR优化的话，需要设置set</p>
<p>optimizer_switch&#x3D;”mrr_cost_based&#x3D;off”。（官方文档的说法，是现在的优化器策略，判断消耗</p>
<p>的时候，会更倾向于不使用MRR，把mrr_cost_based设置为off，就是固定使用MRR了。）</p>
<p>下面两幅图就是使用了MRR优化后的执行流程和explain结果。图2 MRR执行流程</p>
<p>图3 MRR执行流程的explain结果</p>
<p>从图3的explain结果中，我们可以看到Extra字段多了Using MRR，表示的是用上了MRR优化。而且，由于我们在read_rnd_buffer中按照id做了排序，所以最后得到的结果集也是按照主键id递</p>
<p>增顺序的，也就是与图1结果集中行的顺序相反。到这里，我们小结一下。MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这</p>
<p>是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能</p>
<p>体现出“顺序性”的优势。Batched Key Access</p>
<p>理解了MRR性能提升的原理，我们就能理解MySQL在5.6版本后开始引入的Batched Key</p>
<p>Acess(BKA)算法了。这个BKA算法，其实就是对NLJ算法的优化。我们再来看看上一篇文章中用到的NLJ算法的流程图：</p>
<p>图4 Index Nested-Loop Join流程图</p>
<p>NLJ算法执行的逻辑是：从驱动表t1，一行行地取出a的值，再到被驱动表t2去做join。也就是</p>
<p>说，对于表t2来说，每次都是匹配一个值。这时，MRR的优势就用不上了。那怎么才能一次性地多传些值给表t2呢？方法就是，从表t1里一次性地多拿些行出来，一起传给</p>
<p>表t2。既然如此，我们就把表t1的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，</p>
<p>就是join_buffer。通过上一篇文章，我们知道join_buffer 在BNL算法里的作用，是暂存驱动表的数据。但是在NLJ</p>
<p>算法里并没有用。那么，我们刚好就可以复用join_buffer到BKA算法中。如图5所示，是上面的NLJ算法优化后的BKA算法的流程。图5 Batched Key Acess流程</p>
<p>图中，我在join_buffer中放入的数据是P1~P100，表示的是只会取查询需要的字段。当然，如果</p>
<p>join buffer放不下P1~P100的所有数据，就会把这100行数据分成多段执行上图的流程。那么，这个BKA算法到底要怎么启用呢？如果要使用BKA优化算法的话，你需要在执行SQL语句之前，先设置</p>
<p>其中，前两个参数的作用是要启用MRR。这么做的原因是，BKA算法的优化要依赖于MRR。set optimizer_switch&#x3D;’mrr&#x3D;on,mrr_cost_based&#x3D;off,batched_key_access&#x3D;on’;</p>
<p>BNL算法的性能问题</p>
<p>说完了NLJ算法的优化，我们再来看BNL算法的优化。我在上一篇文章末尾，给你留下的思考题是，使用Block Nested-Loop Join(BNL)算法时，可能会</p>
<p>对被驱动表做多次扫描。如果这个被驱动表是一个大的冷数据表，除了会导致IO压力大以外，还</p>
<p>会对系统有什么影响呢？在第33篇文章中，我们说到InnoDB的LRU算法的时候提到，由于InnoDB对Bufffer Pool的LRU</p>
<p>算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。如果1秒之后这个数据</p>
<p>页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。但是，如果一个使用BNL算法的join语句，多次扫描一个冷表，而且这个语句执行时间超过1秒，</p>
<p>就会在再次扫描冷表的时候，把冷表的数据页移到LRU链表头部。这种情况对应的，是冷表的数据量小于整个Buffer Pool的3&#x2F;8，能够完全放入old区域的情况。如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入young区</p>
<p>域。由于优化机制的存在，一个正常访问的数据页，要进入young区域，需要隔1秒后再次被访问</p>
<p>到。但是，由于我们的join语句在循环读磁盘和淘汰内存页，进入old区域的数据页，很可能在1</p>
<p>秒之内就被淘汰了。这样，就会导致这个MySQL实例的Buffer Pool在这段时间内，young区域的</p>
<p>数据页没有被合理地淘汰。也就是说，这两种情况都会影响Buffer Pool的正常运作。大表join操作虽然对IO有影响，但是在语句执行结束后，对IO的影响也就结束了。但是，</p>
<p>对Buffer Pool的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。为了减少这种影响，你可以考虑增大join_buffer_size的值，减少对被驱动表的扫描次数。也就是说，BNL算法对系统的影响主要包括三个方面：</p>
<ol>
<li><p>可能会多次扫描被驱动表，占用磁盘IO资源；</p>
</li>
<li><p>判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常</p>
</li>
</ol>
<p>多的CPU资源；</p>
<ol start="3">
<li>可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。我们执行语句之前，需要通过理论分析和查看explain结果的方式，确认是否要使用BNL算法。如</li>
</ol>
<p>果确认优化器会使用BNL算法，就需要做优化。优化的常见做法是，给被驱动表的join字段加上</p>
<p>索引，把BNL算法转成BKA算法。接下来，我们就具体看看，这个优化怎么做？BNL转BKA</p>
<p>一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成BKA算法了。但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。比如下面这个语句：</p>
<p>我们在文章开始的时候，在表t2中插入了100万行数据，但是经过where条件过滤后，需要参与</p>
<p>join的只有2000行数据。如果这条语句同时是一个低频的SQL语句，那么再为这个语句在表t2的</p>
<p>字段b上创建一个索引就很浪费了。但是，如果使用BNL算法来join的话，这个语句的执行流程是这样的：</p>
<ol>
<li>把表t1的所有字段取出来，存入join_buffer中。这个表只有1000行，join_buffer_size默认值</li>
</ol>
<p>是256k，可以完全存入。2. 扫描表t2，取出每一行数据跟join_buffer中的数据进行对比，</p>
<p>如果不满足t1.b&#x3D;t2.b，则跳过；</p>
<p>如果满足t1.b&#x3D;t2.b, 再判断其他条件，也就是是否满足t2.b处于[1,2000]的条件，如果</p>
<p>是，就作为结果集的一部分返回，否则跳过。我在上一篇文章中说过，对于表t2的每一行，判断join是否满足的时候，都需要遍历join_buffer中</p>
<p>的所有行。因此判断等值条件的次数是1000*100万&#x3D;10亿次，这个判断的工作量很大。图6 explain结果</p>
<p>图7 语句执行时间</p>
<p>可以看到，explain结果里Extra字段显示使用了BNL算法。在我的测试环境里，这条语句需要执</p>
<p>select * from t1 join t2 on (t1.b&#x3D;t2.b) where t2.b&gt;&#x3D;1 and t2.b&lt;&#x3D;2000;</p>
<p>行1分11秒。在表t2的字段b上创建索引会浪费资源，但是不创建索引的话这个语句的等值条件要判断10亿</p>
<p>次，想想也是浪费。那么，有没有两全其美的办法呢？这时候，我们可以考虑使用临时表。使用临时表的大致思路是：</p>
<ol>
<li><p>把表t2中满足条件的数据放在临时表tmp_t中；</p>
</li>
<li><p>为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；</p>
</li>
<li><p>让表t1和tmp_t做join操作。此时，对应的SQL语句的写法如下：</p>
</li>
</ol>
<p>图8就是这个语句序列的执行效果。图8 使用临时表的执行效果</p>
<p>可以看到，整个过程3个语句执行时间的总和还不到1秒，相比于前面的1分11秒，性能得到了大</p>
<p>幅提升。接下来，我们一起看一下这个过程的消耗：</p>
<ol>
<li>执行insert语句构造temp_t表并插入数据的过程中，对表t2做了全表扫描，这里扫描行数是</li>
</ol>
<p>100万。create temporary table temp_t(id int primary key, a int, b int, index(b))engine&#x3D;innodb;</p>
<p>insert into temp_t select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000;</p>
<p>select * from t1 join temp_t on (t1.b&#x3D;temp_t.b);</p>
<ol start="2">
<li>之后的join语句，扫描表t1，这里的扫描行数是1000；join比较过程中，做了1000次带索引</li>
</ol>
<p>的查询。相比于优化前的join语句需要做10亿次条件判断来说，这个优化效果还是很明显</p>
<p>的。总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让join语句能够用</p>
<p>上被驱动表上的索引，来触发BKA算法，提升查询性能。扩展-hash join</p>
<p>看到这里你可能发现了，其实上面计算10亿次那个操作，看上去有点儿傻。如果join_buffer里面</p>
<p>维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，而是100万次hash查</p>
<p>找。这样的话，整条语句的执行速度就快多了吧？确实如此。这，也正是MySQL的优化器和执行器一直被诟病的一个原因：不支持哈希join。并且，MySQL官</p>
<p>方的roadmap，也是迟迟没有把这个优化排上议程。实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：</p>
<ol>
<li>select * from t1;取得表t1的全部1000行数据，在业务端存入一个hash结构，比如C++里的</li>
</ol>
<p>set、PHP的dict这样的数据结构。2. select * from t2 where b&gt;&#x3D;1 and b&lt;&#x3D;2000; 获取表t2中满足条件的2000行数据。3. 把这2000行数据，一行一行地取到业务端，到hash结构的数据表中寻找匹配的数据。满足</p>
<p>匹配的条件的这行数据，就作为结果集的一行。理论上，这个过程会比临时表方案的执行速度还要快一些。如果你感兴趣的话，可以自己验证一</p>
<p>下。小结</p>
<p>今天，我和你分享了Index Nested-Loop Join（NLJ）和Block Nested-Loop Join（BNL）的优化</p>
<p>方法。在这些优化方法中：</p>
<ol>
<li><p>BKA优化是MySQL已经内置支持的，建议你默认使用；</p>
</li>
<li><p>BNL算法效率低，建议你都尽量转成BKA算法。优化的方向就是给被驱动表的关联字段加上</p>
</li>
</ol>
<p>索引；</p>
<ol start="3">
<li><p>基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的；</p>
</li>
<li><p>MySQL目前的版本还不支持hash join，但你可以配合应用端自己模拟出来，理论上效果要好</p>
</li>
</ol>
<p>于临时表的方案。最后，我给你留下一道思考题吧。我们在讲join语句的这两篇文章中，都只涉及到了两个表的join。那么，现在有一个三个表join的</p>
<p>需求，假设这三个表的表结构如下：</p>
<p>语句的需求实现如下的join逻辑：</p>
<p>现在为了得到最快的执行速度，如果让你来设计表t1、t2、t3上的索引，来支持这个join语句，</p>
<p>你会加哪些索引呢？同时，如果我希望你用straight_join来重写这个语句，配合你创建的索引，你就需要安排连接顺</p>
<p>序，你主要考虑的因素是什么呢？你可以把你的方案和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收</p>
<p>听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我在上篇文章最后留给你的问题，已经在本篇文章中解答了。这里我再根据评论区留言的情况，简单总结下。根据数据量的大小，有这么两种情况：</p>
<p>@长杰 和 @老杨同志 提到了数据量小于old区域内存的情况；</p>
<p>CREATE TABLE t̀1  ̀(</p>
<p> ìd  ̀int(11) NOT NULL,</p>
<p> &#96;a  ̀int(11) DEFAULT NULL,</p>
<p> &#96;b  ̀int(11) DEFAULT NULL,</p>
<p> &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>create table t2 like t1;</p>
<p>create table t3 like t2;</p>
<p>insert into … &#x2F;&#x2F;初始化三张表的数据</p>
<p>select * from t1 join t2 on(t1.a&#x3D;t2.a) join t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;X and t2.c&gt;&#x3D;Y and t3.c&gt;&#x3D;Z;</p>
<p>@Zzz 同学，很认真地看了其他同学的评论，并且提了一个很深的问题。对被驱动表数据量</p>
<p>大于Buffer Pool的场景，做了很细致的推演和分析。给这些同学点赞，非常好的思考和讨论。郭健   2</p>
<p>老师，有几个问题还需要请教一下:</p>
<p>1.上一章t1表100条数据，t21000条数据，mysql会每次都会准确的找出哪张表是合理的驱动表</p>
<p>吗？还是需要人为的添加straight_join。2.像left join这种，左边一定是驱动表吧？以左边为标准查看右边有符合的条件，拼成一条数据</p>
<p>，看到你给其他同学的评论说可能不是，这有些疑惑。3.在做join的时候，有些条件是可以放在on中也可以放在where中，比如(t1.yn&#x3D;1 和t2.yn&#x3D;1)这种</p>
<p>简单判断是否删除的。最主要的是，需要根据两个条件才能join的(productCode和custCode),需</p>
<p>要两个都在on里，还是一个在on中，一个在where中更好呢？2019-02-07</p>
<p> 作者回复</p>
<ol>
<li><p>正常是会自己找到合理的，但是用前explain是好习惯哈</p>
</li>
<li><p>这个问题的展开我放到答疑文章中哈</p>
</li>
<li><p>这也是好问题，需要分析是使用哪种算法，也放到答疑文章展开哈。精选留言</p>
</li>
</ol>
<p>新年快乐~</p>
<p>2019-02-07</p>
<p>Geek_02538c   1</p>
<p>过年了，还有新文章，给个赞。 另，where 和 order 与索引的关系，都讲过了，group by 是否</p>
<p>也搞个篇章说一下。2019-02-02</p>
<p> 作者回复</p>
<p>你说得对^_^ 第37篇就是，新年快乐</p>
<p>2019-02-03</p>
<p>Ryoma   1</p>
<p>read_rnd_buffer_length 参数应该是 read_rnd_buffer_size，见文档：<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/">https://dev.mysql.com/doc/</a></p>
<p>refman&#x2F;8.0&#x2F;en&#x2F;server-system-variables.html#sysvar_read_rnd_buffer_size</p>
<p>2019-02-02</p>
<p> 作者回复</p>
<p>你说得对，多谢</p>
<p>发起勘误了</p>
<p>新年快乐</p>
<p>2019-02-03</p>
<p>Mr.Strive.Z.H.L   1</p>
<p>老师您好，新年快乐~~</p>
<p>关于三表join有一个疑惑点需要确认：</p>
<p>老师您在评论中说到，三表join不会是前两个表join后得到结果集，再和第三张表join。针对这句话，我的理解是：</p>
<p>假设我们不考虑BKA，就按照一行行数据来判断的话，流程应该如下（我会将server端和innod</p>
<p>b端分的很清楚）：</p>
<p>表是t1 ,t2 ,t3。 t1 straight_join t2 straight_join t3，这样的join顺序。1. 调用innodb接口，从t1中取一行数据，数据返回到server端。2. 调用innodb接口，从t2中取满足条件的数据，数据返回到server端。3. 调用innodb接口，从t3中取满足条件的数据，数据返回到server端。上面三步之后，驱动表 t1的一条数据就处理完了，接下来重复上述过程。（如果采用BKA进行优化，可以理解为不是一行行数据的提取，而是一个范围内数据的提取）</p>
<p>。按照我上面的描述，确实没有前两表先join得结果集，然后再join第三张表的过程。不知道我上面的描述的流程对不对？（我个人觉得，将innodb的处理和server端的处理分隔清</p>
<p>晰，对于sql语句的理解，会透彻很多）</p>
<p>2019-02-02</p>
<p> 作者回复</p>
<p>新年快乐，分析得很好。可以再补充一句，会更好理解你说的这个过程 ：</p>
<p>如果采用BKA进行优化,每多一个join，就多一个join_buffer</p>
<p>2019-02-02</p>
<p>LY   1</p>
<p>order by cjsj desc limit 0,20 explain Extra只是显示 Using where ，执行时间 7秒钟</p>
<p>order by cjsj desc limit 5000,20 explain Extra只是显示 Using index condition; Using where; Usin</p>
<p>g filesort, 执行时间 0.1 秒</p>
<p>有些许的凌乱了@^^@</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p>这正常的，一种可能是这样的： </p>
<p>Using where 就是顺序扫，但是这个上要扫很久才能扫到满足条件的20个记录；</p>
<p>虽然有filesort，但是如果参与排序的行数少，可能速度就更快，而且limit 有堆排序优化哦</p>
<p>2019-02-01</p>
<p>郭健   0</p>
<p>老师，新年快乐！！看到您给我提问的回答，特别期待您之后的答疑，因为dba怕我们查询数</p>
<p>据库时连接时间过长，影响线上实际运行。所以就开发出一个网页，让我们进行查询，但是超</p>
<p>过几秒(具体不知道，查询一个200w的数据，条件没有加索引有时候都会)就会返回time out，所</p>
<p>以当查询大表并join的时候，就会很吃力！想法设法的缩小单位，一般我们都不会为createTime</p>
<p>建一个索引，所以在根据时间缩小范围的时候有时候也并不是很好的选择。我们线上做统计sql</p>
<p>的时候，因为数据量比较大，筛选条件也比较多，一个sql可能在0.4s多，这已经是属于慢sql了</p>
<p>。感谢老师对我提问的回答！！</p>
<p>2019-02-09</p>
<p>磊   0</p>
<p>一直对多表的join有些迷惑，希望老师后面专门把这块给讲的透彻些</p>
<p>2019-02-03</p>
<p> 作者回复</p>
<p>这一期45篇 join差不多就讲这些了 </p>
<p>有问题在评论区提出来哈</p>
<p>2019-02-03</p>
<p>bluefantasy3   0</p>
<p>请教老师一个问题：innodb的Buffer Pool的内存是innodb自己管理还是使用OS的page cache? </p>
<p>我理解应该是innodb自己管理。我在另一个课程里看到如果频繁地把OS的&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_c</p>
<p>aches 改成 1会影响MySQL的性能，如果buffer pool是MySQL自己管理，应该不受这个参数影</p>
<p>响呀？请解答。2019-02-02</p>
<p> 作者回复</p>
<ol>
<li><p>是MySQL 自己管理的</p>
</li>
<li><p>一般只有数据文件是o_direct的，redo log 和 binlog 都是有用到文件系统的page cache, 因此</p>
</li>
</ol>
<p>多少有影响的</p>
<p>好问题  </p>
<p>2019-02-03</p>
<p>信信   0</p>
<p>老师好，有两点疑问请老师解惑：</p>
<p>1、图8上面提到的关于临时表的第三句是不是还是使用straight_join好一些？不然有可能temp_t</p>
<p>被选为驱动表？2、图8下面提到join过程中做了1000次带索引的查询，这里的1000也是在打开mrr的情况下的吗</p>
<p>？是进行了1000次树搜索，还是找到第一个后，依次挨着读呢？2019-02-02</p>
<p> 作者回复</p>
<ol>
<li><p>写straight_join能确定顺序，也可以的，这里写join 也ok的</p>
</li>
<li><p>是进行了1000次树搜索</p>
</li>
</ol>
<p>2019-02-02</p>
<p>HuaMax   0</p>
<p>前提假设：t1.c&gt;&#x3D;X可以让t1成为小表。同时打开BKA和MRR。1、t1表加（c,a)索引。理由：A、t1.c&gt;&#x3D;X可以使用索引；B、加上a的联合索引，join buffer里放</p>
<p>入的是索引（c,a）而不是去主键表取整行，用于与表t2的t1.a &#x3D; t2.a的join查询，不过返回SELE</p>
<p>CT * 最终还是需要回表。2、t2表加(a,b,c)索引。理由：A、加上a避免与t1表join查询的BNL；B、理由同【1-B】；C、加</p>
<p>上c不用回表判断t2.c&gt;&#x3D;Y的筛选条件</p>
<p>3、t3表加（b,c）索引。理由：A、避免与t2表join查询的BNL;C、理由同【2-C】</p>
<p>问题：</p>
<p>1、【1-B】和【2-B】由于select *要返回所有列数据，不敢肯定join buffer里是回表的整行数据</p>
<p>还是索引（c,a)的数据，需要老师解答一下；不过值得警惕的是，返回的数据列对sql的执行策</p>
<p>略有非常大的影响。2、在有join查询时，被驱动表是先做join连接查询，还是先筛选数据再从筛选后的临时表做join</p>
<p>连接？这将影响上述的理由【2-C】和【3-C】</p>
<p>使用straight_join强制指定驱动表，我会改写成这样:select * from t2 STRAIGHT_JOIN t1 on(t1.</p>
<p>a&#x3D;t2.a) STRAIGHT_JOIN t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;X and t2.c&gt;&#x3D;Y and t3.c&gt;&#x3D;Z;</p>
<p>考虑因素包括：</p>
<p>1、驱动表使用过滤条件筛选后的数据量，使其成为小表，上面的改写也是基于t2是小表</p>
<p>2、因为t2是跟t1,t3都有关联查询的，这样的话我猜测对t1,t3的查询是不是可以并行执行，而如</p>
<p>果使用t1,t3作为主表的话，是否会先跟t2生成中间表，是个串行的过程？3、需要给t1加（a,c)索引，给t2加（c,a,b）索引。2019-02-02</p>
<p> 作者回复</p>
<p>  很深入的思考哈</p>
<ol>
<li><p>select * ，所以放整行；你说得对，select * 不是好习惯；</p>
</li>
<li><p>第一次join后就筛选；第二次join再筛选；</p>
</li>
</ol>
<p>新春快乐~</p>
<p>2019-02-04</p>
<p>库淘淘   0</p>
<p>set optimizer_switch&#x3D;’mrr&#x3D;on,mrr_cost_based&#x3D;off,batched_key_access&#x3D;on’;</p>
<p>create index idx_c on t2(c);</p>
<p>create index idx_a_c on t1(a,c);</p>
<p>create index idx_b_c on t3(b,c);</p>
<p>mysql&gt; explain select * from t2 </p>
<p>-&gt; straight_join t1 on(t1.a&#x3D;t2.a)</p>
<p>-&gt; straight_join t3 on(t2.b&#x3D;t3.b) </p>
<p>-&gt; where t1.c&gt; 800 and t2.c&gt;&#x3D;600 and t3.c&gt;&#x3D;500;</p>
<p>+—-+————-+——-+————+—————————————</p>
<p>| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | </p>
<p>Extra +—————————————-</p>
<p>| 1 | SIMPLE | t2 | NULL | range | idx_c | idx_c | 5 | NULL | 401 | 100.00 | Using index condition</p>
<p>; Using where; Using MRR |</p>
<p>| 1 | SIMPLE | t1 | NULL | ref | idx_a_c | idx_a_c | 5 | test.t2.a | 1 | 33.33 | Using index conditio</p>
<p>n; Using join buffer (Batched Key Access) |</p>
<p>| 1 | SIMPLE | t3 | NULL | ref | idx_b_c | idx_b_c | 5 | test.t2.b | 1 | 33.33 | Using index conditio</p>
<p>n; Using join buffer (Batched Key Access) |</p>
<p>+—-+————-+——-+————+—–+—————————————</p>
<p>3 rows in set, 1 warning (0.00 sec)</p>
<p>以自己理解如下，有问题请老师能够指出</p>
<p>1.根据查询因是select * 肯定回表的，其中在表t2创建索引idx_c,为了能够使用ICP,MRR，如果c</p>
<p>字段重复率高或取值行数多，可以考虑不建索引</p>
<p>2.已t2 作为驱动表，一方面考虑其他两表都有关联,t2表放入join buffer后关联t1后，再关联t2 得</p>
<p>出结果 再各回t2,t3表取出 得到结果集（之前理解都是t1和t2join得结果集再与t3join，本次理解</p>
<p>太确定）</p>
<p>3.t2、t3表建立联合查询目的能够使用ICP</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p> </p>
<p>BKA是从Index Nexted-Loop join 优化而来的，并不是“t1和t2join得结果集再与t3join”，而是直接</p>
<p>嵌套循环执行下去。这个效果相当不错了，MRR，BKA都用上</p>
<p>2019-02-02</p>
<p>LY   0</p>
<p>刚刚凌乱了的那个问题，经explain验证，explain SELECT a.* FROM sys_xxtx a JOIN baq_ryxx</p>
<p>r ON a.ryid &#x3D; r.ID WHERE a.dwbh &#x3D; ‘7E0A13A14101D0A8E0430A0F23BCD0A8’ ORDER BY tx</p>
<p>sj DESC LIMIT 0,20;</p>
<p>使用的索引是txsj ；</p>
<p>explain SELECT a.* FROM sys_xxtx a JOIN baq_ryxx r ON a.ryid &#x3D; r.ID WHERE a.dwbh &#x3D; ‘7E0</p>
<p>A13A14101D0A8E0430A0F23BCD0A8’ ORDER BY txsj DESC LIMIT 5000,20;使用的索引是dw</p>
<p>bh ；</p>
<p>然后回忆起了第10张：MySQL为什么有时候会选错索引？但是从扫描行数、是否使用排序等来看在 LIMIT 5000,20时候也应该优选txsj ?可是这个时候选</p>
<p>择的索引是dwbh, 查询时间也大大缩短</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p>嗯，这个跟我们第十篇那个例子挺像的</p>
<p>我们把limit 1 改成limit 100的时候，MySQL认为，要扫描到“100行那么多”，</p>
<p>你这里是limit 5000，200， 这个5000会让优化器认为，选txsj会要扫“很多行，可能很久”</p>
<p>这个确实是优化器还不够完善的地方，有时候不得不用force index~</p>
<p>2019-02-02</p>
<p>dzkk   0</p>
<p>老师，对于关联查询（inner join），个人有几点理解，请帮助审核是否正确，谢了。正确选择：</p>
<p>结果集小的为驱动表，且被驱动表有索引</p>
<p>未知效果选择：</p>
<p>1）结果集小的为驱动表，但是被驱动表没有索引</p>
<p>2）结果集大的为驱动表，但是被驱动表有索引</p>
<p>最差选择：</p>
<p>结果集大的为驱动表，且被驱动表没有索引</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p>未知效果选择 是啥意思^_^</p>
<p>2019-02-02</p>
<p>老杨同志   0</p>
<p>我准备给</p>
<p>t1增加索引c</p>
<p>t2增加组合索引b,c</p>
<p>t3增加组合索引b,c</p>
<p>select * from t1 straight_join t2 on(t1.a&#x3D;t2.a) straight_join t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;X and t2</p>
<p>.c&gt;&#x3D;Y and t3.c&gt;&#x3D;Z;</p>
<p>另外我还有个问题，开篇提到的这句sql select * from t1 where a&gt;&#x3D;1 and a&lt;&#x3D;100;</p>
<p>a是索引列，如果这句索引有order by a，不使用MRR 优化，查询出来就是按a排序的，使用了</p>
<p>mrr优化，是不是要额外排序</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p>对，好问题，用了order by就不用MRR了</p>
<p>2019-02-02</p>
<p>poppy   0</p>
<p>select * from t1 join t2 on(t1.a&#x3D;t2.a) join t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;X and t2.c&gt;&#x3D;Y and t3.c&gt;&#x3D;</p>
<p>Z;</p>
<p>老师，我的理解是真正做join的三张表的大小实际上是t1.c&gt;&#x3D;X、t2.c&gt;&#x3D;Y、t3.c&gt;&#x3D;Z对应满足条</p>
<p>件的行数，为了方便快速定位到满足条件的数据，t1、t2和t3的c字段最好都建索引。对于join操</p>
<p>作，按道理mysql应该会优先选择join之后数量比较少的两张表先来进行join操作，例如满足t1.a</p>
<p>&#x3D;t2.a的行数小于满足t2.b&#x3D;t3.b的行数，那么就会优先将t1和t2进行join，选择t1.c&gt;&#x3D;X、t2.c&gt;&#x3D;Y</p>
<p>中行数少的表作为驱动表，另外一张作为被驱动表，在被驱动表的a的字段上建立索引，这样就</p>
<p>完成了t1和t2的join操作并把结果放入join_buffer准备与t3进行join操作，则在作为被驱动表的t3</p>
<p>的b字段上建立索引。不知道举的这个例子分析得是否正确，主要是这里不知道t1、t2、t3三张</p>
<p>表的数据量，以及满足t1.c&gt;&#x3D;X ，t2.c&gt;&#x3D;Y ，t3.c&gt;&#x3D;Z的数据量，还有各个字段的区分度如何，</p>
<p>是否适合建立索引等。2019-02-01</p>
<p> 作者回复</p>
<p>嗯 这个问题就是留给大家自己设定条件然后分析的，分析得不错哦</p>
<p>2019-02-02</p>
<p>Destroy、   0</p>
<p>BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给驱动表的关联字段加上索</p>
<p>引；</p>
<p>老师最后总结的时候，这句话后面那句，应该是给被驱动表的关联字段加上索引吧。2019-02-01</p>
<p> 作者回复</p>
<p>对的， 细致</p>
<p>已经发起勘误，谢谢你哦，新年快乐</p>
<p>2019-02-01</p>
<p>LY   0</p>
<p>LY  0</p>
<p>YEAR(txsj) &#x3D; ‘2018’ 有结果集，YEAR(txsj) &#x3D; ‘2019’ 无结果集，</p>
<p>YEAR(txsj) &#x3D; ‘2018’ 和 YEAR(txsj) &#x3D; ‘2019’ 查询所需时间 后者是前者的10倍</p>
<p>请老师分析下大概什么原因？2019-02-01</p>
<p> 作者回复</p>
<p>这个信息太不足了 </p>
<p>我第一时间反应是不是有limit？你给贴一下表结构，</p>
<p>sql语句，还有explain这个语句的结果 ，我们再来分析下哈</p>
<p>2019-02-01</p>
<p>John   0</p>
<p>期待這一篇很久啦 終於出來啦 臨時表和範圍搜索實在是醍醐灌頂 謝謝老師</p>
<p>2019-02-01</p>
<p>永恒记忆   0</p>
<p>老师，记得之前看目录之后要将一篇标题大概为“我的mysql为啥莫名其妙重启了”，最近看怎么</p>
<p>没有了？我们确实遇到这种问题，在系统日志里也找不到OOM信息，现象是半个月左右就会自</p>
<p>动重启一下，时间不固定，想请教下是什么问题呢？2019-02-01</p>
<p> 作者回复</p>
<p>贴一下errorlog里面看看有没有异常信息 如果比较大的文件可以发我微博私信附件</p>
<p>写文章的过程中根据大家的评论问题，发现有些知识点应该优先写，目录有做调整哈</p>
<p>2019-02-01</p>
<p>郭江伟   0</p>
<p>select * from t1 join t2 on(t1.a&#x3D;t2.a) join t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;X and t2.c&gt;&#x3D;Y and t3.c&gt;&#x3D;</p>
<p>Z;</p>
<p>这个语句建索引需要考虑三个表的数据量和相关字段的数据分布、选择率、每个条件返回行数</p>
<p>占比等</p>
<p>我的测试场景是：</p>
<p>t1 1000行数据 t2 100w行数据 t3 100w行，关联字段没有重复值，条件查询返回行数占比很少，</p>
<p>此时索引为： </p>
<p>alter table t1 add key t1_c(c);</p>
<p>alter table t2 add key t2_ac(a,c);</p>
<p>alter table t3 add key t3_bc(b,c);</p>
<p>测试sql无索引是执行需要2分钟多，加了索引后需要0.01秒，加索引后执行计划为：</p>
<p>mysql&gt; explain select * from t1 join t2 on(t1.a&#x3D;t2.a) join t3 on (t2.b&#x3D;t3.b) where t1.c&gt;&#x3D;100 and t</p>
<p>2.c&gt;&#x3D;10 and t3.c&gt;&#x3D;90;</p>
<p>+—-+————-+——-+————+——+—————+——-+———+—————+——+———-</p>
<p>+————————————+</p>
<p>| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | </p>
<p>Extra |</p>
<p>+—-+————-+——-+————+——+—————+——-+———+—————+——+———-</p>
<p>+————————————+</p>
<p>| 1 | SIMPLE | t1 | NULL | ALL | t1_a | NULL | NULL | NULL | 1000 | 90.10 | Using where |</p>
<p>| 1 | SIMPLE | t2 | NULL | ref | t2_ac | t2_ac | 5 | sysbench.t1.a | 1 | 33.33 | Using index conditi</p>
<p>on; Using where |</p>
<p>| 1 | SIMPLE | t3 | NULL | ref | t3_bc | t3_bc | 5 | sysbench.t2.b | 1 | 33.33 | Using index conditi</p>
<p>on |</p>
<p>+—-+————-+——-+————+——+—————+——-+———+—————+——+———-</p>
<p>+————————————+</p>
<p>另外，select * 如果改成具体字段的话考虑覆盖索引 可能需要建立不同的索引。2019-02-01</p>
<p> 作者回复</p>
<p> 验证的结果最有说服力</p>
<p>2019-02-01</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/db4372f3.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/db4372f3.html" class="post-title-link" itemprop="url">mysql-到底可不可以使用join</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-09 06:12:07" itemprop="dateCreated datePublished" datetime="2019-12-09T06:12:07+08:00">2019-12-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>6.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>25 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>34 | 到底可不可以使用join？2019-01-30 林晓斌</p>
<p>在实际生产中，关于join语句使用的问题，一般会集中在以下两类：</p>
<ol>
<li>我们DBA不让使用join，使用join有什么问题呢？2. 如果有两个大小不同的表做join，应该用哪个表做驱动表呢？今天这篇文章，我就先跟你说说join语句到底是怎么执行的，然后再来回答这两个问题。为了便于量化分析，我还是创建两个表t1和t2来和你说明。可以看到，这两个表都有一个主键索引id和一个索引a，字段b上无索引。存储过程idata()往表t2</li>
</ol>
<p>里插入了1000行数据，在表t1里插入的是100行数据。Index Nested-Loop Join</p>
<p>我们来看一下这个语句：</p>
<p>如果直接使用join语句，MySQL优化器可能会选择表t1或t2作为驱动表，这样会影响我们分析</p>
<p>SQL语句的执行过程。所以，为了便于分析执行过程中的性能问题，我改用straight_join让</p>
<p>MySQL使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去join。在这个语句</p>
<p>CREATE TABLE t̀2  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;a  ̀int(11) DEFAULT NULL,</p>
<p>  &#96;b  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  KEY &#96;a  ̀(̀ a )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>drop procedure idata;</p>
<p>delimiter ;;</p>
<p>create procedure idata()</p>
<p>begin</p>
<p>  declare i int;</p>
<p>  set i&#x3D;1;</p>
<p>  while(i&lt;&#x3D;1000)do</p>
<pre><code>insert into t2 values(i, i, i);

set i=i+1;
</code></pre>
<p>  end while;</p>
<p>end;;</p>
<p>delimiter ;</p>
<p>call idata();</p>
<p>create table t1 like t2;</p>
<p>insert into t1 (select * from t2 where id&lt;&#x3D;100)</p>
<p>select * from t1 straight_join t2 on (t1.a&#x3D;t2.a);</p>
<p>里，t1 是驱动表，t2是被驱动表。现在，我们来看一下这条语句的explain结果。图1 使用索引字段join的 explain结果</p>
<p>可以看到，在这条语句里，被驱动表t2的字段a上有索引，join过程用上了这个索引，因此这个语</p>
<p>句的执行流程是这样的：</p>
<ol>
<li><p>从表t1中读入一行数据 R；</p>
</li>
<li><p>从数据行R中，取出a字段到表t2里去查找；</p>
</li>
<li><p>取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；</p>
</li>
<li><p>重复执行步骤1到3，直到表t1的末尾循环结束。这个过程是先遍历表t1，然后根据从表t1中取出的每行数据中的a值，去表t2中查找满足条件的</p>
</li>
</ol>
<p>记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，</p>
<p>所以我们称之为“Index Nested-Loop Join”，简称NLJ。它对应的流程图如下所示：</p>
<p>图2 Index Nested-Loop Join算法的执行流程</p>
<p>在这个流程里：</p>
<ol>
<li><p>对驱动表t1做了全表扫描，这个过程需要扫描100行；</p>
</li>
<li><p>而对于每一行R，根据a字段去表t2查找，走的是树搜索过程。由于我们构造的数据都是一一</p>
</li>
</ol>
<p>对应的，因此每次的搜索过程都只扫描一行，也是总共扫描100行；</p>
<ol start="3">
<li>所以，整个执行流程，总扫描行数是200。现在我们知道了这个过程，再试着回答一下文章开头的两个问题。先看第一个问题：能不能使用join?</li>
</ol>
<p>假设不使用join，那我们就只能用单表查询。我们看看上面这条语句的需求，用单表查询怎么实</p>
<p>现。1. 执行select * from t1，查出表t1的所有数据，这里有100行；</p>
<ol start="2">
<li>循环遍历这100行数据：</li>
</ol>
<p>从每一行R取出字段a的值$R.a；</p>
<p>执行select * from t2 where a&#x3D;$R.a；</p>
<p>把返回的结果和R构成结果集的一行。可以看到，在这个查询过程，也是扫描了200行，但是总共执行了101条语句，比直接join多了</p>
<p>100次交互。除此之外，客户端还要自己拼接SQL语句和结果。显然，这么做还不如直接join好。我们再来看看第二个问题：怎么选择驱动表？在这个join语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。假设被驱动表的行数是M。每次在被驱动表查一行数据，要先搜索索引a，再搜索主键索引。每</p>
<p>次搜索一棵树近似复杂度是以2为底的M的对数，记为log M，所以在被驱动表上查一行的时间复</p>
<p>杂度是 2*log M。假设驱动表的行数是N，执行过程就要扫描驱动表N行，然后对于每一行，到被驱动表上匹配一</p>
<p>次。因此整个执行过程，近似复杂度是 N + N<em>2</em>log M。显然，N对扫描行数的影响更大，因此应该让小表来做驱动表。到这里小结一下，通过上面的分析我们得到了两个结论：</p>
<ol>
<li><p>使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好；</p>
</li>
<li><p>如果使用join语句的话，需要让小表做驱动表。但是，你需要注意，这个结论的前提是“可以使用被驱动表的索引”。接下来，我们再看看被驱动表用不上索引的情况。Simple Nested-Loop Join</p>
</li>
</ol>
<p>现在，我们把SQL语句改成这样：</p>
<p>由于表t2的字段b上没有索引，因此再用图2的执行流程时，每次到t2去匹配的时候，就要做一次</p>
<p>2</p>
<p>2</p>
<p>2</p>
<p>如果你没觉得这个影响有那么“显然”， 可以这么理解：N扩大1000倍的话，扫描行数就会扩大</p>
<p>1000倍；而M扩大1000倍，扫描行数扩大不到10倍。select * from t1 straight_join t2 on (t1.a&#x3D;t2.b);</p>
<p>全表扫描。你可以先设想一下这个问题，继续使用图2的算法，是不是可以得到正确的结果呢？如果只看结</p>
<p>果的话，这个算法是正确的，而且这个算法也有一个名字，叫做“Simple Nested-Loop Join”。但是，这样算来，这个SQL请求就要扫描表t2多达100次，总共扫描100*1000&#x3D;10万行。这还只是两个小表，如果t1和t2都是10万行的表（当然了，这也还是属于小表的范围），就要扫</p>
<p>描100亿行，这个算法看上去太“笨重”了。当然，MySQL也没有使用这个Simple Nested-Loop Join算法，而是使用了另一个叫作“Block</p>
<p>Nested-Loop Join”的算法，简称BNL。Block Nested-Loop Join</p>
<p>这时候，被驱动表上没有可用的索引，算法的流程是这样的：</p>
<ol>
<li>把表t1的数据读入线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整</li>
</ol>
<p>个表t1放入了内存；</p>
<ol start="2">
<li>扫描表t2，把表t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为</li>
</ol>
<p>结果集的一部分返回。这个过程的流程图如下：</p>
<p>图3 Block Nested-Loop Join 算法的执行流程</p>
<p>对应地，这条SQL语句的explain结果如下所示：</p>
<p>图4 不使用索引字段join的 explain结果</p>
<p>可以看到，在这个过程中，对表t1和t2都做了一次全表扫描，因此总的扫描行数是1100。由于</p>
<p>join_buffer是以无序数组的方式组织的，因此对表t2中的每一行，都要做100次判断，总共需要</p>
<p>在内存中做的判断次数是：100*1000&#x3D;10万次。前面我们说过，如果使用Simple Nested-Loop Join算法进行查询，扫描行数也是10万行。因</p>
<p>此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join算法的这10万</p>
<p>次判断是内存操作，速度上会快很多，性能也更好。接下来，我们来看一下，在这种情况下，应该选择哪个表做驱动表。假设小表的行数是N，大表的行数是M，那么在这个算法里：</p>
<ol>
<li><p>两个表都做一次全表扫描，所以总的扫描行数是M+N；</p>
</li>
<li><p>内存中的判断次数是M*N。可以看到，调换这两个算式中的M和N没差别，因此这时候选择大表还是小表做驱动表，执行耗</p>
</li>
</ol>
<p>时是一样的。然后，你可能马上就会问了，这个例子里表t1才100行，要是表t1是一个大表，join_buffer放不</p>
<p>下怎么办呢？join_buffer的大小是由参数join_buffer_size设定的，默认值是256k。如果放不下表t1的所有数</p>
<p>据话，策略很简单，就是分段放。我把join_buffer_size改成1200，再执行：</p>
<p>执行过程就变成了：</p>
<ol>
<li><p>扫描表t1，顺序读取数据行放入join_buffer中，放完第88行join_buffer满了，继续第2步；</p>
</li>
<li><p>扫描表t2，把t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结</p>
</li>
</ol>
<p>果集的一部分返回；</p>
<ol start="3">
<li><p>清空join_buffer；</p>
</li>
<li><p>继续扫描表t1，顺序读取最后的12行数据放入join_buffer中，继续执行第2步。执行流程图也就变成这样：</p>
</li>
</ol>
<p>select * from t1 straight_join t2 on (t1.a&#x3D;t2.b);</p>
<p>图5 Block Nested-Loop Join – 两段</p>
<p>图中的步骤4和5，表示清空join_buffer再复用。这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去join”。可以看到，这时候由于表t1被分成了两次放入join_buffer中，导致表t2会被扫描两次。虽然分成</p>
<p>两次放入join_buffer，但是判断等值条件的次数还是不变的，依然是(88+12)<em>1000&#x3D;10万次。我们再来看下，在这种情况下驱动表的选择问题。假设，驱动表的数据行数是N，需要分K段才能完成算法流程，被驱动表的数据行数是M。注意，这里的K不是常数，N越大K就会越大，因此把K表示为λ</em>N，显然λ的取值范围是(0,1)。所以，在这个算法的执行过程中：</p>
<ol>
<li><p>扫描行数是 N+λ<em>N</em>M；</p>
</li>
<li><p>内存判断 N*M次。显然，内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数，在M和N大小确</p>
</li>
</ol>
<p>定的情况下，N小一些，整个算式的结果会更小。所以结论是，应该让小表当驱动表。当然，你会发现，在N+λ<em>N</em>M这个式子里，λ才是影响扫描行数的关键因素，这个值越小越好。刚刚我们说了N越大，分段数K越大。那么，N固定的时候，什么参数会影响K的大小呢？（也就</p>
<p>是λ的大小）答案是join_buffer_size。join_buffer_size越大，一次可以放入的行越多，分成的段</p>
<p>数也就越少，对被驱动表的全表扫描次数就越少。这就是为什么，你可能会看到一些建议告诉你，如果你的join语句很慢，就把join_buffer_size改</p>
<p>大。理解了MySQL执行join的两种算法，现在我们再来试着回答文章开头的两个问题。第一个问题：能不能使用join语句？1. 如果可以使用Index Nested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是</p>
<p>没问题的；</p>
<ol start="2">
<li>如果使用Block Nested-Loop Join算法，扫描行数就会过多。尤其是在大表上的join操作，这</li>
</ol>
<p>样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用。所以你在判断要不要使用join语句时，就是看explain结果里面，Extra字段里面有没有出现“Block</p>
<p>Nested Loop”字样。第二个问题是：如果要使用join，应该选择大表做驱动表还是选择小表做驱动表？1. 如果是Index Nested-Loop Join算法，应该选择小表做驱动表；</p>
<ol start="2">
<li>如果是Block Nested-Loop Join算法：</li>
</ol>
<p>在join_buffer_size足够大的时候，是一样的；</p>
<p>在join_buffer_size不够大的时候（这种情况更常见），应该选择小表做驱动表。所以，这个问题的结论就是，总是应该使用小表做驱动表。当然了，这里我需要说明下，什么叫作“小表”。我们前面的例子是没有加条件的。如果我在语句的where条件加上 t2.id&lt;&#x3D;50这个限定条件，再来</p>
<p>看下这两条语句：</p>
<p>select * from t1 straight_join t2 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;50;</p>
<p>select * from t2 straight_join t1 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;50;</p>
<p>注意，为了让两条语句的被驱动表都用不上索引，所以join字段都使用了没有索引的字段b。但如果是用第二个语句的话，join_buffer只需要放入t2的前50行，显然是更好的。所以这里，“t2</p>
<p>的前50行”是那个相对小的表，也就是“小表”。我们再来看另外一组例子：</p>
<p>这个例子里，表t1 和 t2都是只有100行参加join。但是，这两条语句每次查询放入join_buffer中</p>
<p>的数据是不一样的：</p>
<p>表t1只查字段b，因此如果把t1放到join_buffer中，则join_buffer中只需要放入b的值；</p>
<p>表t2需要查所有的字段，因此如果把表t2放到join_buffer中的话，就需要放入三个字段id、a和</p>
<p>b。这里，我们应该选择表t1作为驱动表。也就是说在这个例子里，“只需要一列参与join的表t1”是那</p>
<p>个相对小的表。所以，更准确地说，在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过</p>
<p>滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该</p>
<p>作为驱动表。小结</p>
<p>今天，我和你介绍了MySQL执行join语句的两种可能算法，这两种算法是由能否使用被驱动表的</p>
<p>索引决定的。而能否用上被驱动表的索引，对join语句的性能影响很大。通过对Index Nested-Loop Join和Block Nested-Loop Join两个算法执行过程的分析，我们也得到</p>
<p>了文章开头两个问题的答案：</p>
<ol>
<li><p>如果可以使用被驱动表的索引，join语句还是有其优势的；</p>
</li>
<li><p>不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法，这样的语句就尽量不要</p>
</li>
</ol>
<p>使用；</p>
<ol start="3">
<li>在使用join的时候，应该让小表做驱动表。最后，又到了今天的问题时间。我们在上文说到，使用Block Nested-Loop Join算法，可能会因为join_buffer不够大，需要对被</li>
</ol>
<p>select t1.b,t2.* from  t1  straight_join t2 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;100;</p>
<p>select t1.b,t2.* from  t2  straight_join t1 on (t1.b&#x3D;t2.b) where t2.id&lt;&#x3D;100;</p>
<p>驱动表做多次全表扫描。我的问题是，如果被驱动表是一个大表，并且是一个冷数据表，除了查询过程中可能会导致IO压</p>
<p>力大以外，你觉得对这个MySQL服务还有什么更严重的影响吗？（这个问题需要结合上一篇文</p>
<p>章的知识点）</p>
<p>你可以把你的结论和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收</p>
<p>听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我在上一篇文章最后留下的问题是，如果客户端由于压力过大，迟迟不能接收数据，会对服务端</p>
<p>造成什么严重的影响。这个问题的核心是，造成了“长事务”。至于长事务的影响，就要结合我们前面文章中提到的锁、MVCC的知识点了。如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；</p>
<p>当然读的事务也有问题，就是会导致undo log不能被回收，导致回滚段空间膨胀。评论区留言点赞板：</p>
<p>@老杨同志 提到了更新之间会互相等锁的问题。同一个事务，更新之后要尽快提交，不要做</p>
<p>没必要的查询，尤其是不要执行需要返回大量数据的查询；</p>
<p>@长杰 同学提到了undo表空间变大，db服务堵塞，服务端磁盘空间不足的例子。没时间了ngu   0</p>
<p>join这种用的多的，看完还是有很大收获的。像之前讲的锁之类，感觉好抽象，老是记不住，唉</p>
<p>。2019-01-30</p>
<p> 作者回复</p>
<p>嗯嗯，因为其实每个同学的只是背景不一样。这45讲里，每个同学都能从部分文章感觉到有收获，我觉得也很好了 </p>
<p>不过 锁其实用得也多的。。我以前负责业务库的时候，被开发同学问最多的问题之一就是，为啥死锁了^_^</p>
<p>2019-01-30</p>
<p>抽离の    8</p>
<p>早上听老师一节课感觉获益匪浅</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>好早呀 </p>
<p>2019-01-30</p>
<p>信信   6</p>
<p>老师好，回答本期问题：如果驱动表分段，那么被驱动表就被多次读，而被驱动表又是大表，</p>
<p>循环读取的间隔肯定得超1秒，这就会导致上篇文章提到的：“数据页在LRU_old的存在时间超</p>
<p>过1秒，就会移到young区”。最终结果就是把大部分热点数据都淘汰了，导致“Buffer pool hit rat</p>
<p>e”命中率极低，其他请求需要读磁盘，因此系统响应变慢，大部分请求阻塞。2019-01-30</p>
<p> 作者回复</p>
<p> </p>
<p>2019-01-30</p>
<p>老杨同志   3</p>
<p>对被驱动表进行全表扫描，会把冷数据的page加入到buffer pool.,并且block nested-loop要扫描</p>
<p>多次，两次扫描的时间可能会超过1秒，使lru的那个优化失效，把热点数据从buffer pool中淘汰</p>
<p>掉，影响正常业务的查询效率</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>漂亮 </p>
<p>2019-01-30</p>
<p>萤火虫   3</p>
<p>精选留言</p>
<p>萤火虫   3</p>
<p>年底了有一种想跳槽的冲动 身在武汉的我想出去看看 可一想到自身的能力和学历 又不敢去了 </p>
<p>苦恼…</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>今年这情况还是要先克制一下^_^ </p>
<p>先把内功练起来 </p>
<p>2019-01-30</p>
<p>清风浊酒   2</p>
<p>老师您好，left join 和 right join 会固定驱动表吗？2019-01-30</p>
<p> 作者回复</p>
<p>不会强制，但是由于语义的关系，大概率上是按照语句上写的关系去驱动，效率是比较高的</p>
<p>2019-01-30</p>
<p>柚子   2</p>
<p>join在热点表操作中，join查询是一次给两张表同时加锁吧，会不会增大锁冲突的几率？业务中肯定要使用被驱动表的索引，通常我们是先在驱动表查出结果集，然后再通过in被驱动</p>
<p>表索引字段，分两步查询，这样是否比直接join委托点？2019-01-30</p>
<p> 作者回复</p>
<p>join也是普通查询，都不需要加锁哦，参考下MVCC那篇；</p>
<p>就是我们文中说的，“分两步查询，先查驱动表，然后查多个in”，如果可以用上被驱动表的索引</p>
<p>，我觉得可以用上Index Nested-Loop Join算法，其实效果是跟拆开写类似的</p>
<p>2019-01-30</p>
<p>郝攀刚จุ๊บ   1</p>
<p>业务逻辑关系，一个SQL中left join7，8个表。这我该怎么优化。每次看到这些脑壳就大！</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p> </p>
<p>Explain下，没用用index nested-loop 的全要优化</p>
<p>2019-01-31</p>
<p>Zzz   1</p>
<p>林老师，我没想清楚为什么会进入young区域。假设大表t大小是M页&gt;old区域N页，由于Block </p>
<p>Nested-Loop Join需要对t进行k次全表扫描。第一次扫描时，1~N页依次被放入old区域，访问</p>
<p>N+1页时淘汰1页，放入N+1页，以此类推，第一次扫描结束后old区域存放的是M-N+1~M页。第二次扫描开始，访问1页，淘汰M-N+1页，放入1页。可以把M页想象成一个环，N页想象成</p>
<p>在这个环上滑动的窗口，由于M&gt;N，不管是哪次扫描，需要访问的页都不会在滑动窗口上，所</p>
<p>以不会存在“被访问的时候数据页在 LRU 链表中存在的时间超过了 1 秒“而被放入young的情况</p>
<p>。我能想到的会被放入young区域的情况是，在当次扫描中，由于一页上有多行数据，需要对</p>
<p>该页访问多次，超过了1s，不管这种情况就和t大小没关系了，而是由于page size太大，而一行</p>
<p>数据太少。2019-01-30</p>
<p> 作者回复</p>
<p>你说得对，分两类情况，</p>
<p>小于bp 3&#x2F;8的情况会跑到young，</p>
<p>大于3&#x2F;8的会影响young部分的更新</p>
<p>2019-01-30</p>
<p>700   1</p>
<p>老师，您好。看完文章后有如下问题请教：</p>
<p>1）文章内容「可以看到，在这个查询过程，也是扫描了 200 行，但是总共执行了 101 条语句</p>
<p>，比直接 join 多了 100 次交互。除此之外，客户端还要自己拼接 SQL 语句和结果。」</p>
<p>这个有没有啥方法来仅通过1次交互就将这101条语句发到服务端执行？2）文章内容「每次搜索一棵树近似复杂度是以 2 为底的 M 的对数，记为 log2M，所以在被驱</p>
<p>动表上查一行的时间复杂度是 2*log2M。」</p>
<p>这个复杂度的计算难理解，为什么是这么计算？假设 M &#x3D; 256，则搜索树的复杂度为8？3）文章内容「因此整个执行过程，近似复杂度是 N + N<em>2</em>log2M。」</p>
<p>驱动表的复杂度直接记为 N？4）文中提到索引扫描需扫1行数据，全表扫描需扫1000行数据。这是由统计信息决定的？提前感谢老师！</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<ol>
<li><p>用 in，但是不建议语句太长</p>
</li>
<li><p>看一下前面我们介绍索引的文章哈</p>
</li>
<li><p>因为是在叶子索引上直接顺序扫描，是一个大致值哈</p>
</li>
<li><p>不是呀，因为表t2是1000行哦</p>
</li>
</ol>
<p>2019-01-30</p>
<p>Ryoma   1</p>
<p>前提：冷数据表 &amp; 大表</p>
<p>buffer pool 中的old区会被持续刷新，并且基本没有升级到young区的可能性。一定程度上会降低hit rate</p>
<p>2019-01-30</p>
<p>403   0</p>
<p>用那个作为驱动表，mysql会自己优化么？2019-02-09</p>
<p> 作者回复</p>
<p>会的</p>
<p>2019-02-10</p>
<p>陈华应   0</p>
<p>老师，放完88行就满了，88是怎么计算得来的呢？2019-02-02</p>
<p> 作者回复</p>
<p>这个是实际跑出来的效果</p>
<p>如果说计算的话，每一行固定长度，你用1024除一下 </p>
<p>2019-02-02</p>
<p>库淘淘   0</p>
<p>set optimizer_switch&#x3D;’mrr&#x3D;on,mrr_cost_based&#x3D;off,batched_key_access&#x3D;on’;</p>
<p>create index idx_c on t2(c);</p>
<p>create index idx_a_c on t1(a,c);</p>
<p>create index idx_b_c on t3(b,c);</p>
<p>mysql&gt; explain select * from t2 </p>
<p>-&gt; straight_join t1 on(t1.a&#x3D;t2.a)</p>
<p>-&gt; straight_join t3 on(t2.b&#x3D;t3.b) </p>
<p>-&gt; where t1.c&gt; 800 and t2.c&gt;&#x3D;600 and t3.c&gt;&#x3D;500;</p>
<p>+—-+————-+——-+————+——-+—————+———+———+———–+——+———-+</p>
<p>—————————————————————+</p>
<p>| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | </p>
<p>Extra |</p>
<p>+—-+————-+——-+————+——-+—————+———+———+———–+——+———-+</p>
<p>—————————————————————+</p>
<p>| 1 | SIMPLE | t2 | NULL | range | idx_c | idx_c | 5 | NULL | 401 | 100.00 | Using index condition</p>
<p>; Using where; Using MRR |</p>
<p>| 1 | SIMPLE | t1 | NULL | ref | idx_a_c | idx_a_c | 5 | test.t2.a | 1 | 33.33 | Using index conditio</p>
<p>n; Using join buffer (Batched Key Access) |</p>
<p>| 1 | SIMPLE | t3 | NULL | ref | idx_b_c | idx_b_c | 5 | test.t2.b | 1 | 33.33 | Using index conditio</p>
<p>n; Using join buffer (Batched Key Access) |</p>
<p>+—-+————-+——-+————+——-+—————+———+———+———–+——+———-+</p>
<p>—————————————————————+</p>
<p>3 rows in set, 1 warning (0.00 sec)</p>
<p>以自己理解考虑如下，有问题请老师能够指出</p>
<p>1.根据查询因是select * 肯定回表的，其中在表t2创建索引idx_c,为了能够使用ICP,MRR，如果c</p>
<p>字段重复率高或取值行数多，可以考虑不建索引</p>
<p>2.已t2 作为驱动表，一方面考虑其他两表都有关联,t2表放入join buffer后关联t1后，再关联t2 得</p>
<p>出结果 再各回t2,t3表取出 得到结果集（之前理解都是t1和t2join得结果集再与t3join，本次理解</p>
<p>太确定）</p>
<p>3.t2、t3表建立联合查询目的能够使用ICP</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p>“2.已t2 作为驱动表，一方面考虑其他两表都有关联,t2表放入join buffer后关联t1后，再关联t2 得</p>
<p>出结果 再各回t2,t3表取出 得到结果集”</p>
<p>即使是用t1做驱动表，也是可能可以都用上BKA的哈</p>
<p>新春快乐~</p>
<p>2019-02-04</p>
<p>郭健   0</p>
<p>老师，太棒了！！终于讲join了！！！作为一个实际开发人员，索引了解是必须得，单表索引有</p>
<p>所掌握，始终对join没法理解，这节课对我的帮助是最大的。谢谢老师</p>
<p>2019-02-01</p>
<p> 作者回复</p>
<p> </p>
<p>2019-02-01</p>
<p>辣椒   0</p>
<p>我是开发，但是看了老师的专栏，对怎么写数据库应用更有心得了</p>
<p>2019-01-31</p>
<p> 作者回复</p>
<p> ，如果有有趣的经验也放到这里跟大家分享哦</p>
<p>2019-02-01</p>
<p>泡泡爱dota   0</p>
<p>explain select * from t1 straight_join t2 on (t1.a&#x3D;t2.a) where t1.a &lt; 50; </p>
<p>老师, 这条sql为什么t1.a的索引没有用上, t1还是走全表</p>
<p>2019-01-31</p>
<p> 作者回复</p>
<p>如果数据量不够多，并且满足a&lt;50的行，占比比较高的话，优化器有可能会认为“还要回表，还</p>
<p>不如直接扫主键id”</p>
<p>2019-01-31</p>
<p>剃刀吗啡   0</p>
<p>我们某个业务使用infobright这种列式存储，字段没用索引。我在想这种引擎在join的时候是否也</p>
<p>会遵守类似的规则？但列式存储并不是按行扫描，所以有点困惑。2019-01-31</p>
<p> 作者回复</p>
<p>是的，只是获取数据的时候，不会去读整行。但是没有索引就也只能用BNL，可以explain看看</p>
<p>2019-01-31</p>
<p>一大只    0</p>
<p>老师，我想问下，如果使用的是Index Nested-Loop Join，是不是就不会使用join_buffer了？直</p>
<p>接将循环结果放到net_buffer_length中，边读边发哈？2019-01-31</p>
<p> 作者回复</p>
<p>是的，Index Nested-Loop Join没有用到join buffer</p>
<p>不过35篇马上会介绍到一个优化，把join buffer用上，晚上关注下哦 </p>
<p>2019-01-31</p>
<p>斜面镜子 Bill   0</p>
<p>因为 join_buffer 不够大，需要对被驱动表做多次全表扫描，也就造成了“长事务”。除了老师上</p>
<p>节课提到的导致undo log 不能被回收，导致回滚段空间膨胀问题，还会出现：1. 长期占用DML</p>
<p>锁，引发DDL拿不到锁堵慢连接池； 2. SQL执行socket_timeout超时后业务接口重复发起，导</p>
<p>致实例IO负载上升出现雪崩；3. 实例异常后，DBA kill SQL因繁杂的回滚执行时间过长，不能</p>
<p>快速恢复可用；4. 如果业务采用select *作为结果集返回，极大可能出现网络拥堵，整体拖慢服</p>
<p>务端的处理；5. 冷数据污染buffer pool，block nested-loop多次扫描，其中间隔很有可能超过1</p>
<p>s，从而污染到lru 头部，影响整体的查询体验。2019-01-31</p>
<p> 作者回复</p>
<p> 很赞</p>
<p>之前知识点的也都加进来啦</p>
<p>2019-01-31</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/f0491e2a.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/f0491e2a.html" class="post-title-link" itemprop="url">mysql-我查这么多数据会不会把数据库内存打爆</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-08 06:03:33" itemprop="dateCreated datePublished" datetime="2019-12-08T06:03:33+08:00">2019-12-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>26 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>33 | 我查这么多数据，会不会把数据库内存打爆？2019-01-28 林晓斌</p>
<p>我经常会被问到这样一个问题：我的主机内存只有100G，现在要对一个200G的大表做全表扫</p>
<p>描，会不会把数据库主机的内存用光了？这个问题确实值得担心，被系统OOM（out of memory）可不是闹着玩的。但是，反过来想想，</p>
<p>逻辑备份的时候，可不就是做整库扫描吗？如果这样就会把内存吃光，逻辑备份不是早就挂了？所以说，对大表做全表扫描，看来应该是没问题的。但是，这个流程到底是怎么样的呢？全表扫描对server层的影响</p>
<p>假设，我们现在要对一个200G的InnoDB表db1. t，执行一个全表扫描。当然，你要把扫描结果</p>
<p>保存在客户端，会使用类似这样的命令：</p>
<p>你已经知道了，InnoDB的数据是保存在主键索引上的，所以全表扫描实际上是直接扫描表t的主</p>
<p>键索引。这条查询语句由于没有其他的判断条件，所以查到的每一行都可以直接放到结果集里</p>
<p>面，然后返回给客户端。那么，这个“结果集”存在哪里呢？mysql -h$host -P$port -u$user -p$pwd -e “select * from db1.t” &gt; $target_file</p>
<p>实际上，服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：</p>
<ol>
<li>获取一行，写到net_buffer中。这块内存的大小是由参数net_buffer_length定义的，默认是</li>
</ol>
<p>16k。2. 重复获取行，直到net_buffer写满，调用网络接口发出去。3. 如果发送成功，就清空net_buffer，然后继续取下一行，并写入net_buffer。4. 如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket send</p>
<p>buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。这个过程对应的流程图如下所示。图1 查询结果发送流程</p>
<p>从这个流程中，你可以看到：</p>
<ol>
<li>一个查询在发送过程中，占用的MySQL内部的内存最大就是net_buffer_length这么大，并不</li>
</ol>
<p>会达到200G；</p>
<ol start="2">
<li>socket send buffer 也不可能达到200G（默认定义&#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;wmem_default），如</li>
</ol>
<p>果socket send buffer被写满，就会暂停读数据的流程。也就是说，MySQL是“边读边发的”，这个概念很重要。这就意味着，如果客户端接收得慢，会</p>
<p>导致MySQL服务端由于结果发不出去，这个事务的执行时间变长。比如下面这个状态，就是我故意让客户端不去读socket receive buffer中的内容，然后在服务端</p>
<p>show processlist看到的结果。图2 服务端发送阻塞</p>
<p>如果你看到State的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。我在上一篇文章中曾提到，如果客户端使用–quick参数，会使用mysql_use_result方法。这个方</p>
<p>法是读一行处理一行。你可以想象一下，假设有一个业务的逻辑比较复杂，每读一行数据以后要</p>
<p>处理的逻辑如果很慢，就会导致客户端要过很久才会去取下一行数据，可能就会出现如图2所示</p>
<p>的这种情况。因此，对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，我都建议你使</p>
<p>用mysql_store_result这个接口，直接把查询结果保存到本地内存。当然前提是查询返回结果不多。在第30篇文章评论区，有同学说到自己因为执行了一个大查询</p>
<p>导致客户端占用内存近20G，这种情况下就需要改用mysql_use_result接口了。另一方面，如果你在自己负责维护的MySQL里看到很多个线程都处于“Sending to client”这个状</p>
<p>态，就意味着你要让业务开发同学优化查询结果，并评估这么多的返回结果是否合理。而如果要快速减少处于这个状态的线程的话，将net_buffer_length参数设置为一个更大的值是一</p>
<p>个可选方案。与“Sending to client”长相很类似的一个状态是“Sending data”，这是一个经常被误会的问题。有同学问我说，在自己维护的实例上看到很多查询语句的状态是“Sending data”，但查看网络也</p>
<p>没什么问题啊，为什么Sending data要这么久？实际上，一个查询语句的状态变化是这样的（注意：这里，我略去了其他无关的状态）：</p>
<p>MySQL查询语句进入执行阶段后，首先把状态设置成“Sending data”；</p>
<p>然后，发送执行结果的列相关的信息（meta data) 给客户端；</p>
<p>再继续执行语句的流程；</p>
<p>执行完成后，把状态设置成空字符串。也就是说，“Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶</p>
<p>段。比如，你可以构造一个锁等待的场景，就能看到Sending data状态。图3 读全表被锁</p>
<p>图 4 Sending data状态</p>
<p>可以看到，session B明显是在等锁，状态显示为Sending data。也就是说，仅当一个线程处于“等待客户端接收结果”的状态，才会显示”Sending to client”；而如</p>
<p>果显示成“Sending data”，它的意思只是“正在执行”。现在你知道了，查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会</p>
<p>把内存打爆。在server层的处理逻辑我们都清楚了，在InnoDB引擎里面又是怎么处理的呢？ 扫描全表会不会</p>
<p>对引擎系统造成影响呢？全表扫描对InnoDB的影响</p>
<p>在第2和第15篇文章中，我介绍WAL机制的时候，和你分析了InnoDB内存的一个作用，是保存</p>
<p>更新的结果，再配合redo log，就避免了随机写盘。内存的数据页是在Buffer Pool (BP)中管理的，在WAL里Buffer Pool 起到了加速更新的作用。而</p>
<p>实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。在第2篇文章的评论区有同学问道，由于有WAL机制，当事务提交的时候，磁盘上的数据页是旧</p>
<p>的，那如果这时候马上有一个查询要来读这个数据页，是不是要马上把redo log应用到数据页</p>
<p>呢？答案是不需要。因为这时候内存数据页的结果是最新的，直接读内存页就可以了。你看，这时候</p>
<p>查询根本不需要读磁盘，直接从内存拿结果，速度是很快的。所以说，Buffer Pool还有加速查询</p>
<p>的作用。而Buffer Pool对查询的加速效果，依赖于一个重要的指标，即：内存命中率。你可以在show engine innodb status结果中，查看一个系统当前的BP命中率。一般情况下，一</p>
<p>个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在99%以上。执行show engine innodb status ，可以看到“Buffer pool hit rate”字样，显示的就是当前的命中</p>
<p>率。比如图5这个命中率，就是99.0%。图5 show engine innodb status显示内存命中率</p>
<p>如果所有查询需要的数据页都能够直接从内存得到，那是最好的，对应的命中率就是100%。但，这在实际生产上是很难做到的。InnoDB Buffer Pool的大小是由参数 innodb_buffer_pool_size确定的，一般建议设置成可用物理</p>
<p>内存的60%~80%。在大约十年前，单机的数据量是上百个G，而物理内存是几个G；现在虽然很多服务器都能有</p>
<p>128G甚至更高的内存，但是单机的数据量却达到了T级别。所以，innodb_buffer_pool_size小于磁盘的数据量是很常见的。如果一个 Buffer Pool满了，而</p>
<p>又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。InnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是</p>
<p>淘汰最久未使用的数据。下图是一个LRU算法的基本模型。图6 基本LRU算法</p>
<p>InnoDB管理Buffer Pool的LRU算法，是用链表来实现的。1. 在图6的状态1里，链表头部是P1，表示P1是最近刚刚被访问过的数据页；假设内存里只能</p>
<p>放下这么多数据页；</p>
<ol start="2">
<li><p>这时候有一个读请求访问P3，因此变成状态2，P3被移到最前面；</p>
</li>
<li><p>状态3表示，这次访问的数据页是不存在于链表中的，所以需要在Buffer Pool中新申请一个</p>
</li>
</ol>
<p>数据页Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表</p>
<p>末尾Pm这个数据页的内存，存入Px的内容，然后放到链表头部。4. 从效果上看，就是最久没有被访问的数据页Pm，被淘汰了。这个算法乍一看上去没什么问题，但是如果考虑到要做一个全表扫描，会不会有问题呢？假设按照这个算法，我们要扫描一个200G的表，而这个表是一个历史数据表，平时没有业务访</p>
<p>问它。那么，按照这个算法扫描的话，就会把当前的Buffer Pool里的数据全部淘汰掉，存入扫描过程中</p>
<p>访问到的数据页的内容。也就是说Buffer Pool里面主要放的是这个历史数据表的数据。对于一个正在做业务服务的库，这可不妙。你会看到，Buffer Pool的内存命中率急剧下降，磁盘</p>
<p>压力增加，SQL语句响应变慢。所以，InnoDB不能直接使用这个LRU算法。实际上，InnoDB对LRU算法做了改进。图 7 改进的LRU算法</p>
<p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指</p>
<p>向的就是old区域的第一个位置，是整个链表的5&#x2F;8处。也就是说，靠近链表头部的5&#x2F;8是young区</p>
<p>域，靠近链表尾部的3&#x2F;8是old区域。改进后的LRU算法执行流程变成了下面这样。1. 图7中状态1，要访问数据页P3，由于P3在young区域，因此和优化前的LRU算法一样，将</p>
<p>其移到链表头部，变成状态2。2. 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新</p>
<p>插入的数据页Px，是放在LRU_old处。3. 处于old区域的数据页，每次被访问的时候都要做下面这个判断：</p>
<p>若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；</p>
<p>如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由</p>
<p>参数innodb_old_blocks_time控制的。其默认值是1000，单位毫秒。这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描200G的历史数据</p>
<p>表为例，我们看看改进后的LRU算法的操作逻辑：</p>
<ol>
<li><p>扫描过程中，需要新插入的数据页，都被放到old区域;</p>
</li>
<li><p>一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页</p>
</li>
</ol>
<p>第一次被访问和最后一次被访问的时间间隔不会超过1秒，因此还是会被保留在old区域；</p>
<ol start="3">
<li>再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到</li>
</ol>
<p>链表头部（也就是young区域），很快就会被淘汰出去。可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了Buffer Pool，但</p>
<p>是对young区域完全没有影响，从而保证了Buffer Pool响应正常业务的查询命中率。小结</p>
<p>今天，我用“大查询会不会把内存用光”这个问题，和你介绍了MySQL的查询结果，发送给客户端</p>
<p>的过程。由于MySQL采用的是边算边发的逻辑，因此对于数据量很大的查询结果来说，不会在server端保</p>
<p>存完整的结果集。所以，如果客户端读结果不及时，会堵住MySQL的查询过程，但是不会把内</p>
<p>存打爆。而对于InnoDB引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。并且，由于InnoDB对</p>
<p>LRU算法做了改进，冷数据的全表扫描，对Buffer Pool的影响也能做到可控。当然，我们前面文章有说过，全表扫描还是比较耗费IO资源的，所以业务高峰期还是不能直接在</p>
<p>线上主库执行全表扫描的。最后，我给你留一个思考题吧。我在文章中说到，如果由于客户端压力太大，迟迟不能接收结果，会导致MySQL无法发送结果</p>
<p>而影响语句执行。但，这还不是最糟糕的情况。你可以设想出由于客户端的性能问题，对数据库影响更严重的例子吗？或者你是否经历过这样的</p>
<p>场景？你又是怎么优化的？你可以把你的经验和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收</p>
<p>听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期的问题是，如果一个事务被kill之后，持续处于回滚状态，从恢复速度的角度看，你是应该重</p>
<p>启等它执行结束，还是应该强行重启整个MySQL进程。因为重启之后该做的回滚动作还是不能少的，所以从恢复速度的角度来说，应该让它自己结束。当然，如果这个语句可能会占用别的锁，或者由于占用IO资源过多，从而影响到了别的语句执行</p>
<p>的话，就需要先做主备切换，切到新主库提供服务。切换之后别的线程都断开了连接，自动停止执行。接下来还是等它自己执行完成。这个操作属于</p>
<p>我们在文章中说到的，减少系统压力，加速终止逻辑。评论区留言点赞板：</p>
<p>700   2</p>
<p>老师，您好。根据文章内容，提炼如下信息：</p>
<p>@HuaMax 的回答中提到了对其他线程的影响；</p>
<p>@夹心面包 @Ryoma @曾剑 同学提到了重启后依然继续做回滚操作的逻辑。精选留言</p>
<p>如果你看到 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。如何处理？1)使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。2)优化查询结果，并评估这么多的返回结果是否合理。3)而如果要快速减少处于这个状态的线程的话，将 net_buffer_length 参数设置为一个更大的值</p>
<p>是一个可选方案。对于第3)方案不是很懂，“Sending to client” 表示服务器端的网路栈写满了，那不是应该加大 so</p>
<p>cket send buffer 吗？跟加大 net_buffer_length 有什么关系？net_buffer_length 加再大，但 sock</p>
<p>et send buffer 很小的话，网络栈不还是处于写满状态？2019-01-28</p>
<p> 作者回复</p>
<p>好问题  很好的思考 </p>
<p>是这样的，net_buffer_length 的最大值是 1G，这个值比 socket send buffer大（一般是几M）</p>
<p>比如假设一个业务，他的平均查询结果都是10M （当然这个业务有有问题，最终是要通过业务</p>
<p>解决）</p>
<p>但是如果我把net_buffer_length 改成10M，就不会有“Sending to client” 的情况。虽然网络栈还</p>
<p>是慢慢发的，但是那些没发完的都缓存在net_buffer中，对于执行器来说，都是“已经写出去了”</p>
<p>。2019-01-28</p>
<p>Long   4</p>
<p>最近没时间看，今天终于补完了几天的课。2019-01-28</p>
<p>长杰   3</p>
<p>遇到过一个场景，用mysqldump对业务db做逻辑备份保存在客户端，客户端是虚拟机，磁盘很</p>
<p>快满了，导致server端出现sending to client状态，更糟糕的是业务db更新频繁，导致undo表空</p>
<p>间变大，db服务堵塞，服务端磁盘空间不足。2019-01-28</p>
<p> 作者回复</p>
<p>非常好，正是我要说明的一个场景呢，直接用你的例子放在下篇答疑部分哈</p>
<p>2019-01-29</p>
<p>Sinyo   1</p>
<p>@700 的置顶提问 </p>
<p>老师你说：”但是如果把 net_buffer_length 改成 10M，就不会有“Sending to client”的情况。虽然</p>
<p>网络栈还是慢慢发的，但是那些没发完的都缓存在net_buffer中，对于执行器来说，都是“已经</p>
<p>写出去了”。”</p>
<p>假如数据量有1G，而如果要快速减少处于这个状态的线程的话，我们把net_buffer_length 从10</p>
<p>M改成1G，快速减少的那部分操作是不是只有服务端发送到net_buffer的这部分？这样就不会有</p>
<p>“Sending to client”的情况么？2019-01-29</p>
<p> 作者回复</p>
<p>还是会显示为“Sending to client”，但是语句已经执行完了。不会占着资源（比如MDL读锁）</p>
<p>2019-01-29</p>
<p>700   1</p>
<p>老师，您好。感谢解答。接上个问题。Sending to client 是发生在下面哪个阶段的事件呢？1)是 “获取一行，写到 net_buffer 中。”</p>
<p>2)还是“直到 net_buffer 写满，调用网络接口发出去。” &#x2F;&#x2F;即数据从 net_buffer 发到 socket send b</p>
<p>uffer？3)还是“将 socket send buffer 的数据发送给 socket receive buffer”</p>
<p>从您的回答“但是如果我把net_buffer_length 改成10M，就不会有“Sending to client” 的情况。”，</p>
<p>我感觉应该是属于第1)阶段的事件。但感觉这又与您说的“Sending to client 表示的是服务器端</p>
<p>的网络栈写满了”相矛盾。2019-01-28</p>
<p> 作者回复</p>
<p>写net_buffer – &gt; net_buffer满了，调用网络接口发 –&gt;发不出去</p>
<p>这个是同一个调用链条呀</p>
<p>“哪个阶段”没看懂，是同一个时刻</p>
<p>2019-01-28</p>
<p>慕塔   0</p>
<p>young区域其实还有优化，频道调整LRU页的顺序为影响性能(LRU很长)，如果要读页在young</p>
<p>区域某位置，其实是没有必要将要读页拿到头部，本身已在热点区。页的属性有一个时间戳字</p>
<p>段，可以用于计算处于old区域的时间。 </p>
<p>2019-02-03</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师您好：</p>
<p>我看到评论的问题，有个疑惑：</p>
<p>“</p>
<p>之前有特殊功能需要从主要业务库拉取指定范围的数据到另外同一个库的其他数据表的动作（i</p>
<p>nsert into xxxxx select xxx from xxx 这种操作）数据量在万级或者十万级，对于这种操作，和本</p>
<p>文讲的应该有些不同吧？能否帮分析一下这种场景的大致情况呢？或者有什么好的建议吗？作者回复: 嗯，这个不会返回结果到客户端，所以网络上不会有问题</p>
<p>引擎内部的扫描机制是差不多的</p>
<p>唯一不同是这个过程可能对原表有行锁（如果设置的是RR）</p>
<p>万或者十万还好，是小数据，可以考虑拿到客户端再写回去，避免锁的问题</p>
<p>”</p>
<p>先把数据拿回客户端，再insert到另一个库。是为了避免锁的问题。这里从原库拉取数据就是select语句，没有涉及到next-key锁呀，为啥会有锁的问题呢？2019-02-01</p>
<p> 作者回复</p>
<p>好问题 ，第40篇会说这个问题哈，新年快乐</p>
<p>2019-02-01</p>
<p>梁中华   0</p>
<p>感觉young 和old 的叫法反了，后面的应该叫young 才好理解。另外文中的old 区也会有类似yo</p>
<p>ung 区域的淘汰策略吧</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>好几个同学这么说，我都方了 </p>
<p>这句是官方文档上的</p>
<p>“Accessing a page in the old sublist makes it “young”, moving it to the head of the buffer pool”</p>
<p>2019-01-30</p>
<p>Leon    0</p>
<p>如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是不会把内存打爆。这个是指客户</p>
<p>端的tcp滑动窗口处理没有及时确认，导致server端的网络协议栈没有多余的空间可以发送数据</p>
<p>，导致server的处理线程停止从db读取数据发送给client，是这样理解吗</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>对的</p>
<p>2019-01-30</p>
<p>Richie   0</p>
<p>老师，怎么才能了解什么地方占用内存，查了很多资料都没有这方面的信息，MySQL5.6</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>这个官方版本确实是还没有系统的地方查看~</p>
<p>2019-02-04</p>
<p>changshan   0</p>
<p>老师好，咨询一个于之前文章有关的问题，在rr隔离级别下会产生幻读，然而这个幻读mysql是</p>
<p>通过什么机制来解决的呢？有的说是mvcc，有的说是next-key锁。有点疑惑了。另外，怎么能</p>
<p>够验证mysql使用具体的哪种技术解决了幻读？2019-01-29</p>
<p> 作者回复</p>
<p>看一下20和21篇哈</p>
<p>2019-01-29</p>
<p>天使梦泪   0</p>
<p>老师好，针对我上次问您的mysql缓存中的数据储存问题，您回答可以一直保存的，具体是怎</p>
<p>么实现一直保存的（也不是储存在磁盘上，是使用的内存）？内存重启了之后，缓存不就也丢</p>
<p>失了，是怎么做到持久化保存的，老师可以帮忙详细解答下么？2019-01-29</p>
<p> 作者回复</p>
<p>InnoDB 的是buffer pool，是在内存里。”内存重启了之后，缓存不就也丢失了，是怎么做到持久化保存的，老师可以帮忙详细解答下么</p>
<p>？“</p>
<p>没有保存，重启就没有了，要访问的时候需要重新去磁盘读</p>
<p>2019-01-29</p>
<p>有铭   0</p>
<p>感觉mysql的做法有点流式读取的意思。但是，老师，虽然这篇文章讲述了Mysql是如何“边读边发”。但是更复杂的情况没有说明，比如</p>
<p>我现在要执行一个复杂的查询，而且查询是排序的，这意味着mysql需要对整个结构排序，然</p>
<p>后才能一条条的发出去，如果数据量极大的情况，Mysql如何完成排序过程，需要把数据全部</p>
<p>载入内存吗？还是存储在缓存文件里搞分而治之的排序，然后再“边读边发”</p>
<p>2019-01-29</p>
<p> 作者回复</p>
<p>看一下 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/73479">https://time.geekbang.org/column/article/73479</a> 这篇文章的图5哈</p>
<p>有说到哦</p>
<p>2019-01-29</p>
<p>Max   0</p>
<p>林Sir,你好。曾经发生过二个问题</p>
<p>第一个问题是show columns from table带来的临时表产生和移除</p>
<p>大量的session opening tmp tables 和removing tmp tables</p>
<p>也kill不掉会话，首先主从先切，让原主停止对外服务。在kill掉所有用户会话。问题解决，同时修改innodb_thread_concurrency参数数量。另外一个感觉是mysql bug引起的。当时环境是percona-mysql-20-21主从环境</p>
<p>没有高并发所，所有的用户会话状态都是query end，会话不释放。造成会话连接数暴涨。撑满了所有的会话。查看engine innodb status，发现latch等待非常高 </p>
<p>OS WAIT ARRAY INFO: signal count 5607657</p>
<p>RW-shared spins 0, rounds 2702261, OS waits 70377</p>
<p>RW-excl spins 0, rounds 216191633, OS waits 1802414</p>
<p>RW-sx spins 1588, rounds 5965, OS waits 70</p>
<p>Spin rounds per wait: 2702261.00 RW-shared, 216191633.00 RW-excl, 3.76 RW-sx</p>
<p>MySQL thread id 79467374, OS thread handle 140327525230336, query id 949505008 10.0.2.6 </p>
<p>apirwuser query end</p>
<p>INSERT INTO <code>xxxxxx</code> (<code>xxxx</code>,<code>xxxx</code>,<code>xxxx</code>,<code>xxxx</code>) VALUES (‘c2aab326-adf9-470b-940e-133fa2</p>
<p>c7f685’,’android’,’862915033153129’,1535597836)</p>
<p>—TRANSACTION 1154797559, ACTIVE (PREPARED) 1 sec</p>
<p>mysql tables in use 1, locked 1</p>
<p>第二个问题一直没有解决，后来把mysql 5.7 降到mysql 5.6</p>
<p>还有一个关于out of memory问题</p>
<p>sql如下: a是父表，b是子表</p>
<p>select a.id,a.name,b.title from a inner join b on a.id&#x3D;b.aid </p>
<p>where a.create_time&gt;’2010-08-01 00:00:00’ and a.create_time&lt;’2010-08-10 23:59:59’ </p>
<p>它的执行计划应该是</p>
<p>1 a表和b表生产迪卡集产生虚列集合T。2从集合T筛选出 a.id(主键)&#x3D;b.aid(外键)产生虚集合V 3</p>
<p>最后从集合v筛选出where条件，得到最终结果。如果二个表都超过千万条记录，产生的集合数据应该是放到内存中。如果是这样会不会打暴内</p>
<p>存</p>
<p>2019-01-29</p>
<p> 作者回复</p>
<ol>
<li><p>是的，show columns 其实不是一个好操作 </p>
</li>
<li><p>这个没见过，也没印象在社区中碰到这种现象，降成5.6就好了是吗？3. 不会的，34、35两篇就是说这个问题的哈</p>
</li>
</ol>
<p>2019-01-31</p>
<p>PHP-SICUN   0</p>
<p>老师，您好，有两个问题麻烦解惑一下</p>
<p>1.扫描200G的表时数据会先放到InnoDB buffer pool,然后发送时在读取到net_buffer吗？2.如果是的话，异常情况导致socket send buffer被写满，是不是会出现InnoDB buffer中的某一</p>
<p>页有可能出现读取后面的行时，超过1s，而被放到yong区域的情况？不知道这样表述或者理解的对吗</p>
<p>2019-01-29</p>
<p> 作者回复</p>
<ol>
<li><p>是 ，但是也不是“全部放到buffer pool以后”才发，读的时候是一个page 一个page 地读的</p>
</li>
<li><p>会，好在这个是“某一页”而已，量不大。 好问题</p>
</li>
</ol>
<p>很好的思考</p>
<p>2019-01-29</p>
<p>Ryoma   0</p>
<p>有两个问题：</p>
<p>0：MySQL 中的新生代和老生代的名字这么反人类的么</p>
<p>1：我在使用show engine innodb status看Buffer Pool时，发现Buffer Pool有8个（0~8），请问</p>
<p>老师这个是什么策略呢？2019-01-28</p>
<p> 作者回复</p>
<p>0  </p>
<ol>
<li>搜一下 innodb_buffer_pool_instances 这个参数的解释哈</li>
</ol>
<p>2019-01-28</p>
<p>老杨同志   0</p>
<p>老师提示考虑两个客户端都进行update的情况。如果第一个客户端执行select * from t for update 而迟迟不读取返回的数据，会造成server端长</p>
<p>期占用记录的行锁，如果其他线程要更新被锁定的记录，会报锁等待超时的错误</p>
<p>2019-01-28</p>
<p> 作者回复</p>
<p> </p>
<p>2019-01-28</p>
<p>天使梦泪   0</p>
<p>老师，我有个问题不明白，mysql从缓存中取数据，缓存里的数据是怎么实现可以保存一段时</p>
<p>间的？2019-01-28</p>
<p> 作者回复</p>
<p>“保存一段时间”是啥意思，LRU算法不是按照时间的哈，如果没人来淘汰，是可以一直保存的</p>
<p>。2019-01-28</p>
<p>如明如月   0</p>
<p>之前有特殊功能需要从主要业务库拉取指定范围的数据到另外同一个库的其他数据表的动作（i</p>
<p>nsert into xxxxx select xxx from xxx 这种操作）数据量在万级或者十万级，对于这种操作，和本</p>
<p>文讲的应该有些不同吧？能否帮分析一下这种场景的大致情况呢？或者有什么好的建议吗？2019-01-28</p>
<p> 作者回复</p>
<p>嗯，这个不会返回结果到客户端，所以网络上不会有问题</p>
<p>引擎内部的扫描机制是差不多的</p>
<p>唯一不同是这个过程可能对原表有行锁（如果设置的是RR）</p>
<p>万或者十万还好，是小数据，可以考虑拿到客户端再写回去，避免锁的问题</p>
<p>2019-01-28</p>
<p>garming   0</p>
<p>老师你好，如果是MyISAM存储引擎，大查询会导致内存暴涨吗？如果过，是什么原因呢？2019-01-28</p>
<p> 作者回复</p>
<p>也是不会的，跟InnoDB一样</p>
<p>2019-01-28</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/11e721ea.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/11e721ea.html" class="post-title-link" itemprop="url">mysql-为什么还有kill不掉的语句</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-07 06:12:12" itemprop="dateCreated datePublished" datetime="2019-12-07T06:12:12+08:00">2019-12-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>25 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>32 | 为什么还有kill不掉的语句？2019-01-25 林晓斌</p>
<p>在MySQL中有两个kill命令：一个是kill query +线程id，表示终止这个线程中正在执行的语句；一</p>
<p>个是kill connection +线程id，这里connection可缺省，表示断开这个线程的连接，当然如果这个</p>
<p>线程有语句正在执行，也是要先停止正在执行的语句的。不知道你在使用MySQL的时候，有没有遇到过这样的现象：使用了kill命令，却没能断开这个连</p>
<p>接。再执行show processlist命令，看到这条语句的Command列显示的是Killed。你一定会奇怪，显示为Killed是什么意思，不是应该直接在show processlist的结果里看不到这个</p>
<p>线程了吗？今天，我们就来讨论一下这个问题。其实大多数情况下，kill query&#x2F;connection命令是有效的。比如，执行一个查询的过程中，发现执</p>
<p>行时间太久，要放弃继续查询，这时我们就可以用kill query命令，终止这条查询语句。还有一种情况是，语句处于锁等待的时候，直接使用kill命令也是有效的。我们一起来看下这个例</p>
<p>子：</p>
<p>图1 kill query 成功的例子</p>
<p>可以看到，session C 执行kill query以后，session B几乎同时就提示了语句被中断。这，就是我</p>
<p>们预期的结果。收到kill以后，线程做什么？但是，这里你要停下来想一下：session B是直接终止掉线程，什么都不管就直接退出吗？显</p>
<p>然，这是不行的。我在第6篇文章中讲过，当对一个表做增删改查操作时，会在表上加MDL读锁。所以，session B</p>
<p>虽然处于blocked状态，但还是拿着一个MDL读锁的。如果线程被kill的时候，就直接终止，那之</p>
<p>后这个MDL读锁就没机会被释放了。这样看来，kill并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，</p>
<p>可以开始“执行停止的逻辑了”。实现上，当用户执行kill query thread_id_B时，MySQL里处理kill命令的线程做了两件</p>
<p>事：</p>
<ol>
<li><p>把session B的运行状态改成THD::KILL_QUERY(将变量killed赋值为THD::KILL_QUERY)；</p>
</li>
<li><p>给session B的执行线程发一个信号。为什么要发信号呢？因为像图1的我们例子里面，session B处于锁等待状态，如果只是把session B的线程状态设置</p>
</li>
</ol>
<p>THD::KILL_QUERY，线程B并不知道这个状态变化，还是会继续等待。发一个信号的目的，就</p>
<p>是让session B退出等待，来处理这个THD::KILL_QUERY状态。其实，这跟Linux的kill命令类似，kill -N pid并不是让进程直接停止，而是给进程发一个信号，</p>
<p>然后进程处理这个信号，进入终止逻辑。只是对于MySQL的kill命令来说，不需要传信号量参</p>
<p>数，就只有“停止”这个命令。上面的分析中，隐含了这么三层意思：</p>
<ol>
<li>一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态</li>
</ol>
<p>是THD::KILL_QUERY，才开始进入语句终止逻辑；</p>
<ol start="2">
<li><p>如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；</p>
</li>
<li><p>语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。到这里你就知道了，原来不是“说停就停的”。接下来，我们再看一个kill不掉的例子，也就是我们在前面第29篇文章中提到的</p>
</li>
</ol>
<p>innodb_thread_concurrency 不够用的例子。首先，执行set global innodb_thread_concurrency&#x3D;2，将InnoDB的并发线程上限数设置为2；然</p>
<p>后，执行下面的序列：</p>
<p>图2 kill query 无效的例子</p>
<p>可以看到：</p>
<ol>
<li><p>sesssion C执行的时候被堵住了；</p>
</li>
<li><p>但是session D执行的kill query C命令却没什么效果，</p>
</li>
<li><p>直到session E执行了kill connection命令，才断开了session C的连接，提示“Lost</p>
</li>
</ol>
<p>connection to MySQL server during query”，</p>
<ol start="4">
<li>但是这时候，如果在session E中执行show processlist，你就能看到下面这个图。图3 kill connection之后的效果</li>
</ol>
<p>这时候，id&#x3D;12这个线程的Commnad列显示的是Killed。也就是说，客户端虽然断开了连接，但</p>
<p>实际上服务端上这条语句还在执行过程中。为什么在执行kill query命令时，这条语句不像第一个例子的update语句一样退出呢？在实现上，等行锁时，使用的是pthread_cond_timedwait函数，这个等待状态可以被唤醒。但</p>
<p>是，在这个例子里，12号线程的等待逻辑是这样的：每10毫秒判断一下是否可以进入InnoDB执</p>
<p>行，如果不行，就调用nanosleep函数进入sleep状态。也就是说，虽然12号线程的状态已经被设置成了KILL_QUERY，但是在这个等待进入InnoDB的</p>
<p>循环过程中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。而当session E执行kill connection 命令时，是这么做的，</p>
<ol>
<li><p>把12号线程状态设置为KILL_CONNECTION；</p>
</li>
<li><p>关掉12号线程的网络连接。因为有这个操作，所以你会看到，这时候session C收到了断开</p>
</li>
</ol>
<p>连接的提示。那为什么执行show processlist的时候，会看到Command列显示为killed呢？其实，这就是因为在</p>
<p>执行show processlist的时候，有一个特别的逻辑：</p>
<p>所以其实，即使是客户端退出了，这个线程的状态仍然是在等待中。那这个线程什么时候会退出</p>
<p>呢？答案是，只有等到满足进入InnoDB的条件后，session C的查询语句继续执行，然后才有可能判</p>
<p>断到线程状态已经变成了KILL_QUERY或者KILL_CONNECTION，再进入终止逻辑阶段。到这里，我们来小结一下。这个例子是kill无效的第一类情况，即：线程没有执行到判断线程状态的逻辑。跟这种情况</p>
<p>相同的，还有由于IO压力过大，读写IO的函数一直无法返回，导致不能及时判断线程的状态。如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed。另一类情况是，终止逻辑耗时较长。这时候，从show processlist结果上看也是</p>
<p>Command&#x3D;Killed，需要等到终止逻辑完成，语句才算真正完成。这类情况，比较常见的场景有</p>
<p>以下几种：</p>
<ol>
<li>超大事务执行期间被kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回</li>
</ol>
<p>收操作，耗时很长。2. 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临</p>
<p>时文件可能需要等待IO资源，导致耗时较长。3. DDL命令执行到最后阶段，如果被kill，需要删除中间过程的临时文件，也可能受IO资源影响</p>
<p>耗时较久。之前有人问过我，如果直接在客户端通过Ctrl+C命令，是不是就可以直接终止线程呢？答案是，不可以。这里有一个误解，其实在客户端的操作只能操作到客户端的线程，客户端和服务端只能通过网络</p>
<p>交互，是不可能直接操作服务端线程的。而由于MySQL是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继</p>
<p>续发命令也是没有用的。实际上，执行Ctrl+C的时候，是MySQL客户端另外启动一个连接，然后</p>
<p>发送一个kill query 命令。所以，你可别以为在客户端执行完Ctrl+C就万事大吉了。因为，要kill掉一个线程，还涉及到后端</p>
<p>的很多操作。另外两个关于客户端的误解</p>
<p>在实际使用中，我也经常会碰到一些同学对客户端的使用有误解。接下来，我们就来看看两个最</p>
<p>常见的误解。第一个误解是：如果库里面的表特别多，连接就会很慢。有些线上的库，会包含很多表（我见过最多的一个库里有6万个表）。这时候，你就会发现，每</p>
<p>次用客户端连接都会卡在下面这个界面上。图4 连接等待</p>
<p>而如果db1这个库里表很少的话，连接起来就会很快，可以很快进入输入命令的状态。因此，有</p>
<p>同学会认为是表的数目影响了连接性能。从第一篇文章你就知道，每个客户端在和服务端建立连接的时候，需要做的事情就是TCP握手、</p>
<p>用户校验、获取权限。但这几个操作，显然跟库里面表的个数无关。但实际上，正如图中的文字提示所说的，当使用默认参数连接的时候，MySQL客户端会提供一</p>
<p>个本地库名和表名补全的功能。为了实现这个功能，客户端在连接成功后，需要多做一些操作：</p>
<ol>
<li><p>执行show databases；</p>
</li>
<li><p>切到db1库，执行show tables；</p>
</li>
<li><p>把这两个命令的结果用于构建一个本地的哈希表。在这些操作中，最花时间的就是第三步在本地构建哈希表的操作。所以，当一个库中的表个数非</p>
</li>
</ol>
<p>常多的时候，这一步就会花比较长的时间。也就是说，我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端</p>
<p>慢。图中的提示也说了，如果在连接命令中加上-A，就可以关掉这个自动补全的功能，然后客户端就</p>
<p>可以快速返回了。这里自动补全的效果就是，你在输入库名或者表名的时候，输入前缀，可以使用Tab键自动补全</p>
<p>表名或者显示提示。实际使用中，如果你自动补全功能用得并不多，我建议你每次使用的时候都默认加-A。其实提示里面没有说，除了加-A以外，加–quick(或者简写为-q)参数，也可以跳过这个阶段。但</p>
<p>是，这个–quick是一个更容易引起误会的参数，也是关于客户端常见的一个误解。你看到这个参数，是不是觉得这应该是一个让服务端加速的参数？但实际上恰恰相反，设置了这</p>
<p>个参数可能会降低服务端的性能。为什么这么说呢？MySQL客户端发送请求后，接收服务端返回结果的方式有两种：</p>
<ol>
<li>一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用API开发，对应的</li>
</ol>
<p>就是mysql_store_result 方法。2. 另一种是不缓存，读一个处理一个。如果你用API开发，对应的就是mysql_use_result方</p>
<p>法。MySQL客户端默认采用第一种方式，而如果加上–quick参数，就会使用第二种不缓存的方式。采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变</p>
<p>慢。关于服务端的具体行为，我会在下一篇文章再和你展开说明。那你会说，既然这样，为什么要给这个参数取名叫作quick呢？这是因为使用这个参数可以达到</p>
<p>以下三点效果：</p>
<p>第一点，就是前面提到的，跳过表名自动补全功能。第二点，mysql_store_result需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费</p>
<p>较多的本地内存，可能会影响客户端本地机器的性能；</p>
<p>第三点，是不会把执行命令记录到本地的命令历史文件。所以你看到了，–quick参数的意思，是让客户端变得更快。小结</p>
<p>在今天这篇文章中，我首先和你介绍了MySQL中，有些语句和连接“kill不掉”的情况。这些“kill不掉”的情况，其实是因为发送kill命令的客户端，并没有强行停止目标线程的执行，而只</p>
<p>是设置了个状态，并唤醒对应的线程。而被kill的线程，需要执行到判断状态的“埋点”，才会开始</p>
<p>进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。所以，如果你发现一个线程处于Killed状态，你可以做的事情就是，通过影响系统环境，让这个</p>
<p>Killed状态尽快结束。比如，如果是第一个例子里InnoDB并发度的问题，你就可以临时调大</p>
<p>innodb_thread_concurrency的值，或者停掉别的线程，让出位子给这个线程执行。而如果是回滚逻辑由于受到IO资源限制执行得比较慢，就通过减少系统压力让它加速。做完这些操作后，其实你已经没有办法再对它做什么了，只能等待流程自己完成。最后，我给你留下一个思考题吧。如果你碰到一个被killed的事务一直处于回滚状态，你认为是应该直接把MySQL进程强行重启，</p>
<p>还是应该让它自己执行完成呢？为什么呢？你可以把你的结论和分析写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收</p>
<p>听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我在上一篇文章末尾，给你留下的问题是，希望你分享一下误删数据的处理经验。@苍茫 同学提到了一个例子，我觉得值得跟大家分享一下。运维的同学直接拷贝文本去执</p>
<p>行，SQL语句截断，导致数据库执行出错。从浏览器拷贝文本执行，是一个非常不规范的操作。除了这个例子里面说的SQL语句截断问题，</p>
<p>还可能存在乱码问题。一般这种操作，如果脚本的开发和执行不是同一个人，需要开发同学把脚本放到git上，然后把</p>
<p>git地址，以及文件的md5发给运维同学。这样就要求运维同学在执行命令之前，确认要执行的文件的md5，跟之前开发同学提供的md5相</p>
<p>同才能继续执行。另外，我要特别点赞一下@苍茫 同学复现问题的思路和追查问题的态度。@linhui0705 同学提到的“四个脚本”的方法，我非常推崇。这四个脚本分别是：备份脚本、</p>
<p>执行脚本、验证脚本和回滚脚本。如果能够坚持做到，即使出现问题，也是可以很快恢复的，一</p>
<p>定能降低出现故障的概率。不过，这个方案最大的敌人是这样的思想：这是个小操作，不需要这么严格。@Knight²º¹  给了一个保护文件的方法，我之前没有用过这种方法，不过这确实是一个不错的</p>
<p>思路。为了数据安全和服务稳定，多做点预防方案的设计讨论，总好过故障处理和事后复盘。方案设计</p>
<p>讨论会和故障复盘会，这两种会议的会议室气氛完全不一样。经历过的同学一定懂的。Leon    2</p>
<p>kill connection本质上只是把客户端的sql连接断开，后面的执行流程还是要走kill query的，是这</p>
<p>样理解吧</p>
<p>2019-01-30</p>
<p> 作者回复</p>
<p>这个理解非常到位 </p>
<p>额外的一个不同就是show processlist的时候，kill connection会显示“killed”</p>
<p>这两句加起来可以用来替换我们文中的描述 </p>
<p>2019-01-30</p>
<p>Mr.sylar   2</p>
<p>老师，我想问下这些原理的”渔”的方法除了看源码，还有别的建议吗</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>不同的知识点不太一样哈，</p>
<p>有些可以看文档；</p>
<p>有些可以自己验证；</p>
<p>还有就是看其他人文章，加验证；（就是我们这个专栏的方法^_^）</p>
<p>2019-01-25</p>
<p>夹心面包   2</p>
<p>对于结尾的问题,我觉得肯定是等待,即便是mysql重启,也是需要对未提交的事务进行回滚操作的</p>
<p>,保证数据库的一致性</p>
<p>2019-01-25</p>
<p>Ryoma   1</p>
<p>想得简单点：既然事务处于回滚状态了，重启MySQL这部分事务还是需要回滚。私以为让它执</p>
<p>行完成比较好。2019-01-25</p>
<p>斜面镜子 Bill   0</p>
<p>“采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端</p>
<p>变慢” 这个怎么理解？2019-01-28</p>
<p> 作者回复</p>
<p>堵住了不就变慢了 </p>
<p>2019-01-28</p>
<p>700   0</p>
<p>精选留言</p>
<p> 0</p>
<p>老师，您好。客户端版本如下：</p>
<p>mysql Ver 14.14 Distrib 5.7.24, for linux-glibc2.12 (x86_64) using EditLine wrapper</p>
<p>老师，再请教另一个问题。并非所有的 DDL 操作都可以通过主从切换来实现吧？不适用的场景</p>
<p>有哪些呢？2019-01-27</p>
<p> 作者回复</p>
<p>对，其实只有 改索引、 加最后一列、删最后一列</p>
<p>其他的大多数不行，比如删除中间一列这种</p>
<p>2019-01-28</p>
<p>千年孤独   0</p>
<p>可能不是本章讨论的问题，我想请问老师“MySQL使用自增ID和UUID作为主键的优劣”，基于什</p>
<p>么样的业务场景用哪种好?</p>
<p>2019-01-27</p>
<p> 作者回复</p>
<p>后面会有文章会提到这个问题哈：）</p>
<p>2019-01-27</p>
<p>Geek_a67865   0</p>
<p>老师好，我猜发条橙子的问题 因为很多日志监控会统计error日志，这样并不很优雅，觉得他是</p>
<p>想有什么办法规避这种并发引起的问题，</p>
<p>2019-01-26</p>
<p> 作者回复</p>
<p>嗯嗯 不过我也确实没有想到更好的方法</p>
<p>毕竟两个线程要同时发起一个insert操作，这个服务端也拦不住呀 </p>
<p>2019-01-26</p>
<p>路过   0</p>
<p>老师，kill语法是：</p>
<p>KILL [CONNECTION | QUERY] processlist_id</p>
<p>processlist_id是conn_id，不是thd_id.通过对比sys.processlist表中的信息就可以知道了。通过查询官方文档也说明了：</p>
<p>thd_id：The thread ID.</p>
<p>conn_id：The connection ID.</p>
<p>所以，这篇文章开头的：</p>
<p>在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id</p>
<p>感觉有点不对。请老师指正。谢谢！</p>
<p>2019-01-26</p>
<p> 作者回复</p>
<p>这两个是一样的吧？都是对应show processlist这个命令结果里的第一列</p>
<p>2019-01-26</p>
<p>HuaMax   0</p>
<p>课后题。我认为需要看当时的业务场景。重启会导致其他的连接也断开，返回给其他业务连接</p>
<p>丢失的错误。如果有很多事务在等待该事务的锁，则应该重启，让其他事务快速重试获取锁。另外如果是RR的事务隔离级别，长事务会因为数据可见性的问题，对于多版本的数据需要找到</p>
<p>正确的版本，对读性能是不是也会有影响，这时候重启也更好。个人理解，请老师指正。2019-01-26</p>
<p> 作者回复</p>
<p>有考虑到对其他线程的影响，这个 </p>
<p>其实这种时候往往是要先考虑切换（当然重启也是切换的）</p>
<p>如果只看恢复时间的话，等待会更快 </p>
<p>2019-01-26</p>
<p>Geek_a67865   0</p>
<p>也遇到@发条橙子一样的问题，例如队列两个消息同时查询库存，发现都不存在，然后就都执</p>
<p>行插入语句，一条成功，一条报唯一索引异常，这样程序日志会一直显示一个唯一索引报错，</p>
<p>然后重试执行更新，我暂时是强制查主库</p>
<p>2019-01-26</p>
<p> 作者回复</p>
<p>“我暂时是强制查主库” 从这就看你是因为读是读的备库，才出现这个问题的是吧。发条橙子的问题是，他都是操作主库。其实如果索引有唯一键，就直接上insert。然后碰到违反唯一键约束就报错，这个应该就是唯一键约束正常的用法吧 </p>
<p>2019-01-26</p>
<p>gaohueric   0</p>
<p>老师您好，一个表中 1个主键，2个唯一索引，1个普通索引 4个普通字段，当插入一条全部字</p>
<p>段不为空的数据时，此时假设有4个索引文件，分别对应 主键 唯一性索引，普通索引，假设内</p>
<p>存中没有这个数据页，那么server是直接调用innodb的接口，然后依次校验 （读取磁盘数据，</p>
<p>验证唯一性）主键，唯一性索引，然后确认无误A时刻之后，吧主键和唯一性索引的写入内存</p>
<p>，再把普通索引写入change buffer？那普通数据呢，是不是跟着主键一块写入内存了？2019-01-26</p>
<p> 作者回复</p>
<ol>
<li><p>是的，如果普通索引上的数据页这时候没有在内存中，就会使用change buffer</p>
</li>
<li><p>“那普通数据呢，是不是跟着主键一块写入内存了？” 你说的是无索引的字段是吧，这些数据</p>
</li>
</ol>
<p>就在主键索引上，其实改的就是主键索引。2019-01-26</p>
<p>700   0</p>
<p>老师，您好。我继续接着我上条留言。关于2），因为是测试机，我是直接 tail -0f 观察 general log 输出的。确实没看到 KILL QUERY </p>
<p>等字眼。数据库版本是 MySQL 5.7.24。关于4），文中您不是这样说的吗？2.但是 session D 执行的 kill query C 命令却没什么效果， </p>
<p>3.直到 session E 执行了 kill connection 命令，才断开了 session C 的连接，提示“Lost connec</p>
<p>tion to MySQL server during query”， </p>
<p>感谢您的解答。2019-01-26</p>
<p> 作者回复</p>
<ol>
<li><p>你的客户端版本是什么 mysql –version 看看</p>
</li>
<li><p>嗯，是的，连接会断开，但是这个语句在server端还是会继续执行 （如果kill query 无效的话</p>
</li>
</ol>
<p>）</p>
<p>2019-01-26</p>
<p>700   0</p>
<p>老师，请教。1）文中开头说“当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的”。我个人</p>
<p>在平时使用中就是按默认的执行，不管这个线程有无正在执行语句。不知这样会有什么潜在问</p>
<p>题？2）文中说“实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 </p>
<p>kill query 命令“。这个怎么解释呢？我开启 general log 的时候执行 Ctrl+C 或 Ctrl+D 并没有看到有另外启动一个连接，也没有看到 </p>
<p>kill query 命令。general log 中仅看到对应线程 id 和 Quit。3）MySQL 为什么要同时存在 kill query 和 kill connection，既然 kill query 有无效的场景，干嘛</p>
<p>不直接存在一个 kill connection 命令就好了？那它俩分别对应的适用场景是什么，什么时候考</p>
<p>虑 kill query，什么时候考虑 kill connection？我个人觉得连接如果直接被 kill 掉大不了再重连一</p>
<p>次好了。也没啥损失。4）小小一个总结，不知对否？kill query - 会出现无法 kill 掉的情况，只能再次执行 kill connection。kill connection - 会出现 Command 列显示成 Killed 的情况。2019-01-25</p>
<p> 作者回复</p>
<ol>
<li><p>一般你执行kill就是要停止正在执行的语句，所以问题不大 </p>
</li>
<li><p>不应该呀， KILL QUERY 是大写哦，你再grep一下日志；</p>
</li>
<li><p>多提供一种方法嘛。kill query是指你只是想停止这个语句，但是事务不会回滚。一般kill quer</p>
</li>
</ol>
<p>y是发生在客户端执行ctrl+c的时候啦。平时紧急处理确实直接用kill + thread_id。 好问题</p>
<ol start="4">
<li>对，另外，在kill query无效的时候，其实kill connection也是无效的</li>
</ol>
<p>2019-01-26</p>
<p>Justin   0</p>
<p>想咨询一个问题 如果走索引找寻比如age&#x3D;11的人的时候是只会锁age&#x3D;10到age&#x3D;12吗 如果那个</p>
<p>索引页包含了从5到13的数据 是只会锁离11最近的还是说二分查找时候每一个访问到的都会锁</p>
<p>呢</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>只会锁左右。2019-01-26</p>
<p>往事随风，顺其自然   0</p>
<p>12 号线程的等待逻辑是这样的：每 10 毫秒判断一下是否可以进入 InnoDB 执行，如果不行，</p>
<p>如果不行，就调用 nanosleep 函数进入 sleep状态。这里为什么是10毫秒判断一下？怎么查看</p>
<p>和设置这个参数？2019-01-25</p>
<p>发条橙子 。   0</p>
<p>老师我这里问一下唯一索引的问题 ，希望老师能给点思路</p>
<p>背景 ： 一张商品库存表 ， 如果表里没这个商品则插入 ，如果已经存在就更新库存 。同步这</p>
<p>个库存表是异步的 ，每次添加商品库存成功后会发消息 ， 收到消息后会去表里新增&#x2F;更新库存</p>
<p>问题 ： </p>
<p>商品库存表会有一个 商品的唯一索引。当我们批量添加同一商品库存后会批量发消息 ，消息同时生效后去处理就有了并发的问题 。这</p>
<p>时候两个消息都判断表里没有该商品记录， 但是插入的时候就会有一个消息插入成功，另一个</p>
<p>消息执行失败报唯一索引的错误， 之后消息重试走更新的逻辑。这个这样做对业务没有影响 ，但是现在批量添加的需求量上来了 ，线上一直报这种错误日志也</p>
<p>不是个办法， 我能想到的除了 catch 掉这个异常就没什么其他思路了。 </p>
<p>老师能给一些其他的思路么</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>有唯一索引了，就直接插入，然后出现唯一性约束就放弃，这个逻辑的问题是啥，我感觉挺好</p>
<p>的呀 </p>
<p>是不是我没有get到问题的点</p>
<p>2019-01-25</p>
<p>AI杜嘉嘉   0</p>
<p>我想请问下老师，一个事务执行很长时间，我去kill。那么，执行这个事务过程中的数据会不会</p>
<p>回滚？2019-01-25</p>
<p> 作者回复</p>
<p>这个事务执行过程中新生成的数据吗？ 会回滚的</p>
<p>2019-01-25</p>
<p>曾剑   0</p>
<p>曾剑  0</p>
<p>今天的问题，我觉得得让他自己执行完成后自动恢复。因为强制重启后该做的回滚还是会继续</p>
<p>做。2019-01-25</p>
<p>Dkey   0</p>
<p>老师，请教一个 第八章 的问题。关于可见性判断，文中都是说事务id大于高水位都不可见。如</p>
<p>果等于是不是也不可见。还有一个，readview中是否不包含当前事务id。谢谢老师</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>代码实现上，事务生成trxid后，trxid的分配器会+1，以这个加1以后的数作为高水位，所以“等</p>
<p>于”是不算的。其实有没有包含是一样的，实现上没有包含。2019-01-25</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/3ffe231f.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3ffe231f.html" class="post-title-link" itemprop="url">mysql-误删数据后除了跑路还能怎么办</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-06 06:02:07" itemprop="dateCreated datePublished" datetime="2019-12-06T06:02:07+08:00">2019-12-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>8.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>31 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>31 | 误删数据后除了跑路，还能怎么办？2019-01-23 林晓斌</p>
<p>今天我要和你讨论的是一个沉重的话题：误删数据。在前面几篇文章中，我们介绍了MySQL的高可用架构。当然，传统的高可用架构是不能预防误</p>
<p>删数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整</p>
<p>个集群的实例都会执行这个命令。虽然我们之前遇到的大多数的数据被删，都是运维同学或者DBA背锅的。但实际上，只要有数</p>
<p>据操作权限的同学，都有可能踩到误删数据这条线。今天我们就来聊聊误删数据前后，我们可以做些什么，减少误删数据的风险，和由误删数据带来</p>
<p>的损失。为了找到解决误删数据的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：</p>
<ol>
<li><p>使用delete语句误删数据行；</p>
</li>
<li><p>使用drop table或者truncate table语句误删数据表；</p>
</li>
<li><p>使用drop database语句误删数据库；</p>
</li>
<li><p>使用rm命令误删整个MySQL实例。误删行</p>
</li>
</ol>
<p>在第24篇文章中，我们提到如果是使用delete语句误删了数据行，可以用Flashback工具通过闪</p>
<p>回把数据恢复回来。Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提</p>
<p>是，需要确保binlog_format&#x3D;row 和 binlog_row_image&#x3D;FULL。具体恢复数据时，对单个事务做如下处理：</p>
<ol>
<li>对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event</li>
</ol>
<p>即可；</p>
<ol start="2">
<li><p>同理，对于delete语句，也是将Delete_rows event改为Write_rows event；</p>
</li>
<li><p>而如果是Update_rows的话，binlog里面记录了数据行修改前和修改后的值，对调这两行的</p>
</li>
</ol>
<p>位置即可。如果误操作不是一个，而是多个，会怎么样呢？比如下面三个事务：</p>
<p>现在要把数据库恢复回这三个事务操作之前的状态，用Flashback工具解析binlog后，写回主库</p>
<p>的命令是：</p>
<p>也就是说，如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。需要说明的是，我不建议你直接在主库上执行这些操作。恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执</p>
<p>行这些操作，然后再将确认过的临时库的数据，恢复回主库。为什么要这么做呢？这是因为，一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。可能由于发现数据问</p>
<p>题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数</p>
<p>据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破</p>
<p>(A)delete …</p>
<p>(B)insert …</p>
<p>(C)update …</p>
<p>(reverse C)update …</p>
<p>(reverse B)delete …</p>
<p>(reverse A)insert …</p>
<p>坏。当然，我们不止要说误删数据的事后处理办法，更重要是要做到事前预防。我有以下两个建</p>
<p>议：</p>
<ol>
<li>把sql_safe_updates参数设置为on。这样一来，如果我们忘记在delete或者update语句中写</li>
</ol>
<p>where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。2. 代码上线前，必须经过SQL审计。你可能会说，设置了sql_safe_updates&#x3D;on，如果我真的要把一个小表的数据全部删掉，应该怎</p>
<p>么办呢？如果你确定这个删除操作没问题的话，可以在delete语句中加上where条件，比如where id&gt;&#x3D;0。但是，delete全表是很慢的，需要生成回滚日志、写redo、写binlog。所以，从性能角度考虑，</p>
<p>你应该优先考虑使用truncate table或者drop table命令。使用delete命令删除的数据，你还可以用Flashback来恢复。而使用truncate &#x2F;drop table和drop</p>
<p>database命令删除的数据，就没办法通过Flashback来恢复了。为什么呢？这是因为，即使我们配置了binlog_format&#x3D;row，执行这三个命令时，记录的binlog还是</p>
<p>statement格式。binlog里面就只有一个truncate&#x2F;drop 语句，这些信息是恢复不出数据的。那么，如果我们真的是使用这几条命令误删数据了，又该怎么办呢？误删库&#x2F;表</p>
<p>这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有</p>
<p>定期的全量备份，并且实时备份binlog。在这两个条件都具备的情况下，假如有人中午12点误删了一个库，恢复数据的流程如下：</p>
<ol>
<li><p>取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；</p>
</li>
<li><p>用备份恢复出一个临时库；</p>
</li>
<li><p>从日志备份里面，取出凌晨0点之后的日志；</p>
</li>
<li><p>把这些日志，除了误删除数据的语句外，全部应用到临时库。这个流程的示意图如下所示：</p>
</li>
</ol>
<p>图1 数据恢复流程-mysqlbinlog方法</p>
<p>关于这个过程，我需要和你说明如下几点：</p>
<ol>
<li>为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用mysqlbinlog命令时，加</li>
</ol>
<p>上一个–database参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用</p>
<p>其他库日志的情况。2. 在应用日志的时候，需要跳过12点误操作的那个语句的binlog：</p>
<p>如果原实例没有使用GTID模式，只能在应用到包含12点的binlog文件的时候，先用–</p>
<p>stop-position参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日</p>
<p>志继续执行；</p>
<p>如果实例使用了GTID模式，就方便多了。假设误操作命令的GTID是gtid1，那么只需要</p>
<p>执行set gtid_next&#x3D;gtid1;begin;commit; 先把这个GTID加到临时实例的GTID集合，之后</p>
<p>按顺序执行binlog的时候，就会自动跳过误操作的语句。不过，即使这样，使用mysqlbinlog方法恢复数据还是不够快，主要原因有两个：</p>
<ol>
<li>如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog工</li>
</ol>
<p>具并不能指定只解析一个表的日志；</p>
<ol start="2">
<li>用mysqlbinlog解析出日志应用，应用日志的过程就只能是单线程。我们在第26篇文章中介</li>
</ol>
<p>绍的那些并行复制的方法，在这里都用不上。一种加速的方法是，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，</p>
<p>这样：</p>
<ol>
<li>在start slave之前，先通过执行</li>
</ol>
<p>change replication filter replicate_do_table &#x3D; (tbl_name) 命令，就可以让临时库只同步误操</p>
<p>作的表；</p>
<ol start="2">
<li>这样做也可以用上并行复制技术，来加速整个数据恢复过程。这个过程的示意图如下所示。图2 数据恢复流程-master-slave方法</li>
</ol>
<p>可以看到，图中binlog备份系统到线上备库有一条虚线，是指如果由于时间太久，备库上已经删</p>
<p>除了临时实例需要的binlog的话，我们可以从binlog备份系统中找到需要的binlog，再放回备库</p>
<p>中。假设，我们发现当前临时实例需要的binlog是从master.000005开始的，但是在备库上执行show</p>
<p>binlogs 显示的最小的binlog文件是master.000007，意味着少了两个binlog文件。这时，我们就</p>
<p>需要去binlog备份系统中找到这两个文件。把之前删掉的binlog放回备库的操作步骤，是这样的：</p>
<ol>
<li><p>从备份系统下载master.000005和master.000006这两个文件，放到备库的日志目录下；</p>
</li>
<li><p>打开日志目录下的master.index文件，在文件开头加入两行，内容分别是</p>
</li>
</ol>
<p>“.&#x2F;master.000005”和“.&#x2F;master.000006”;</p>
<ol start="3">
<li><p>重启备库，目的是要让备库重新识别这两个日志文件；</p>
</li>
<li><p>现在这个备库上就有了临时库需要的所有binlog了，建立主备关系，就可以正常同步了。不论是把mysqlbinlog工具解析出的binlog文件应用到临时库，还是把临时库接到备库上，这两个</p>
</li>
</ol>
<p>方案的共同点是：误删库或者表后，恢复数据的思路主要就是通过备份，再加上应用binlog的方</p>
<p>式。也就是说，这两个方案都要求备份系统定期备份全量日志，而且需要确保binlog在被从本地删除</p>
<p>之前已经做了备份。但是，一个系统不可能备份无限的日志，你还需要根据成本和磁盘空间资源，设定一个日志保留</p>
<p>的天数。如果你的DBA团队告诉你，可以保证把某个实例恢复到半个月内的任意时间点，这就</p>
<p>表示备份系统保留的日志时间就至少是半个月。另外，我建议你不论使用上述哪种方式，都要把这个数据恢复功能做成自动化工具，并且经常拿</p>
<p>出来演练。为什么这么说呢？这里的原因，主要包括两个方面：</p>
<ol>
<li>虽然“发生这种事，大家都不想的”，但是万一出现了误删事件，能够快速恢复数据，将损失</li>
</ol>
<p>降到最小，也应该不用跑路了。2. 而如果临时再手忙脚乱地手动操作，最后又误操作了，对业务造成了二次伤害，那就说不过</p>
<p>去了。延迟复制备库</p>
<p>虽然我们可以通过利用并行复制来加速恢复数据的过程，但是这个方案仍然存在“恢复时间不可</p>
<p>控”的问题。如果一个库的备份特别大，或者误操作的时间距离上一个全量备份的时间较长，比如一周一备的</p>
<p>实例，在备份之后的第6天发生误操作，那就需要恢复6天的日志，这个恢复时间可能是要按天</p>
<p>来计算的。那么，我们有什么方法可以缩短恢复数据需要的时间呢？如果有非常核心的业务，不允许太长的恢复时间，我们可以考虑搭建延迟复制的备库。这个功</p>
<p>能是MySQL 5.6版本引入的。一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有</p>
<p>从库，进而导致所有从库的数据表也都一起被误删了。延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY &#x3D; N命令，</p>
<p>可以指定这个备库持续保持跟主库有N秒的延迟。比如你把N设置为3600，这就代表了如果主库上有数据被误删了，并且在1小时内发现了这个误</p>
<p>操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop</p>
<p>slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。这样的话，你就随时可以得到一个，只需要最多再追1小时，就可以恢复出数据的临时实例，也</p>
<p>就缩短了整个数据恢复需要的时间。预防误删库&#x2F;表的方法</p>
<p>虽然常在河边走，很难不湿鞋，但终究还是可以找到一些方法来避免的。所以这里，我也会给你</p>
<p>一些减少误删操作风险的建议。第一条建议是，账号分离。这样做的目的是，避免写错命令。比如：</p>
<p>我们只给业务开发同学DML权限，而不给truncate&#x2F;drop权限。而如果业务开发人员有DDL需</p>
<p>求的话，也可以通过开发管理系统得到支持。即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账</p>
<p>号。第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。比如：</p>
<p>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后</p>
<p>再删除这张表。改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须</p>
<p>通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。rm删除数据</p>
<p>其实，对于一个有高可用机制的MySQL集群来说，最不怕的就是rm删除数据了。只要不是恶意</p>
<p>地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA系统就会开始工作，选出一</p>
<p>个新的主库，从而保证整个集群的正常工作。这时，你要做的就是在这个节点上把数据恢复回来，再接入整个集群。当然了，现在不止是DBA有自动化系统，SA（系统管理员）也有自动化系统，所以也许一个批</p>
<p>量下线机器的操作，会让你整个MySQL集群的所有节点都全军覆没。应对这种情况，我的建议只能是说尽量把你的备份跨机房，或者最好是跨城市保存。小结</p>
<p>今天，我和你讨论了误删数据的几种可能，以及误删后的处理方法。但，我要强调的是，预防远比处理的意义来得大。另外，在MySQL的集群方案中，会时不时地用到备份来恢复实例，因此定期检查备份的有效性</p>
<p>也很有必要。如果你是业务开发同学，你可以用show grants命令查看账户的权限，如果权限过大，可以建议</p>
<p>DBA同学给你分配权限低一些的账号；你也可以评估业务的重要性，和DBA商量备份的周期、</p>
<p>是否有必要创建延迟复制的备库等等。数据和服务的可靠性不止是运维团队的工作，最终是各个环节一起保障的结果。今天的课后话题是，回忆下你亲身经历过的误删数据事件吧，你用了什么方法来恢复数据呢？你</p>
<p>在这个过程中得到的经验又是什么呢？你可以把你的经历和经验写在留言区，我会在下一篇文章的末尾选取有趣的评论和你一起讨论。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我在上一篇文章给你留的问题，是关于空表的间隙的定义。一个空表就只有一个间隙。比如，在空表上执行：</p>
<p>这个查询语句加锁的范围就是next-key lock (-∞, supremum]。验证方法的话，你可以使用下面的操作序列。你可以在图4中看到显示的结果。begin;</p>
<p>select * from t where id&gt;1 for update;</p>
<p>图3 复现空表的next-key lock</p>
<p>图4 show engine innodb status 部分结果</p>
<p>评论区留言点赞板：</p>
<p>赞这些思考和反馈。@老杨同志 给出了正确的分析和SQL语句验证方法；</p>
<p>@库淘淘 指出了show engine innodb status验证结论。苍茫   3</p>
<p>有一次，我维护一张表，需要手动修改大量数据的状态，sql就很多，然后我保存到txt文件中以</p>
<p>附件的形式发给部门老大审批，部门老大审批后转发邮件给运维，然后运维这哥们用的是360</p>
<p>浏览器，他预览的sql，然后全部复制到客户端执行，但是问题也在这，360浏览器预览的时候</p>
<p>由于文本偏长，到了某一条语句只有前半部分的update语句，没有后面的条件，然后就悲剧了</p>
<p>。全表的状态都变成同一个。然后我就特别莫名其妙，还被老大批了一顿。说我写的脚本有问</p>
<p>题。这锅我可不背，我把脚本在本地备份库跑了一遍又一遍就是没有问题。然后我再去运维哥</p>
<p>们那，叫他再复制一下脚本就发现问题了。好在执行脚本前进行了表备份。扩展一下，如果你</p>
<p>用谷歌浏览器就不会出现这种问题！发现问题后，立马恢复了数据</p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p>  这个是血泪经验</p>
<p>拷贝文本执行，这个操作还可能存在字符集隐患。这个事情更深一层逻辑，是你做了创造性的事情，非常优秀 。而这个运维同学认为他只是一个”复制粘贴执行的人”， 这种思路下是迟早会出问题的。2019-01-24</p>
<p>linhui0705   1</p>
<p>对生产数据库操作，公司DBA提出的编写脚本方法，个人觉得还是值得分享，虽说可能大部分</p>
<p>公司也可能有这样的规范。修改生产的数据，或者添加索引优化，都要先写好四个脚本：备份脚本、执行脚本、验证脚本</p>
<p>和回滚脚本。备份脚本是对需要变更的数据备份到一张表中，固定需要操作的数据行，以便误</p>
<p>操作或业务要求进行回滚；执行脚本就是对数据变更的脚本，为防Update错数据，一般连备份</p>
<p>表进行Update操作；验证脚本是验证数据变更或影响行数是否达到预期要求效果；回滚脚本就</p>
<p>是将数据回滚到修改前的状态。虽说分四步骤写脚本可能会比较繁琐，但是这能够很大程度避免数据误操作。2019-01-23</p>
<p> 作者回复</p>
<p>  非常好的经验</p>
<p>如果能够切实执行，即使有出问题，也是可以很快恢复的</p>
<p>把这些脚本当做开发代码来维护，是一个很好的实践</p>
<p>2019-01-23</p>
<p>某、人   9</p>
<p>总结下今天的知识点:</p>
<p>我觉得DBA的最核心的工作就是保证数据的完整性</p>
<p>今天老师也讲到了先要做好预防,预防的话大概是通过这几个点：</p>
<p>1.权限控制与分配(数据库和服务器权限)</p>
<p>精选留言</p>
<p>2.制作操作规范</p>
<p>3.定期给开发进行培训</p>
<p>4.搭建延迟备库</p>
<p>5.做好sql审计,只要是对线上数据有更改操作的语句(DML和DDL)都需要进行审核</p>
<p>6.做好备份。备份的话又分为两个点.</p>
<p>(1)如果数据量比较大,用物理备份xtrabackup。定期对数据库进行全量备份,也可以做增量备份。(2)如果数据量较少,用mysqldump或者mysqldumper。再利用binlog来恢复或者搭建主从的方式</p>
<p>来恢复数据。定期备份binlog文件也是很有必要的</p>
<p>还需要定期检查备份文件是否可用,如果真的发生了误操作,需要恢复数据的时候,发生备份文件</p>
<p>不可用,那就更悲剧了</p>
<p>如果发生了数据删除的操作,又可以从以下几个点来恢复:</p>
<p>1.DML误操作语句造成数据不完整或者丢失。可以通过flashback,不过我们目前用的是美团的m</p>
<p>yflash,也是一个不错的工具，本质都差不多.都是先解析binlog event,然后在进行反转。把delete</p>
<p>反转为insert,insert反转为delete,update前后image对调。所以必须设置binlog_format&#x3D;row 和 bi</p>
<p>nlog_row_image&#x3D;full.</p>
<p>切记恢复数据的时候,应该先恢复到临时的实例,然后在恢复回主库上。2.DDL语句误操作(truncate和drop),由于DDL语句不管binlog_format是row还是statement.在binl</p>
<p>og里都只记录语句,不记录image所以恢复起来相对要麻烦得多。只能通过全量备份+应用binlog</p>
<p>的方式来恢复数据。一旦数据量比较大,那么恢复时间就特别长,</p>
<p>对业务是个考验。所以就涉及到老师在第二讲提到的问题了，全量备份的周期怎么去选择</p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p> </p>
<p>2019-01-23</p>
<p>亮   2</p>
<p>CREATE TABLE <code>t</code> (</p>
<p><code>id</code> int(11) NOT NULL,</p>
<p><code>city</code> varchar(16) NOT NULL,</p>
<p><code>name</code> varchar(16) NOT NULL,</p>
<p><code>age</code> int(11) NOT NULL,</p>
<p><code>addr</code> varchar(128) DEFAULT NULL,</p>
<p>PRIMARY KEY (<code>id</code>),</p>
<p>KEY <code>city</code> (<code>city</code>)</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>老师请教您16章的问题，您提到“city、name、age 这三个字段的定义总长度是36”，这个是怎</p>
<p>么算出来的呢，varchar(16)是可以保存16个字符，占用了49个字节（utf8），所以我没想明白3</p>
<p>6是怎么来的。第二个问题是max_length_for_sort_data参数系统默认是1024，是1024个字节的意思吗？2019-01-23</p>
<p>  作者回复</p>
<ol>
<li><p>age(11)其实是4个字节哈</p>
</li>
<li><p>对，单位是字节</p>
</li>
</ol>
<p>谢谢老师，不过还是没明白，age是4个字节，city和name分别是49个字节，49+49+4&#x3D;102字节</p>
<p>，36是怎么来的呢？再次感谢</p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p>哦 抱歉哈，我这边验证的时候默认用的latin1，是16+16+4</p>
<p>2019-01-23</p>
<p>技术人成长   1</p>
<p>我只想说，作者功力过于深厚了！</p>
<p>2019-01-25</p>
<p>Cranliu   1</p>
<p>个人觉得，预防同样很重要，一般的dml操作，我是先ctas要操作的数据，drop&#x2F;truncate 的时候</p>
<p>先逻辑备份。2019-01-23</p>
<p> 作者回复</p>
<p>对的，备份的意识很重要。不过“drop&#x2F;truncate 的时候先逻辑备份”这么做的不多^_^ </p>
<p>主要的原因是逻辑备份可能会对系统有额外消耗。（全表扫描）</p>
<p>2019-01-23</p>
<p>511   1</p>
<p>早~</p>
<p>2019-01-23</p>
<p>Long   0</p>
<p>又到了讲故事(事故)的时候了，历史上遇到过很多次事故。全表误删除，误更新不下于8次，有</p>
<p>MySQL 的DB也有memory DB. 有一次同事比较搞笑的是，有一次一张重要的权限控制表更新</p>
<p>，由于用的是workbench 界面工具当时写了where条件，但是在选中执行行的时候where条件在</p>
<p>第二行，没选中，还在执行前的时候手动把session 级的sql_safe_updates&#x3D;0了，也没有点开那</p>
<p>个autocommit取消的按钮。然后一执行，全表更新了，导致全网只有一个用户可以正常登录。还有其他的误操作，总结历史遇到过的这类问题基本就是几类</p>
<ol>
<li>登错环境，以为是测试环境，一顿操作猛如虎，一看环境是生产，回头一看，表已经drop了</li>
</ol>
<p>……</p>
<ol start="2">
<li>sql写的有问题，逻辑错误，或者条件缺失，常见的如不带where；or关键字的逻辑没有用括</li>
</ol>
<p>号括好</p>
<ol start="3">
<li>还有一些奇葩的，比如where 字段1&#x3D;字段2写成了字段1+字段2，逻辑等于判断变成了是否为</li>
</ol>
<p>1的判断了，大概率全表更新了。错误解决大部分都是用备份恢复或者根据错误的逻辑来逻辑恢复。还有一个，最近在尝试的，就是ibd文件中有坏页，只要一读到那个坏页，就会crash，报错spa</p>
<p>ceid page no should be多少多少，尝试了copy frm, ibd，ibdata, iblogfile这些表结构，数据文件</p>
<p>，数据字典，undo redo 日志，也尝试用了undrop的工具也解析不出来。这个表比较特殊，是</p>
<p>一个特殊库，没备份，表没有索引没法通过走索引跳过那个坏页的那些行，现在的状态是，只</p>
<p>能用nysqldump恢复一部分数据。 我想通过16进制，自己慢慢找到那个脏写的数据，然后修改</p>
<p>一下文件……</p>
<p>老师有什么比较好的建议吗？或者后面会说到ibd文件的物理结构之类的吗？ 感谢</p>
<p>2019-01-28</p>
<p> 作者回复</p>
<p>感谢你的分享，都是血泪教训。。我看有几个是用的可视化工具导致的，后面还是尽量用MySQL客户端敲命令吧 </p>
<p>ibd文件坏页我之前有回答过其他同学的，看下这个</p>
<p><a target="_blank" rel="noopener" href="https://weibo.com/1933424965/H3qIu0JYo?from=page_1005051933424965_profile&wvr=6&mo">https://weibo.com/1933424965/H3qIu0JYo?from=page_1005051933424965_profile&amp;wvr=6&amp;mo</a></p>
<p>d&#x3D;weibotime</p>
<p>2019-01-28</p>
<p>PengfeiWang   0</p>
<p>老师，您好，有个问题请教一下：</p>
<p>关于MySQL备份有效性的验证，你有什么好的方法可以推荐吗？目前只能通过不定期的备份恢</p>
<p>复来验证。2019-01-25</p>
<p> 作者回复</p>
<p>大家都是这么做的 </p>
<p>2019-01-25</p>
<p>AI杜嘉嘉   0</p>
<p>老师，接着上面问题。是删表，线上rename，有什么风险吗？需要注意什么？rename是不是d</p>
<p>dl操作</p>
<p>2019-01-25</p>
<p> 作者回复</p>
<p>是，不过rename的执行速度很快</p>
<p>2019-01-25</p>
<p>还一棵树   0</p>
<p>我遇到过一个线上误truncate表的，最终选择的处理过程如下：</p>
<p>1、创建一个同版本的空mysql实例，建一个名字+结构一模一样的表</p>
<p>2、discard这个表的tablespace</p>
<p>3、从之前的备份集中 innobackupex –apply-log 并记录binlog位置（用innobackupex备份的）</p>
<p>。还原后找到误操作表的.ibd文件，copy到新实例对应的位置</p>
<p>4、在之前创建的mysql实例上import tablespace</p>
<p>5、利用mysqlbinlog 处理增量数据</p>
<p>6、最后导出 再导入</p>
<p>2019-01-24</p>
<p> 作者回复</p>
<p> </p>
<p>这基本上是最快的恢复步骤了</p>
<p>2019-01-24</p>
<p>苍茫   0</p>
<p>有一次我在查询数据倒数报表给业务方，那个脚本是我写的，关联了很多表，还跨了库，一个</p>
<p>主表有一万多条纪录，关联另一张操作记录表好像是10万条数据。因为要统计多步操作步骤，</p>
<p>所以每一步的操作记录我就得按照不同的条件关联产生临时表（关联中有group 还有max（）</p>
<p>聚合函数，这个是需求导致的），一开始写好的查询很快有了结果。那天11点多的时候，我执</p>
<p>行那个脚本，发现很慢没有反应，然后我就把连接关了，重复几次操作，然后生产库就被我搞</p>
<p>挂了。后面运维的同学操作了一波才恢复过来。这次也是运维同学背的锅。后面，还把我的操</p>
<p>作给贴出来了，做通报批评。我想问下为啥会出现这种情况呢？后续我的组长对我写的sql进行了优化，主要是把联表操作需要的信息放在子查询中，然后再操</p>
<p>作记录表中加了索引，有了备份库，每次执行脚本导出数据都是在备份库中导出，就再也没有</p>
<p>发生这个问题了。2019-01-24</p>
<p> 作者回复</p>
<p>后面有一篇专门说这个，敬请期待哈</p>
<p>2019-01-24</p>
<p>xishuai   0</p>
<p>老师，麻烦问一下，5.7.21上innodb的表两列（有中文有英文）建的全文索引，最小分词1，按</p>
<p>中文可以查询，按英文有些查询不出来，您知道原因吗？2019-01-24</p>
<p> 作者回复</p>
<p>全文索引有stop words的，你看看是不是落在stop words里了</p>
<p>2019-01-24</p>
<p>catalina   0</p>
<p>老师，我们现在需要将一个库下面的所有表的数据同步到另外一个库，每个表有几百万数据吧</p>
<p>，大约十多张表。有什么好的方法吗？2019-01-24</p>
<p> 作者回复</p>
<p>原库的这几个表还会继续更新吗？ 如果会继续更新，就用搭主备的方法；</p>
<p>如果没更新了，后面有一个文章专门讲这个问题哈</p>
<p>2019-01-24</p>
<p>hua168   0</p>
<p>大神，有亲戚小公司搞DBA一年，我想问一下：</p>
<p>1.DBA一般发展方向是怎样的呀？运维和开发我了解，DBA没接触过，无法给建议，一般的升</p>
<p>级过程是怎样的？2.以后发展方向是怎样？现在都是开源、大数据时代时代，阿里又搞“去IOE”，一般oracle DBA</p>
<p>发展前景不好吧？能帮指一个大概的方向吗？谢谢~~</p>
<p>2019-01-24</p>
<p>aliang   0</p>
<p>老师好。这是第6讲评论区Tony Du的评论：</p>
<p>session A: begin; select * from t limit 1; 最先启动sessionA</p>
<p>session B: begin; select * from t limit 1; 紧接着启动sessionB</p>
<p>session C: alter table t add f int; 然后再是启动sessionC</p>
<p>session D: begin; select * from t limit 1; 最后是启动sessionD</p>
<p>他说session C会被A和B阻塞，D会被C阻塞；当A和B提交后，D是可以继续执行得到查询结果</p>
<p>的，但是C仍然被阻塞，只有D提交后C才能执行成功。我自己在5.6和5.7按他的步骤做了试验</p>
<p>，结果和他一样。然后我再做了一次试验，这次把D的begin;去掉，变成了：</p>
<p>session A: begin; select * from t limit 1; 最先启动sessionA</p>
<p>session B: begin; select * from t limit 1; 紧接着启动sessionB</p>
<p>session C: alter table t add f int; 然后再是启动sessionC</p>
<p>session D: select * from t limit 1; 最后是启动sessionD</p>
<p>结果是当A和B提交后，D和C都能执行成功了（和老师的结果一样）。我的问题是：为什么第</p>
<p>一次session D显式开启事务，和第二次不显式开启的结果不一样呢？2019-01-24</p>
<p> 作者回复</p>
<p>可否贴一下你的show variables 的结果，我这边验证（不论D有没有加begin）的效果都是你说</p>
<p>的第二次的情况哦</p>
<p>2019-02-04</p>
<p>太福   0</p>
<p>因为时间原因，前面的课程没跟上，在这里请教个最近线上mysql遇到的问题：</p>
<p>一个从库mysql5.6版本,正常情况下只有3到5个并发sql在查询，每分钟用下面的sql查看一次检</p>
<p>测到的</p>
<p>SELECT t1.* FROM information_schema.<code>PROCESSLIST</code> t1 WHERE info is not null ORDER</p>
<p>BY time desc;</p>
<p>前一次检测还是几个sql在查询，下1分钟查到2000多个sql在跑，很多堆积了几十秒的sql，状态</p>
<p>“Sending data” “Creating sort index”</p>
<p>，而这些sql在正常情况下是不到1秒就查到结果了的，且cpu使用率与io很低，看起来mysql僵</p>
<p>死的了。有两个问题：1）问题突然出现</p>
<p>2）大量sql在跑，而cpu与磁盘io反而比正常下降；这是从库，写只有主从同步，其它都是读查</p>
<p>询。配置：64G内存，bp分配40G，io使用不高</p>
<p>,业务量没大变动，也没新版本发布，大体排除业务并发加大导致的。2019-01-24</p>
<p> 作者回复</p>
<p>这个不算突然出现吧，你两次检测之间是1分钟是吧？你这样说我看不太明白，可否给一个当时的show processlist的截图；</p>
<p>你还能执行show processlist，就不能算”僵死“；</p>
<p>io的状态如果有保存，也贴一下当时的iostat的结果；</p>
<p>可以发个微博附图，然后地址发到评论区哈</p>
<p>2019-02-01</p>
<p>风二中   0</p>
<p>老师，您好。如何设置binlog 的备份时间呢，感觉RPO 时间总是不能为零，如果是informix 可</p>
<p>以只丢一个逻辑日志。对于需要保证mysql恢复 RPO 时间为零，有什么建议吗？备库延迟1小</p>
<p>时，加每小时备份一次binlog 。2019-01-23</p>
<p> 作者回复</p>
<p>嗯 对于核心业务，使用延迟复制的备份</p>
<p>RPO时间为0？有这么凶残的业务需求吗。。我能想到的就是多套延迟备份的库。比如开3个， 一个是10分钟，一个20分钟，一个30分钟（主要考虑成本）</p>
<p>RPO这么敏感的，应该有对应敏感的监控，误操作要是30分钟还不能发现，可以挑战一下，这</p>
<p>个业务是不是值得这么高的指标^_^</p>
<p>2019-01-23</p>
<p>700   0</p>
<p>老师，请教。假如我有数据库的物理备份和逻辑备份（mydumper），因为 mydumper 导出的</p>
<p>数据是按表名分开存放的，那么表误删数据的时候优先考虑逻辑备份（误删数据表的备份集）</p>
<p>+binlog 恢复比物理备份恢复会快点？基于此，我总感觉物理备份只是在要恢复整个实例时才会</p>
<p>优先考虑，而恢复整个实例的场景又是比较少的，毕竟一般大家的线上架构至少都是主从模式</p>
<p>。所以逻辑备份被物理备份更实用。这种想法算是说得通吗？2019-01-23</p>
<p> 作者回复</p>
<p>其实是要看表的大小</p>
<p>如果是一个大表，逻辑恢复还是比较慢的，毕竟用物理备份来恢复出实例，相对会快些。当然如果你已经有了一个成熟系统用逻辑恢复来实现，也不用改它，主要关注一下是否满足SL</p>
<p>A就可以了^_^</p>
<p>facebook就是主要用逻辑备份的</p>
<p>2019-01-23</p>
<p>高强   0</p>
<p>老师你好，问个带子查询的delete&#x2F;update&#x2F;insert问题，Delete from A where name in( </p>
<p>Select name from B where time&lt;’2019-01-23 11:11:12’ </p>
<p>) 这条语句删除A表记录之前是不是也会把表 B满足条件的记录也会给锁住呢?</p>
<p>我试验了一下会锁住B表记录的，有没有其他办法不让锁B表呢?</p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p>改成RC隔离级别试试</p>
<p>2019-01-23</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/90c350b7.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/90c350b7.html" class="post-title-link" itemprop="url">mysql-答疑文章（二）：用动态的观点看加锁</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-05 06:11:28" itemprop="dateCreated datePublished" datetime="2019-12-05T06:11:28+08:00">2019-12-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>27 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>30 | 答疑文章（二）：用动态的观点看加锁</p>
<p>2019-01-21 林晓斌</p>
<p>在第20和21篇文章中，我和你介绍了InnoDB的间隙锁、next-key lock，以及加锁规则。在这两</p>
<p>篇文章的评论区，出现了很多高质量的留言。我觉得通过分析这些问题，可以帮助你加深对加锁</p>
<p>规则的理解。所以，我就从中挑选了几个有代表性的问题，构成了今天这篇答疑文章的主题，即：用动态的观</p>
<p>点看加锁。为了方便你理解，我们再一起复习一下加锁规则。这个规则中，包含了两个“原则”、两</p>
<p>个“优化”和一个“bug”：</p>
<p>原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。原则2：查找过程中访问到的对象才会加锁。优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock</p>
<p>退化为间隙锁。一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。接下来，我们的讨论还是基于下面这个表t：</p>
<p>不等号条件里的等值查询</p>
<p>有同学对“等值查询”提出了疑问：等值查询和“遍历”有什么区别？为什么我们文章的例子里</p>
<p>面，where条件是不等号，这个过程里也有等值查询？我们一起来看下这个例子，分析一下这条查询语句的加锁范围：</p>
<p>利用上面的加锁规则，我们知道这个语句的加锁范围是主键索引上的 (0,5]、(5,10]和(10, 15)。也</p>
<p>就是说，id&#x3D;15这一行，并没有被加上行锁。为什么呢？我们说加锁单位是next-key lock，都是前开后闭区间，但是这里用到了优化2，即索引上的等值</p>
<p>查询，向右遍历的时候id&#x3D;15不满足条件，所以next-key lock退化为了间隙锁 (10, 15)。但是，我们的查询语句中where条件是大于号和小于号，这里的“等值查询”又是从哪里来的呢？要知道，加锁动作是发生在语句执行过程中的，所以你在分析加锁行为的时候，要从索引上的数</p>
<p>据结构开始。这里，我再把这个过程拆解一下。如图1所示，是这个表的索引id的示意图。CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  &#96;d  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀,</p>
<p>  KEY &#96;c  ̀(̀ c )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>insert into t values(0,0,0),(5,5,5),</p>
<p>(10,10,10),(15,15,15),(20,20,20),(25,25,25);</p>
<p>begin;</p>
<p>select * from t where id&gt;9 and id&lt;12 order by id desc for update;</p>
<p>图1 索引id示意图</p>
<ol>
<li>首先这个查询语句的语义是order by id desc，要拿到满足条件的所有行，优化器必须先找</li>
</ol>
<p>到“第一个id&lt;12的值”。2. 这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到id&#x3D;12的这个值，只</p>
<p>是最终没找到，但找到了(10,15)这个间隙。3. 然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到id&#x3D;5这一行，所以会加一个</p>
<p>next-key lock (0,5]。也就是说，在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法。等值查询的过程</p>
<p>与上面这个例子对应的，是@发条橙子同学提出的问题：下面这个语句的加锁范围是什么？这条查询语句里用的是in，我们先来看这条语句的explain结果。begin;</p>
<p>select id from t where c in(5,20,10) lock in share mode;</p>
<p>图2 in语句的explain结果</p>
<p>可以看到，这条in语句使用了索引c并且rows&#x3D;3，说明这三个值都是通过B+树搜索定位的。在查找c&#x3D;5的时候，先锁住了(0,5]。但是因为c不是唯一索引，为了确认还有没有别的记录c&#x3D;5，</p>
<p>就要向右遍历，找到c&#x3D;10才确认没有了，这个过程满足优化2，所以加了间隙锁(5,10)。同样的，执行c&#x3D;10这个逻辑的时候，加锁的范围是(5,10] 和 (10,15)；执行c&#x3D;20这个逻辑的时</p>
<p>候，加锁的范围是(15,20] 和 (20,25)。通过这个分析，我们可以知道，这条语句在索引c上加的三个记录锁的顺序是：先加c&#x3D;5的记录</p>
<p>锁，再加c&#x3D;10的记录锁，最后加c&#x3D;20的记录锁。你可能会说，这个加锁范围，不就是从(5,25)中去掉c&#x3D;15的行锁吗？为什么这么麻烦地分段说</p>
<p>呢？因为我要跟你强调这个过程：这些锁是“在执行过程中一个一个加的”，而不是一次性加上去的。理解了这个加锁过程之后，我们就可以来分析下面例子中的死锁问题了。如果同时有另外一个语句，是这么写的：</p>
<p>此时的加锁范围，又是什么呢？我们现在都知道间隙锁是不互锁的，但是这两条语句都会在索引c上的c&#x3D;5、10、20这三行记录</p>
<p>上加记录锁。这里你需要注意一下，由于语句里面是order by c desc， 这三个记录锁的加锁顺序，是先锁</p>
<p>c&#x3D;20，然后c&#x3D;10，最后是c&#x3D;5。也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，</p>
<p>就可能出现死锁。关于死锁的信息，MySQL只保留了最后一个死锁的现场，但这个现场还是不完备的。有同学在评论区留言到，希望我能展开一下怎么看死锁。现在，我就来简单分析一下上面这个例</p>
<p>子的死锁现场。select id from t where c in(5,20,10) order by c desc for update;</p>
<p>怎么看死锁？图3是在出现死锁后，执行show engine innodb status命令得到的部分输出。这个命令会输出很</p>
<p>多信息，有一节LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息。图3 死锁现场</p>
<p>我们来看看这图中的几个关键信息。1. 这个结果分成三部分：</p>
<p>(1) TRANSACTION，是第一个事务的信息；</p>
<p>(2) TRANSACTION，是第二个事务的信息；</p>
<p>WE ROLL BACK TRANSACTION (1)，是最终的处理结果，表示回滚了第一个事务。2. 第一个事务的信息中：</p>
<p>WAITING FOR THIS LOCK TO BE GRANTED，表示的是这个事务在等待的锁信息；</p>
<p>index c of table t̀est .̀̀ t&#96;，说明在等的是表t的索引c上面的锁；</p>
<p>lock mode S waiting 表示这个语句要自己加一个读锁，当前的状态是等待中；</p>
<p>Record lock说明这是一个记录锁；</p>
<p>n_fields 2表示这个记录是两列，也就是字段c和主键字段id；</p>
<p>0: len 4; hex 0000000a; asc ;;是第一个字段，也就是c。值是十六进制a，也就是10；</p>
<p>1: len 4; hex 0000000a; asc ;;是第二个字段，也就是主键id，值也是10；</p>
<p>这两行里面的asc表示的是，接下来要打印出值里面的“可打印字符”，但10不是可打印</p>
<p>字符，因此就显示空格。第一个事务信息就只显示出了等锁的状态，在等待(c&#x3D;10,id&#x3D;10)这一行的锁。当然你是知道的，既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出</p>
<p>来。别着急，我们从第二个事务的信息中推导出来。3. 第二个事务显示的信息要多一些：</p>
<p>“ HOLDS THE LOCK(S)”用来显示这个事务持有哪些锁；</p>
<p>index c of table t̀est .̀̀ t  ̀表示锁是在表t的索引c上；</p>
<p>hex 0000000a和hex 00000014表示这个事务持有c&#x3D;10和c&#x3D;20这两个记录锁；</p>
<p>WAITING FOR THIS LOCK TO BE GRANTED，表示在等(c&#x3D;5,id&#x3D;5)这个记录锁。从上面这些信息中，我们就知道：</p>
<ol>
<li><p>“lock in share mode”的这条语句，持有c&#x3D;5的记录锁，在等c&#x3D;10的锁；</p>
</li>
<li><p>“for update”这个语句，持有c&#x3D;20和c&#x3D;10的记录锁，在等c&#x3D;5的记录锁。因此导致了死锁。这里，我们可以得到两个结论：</p>
</li>
<li><p>由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；</p>
</li>
<li><p>在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以InnoDB选</p>
</li>
</ol>
<p>择了回滚成本更小的lock in share mode语句，来回滚。怎么看锁等待？看完死锁，我们再来看一个锁等待的例子。在第21篇文章的评论区，@Geek_9ca34e 同学做了一个有趣验证，我把复现步骤列出来：</p>
<p>图4 delete导致间隙变化</p>
<p>可以看到，由于session A并没有锁住c&#x3D;10这个记录，所以session B删除id&#x3D;10这一行是可以</p>
<p>的。但是之后，session B再想insert id&#x3D;10这一行回去就不行了。现在我们一起看一下此时show engine innodb status的结果，看看能不能给我们一些提示。锁信</p>
<p>息是在这个命令输出结果的TRANSACTIONS这一节。你可以在文稿中看到这张图片</p>
<p>图 5 锁等待信息</p>
<p>我们来看几个关键信息。1. index PRIMARY of table t̀est .̀̀ t  ̀，表示这个语句被锁住是因为表t主键上的某个锁。2. lock_mode X locks gap before rec insert intention waiting 这里有几个信息：</p>
<p>insert intention表示当前线程准备插入一个记录，这是一个插入意向锁。为了便于理</p>
<p>解，你可以认为它就是这个插入动作本身。gap before rec 表示这是一个间隙锁，而不是记录锁。3. 那么这个gap是在哪个记录之前的呢？接下来的0~4这5行的内容就是这个记录的信息。4. n_fields 5也表示了，这一个记录有5列：</p>
<p>0: len 4; hex 0000000f; asc ;;第一列是主键id字段，十六进制f就是id&#x3D;15。所以，这时我</p>
<p>们就知道了，这个间隙就是id&#x3D;15之前的，因为id&#x3D;10已经不存在了，它表示的就是</p>
<p>(5,15)。1: len 6; hex 000000000513; asc ;;第二列是长度为6字节的事务id，表示最后修改这一</p>
<p>行的是trx id为1299的事务。2: len 7; hex b0000001250134; asc % 4;; 第三列长度为7字节的回滚段信息。可以看</p>
<p>到，这里的acs后面有显示内容(%和4)，这是因为刚好这个字节是可打印字符。后面两列是c和d的值，都是15。因此，我们就知道了，由于delete操作把id&#x3D;10这一行删掉了，原来的两个间隙(5,10)、(10,15）</p>
<p>变成了一个(5,15)。说到这里，你可以联合起来再思考一下这两个现象之间的关联：</p>
<ol>
<li><p>session A执行完select语句后，什么都没做，但它加锁的范围突然“变大”了；</p>
</li>
<li><p>第21篇文章的课后思考题，当我们执行select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c</p>
</li>
</ol>
<p>desc lock in share mode; 向左扫描到c&#x3D;10的时候，要把(5, 10]锁起来。也就是说，所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。update的例子</p>
<p>看过了insert和delete的加锁例子，我们再来看一个update语句的案例。在留言区中@信信 同学</p>
<p>做了这个试验：</p>
<p>图 6 update 的例子</p>
<p>你可以自己分析一下，session A的加锁范围是索引c上的 (5,10]、(10,15]、(15,20]、(20,25]和</p>
<p>(25,supremum]。之后session B的第一个update语句，要把c&#x3D;5改成c&#x3D;1，你可以理解为两步：</p>
<ol>
<li><p>插入(c&#x3D;1, id&#x3D;5)这个记录；</p>
</li>
<li><p>删除(c&#x3D;5, id&#x3D;5)这个记录。按照我们上一节说的，索引c上(5,10)间隙是由这个间隙右边的记录，也就是c&#x3D;10定义的。所以</p>
</li>
</ol>
<p>通过这个操作，session A的加锁范围变成了图7所示的样子：</p>
<p>注意：根据c&gt;5查到的第一个记录是c&#x3D;10，因此不会加(0,5]这个next-key lock。图 7 session B修改后， session A的加锁范围</p>
<p>好，接下来session B要执行 update t set c &#x3D; 5 where c &#x3D; 1这个语句了，一样地可以拆成两步：</p>
<ol>
<li><p>插入(c&#x3D;5, id&#x3D;5)这个记录；</p>
</li>
<li><p>删除(c&#x3D;1, id&#x3D;5)这个记录。第一步试图在已经加了间隙锁的(1,10)中插入数据，所以就被堵住了。小结</p>
</li>
</ol>
<p>今天这篇文章，我用前面第20和第21篇文章评论区的几个问题，再次跟你复习了加锁规则。并</p>
<p>且，我和你重点说明了，分析加锁范围时，一定要配合语句执行逻辑来进行。在我看来，每个想认真了解MySQL原理的同学，应该都要能够做到：通过explain的结果，就能</p>
<p>够脑补出一个SQL语句的执行流程。达到这样的程度，才算是对索引组织表、索引、锁的概念有</p>
<p>了比较清晰的认识。你同样也可以用这个方法，来验证自己对这些知识点的掌握程度。在分析这些加锁规则的过程中，我也顺便跟你介绍了怎么看show engine innodb status输出结果</p>
<p>中的事务信息和死锁信息，希望这些内容对你以后分析现场能有所帮助。老规矩，即便是答疑文章，我也还是要留一个课后问题给你的。上面我们提到一个很重要的点：所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义</p>
<p>的。那么，一个空表有间隙吗？这个间隙是由谁定义的？你怎么验证这个结论呢？你可以把你关于分析和验证方法写在留言区，我会在下一篇文章的末尾和你讨论这个问题。感谢</p>
<p>你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>我在上一篇文章最后留给的问题，是分享一下你关于业务监控的处理经验。在这篇文章的评论区，很多同学都分享了不错的经验。这里，我就选择几个比较典型的留言，和</p>
<p>你分享吧：</p>
<p>@老杨同志 回答得很详细。他的主要思路就是关于服务状态和服务质量的监控。其中，服务</p>
<p>状态的监控，一般都可以用外部系统来实现；而服务的质量的监控，就要通过接口的响应时</p>
<p>间来统计。@Ryoma 同学，提到服务中使用了healthCheck来检测，其实跟我们文中提到的select 1的模</p>
<p>式类似。@强哥 同学，按照监控的对象，将监控分成了基础监控、服务监控和业务监控，并分享了每</p>
<p>种监控需要关注的对象。这些都是很好的经验，你也可以根据具体的业务场景借鉴适合自己的方案。令狐少侠   2</p>
<p>有个问题想确认下，在死锁日志里，lock_mode X waiting是间隙锁+行锁，lock_mode X locks </p>
<p>rec but not gap这种加but not gap才是行锁？老师你后面能说下group by的原理吗，我看目录里面没有</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>对， 好问题</p>
<p>lock_mode X waiting表示next-key lock；</p>
<p>lock_mode X locks rec but not gap是只有行锁；</p>
<p>还有一种 “locks gap before rec”，就是只有间隙锁；</p>
<p>2019-01-23</p>
<p>Ryoma   2</p>
<p>删除数据，导致锁扩大的描述：“因此，我们就知道了，由于 delete 操作把 id&#x3D;10 这一行删掉了</p>
<p>，原来的两个间隙 (5,10)、(10,15）变成了一个 (5,15)。”</p>
<p>我觉得这个提到的(5, 10) 和 (10, 15)两个间隙会让人有点误解，实际上在删除之前间隙锁只有</p>
<p>一个(10, 15)，删除了数据之后，导致间隙锁左侧扩张成了5，间隙锁成为了(5, 15)。2019-01-22</p>
<p> 作者回复</p>
<p>嗯 所以我这里特别小心地没有写“锁“这个字。间隙 (5,10)、(10,15）是客观存在的。你提得也很对，“锁”是执行过程中才加的，是一个动态的概念。这个问题也能够让大家更了解我们标题的意思，置顶了哈  </p>
<p>2019-01-22</p>
<p>    1</p>
<p>老师好：</p>
<p>select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc for update;</p>
<p>为什么这种c&#x3D;20就是用来查数据的就不是向右遍历</p>
<p>select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 这种就是向右遍历</p>
<p>怎么去判断合适是查找数据，何时又是遍历呢，是因为第一个有order by desc，然后反向向左</p>
<p>遍历了吗？所以只需要[20,25)来判断已经是最后一个20就可以了是吧</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>索引搜索就是 “找到第一个值，然后向左或向右遍历”，</p>
<p>order by desc 就是要用最大的值来找第一个；</p>
<p>精选留言</p>
<p>order by就是要用做小的值来找第一个；</p>
<p>“所以只需要[20,25)来判断已经是最后一个20就可以了是吧”，</p>
<p>你描述的意思是对的，但是在MySQL里面不建议写这样的前闭后开区间哈，容易造成误解。可以描述为：</p>
<p>“取第一个id&#x3D;20后，向右遍历(25,25)这个间隙”^_^</p>
<p>2019-01-22</p>
<p>老杨同志   1</p>
<p>先说结论：空表锁 (-supernum，supernum],老师提到过mysql的正无穷是supernum，在没有数</p>
<p>据的情况下，next-key lock 应该是supernum前面的间隙加 supernum的行锁。但是前开后闭的</p>
<p>区间，前面的值是什么我也不知道，就写了一个-supernum。稍微验证一下</p>
<p>session 1）</p>
<p>begin;</p>
<p>select * from t where id&gt;9 for update;</p>
<p>session 2）</p>
<p>begin;</p>
<p>insert into t values(0,0,0),(5,5,5);</p>
<p>（block）</p>
<p>2019-01-21</p>
<p> 作者回复</p>
<p>赞</p>
<p>show engine innodb status 有惊喜 </p>
<p>2019-01-21</p>
<p>Long   0</p>
<p>感觉这篇文章以及前面加锁的文章，提升了自己的认知。还有，谢谢老师讲解了日志的对应细</p>
<p>节……还愿了</p>
<p>2019-01-28</p>
<p> 作者回复</p>
<p>   </p>
<p>2019-01-28</p>
<p>滔滔   0</p>
<p>老师，有个疑问，select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc lock in share mode; </p>
<p>向左扫描到 c&#x3D;10 的时候，为什么要把 (5, 10] 锁起来？不锁也不会出现幻读或者逻辑上的不一</p>
<p>致吧 </p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p>会加锁，insert into t values (6,6,6) 被堵住了</p>
<p>2019-01-23</p>
<p>尘封   0</p>
<p>尘封   0</p>
<p>老师，咨询个问题，本来想在后面分区表的文章问，发现大纲里没有分区表这一讲。1，timestamp类型为什么不支持分区？2，前面的文章讲过分区不要太多，这个多了会怎么样？比如一个表一千多个分区</p>
<p>谢谢</p>
<p>2019-01-23</p>
<p> 作者回复</p>
<p>会讲的哈~</p>
<p>新春快乐~</p>
<p>2019-02-04</p>
<p>长杰   0</p>
<p>老师，还是select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc in share mode与select * fro</p>
<p>m t where id&gt;10 and id&lt;&#x3D;15 for update的问题，为何select * from t where id&gt;10 and id&lt;&#x3D;15 for </p>
<p>update不能解释为：根据id&#x3D;15来查数据，加锁(15, 20]的时候，可以使用优化2，</p>
<p>这个等值查询是根据什么规则来定的？ 如果select * from t where id&gt;10 and id&lt;&#x3D;15 for update</p>
<p>加上order by id desc是否可以按照id&#x3D;15等值查询，利用优化2？多谢指教。2019-01-22</p>
<p> 作者回复</p>
<ol>
<li><p>代码实现上，传入的就是id&gt;10里面的这个10</p>
</li>
<li><p>可以的，不过因为id是主键，而且id&#x3D;15这一行存在，我觉得用优化1解释更好哦</p>
</li>
</ol>
<p>2019-01-23</p>
<p>堕落天使   0</p>
<p>老师，您好：</p>
<p>我执行“explain select id from t where c in(5,20,10) lock in share mode;” 时，显示的rows对应的</p>
<p>值是4。为什么啊？我的mysql版本是：5.7.23-0ubuntu0.16.04.1，具体sql语句如下：</p>
<p>mysql&gt; select * from t;</p>
<p>+—-+——+——+</p>
<p>| id | c | d |</p>
<p>+—-+——+——+</p>
<p>| 0 | 0 | 0 |</p>
<p>| 5 | 5 | 5 |</p>
<p>| 10 | 10 | 10 |</p>
<p>| 15 | 15 | 15 |</p>
<p>| 20 | 20 | 20 |</p>
<p>| 25 | 25 | 25 |</p>
<p>| 30 | 10 | 30 |</p>
<p>+—-+——+——+</p>
<p>7 rows in set (0.00 sec)</p>
<p>mysql&gt; explain select id from t where c in(5,20,10) lock in share mode;</p>
<p>+—-+————-+——-+————+——-+—————+——+———+——+——+———-+——–</p>
<p>——————+</p>
<p>| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | </p>
<p>Extra |</p>
<p>+—-+————-+——-+————+——-+—————+——+———+——+——+———-+——–</p>
<p>——————+</p>
<p>| 1 | SIMPLE | t | NULL | range | c | c | 5 | NULL | 4 | 100.00 | Using where; Using index |</p>
<p>+—-+————-+——-+————+——-+—————+——+———+——+——+———-+——–</p>
<p>——————+</p>
<p>1 row in set, 1 warning (0.00 sec)</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>你这个例子里面有两行c&#x3D;10</p>
<p>2019-01-23</p>
<p>Ivan   0</p>
<p>Jan 17 23:52:27 prod-mysql-01 kernel: [ pid ] uid tgid total_vm rss cpu oom_adj oom_score_adj</p>
<p>name</p>
<p>Jan 17 23:52:27 prod-mysql-01 kernel: [125254] 0 125254 27087 5 0 0 0 mysqld_safe</p>
<p>Jan 17 23:52:27 prod-mysql-01 kernel: [126004] 498 126004 24974389 22439356 5 0 0 mysqld</p>
<p>Jan 17 23:52:27 prod-mysql-01 kernel: [ 5733] 0 5733 7606586 6077037 7 0 0 mysql</p>
<p>—————————系统日志——————————————————————————–</p>
<p>老师你好，请教一个问题 ，我在mysql服务器上本地登录，执行了一个SQL（select b.id,b.statu</p>
<p>s from rb_bak b where id not in (select id from rb );该语句问了找不同数据， rb和 rb_bak 数据</p>
<p>量均为500万左右），SQL很慢，30分钟也没结果；</p>
<p>在SQL语句执行期间，发生了OOM，mysql服务被kill。查看系统日志发现 mysqld 占用内存基</p>
<p>本没有变，但是本机连接mysql的客户端进程（5733）却占用了内存近20G，这很让人费解，S</p>
<p>QL没有执行完，客户端怎么会占用这么多内存？用其他SQL查询查询不同数据，也就十几条数据，更不可能占用这么多内存呀。还请老师帮忙</p>
<p>分析一下，谢谢。2019-01-22</p>
<p> 作者回复</p>
<p>好问题，第33篇会说到哈</p>
<p>你可以在mysql客户端参数增加 –quick 再试试</p>
<p>2019-01-23</p>
<p>PengfeiWang   0</p>
<p>老师，您好：</p>
<p>对文中以下语句感到有困惑：</p>
<p>我们说加锁单位是 next-key lock，都是前开后闭区，但是这里用到了优化 2，即索引上的等值</p>
<p>查询，向右遍历的时候id&#x3D;15不满足条件，所以 next-key lock 退化为了间隙锁 (10, 15)。SQL语句中条件中使用的是id字段（唯一索引），那么根据加锁规则这里不应该用的是优化 2，</p>
<p>而是优化 1，因为优化1中明确指出给唯一索引加锁，从而优化 2的字面意思来理解，它适用于</p>
<p>普通索引。不知道是不是我理解的不到位？2019-01-22</p>
<p> 作者回复</p>
<p>主要是这里这一行不存在。。如果能够明确找到一行锁住的话，使用优化1就更准确些</p>
<p>2019-01-23</p>
<p>Justin   0</p>
<p>想咨询一下 普通索引 如果索引中包括的元素都相同 在索引中顺序是怎么排解的呢 是按主键排</p>
<p>列的吗 比如(name ,age ) 索引 name age都一样 那索引中会按照主键排序吗？2019-01-22</p>
<p> 作者回复</p>
<p>会的</p>
<p>2019-01-23</p>
<p>ServerCoder   0</p>
<p>林老师我有个问题想请教一下，描述如下，望给予指点，先谢谢了！</p>
<p>环境：虚拟机，CPU 4核，内存8G，系统CentOS7.4，MySQL版本5.6.40</p>
<p>数据库配置：</p>
<p>bulk_insert_buffer_size &#x3D; 256M</p>
<p>sql_mode&#x3D;NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>
<p>secure_file_priv&#x3D;’’</p>
<p>default-storage-engine&#x3D;MYISAM</p>
<p>测试场景修改过的参数(以下这些参数得调整对加载效率没有实质的提升)：</p>
<p>myisam_repair_threads&#x3D;3</p>
<p>myisam_sort_buffer_size&#x3D;256M</p>
<p>net_buffer_length&#x3D;1M</p>
<p>myisam_use_mmap&#x3D;ON</p>
<p>key_buffer_size&#x3D;256M</p>
<p>测试场景：测试程序多线程，通过客户端API，执行load data infile语句加载数据文件</p>
<p>三个线程，三个文件(每个文件100万条数据、150MB)，三张表(表结构相同，字段类型均为整</p>
<p>形，没有定义主键，有一个字段加了非唯一索引)，一一对应进行数据加载，数据库没有使用多</p>
<p>核，而是把一个核心的利用率均分给了三个线程。单个线程加载一个文件大约耗时3秒</p>
<p>单线程加载三个文件到三张表大约耗时9秒</p>
<p>三个线程分别加载三个文件到三张表，则每个线程均耗时大约9秒。从这个效果看，单线程顺序</p>
<p>加载和三线程并发加载耗时相同，没有提升效果。三线程加载过程中查看processlist发现时间主要耗费在了网络读取上。问题：为啥这种场景下MySQL不利用多核？这种并行加载的情况要如何才能让其利用多核，提</p>
<p>升加载速度</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>可以用到多核呀，你是怎么得到 “时间主要耗费在了网络读取上。”这个结论的？另外，把这三个文件先拷贝到数据库本地，然后本地执行load看看什么效果？2019-01-23</p>
<p>慕塔   0</p>
<p>是这样的 假设只有一主一从 1)是集群只有一个sysbench实例，产生的数据流通过中间件，主</p>
<p>机分全部写，和30%的读，另外70%的读全部分给从机。2)有两个sysbench，一个读写加压到</p>
<p>主机，另一个只有加压到从机。主从复制之间通过binlog。问题在1)的QPS累加与2)QPS累加 </p>
<p>意义一样吗 1)的一条事务有读写，而2)的情况，主机与1)一样，从机的读事务与主机里的读不</p>
<p>一样吧 </p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>我觉得这两个对比不太公平^_^</p>
<p>1）的测试可能会出现中间件瓶颈，</p>
<p>a)网络环节中间增加了一跳；</p>
<p>b) 如果是小查询，可能proxy先打到瓶颈</p>
<p>2)的测试结论一般会比1）好些</p>
<p>但是有这个架构，你肯定是从中间件访问数据库的，所以应该以1的测试结果为准</p>
<p>2019-01-23</p>
<p>Jason_鹏   0</p>
<p>最后一个update的例子，为没有加（0，5）的间隙呢？我理解应该是先拿c＝5去b+树搜索，按</p>
<p>照间隙索最右原则，应该会加（0，5]的间隙，然后c＝5不满足大于5条件，根据优化2原则退化</p>
<p>成（0，5）的间隙索，我是这样理解的</p>
<p>2019-01-22</p>
<p> 作者回复</p>
<p>根据c&gt;5查到的第一个记录是c&#x3D;10，因此不会加(0,5]这个next-key lock。你提醒得对，我应该多说明这句， 我加到文稿中啦 </p>
<p>2019-01-22</p>
<p>长杰   0</p>
<p>老师，之前讲这个例子时，select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc in share m</p>
<p>ode;</p>
<p>最右边加的是 (20, 25)的间隙锁，</p>
<p>而这个例子select * from t where id&gt;10 and id&lt;&#x3D;15 for update中，最右边加的是(15,20]的next-k</p>
<p>ey锁，</p>
<p>这两个查询为何最后边一个加的gap锁，一个加的next-key锁，他们都是&lt;&#x3D;的等值范围查询，区</p>
<p>别在哪里？2019-01-22</p>
<p> 作者回复</p>
<p>select * from t where c&gt;&#x3D;15 and c&lt;&#x3D;20 order by c desc in share mode;</p>
<p>这个语句是根据 c&#x3D;20 来查数据的，所以加锁(20,25]的时候，可以使用优化2；</p>
<p>select * from t where id&gt;10 and id&lt;&#x3D;15 for update；</p>
<p>这里的id&#x3D;20，是用“向右遍历”的方式得到的，没有优化，按照“以next-key lock”为加锁单位来执</p>
<p>行</p>
<p>2019-01-22</p>
<p>库淘淘   0</p>
<p>对于问题 我理解是这样 </p>
<p>session 1：</p>
<p>delete from t;</p>
<p>begin; select * from t for update;</p>
<p>session 2:</p>
<p>insert into t values(1,1,1);发生等待</p>
<p>show engine innodb status\G; </p>
<p>…..</p>
<p>——- TRX HAS BEEN WAITING 5 SEC FOR THIS LOCK TO BE GRANTED:</p>
<p>RECORD LOCKS space id 75 page no 3 n bits 72 index PRIMARY of table <code>test</code>.<code>t</code> trx id 75209</p>
<p>0 lock_mode X insert intention waiting</p>
<p>Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0</p>
<p>0: len 8; hex 73757072656d756d; asc supremum;;</p>
<p>其中申请插入意向锁与间隙锁 冲突，supremum这个能否理解为 间隙右边的那个记录</p>
<p>2019-01-21</p>
<p> 作者回复</p>
<p>发现了  </p>
<p>2019-01-22</p>
<p>慕塔   0</p>
<p>大佬 请教下一主多从集群性能测试性能计算问题 如果使用基准测试工具sysbench。数据流有</p>
<p>两种</p>
<ol>
<li></li>
</ol>
<p>sysbench—mycat—mysql主机(读写) TPS QPS1</p>
<p>| |binlog</p>
<p>mysql从机(只读)QPS2</p>
<p>那性能指标 TPS QPS&#x3D;QPS1+QPS2</p>
<ol start="2">
<li></li>
</ol>
<p>sysbench—mysql主机(读写) TPS QPS1</p>
<p>| binlog</p>
<p>sysbench—mysql从机(只读)TPS QPS2</p>
<p>集群性能指标TPS QPS&#x3D;QPS1+QPS2</p>
<p>这两种哪种严谨些啊？mycat的损失忽略。生产中的集群性能怎么算的呢？？？(还是学生 谢谢！)</p>
<p>2019-01-21</p>
<p> 作者回复</p>
<p>TPS就看主库的写入</p>
<p>QPS就看所有从库的读能力加和</p>
<p>不过没看懂你问题中1）和2）的区别 </p>
<p>2019-01-22</p>
<p>HuaMax   0</p>
<p>删除导致锁范围扩大那个例子，id&gt;10 and id&lt;&#x3D;15，锁范围为什么没有10呢？不是应该（5，10]</p>
<p>吗？2019-01-21</p>
<p> 作者回复</p>
<p>不是的，要找id&gt;10的，并没有命中id&#x3D;10哦，你可以理解成就是查到了(10,15)这个间隙</p>
<p>2019-01-21</p>
<p>llx   0</p>
<p>回复@往事随风，顺其自然</p>
<p>前面有解释为什么，这篇文章有更详细的解释。Gap lock 由右值指定的，由于 c 不是唯一键，</p>
<p>需要到10，遍历到10的时候，就把 5-10 锁了</p>
<p>2019-01-21</p>
<p> 作者回复</p>
<p> </p>
<p>2019-01-21</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/e5c71a8.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/e5c71a8.html" class="post-title-link" itemprop="url">mysql-如何判断一个数据库是不是出问题了</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-04 06:04:41" itemprop="dateCreated datePublished" datetime="2019-12-04T06:04:41+08:00">2019-12-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>26 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>29 | 如何判断一个数据库是不是出问题了？2019-01-18 林晓斌</p>
<p>我在第25和27篇文章中，和你介绍了主备切换流程。通过这些内容的讲解，你应该已经很清楚</p>
<p>了：在一主一备的双M架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，</p>
<p>主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出</p>
<p>问题了，由HA系统发起的。这也就引出了我们今天要讨论的问题：怎么判断一个主库出问题了？你一定会说，这很简单啊，连上MySQL，执行个select 1就好了。但是select 1成功返回了，就</p>
<p>表示主库没问题吗？select 1判断</p>
<p>实际上，select 1成功返回，只能说明这个库的进程还在，并不能说明主库没问题。现在，我们</p>
<p>来看一下这个场景。图1 查询blocked</p>
<p>我们设置innodb_thread_concurrency参数的目的是，控制InnoDB的并发线程上限。也就是说，</p>
<p>一旦并发线程数达到这个值，InnoDB在接收到新请求的时候，就会进入等待状态，直到有线程</p>
<p>退出。这里，我把innodb_thread_concurrency设置成3，表示InnoDB只允许3个线程并行执行。而在我</p>
<p>们的例子中，前三个session 中的sleep(100)，使得这三个语句都处于“执行”状态，以此来模拟大</p>
<p>查询。你看到了， session D里面，select 1是能执行成功的，但是查询表t的语句会被堵住。也就是</p>
<p>说，如果这时候我们用select 1来检测实例是否正常的话，是检测不出问题的。在InnoDB中，innodb_thread_concurrency这个参数的默认值是0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的。因为，一个机器的CPU核数有限，线程全冲进来，上下</p>
<p>文切换的成本就会太高。所以，通常情况下，我们建议把innodb_thread_concurrency设置为64~128之间的值。这时，你</p>
<p>一定会有疑问，并发线程上限数设置为128够干啥，线上的并发连接数动不动就上千了。产生这个疑问的原因，是搞混了并发连接和并发查询。set global innodb_thread_concurrency&#x3D;3;</p>
<p>CREATE TABLE t̀  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  &#96;c  ̀int(11) DEFAULT NULL,</p>
<p>  PRIMARY KEY (̀ id )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p> insert into t values(1,1)</p>
<p>并发连接和并发查询，并不是同一个概念。你在show processlist的结果里，看到的几千个连</p>
<p>接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为</p>
<p>并发查询太高才是CPU杀手。这也是为什么我们需要设置innodb_thread_concurrency参数的原</p>
<p>因。然后，你可能还会想起我们在第7篇文章中讲到的热点更新和死锁检测的时候，如果把</p>
<p>innodb_thread_concurrency设置为128的话，那么出现同一行热点更新的问题时，是不是很快就</p>
<p>把128消耗完了，这样整个系统是不是就挂了呢？实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙</p>
<p>锁）的线程是不算在128里面的。MySQL这样设计是非常有意义的。因为，进入锁等待的线程已经不吃CPU了；更重要的是，必</p>
<p>须这么设计，才能避免整个系统锁死。为什么呢？假设处于锁等待的线程也占并发线程的计数，你可以设想一下这个场景：</p>
<ol>
<li>线程1执行begin; update t set c&#x3D;c+1 where id&#x3D;1, 启动了事务trx1， 然后保持这个状态。这时</li>
</ol>
<p>候，线程处于空闲状态，不算在并发线程里面。2. 线程2到线程129都执行 update t set c&#x3D;c+1 where id&#x3D;1; 由于等行锁，进入等待状态。这样</p>
<p>就有128个线程处于等待状态；</p>
<ol start="3">
<li>如果处于锁等待状态的线程计数不减一，InnoDB就会认为线程数用满了，会阻止其他语句</li>
</ol>
<p>进入引擎执行，这样线程1不能提交事务。而另外的128个线程又处于锁等待状态，整个系</p>
<p>统就堵住了。下图2显示的就是这个状态。图2 系统锁死状态（假设等行锁的语句占用并发计数）</p>
<p>这时候InnoDB不能响应任何请求，整个系统被锁死。而且，由于所有线程都处于等待状态，此</p>
<p>时占用的CPU却是0，而这明显不合理。所以，我们说InnoDB在设计时，遇到进程进入锁等待的</p>
<p>情况时，将并发线程的计数减1的设计，是合理而且是必要的。虽然说等锁的线程不算在并发线程计数里，但如果它在真正地执行查询，就比如我们上面例子中</p>
<p>前三个事务中的select sleep(100) from t，还是要算进并发线程的计数的。在这个例子中，同时在执行的语句超过了设置的innodb_thread_concurrency的值，这时候系统</p>
<p>其实已经不行了，但是通过select 1来检测系统，会认为系统还是正常的。因此，我们使用select 1的判断逻辑要修改一下。查表判断</p>
<p>为了能够检测InnoDB并发线程数过多导致的系统不可用情况，我们需要找一个访问InnoDB的场</p>
<p>景。一般的做法是，在系统库（mysql库）里创建一个表，比如命名为health_check，里面只放</p>
<p>一行数据，然后定期执行：</p>
<p>mysql&gt; select * from mysql.health_check; </p>
<p>使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。我们知道，更新事务要写binlog，而一旦binlog所在磁盘的空间占用率达到100%，那么所有的更</p>
<p>新语句和事务提交的commit语句就都会被堵住。但是，系统这时候还是可以正常读数据的。因此，我们还是把这条监控语句再改进一下。接下来，我们就看看把查询语句改成更新语句后的</p>
<p>效果。更新判断</p>
<p>既然要更新，就要放个有意义的字段，常见做法是放一个timestamp字段，用来表示最后一次执</p>
<p>行检测的时间。这条更新语句类似于：</p>
<p>节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新</p>
<p>检测。但，备库的检测也是要写binlog的。由于我们一般会把数据库A和B的主备关系设计为双M结构，</p>
<p>所以在备库B上执行的检测命令，也要发回给主库A。但是，如果主库A和备库B都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同</p>
<p>步停止。所以，现在看来mysql.health_check 这个表就不能只有一行数据了。为了让主备之间的更新不产生冲突，我们可以在mysql.health_check表上存入多行数据，并用</p>
<p>A、B的server_id做主键。由于MySQL规定了主库和备库的server_id必须不同（否则创建主备关系的时候就会报错），这</p>
<p>mysql&gt; update mysql.health_check set t_modified&#x3D;now();</p>
<p>mysql&gt; CREATE TABLE &#96;health_check  ̀(</p>
<p>  ìd  ̀int(11) NOT NULL,</p>
<p>  t̀_modified  ̀timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,</p>
<p>  PRIMARY KEY (̀ id )̀</p>
<p>) ENGINE&#x3D;InnoDB;</p>
<p>&#x2F;* 检测命令 *&#x2F;</p>
<p>insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified&#x3D;now();</p>
<p>样就可以保证主、备库各自的检测命令不会发生冲突。更新判断是一个相对比较常用的方案了，不过依然存在一些问题。其中，“判定慢”一直是让DBA</p>
<p>头疼的问题。你一定会疑惑，更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定</p>
<p>慢的问题呢？其实，这里涉及到的是服务器IO资源分配的问题。首先，所有的检测逻辑都需要一个超时时间N。执行一条update语句，超过N秒后还不返回，就</p>
<p>认为系统不可用。你可以设想一个日志盘的IO利用率已经是100%的场景。这时候，整个系统响应非常慢，已经需</p>
<p>要做主备切换了。但是你要知道，IO利用率100%表示系统的IO是在工作的，每个请求都有机会获得IO资源，执行</p>
<p>自己的任务。而我们的检测使用的update命令，需要的资源很少，所以可能在拿到IO资源的时</p>
<p>候就可以提交成功，并且在超时时间N秒未到达之前就返回给了检测系统。检测系统一看，update命令没有超时，于是就得到了“系统正常”的结论。也就是说，这时候在业务系统上正常的SQL语句已经执行得很慢了，但是DBA上去一看，HA系</p>
<p>统还在正常工作，并且认为主库现在处于可用状态。之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天</p>
<p>然有一个问题，就是随机性。因为，外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起</p>
<p>执行语句的时候，我们才有可能发现问题。而且，如果你的运气不够好的话，可能第一次轮询还</p>
<p>不能发现，这就会导致切换慢的问题。所以，接下来我要再和你介绍一种在MySQL内部发现数据库问题的方法。内部统计</p>
<p>针对磁盘利用率这个问题，如果MySQL可以告诉我们，内部每一次IO请求的时间，那我们判断</p>
<p>数据库是否出问题的方法就可靠得多了。其实，MySQL 5.6版本以后提供的performance_schema库，就在file_summary_by_event_name</p>
<p>表里统计了每次IO请求的时间。file_summary_by_event_name表里有很多行数据，我们先来看看</p>
<p>event_name&#x3D;’wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file’这一行。图3 performance_schema.file_summary_by_event_name的一行</p>
<p>图中这一行表示统计的是redo log的写入时间，第一列EVENT_NAME 表示统计的类型。接下来的三组数据，显示的是redo log操作的时间统计。第一组五列，是所有IO类型的统计。其中，COUNT_STAR是所有IO的总次数，接下来四列是具</p>
<p>体的统计项， 单位是皮秒；前缀SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、</p>
<p>平均值和最大值。第二组六列，是读操作的统计。最后一列SUM_NUMBER_OF_BYTES_READ统计的是，总共</p>
<p>从redo log里读了多少个字节。第三组六列，统计的是写操作。最后的第四组数据，是对其他类型数据的统计。在redo log里，你可以认为它们就是对fsync的统</p>
<p>计。在performance_schema库的file_summary_by_event_name表里，binlog对应的是event_name &#x3D;</p>
<p>“wait&#x2F;io&#x2F;file&#x2F;sql&#x2F;binlog”这一行。各个字段的统计逻辑，与redo log的各个字段完全相同。这里，我</p>
<p>就不再赘述了。因为我们每一次操作数据库，performance_schema都需要额外地统计这些信息，所以我们打开</p>
<p>这个统计功能是有性能损耗的。我的测试结果是，如果打开所有的performance_schema项，性能大概会下降10%左右。所以，</p>
<p>我建议你只打开自己需要的项进行统计。你可以通过下面的方法打开或者关闭某个具体项的统</p>
<p>计。如果要打开redo log的时间监控，你可以执行这个语句：</p>
<p>假设，现在你已经开启了redo log和binlog这两个统计信息，那要怎么把这个信息用在实例状态</p>
<p>诊断上呢？很简单，你可以通过MAX_TIMER的值来判断数据库是否出问题了。比如，你可以设定阈值，单</p>
<p>次IO请求时间超过200毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。发现异常后，取到你需要的信息，再通过下面这条语句：</p>
<p>把之前的统计信息清空。这样如果后面的监控中，再次出现这个异常，就可以加入监控累积值</p>
<p>了。小结</p>
<p>今天，我和你介绍了检测一个MySQL实例健康状态的几种方法，以及各种方法存在的问题和演</p>
<p>进的逻辑。你看完后可能会觉得，select 1这样的方法是不是已经被淘汰了呢，但实际上使用非常广泛的</p>
<p>MHA（Master High Availability），默认使用的就是这个方法。MHA中的另一个可选方法是只做连接，就是 “如果连接成功就认为主库没问题”。不过据我所</p>
<p>知，选择这个方法的很少。其实，每个改进的方案，都会增加额外损耗，并不能用“对错”做直接判断，需要你根据业务实际</p>
<p>情况去做权衡。我个人比较倾向的方案，是优先考虑update系统表，然后再配合增加检测performance_schema</p>
<p>的信息。最后，又到了我们的思考题时间。今天，我想问你的是：业务系统一般也有高可用的需求，在你开发和维护过的服务中，你是怎么</p>
<p>判断服务有没有出问题的呢？mysql&gt; update setup_instruments set ENABLED&#x3D;’YES’, Timed&#x3D;’YES’ where name like ‘%wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file%’;</p>
<p>mysql&gt; select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in (‘wait&#x2F;io&#x2F;file&#x2F;innodb&#x2F;innodb_log_file’,’wait&#x2F;io&#x2F;file&#x2F;sql&#x2F;binlog’) and MAX_TIMER_WAIT&gt;200*1000000000;</p>
<p>mysql&gt; truncate table performance_schema.file_summary_by_event_name;</p>
<p>你可以把你用到的方法和分析写在留言区，我会在下一篇文章中选取有趣的方案一起来分享和分</p>
<p>析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期的问题是，如果使用GTID等位点的方案做读写分离，在对大表做DDL的时候会怎么样。假设，这条语句在主库上要执行10分钟，提交后传到备库就要10分钟（典型的大事务）。那</p>
<p>么，在主库DDL之后再提交的事务的GTID，去备库查的时候，就会等10分钟才出现。这样，这个读写分离机制在这10分钟之内都会超时，然后走主库。这种预期内的操作，应该在业务低峰期的时候，确保主库能够支持所有业务查询，然后把读请求</p>
<p>都切到主库，再在主库上做DDL。等备库延迟追上以后，再把读请求切回备库。通过这个思考题，我主要想让关注的是，大事务对等位点方案的影响。当然了，使用gh-ost方案来解决这个问题也是不错的选择。评论区留言点赞板：</p>
<p>@曾剑、@max 同学提到的备库先做，再切主库的方法也是可以的。精选留言</p>
<p>某、人   6</p>
<p>目前是只有一台服务器来做判断,是否数据库出问题了,就是采用的update的方式。如果是主从架</p>
<p>构就一条语句,如果是双主的话就是两条update语句。但是这种方式有很大的弊端,只有一个进程</p>
<p>来判断数据库出问题的话,会出现单点判断的问题。所以后续准备多个单数进程来做判断,如果超</p>
<p>过了半数以上的监控进程都认为数据库出问题,才做切换。老师我有两个问题:</p>
<p>1.innodb_thread_concurrency的设置是不是应该跟计算机核数成正比,一般是1.5倍-2倍左右？2.怎么之前遇到空间满了,数据库都登不上了,所有的连接都连不上,更不用执行select语句了,这个</p>
<p>是什么原因啊？2019-01-20</p>
<p> 作者回复</p>
<ol>
<li>虽然理论上是核数的2倍左右最好，但是现在很多人把MySQL创建在虚拟机上，就分1~2个</li>
</ol>
<p>核，我怕那么写，有同学会认为innodb_thread_concurrency建议设置成4。。2. 空间满本身是不会导致连不上的。但是因为空间满，事务无法提交，可能会导致接下来外部</p>
<p>事务重试，新重试的业务还是堵在提交阶段，持续累积可能会把连接数用满</p>
<p>2019-01-21</p>
<p>IceGeek17   1</p>
<p>对于使用 GTID 等位点的方案做读写分离，对大表做DDL的问题，</p>
<p>有一种做法是先在从库上设置 set_log_bin &#x3D; off，在从库上先做DDL，完成后做一下主从切换。然后再在之前的主库上同样操作一遍。但这会有一个问题，当先在从库上做DDL（大表DDL时间会比较长，比如10分钟），在这段时</p>
<p>间内，此时如果读写请求都走主库的话，如果写请求对于DDL的改动是有依赖的，那这些写请</p>
<p>求在主库就可能会失败；同样此时对于主库上的读请求，也可能会读到“过期”的数据（读请求</p>
<p>希望读到DDL之后的数据，但此时DDL在从库执行，主库上还是DDL之前的），老师怎么看这</p>
<p>个问题 ？2019-01-29</p>
<p> 作者回复</p>
<p>是这样的，我们说DDL，一般是指加减索引，增加字段在最后一列，这种操作…</p>
<p>2019-01-31</p>
<p>Mr.Strive.Z.H.L   1</p>
<p>老师您好：</p>
<p>本章有个疑惑：</p>
<p>”外部检测的时候，主备使用同一条更新语句，造成行冲突，导致主备同步停止”</p>
<p>上面这句话实在想不通。外部检测是只是看更新语句的返回时间，health_check表在主库备库</p>
<p>都有，为啥会造成行冲突？为啥会导致主备同步停止？即使是相同的binlog，也没啥影响呀。2019-01-22</p>
<p> 作者回复</p>
<p>比如两个表刚开始都是空表，</p>
<p>然后第一个语句执行</p>
<p>insert into mysql.health_check(id, t_modified) values (1, now()) on duplicate key update t_modifi</p>
<p>ed&#x3D;now();</p>
<p>就会两边各写入一个insert语句的binlog日志，传到对面就导致同步停止了</p>
<p>2019-01-22</p>
<p>慧鑫coming   1</p>
<p>老师，文中提到的“但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也</p>
<p>就是可能会导致主备同步停止。”，这个能展开说一下吗，这个行冲突指什么？它们会都更新各</p>
<p>自检测表的同一字段我觉得会带来不准确的问题，怎么导致主从同步停止了呢？2019-01-22</p>
<p> 作者回复</p>
<p>好问题</p>
<p>比如两个表刚开始都是空表，</p>
<p>然后第一个语句执行</p>
<p>insert into mysql.health_check(id, t_modified) values (1, now()) on duplicate key update t_modifi</p>
<p>ed&#x3D;now();</p>
<p>就会两边各写入一个insert语句的binlog日志，传到对面就导致同步停止了</p>
<p>2019-01-22</p>
<p>heat nan   1</p>
<p>老师，一直有个疑问，想咨询下。innodb buffer 会缓存表的数据页和索引页。现在我想知道如</p>
<p>何确认一个查询的行已经被缓存在内存中了。 我想了一下，第一种方法是直接去内存中遍历这</p>
<p>个表相关的数据页。这样的话，因为内存中的页可能是分散的，可能不构成一个完成的索引结</p>
<p>构，可能不能利用b+树叶子节点的路由功能。 这里有点模糊，希望老师有空可以解释一下</p>
<p>2019-01-19</p>
<p> 作者回复</p>
<p>“因为内存中的页可能是分散的，可能不构成一个完成的索引结构，可能不能利用b+树叶子节点</p>
<p>的路由功能。”</p>
<p>这里不对哈</p>
<p>放在内存里是b+树组织的，可以利用b+树叶子节点的路由功能的</p>
<p>2019-01-19</p>
<p>老杨同志   1</p>
<p>现在很多公司都是使用dubbo或者类似dubbo的rpc调用。说说我对dubbo的理解 </p>
<p>dubbo 存活检测感觉分为下面三个层面</p>
<p>服务端与注册中心的链接状态</p>
<p>通常注册中心是zookeeper，服务端注册临时节点，客户端注册这个节点的watch事件，一但服</p>
<p>务端失联，</p>
<p>客户端将把该服务从自己可用服务列表中移除。（一个服务通常有多个提供者，只是把失联的</p>
<p>提供者移除）。zookeeper是通过心跳发现服务提供者失联的，心跳实际上就是以固定的频率（比如每秒）发</p>
<p>送检测的数据包；</p>
<p>客户端与注册中心的链接状态</p>
<p>客户端与zookeeper失联，会暂时使用自己缓存的服务提供者列表。如果每个提供者多次调不</p>
<p>通，把它移除。客户端与服务单的链接状态</p>
<p>服务端提供类似于echo的方法，客户定时调用。部分返回正常，认为服务处于亚健康状态，如</p>
<p>果超过阀值，会被降级</p>
<p>从服务提供者列表移除。被移除的方法可能会在超过一定时间后，拿回来重试，可以恢复成正</p>
<p>常服务，也可能继续降级。2019-01-18</p>
<p> 作者回复</p>
<p>很好的实践分享。是不是还有配套一些服务的RT时间的报告？毕竟echo是一个比较轻量的调用，正确率可能比实际业务调用的正确率高</p>
<p>2019-01-20</p>
<p>强哥   1</p>
<p>1.基础监控，包括硬盘，CPU，网络，内存等。2.服务监控，包括jvm，服务端口，接入上下游服务的超时监控等。3.业务监控，主要是监控业务的流程是否出现问题。2019-01-18</p>
<p> 作者回复</p>
<p> ，这里的“超时监控”，是怎么得到的？是单独有命令检测，还是去看业务请求的返回时间？2019-01-18</p>
<p>长杰   1</p>
<p>老师请教一个问题，在gtid模式下，对于大的ddl操作，采用在备库执行sql_log_bin&#x3D;0的方式先</p>
<p>执行，然后再切换主备的方式在主库再执行，这种情况下，ddl操作是不记录binlog的，不知道</p>
<p>对gtid的计数有什么影响，是按顺序递增还是会跳过这个序列号？另外补充一下有些dl操作是不适合这个主备切换的方式，比如drop一个列，如果先在备库执行</p>
<p>就可能导致主备同步异常。这个场景适合osc方式或把读请求切到主库，先在主库执行这两种</p>
<p>方案。2019-01-18</p>
<p> 作者回复</p>
<p>如果set sql_log_bin&#x3D;0， 就不记录binlog，就不会给这个事务分配gtid。你说得对，drop列是很麻烦的，尽量不做。毕竟业务代码直接无视这个列就好了。。2019-01-18</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师您好：</p>
<p>关于 主备同步停止 的问题，看了您的回复。我是这么理解的：</p>
<p>insert into mysql.health_check(id, t_modified) values (1, now()) on duplicate key update t_modifi</p>
<p>ed&#x3D;now(); </p>
<p>按照您说的场景，主备分别执行这句话后，复制给彼此。如果单单看这句话，就算是主库执行备库复制过来的这句话，也不会出现异常呀。（因为如果</p>
<p>主键冲突就会更新时间）</p>
<p>但是这种场景会导致 主备同步停止， 所以实际上主库在应用备库这句话的binlog的时候，发现</p>
<p>主键冲突，自然就会报错。不知道是不是这样，因为如果单单看这句sql，即使主键冲突也没关系呀？2019-01-22</p>
<p> 作者回复</p>
<p>啊 主键冲突为啥没关系？是这样的，这两个语句如果同时执行，那么在主库和备库上就都是“insert行为”</p>
<p>写到binlog里面就都是Write rows event</p>
<p>这个冲突就会导致主备同步停止哦</p>
<p>2019-01-23</p>
<p>一大只    0</p>
<p>老师，我想问下，我的ECS上是8核CPU，只跑一个MySQL实例，那innodb_thread_concurren</p>
<p>cy如果设成2倍，那就是16哈。看并发查询的数量，是不是关注Threads_running是否超过innod</p>
<p>b_thread_concurrency就可以了。2019-01-21</p>
<p> 作者回复</p>
<p>Thread running 是包含“锁等待”状态的线程的，</p>
<p>超过点也没事 </p>
<p>2019-01-22</p>
<p>小橙橙   0</p>
<p>老师，我工作中遇到一个奇怪的问题，java客户端执行查询语句报错：ResultSet is from UPDA</p>
<p>TE. No Data。用navicat执行相同语句，很快就查询结束，但是没有结果显示。请问可能什么问</p>
<p>题造成的呢？2019-01-18</p>
<p> 作者回复</p>
<p>？这两个不是一致的吗</p>
<p>意思就是你要upate的语句找不到呀</p>
<p>你把update改成select，先确定一下是不是能看到你要更新的数据（根据你这个描述，应该是没</p>
<p>有）</p>
<p>2019-01-18</p>
<p>悟空   0</p>
<p>可以大致从DB监控图上判断业务有没有问题：</p>
<p>QPS&#x2F;连接数&#x2F;慢查询&#x2F;查询响应时间(query_response_time插件)等……..</p>
<p>老师请教一个问题： </p>
<p>物理机器是128G内存，DB实例数据量是1.2T，磁盘是pcie ssd</p>
<p>业务查询场景是简单的select * from table where id in (1,2,3….);</p>
<p>实例QPS在1000以下时,数据库看上去一切正常</p>
<p>当QPS大于2000+时, %util持续90+, r&#x2F;s持续2W左右, rMB&#x2F;s持续600+, 伴随着连接数&#x2F;慢查询等报</p>
<p>警</p>
<p>这个时候这个数据库实例可以说是出问题了吧，这类问题该怎么排查根因呢？是由于buffer pool与磁盘大量换入换出冷数据导致的吗，有相关的状态值监控项可以查吗？innodb buffer pool是mysql很重要的一个模块，老师后面有单独的章节来解惑吗，期待 ！！</p>
<p>2019-01-18</p>
<p> 作者回复</p>
<p>有的， 敬请期待</p>
<p>不过buffer pool内部细节很多，只能挑大家使用的时候，可能会用到的知识点来讲哈</p>
<p>2019-01-18</p>
<p>One day   0</p>
<p>作为一个开发我也很想了解一下我们自己生产库上的监控情况，接触到最多的就是Datasource,</p>
<p>以及user，password,port（基本上是基于连接那种级别，最多就是加锁），等等参数，大部分</p>
<p>都是基于业务开发。站在个人层面或者业务开发层面（很少能接触到DBA，以及看到DBA是怎</p>
<p>么设置这些参数情况，除非库挂掉了就会和DBA一起看这些）怎么去修改和观看以及使用这些</p>
<p>参数鸭</p>
<p>2019-01-18</p>
<p> 作者回复</p>
<p>有DBA就不要自己去修改线上的参数啦</p>
<p>如果说观察，一个比较好的管控系统，是会能够让你看到这些值的</p>
<p>如果没有，就让dba给你一份线上的my.cnf的配置，然后你在测试环境自己用这个配置启动实例</p>
<p>来观察</p>
<p>2019-01-18</p>
<p>Ryoma   0</p>
<p>现在的服务中只加了一个healthCheck的接口，和MySQL中使用select判断比较类似。当服务依</p>
<p>赖的MySQL及Redis等第三方资源发生问题时，还是不能有效的判断</p>
<p>2019-01-18</p>
<p>爸爸回来了   0</p>
<p>之前也用select 1。后来发现，硬盘意外塞满时，本地链接很有可能超时导致判断失败。想问问老师，mysqladmin ping这个机制用来判断如何？2019-01-18</p>
<p> 作者回复</p>
<p>跟select 1 属于一类</p>
<p>2019-01-18</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/5d62a522.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/5d62a522.html" class="post-title-link" itemprop="url">mysql-读写分离有哪些坑</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-03 06:13:35" itemprop="dateCreated datePublished" datetime="2019-12-03T06:13:35+08:00">2019-12-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-06 17:44:03" itemprop="dateModified" datetime="2023-01-06T17:44:03+08:00">2023-01-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>8.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>32 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>28 | 读写分离有哪些坑？2019-01-16 林晓斌</p>
<p>在上一篇文章中，我和你介绍了一主多从的结构以及切换流程。今天我们就继续聊聊一主多从架</p>
<p>构的应用场景：读写分离，以及怎么处理主备延迟导致的读写分离问题。我们在上一篇文章中提到的一主多从的结构，其实就是读写分离的基本结构了。这里，我再把这</p>
<p>张图贴过来，方便你理解。图1 读写分离基本结构</p>
<p>读写分离的主要目标就是分摊主库的压力。图1中的结构是客户端（client）主动做负载均衡，这</p>
<p>种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据</p>
<p>库进行查询。还有一种架构是，在MySQL和客户端之间有一个中间代理层proxy，客户端只连接proxy， 由</p>
<p>proxy根据请求类型和上下文决定请求的分发路由。图2 带proxy的读写分离架构</p>
<p>接下来，我们就看一下客户端直连和带proxy的读写分离架构，各有哪些特点。1. 客户端直连方案，因为少了一层proxy转发，所以查询性能稍微好一点儿，并且整体架构简</p>
<p>单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库</p>
<p>迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这</p>
<p>样的架构，一定会伴随一个负责管理后端的组件，比如Zookeeper，尽量让业务端只专注于</p>
<p>业务逻辑开发。2. 带proxy的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维</p>
<p>护等工作，都是由proxy完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy</p>
<p>也需要有高可用架构。因此，带proxy架构的整体就相对比较复杂。理解了这两种方案的优劣，具体选择哪个方案就取决于数据库团队提供的能力了。但目前看，趋</p>
<p>势是往带proxy的架构方向发展的。但是，不论使用哪种架构，你都会碰到我们今天要讨论的问题：由于主从可能存在延迟，客户端</p>
<p>执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更</p>
<p>新之前的状态。这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期</p>
<p>读”。前面我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能</p>
<p>100%避免的。不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。接下来，我们就来讨论怎么处理过期读问题。这里，我先把文章中涉及到的处理过期读的方案汇总在这里，以帮助你更好地理解和掌握全文的</p>
<p>知识脉络。这些方案包括：</p>
<p>强制走主库方案；</p>
<p>sleep方案；</p>
<p>判断主备无延迟方案；</p>
<p>配合semi-sync方案；</p>
<p>等主库位点方案；</p>
<p>等GTID方案。强制走主库方案</p>
<p>强制走主库方案其实就是，将查询请求做分类。通常情况下，我们可以将查询请求分为这么两</p>
<p>类：</p>
<ol>
<li>对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发</li>
</ol>
<p>布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结</p>
<p>果，就必须走主库。2. 对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，</p>
<p>就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。你可能会说，这个方案是不是有点畏难和取巧的意思，但其实这个方案是用得最多的。当然，这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些</p>
<p>金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展</p>
<p>性。因此接下来，我们来讨论的话题是：可以支持读写分离的场景下，有哪些解决过期读的方案，并</p>
<p>分析各个方案的优缺点。Sleep 方案</p>
<p>主库更新后，读从库之前先sleep一下。具体的方案就是，类似于执行一条select sleep(1)命令。这个方案的假设是，大多数情况下主备延迟在1秒之内，做一个sleep可以有很大概率拿到最新的</p>
<p>数据。这个方案给你的第一感觉，很可能是不靠谱儿，应该不会有人用吧？并且，你还可能会说，直接</p>
<p>在发起查询时先执行一条sleep语句，用户体验很不友好啊。但，这个思路确实可以在一定程度上解决问题。为了看起来更靠谱儿，我们可以换一种方式。以卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript</p>
<p>和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查</p>
<p>询。这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商</p>
<p>品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。也就是说，这个sleep方案确实解决了类似场景下的过期读问题。但，从严格意义上来说，这个</p>
<p>方案存在的问题就是不精确。这个不精确包含了两层意思：</p>
<ol>
<li><p>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；</p>
</li>
<li><p>如果延迟超过1秒，还是会出现过期读。看到这里，你是不是有一种“你是不是在逗我”的感觉，这个改进方案虽然可以解决类似Ajax场景</p>
</li>
</ol>
<p>下的过期读问题，但还是怎么看都不靠谱儿。别着急，接下来我就和你介绍一些更准确的方案。判断主备无延迟方案</p>
<p>要确保备库无延迟，通常有三种做法。通过前面的第25篇文章，我们知道show slave status结果里的seconds_behind_master参数的</p>
<p>值，可以用来衡量主备延迟时间的长短。所以第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断</p>
<p>seconds_behind_master是否已经等于0。如果还不等于0 ，那就必须等到这个参数变为0才能执</p>
<p>行查询请求。seconds_behind_master的单位是秒，如果你觉得精度不够的话，还可以采用对比位点和GTID</p>
<p>的方法来确保主备无延迟，也就是我们接下来要说的第二和第三种方法。如图3所示，是一个show slave status结果的部分截图。图3 show slave status结果</p>
<p>现在，我们就通过这个结果，来看看具体如何通过对比位点和GTID来确保主备无延迟。第二种方法，对比位点确保主备无延迟：</p>
<p>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；</p>
<p>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和</p>
<p>Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成。第三种方法，对比GTID集合确保主备无延迟：</p>
<p>Auto_Position&#x3D;1 ，表示这对主备关系使用了GTID协议。Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；</p>
<p>Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成。可见，对比位点和对比GTID这两种方法，都要比判断seconds_behind_master是否为0更准确。在执行查询请求之前，先判断从库是否同步完成的方法，相比于sleep方案，准确度确实提升了</p>
<p>不少，但还是没有达到“精确”的程度。为什么这么说呢？我们现在一起来回顾下，一个事务的binlog在主备库之间的状态：</p>
<ol>
<li><p>主库执行完成，写入binlog，并反馈给客户端；</p>
</li>
<li><p>binlog被从主库发送给备库，备库收到；</p>
</li>
<li><p>在备库执行binlog完成。我们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。但是，从binlog在主备之</p>
</li>
</ol>
<p>间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日</p>
<p>志的状态。如图4所示就是这样的一个状态。图4 备库还没收到trx3</p>
<p>这时，主库上执行完成了三个事务trx1、trx2和trx3，其中：</p>
<ol>
<li><p>trx1和trx2已经传到从库，并且已经执行完成了；</p>
</li>
<li><p>trx3在主库执行完成，并且已经回复给客户端，但是还没有传到从库中。如果这时候你在从库B上执行查询请求，按照我们上面的逻辑，从库认为已经没有同步延迟，但</p>
</li>
</ol>
<p>还是查不到trx3的。严格地说，就是出现了过期读。那么，这个问题有没有办法解决呢？配合semi-sync</p>
<p>要解决这个问题，就要引入半同步复制，也就是semi-sync replication。semi-sync做了这样的设计：</p>
<ol>
<li><p>事务提交的时候，主库把binlog发给从库；</p>
</li>
<li><p>从库收到binlog以后，发回给主库一个ack，表示收到了；</p>
</li>
<li><p>主库收到这个ack以后，才能给客户端返回“事务完成”的确认。也就是说，如果启用了semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经</p>
</li>
</ol>
<p>收到了这个日志。在第25篇文章的评论区，有同学问到：如果主库掉电的时候，有些binlog还来不及发给从库，会</p>
<p>不会导致系统数据丢失？答案是，如果使用的是普通的异步复制模式，就可能会丢失，但semi-sync就可以解决这个问</p>
<p>题。这样，semi-sync配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过</p>
<p>期读。但是，semi-sync+位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只</p>
<p>要等到一个从库的ack，就开始给客户端返回确认。这时，在从库上执行查询请求，就有两种情</p>
<p>况：</p>
<ol>
<li><p>如果查询是落在这个响应了ack的从库上，是能够确保读到最新数据；</p>
</li>
<li><p>但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。其实，判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位</p>
</li>
</ol>
<p>点或者GTID集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上</p>
<p>迟迟无法响应查询请求的情况。实际上，回到我们最初的业务逻辑里，当发起一个查询请求以后，我们要得到准确的结果，其实</p>
<p>并不需要等到“主备完全同步”。为什么这么说呢？我们来看一下这个时序图。图5 主备持续延迟一个事务</p>
<p>图5所示，就是等待位点方案的一个bad case。图中备库B下的虚线框，分别表示relaylog和</p>
<p>binlog中的事务。可以看到，图5中从状态1 到状态4，一直处于延迟一个事务的状态。备库B一直到状态4都和主库A存在延迟，如果用上面必须等到无延迟才能查询的方案，select语</p>
<p>句直到状态4都不能被执行。但是，其实客户端是在发完trx1更新后发起的select语句，我们只需要确保trx1已经执行完成就可</p>
<p>以执行select语句了。也就是说，如果在状态3执行查询请求，得到的就是预期结果了。到这里，我们小结一下，semi-sync配合判断主备无延迟的方案，存在两个问题：</p>
<ol>
<li><p>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；</p>
</li>
<li><p>在持续延迟的情况下，可能出现过度等待的问题。接下来，我要和你介绍的等主库位点方案，就可以解决这两个问题。等主库位点方案</p>
</li>
</ol>
<p>要理解等主库位点方案，我需要先和你介绍一条命令：</p>
<p>这条命令的逻辑如下：</p>
<ol>
<li><p>它是在从库执行的；</p>
</li>
<li><p>参数file和pos指的是主库上的文件名和位置；</p>
</li>
<li><p>timeout可选，设置为正整数N表示这个函数最多等待N秒。这个命令正常返回的结果是一个正整数M，表示从命令开始执行，到应用完file和pos表示的</p>
</li>
</ol>
<p>binlog位置，执行了多少事务。当然，除了正常返回一个正整数M外，这条命令还会返回一些其他结果，包括：</p>
<ol>
<li><p>如果执行期间，备库同步线程发生异常，则返回NULL；</p>
</li>
<li><p>如果等待超过N秒，就返回-1；</p>
</li>
<li><p>如果刚开始执行的时候，就发现已经执行过这个位置了，则返回0。对于图5中先执行trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使</p>
</li>
</ol>
<p>用这个逻辑：</p>
<ol>
<li><p>trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；</p>
</li>
<li><p>选定一个从库执行查询语句；</p>
</li>
<li><p>在从库上执行select master_pos_wait(File, Position, 1)；</p>
</li>
<li><p>如果返回值是&gt;&#x3D;0的正整数，则在这个从库执行查询语句；</p>
</li>
<li><p>否则，到主库执行查询语句。我把上面这个流程画出来。select master_pos_wait(file, pos[, timeout]);</p>
</li>
</ol>
<p>图6 master_pos_wait方案</p>
<p>这里我们假设，这条select查询最多在从库上等待1秒。那么，如果1秒内master_pos_wait返回</p>
<p>一个大于等于0的整数，就确保了从库上执行的这个查询结果一定包含了trx1的数据。步骤5到主库执行查询语句，是这类方案常用的退化机制。因为从库的延迟时间不可控，不能无</p>
<p>限等待，所以如果等待超时，就应该放弃，然后到主库去查。你可能会说，如果所有的从库都延迟超过1秒了，那查询压力不就都跑到主库上了吗？确实是这</p>
<p>样。但是，按照我们设定不允许过期读的要求，就只有两种选择，一种是超时放弃，一种是转到主库</p>
<p>查询。具体怎么选择，就需要业务开发同学做好限流策略了。GTID方案</p>
<p>如果你的数据库开启了GTID模式，对应的也有等待GTID的方案。MySQL中同样提供了一个类似的命令：</p>
<p> select wait_for_executed_gtid_set(gtid_set, 1);</p>
<p>这条命令的逻辑是：</p>
<ol>
<li><p>等待，直到这个库执行的事务中包含传入的gtid_set，返回0；</p>
</li>
<li><p>超时返回1。在前面等位点的方案中，我们执行完事务后，还要主动去主库执行show master status。而</p>
</li>
</ol>
<p>MySQL 5.7.6版本开始，允许在执行完更新类事务后，把这个事务的GTID返回给客户端，这样</p>
<p>等GTID的方案就可以减少一次查询。这时，等GTID的执行流程就变成了：</p>
<ol>
<li><p>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；</p>
</li>
<li><p>选定一个从库执行查询语句；</p>
</li>
<li><p>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；</p>
</li>
<li><p>如果返回值是0，则在这个从库执行查询语句；</p>
</li>
<li><p>否则，到主库执行查询语句。跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。我把这个流程图画出来。图7 wait_for_executed_gtid_set方案</p>
</li>
</ol>
<p>在上面的第一步中，trx1事务更新完成后，从返回包直接获取这个事务的GTID。问题是，怎么能</p>
<p>够让MySQL在执行事务后，返回包中带上GTID呢？你只需要将参数session_track_gtids设置为OWN_GTID，然后通过API接口</p>
<p>mysql_session_track_get_first从返回包解析出GTID的值即可。在专栏的第一篇文章中，我介绍mysql_reset_connection的时候，评论区有同学留言问这类接口</p>
<p>应该怎么使用。这里我再回答一下。其实，MySQL并没有提供这类接口的SQL用法，是提供给程序的</p>
<p>API(<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/c-api-functions.html)%E3%80%82%E6%AF%94%E5%A6%82%EF%BC%8C%E4%B8%BA%E4%BA%86%E8%AE%A9%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%9C%A8%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%90%8E%EF%BC%8C%E8%BF%94%E5%9B%9E%E7%9A%84GITD%E8%83%BD%E5%A4%9F%E5%9C%A8%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%98%BE%E7%A4%BA%E5%87%BA%E6%9D%A5%EF%BC%8C%E6%88%91%E5%AF%B9MySQL%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BB%A3">https://dev.mysql.com/doc/refman/5.7/en/c-api-functions.html)。比如，为了让客户端在事务提交后，返回的GITD能够在客户端显示出来，我对MySQL客户端代</a></p>
<p>码做了点修改，如下所示：</p>
<p>图8 显示更新事务的GTID–代码</p>
<p>这样，就可以看到语句执行完成，显示出GITD的值。图9 显示更新事务的GTID–效果</p>
<p>当然了，这只是一个例子。你要使用这个方案的时候，还是应该在你的客户端代码中调用</p>
<p>mysql_session_track_get_first这个函数。小结</p>
<p>在今天这篇文章中，我跟你介绍了一主多从做读写分离时，可能碰到过期读的原因，以及几种应</p>
<p>对的方案。这几种方案中，有的方案看上去是做了妥协，有的方案看上去不那么靠谱儿，但都是有实际应用</p>
<p>场景的，你需要根据业务需求选择。即使是最后等待位点和等待GTID这两个方案，虽然看上去比较靠谱儿，但仍然存在需要权衡的</p>
<p>情况。如果所有的从库都延迟，那么请求就会全部落到主库上，这时候会不会由于压力突然增</p>
<p>大，把主库打挂了呢？其实，在实际应用中，这几个方案是可以混合使用的。比如，先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期</p>
<p>读；然后，对于不能接受过期读的语句，再使用等GTID或等位点的方案。但话说回来，过期读在本质上是由一写多读导致的。在实际应用中，可能会有别的不需要等待就</p>
<p>可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中</p>
<p>取权衡。最后 ，我给你留下一个问题吧。假设你的系统采用了我们文中介绍的最后一个方案，也就是等GTID的方案，现在你要对主库的</p>
<p>一张大表做DDL，可能会出现什么情况呢？为了避免这种情况，你会怎么做呢？你可以把你的分析和方案设计写在评论区，我会在下一篇文章跟你讨论这个问题。感谢你的收</p>
<p>听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间</p>
<p>上期给你留的问题是，在GTID模式下，如果一个新的从库接上主库，但是需要的binlog已经没</p>
<p>了，要怎么做？@某、人同学给了很详细的分析，我把他的回答略做修改贴过来。1. 如果业务允许主从不一致的情况，那么可以在主库上先执行show global variables like</p>
<p>‘gtid_purged’，得到主库已经删除的GTID集合，假设是gtid_purged1；然后先在从库上执行</p>
<p>reset master，再执行set global gtid_purged &#x3D;‘gtid_purged1’；最后执行start slave，就会从</p>
<p>主库现存的binlog开始同步。binlog缺失的那一部分，数据在从库上就可能会有丢失，造成</p>
<p>主从不一致。2. 如果需要主从数据一致的话，最好还是通过重新搭建从库来做。3. 如果有其他的从库保留有全量的binlog的话，可以把新的从库先接到这个保留了全量binlog</p>
<p>的从库，追上日志以后，如果有需要，再接回主库。4. 如果binlog有备份的情况，可以先在从库上应用缺失的binlog，然后再执行start slave。评论区留言点赞板：</p>
<p>@悟空 同学级联实验，验证了seconds_behind_master的计算逻辑。@_CountingStars 问了一个好问题：MySQL是怎么快速定位binlog里面的某一个GTID位置</p>
<p>的？答案是，在binlog文件头部的Previous_gtids可以解决这个问题。@王朋飞 同学问了一个好问题，sql_slave_skip_counter跳过的是一个event，由于MySQL总</p>
<p>不能执行一半的事务，所以既然跳过了一个event，就会跳到这个事务的末尾，因此set global</p>
<p>sql_slave_skip_counter&#x3D;1;start slave是可以跳过整个事务的。有铭   6</p>
<p>这专栏真的是干货满满，每看一篇我都有“我发现我真的不会使用MySQL”和“我原来把MySQL</p>
<p>用错了”的挫败感</p>
<p>2019-01-16</p>
<p> 作者回复</p>
<p>这样我觉得你和我的时间都值了 </p>
<p>把你更新了认识的点发到评论区，这样会印象更深哈 </p>
<p>2019-01-16</p>
<p>某、人   3</p>
<p>老师我先请教两个问题(估计大多数同学都有这个疑惑) :</p>
<p>1.现在的中间件可以说是乱花渐欲迷人眼,请问老师哪一款中间件适合大多数不分库分表,只是做</p>
<p>读写分离业务的proxy,能推荐一款嘛?毕竟大多数公司都没有专门做中间件开发的团队</p>
<p>2.如果是业务上进行了分库分表,老师能推荐一款分库分表的proxy嘛？我目前了解到的针对分库</p>
<p>分表的proxy都或多或少有些问题。不过分布式数据库是一个趋势也是一个难点。2019-01-16</p>
<p> 作者回复</p>
<p>额，这个最难回答了</p>
<p>精选留言</p>
<p>说实话因为我原来团队是团队自己做的proxy（没有开源），所以我对其他proxy用得并不多，</p>
<p>实在不敢随便指一个。如果我说个比较熟悉的话，可能MariaDB MaxScale还不错</p>
<p>2019-01-17</p>
<p>曾剑   2</p>
<p>老师写的每一篇文章都能让我获益良多。每一篇都值得看好几遍。今天的问题，大表做DDL的时候可能会出现主从延迟，导致等 GTID 的方案可能会导致这部分</p>
<p>流量全打到主库，或者全部超时。如果这部分流量太大的话，我会选择上一篇文章介绍的两种方法：</p>
<p>1.在各个从库先SET sql_log_bin &#x3D; OFF，然后做DDL，所有从库及备主全做完之后，做主从切</p>
<p>换，最后在原来的主库用同样的方式做DDL。2.从库上执行DDL；将从库上执行DDL产生的GTID在主库上利用生成一个空事务GTID的方式将</p>
<p>这个GTID在主库上生成出来。各个从库做完之后再主从切换，然后再在原来的主库上同样做一次。需要注意的是如果有MM架构的情况下，承担写职责的主库上的slave需要先停掉。2019-01-16</p>
<p> 作者回复</p>
<p>  表示这两篇文章你都get到了</p>
<p>2019-01-16</p>
<p>二马   2</p>
<p>最近做性能测试时发现当并发用户达到一定量(比如500)，部分用户连接不上，能否介绍下MyS</p>
<p>QL连接相关问题，谢谢！</p>
<p>2019-01-16</p>
<p> 作者回复</p>
<p>修改max_connections参数</p>
<p>2019-01-16</p>
<p>IceGeek17   1</p>
<p>老师，能不能分析下，如果去实现一个做读写分离的proxy，有哪些重要的点要考虑，比如：连</p>
<p>接管理、流量分配管理、proxy自己的高可用，等等。因为老师原来的团队自己开发过proxy，肯定有相关的经验，也趟过很多坑，能不能从如何实现</p>
<p>一个proxy需要考虑哪些关键点，在架构上做一个分析和梳理</p>
<p>2019-01-29</p>
<p> 作者回复</p>
<p>额，这个问题有点大… 你提一个具体问题我们来讨论吧</p>
<p>2019-01-31</p>
<p>猪哥哥   1</p>
<p>老师, 你真棒, 我公司的生产环境解决过期读使用的就是强制走主库方案, 看了这篇文章, 困惑了</p>
<p>很久的问题迎刃而解！很感谢!</p>
<p>2019-01-17</p>
<p>易翔   1</p>
<p>为老师一句你的时间和我的时间都值了。点赞</p>
<p>2019-01-16</p>
<p>Mr.Strive.Z.H.L   0</p>
<p>老师您好：</p>
<p>关于主库大表的DDL操作，我看了问题答案，有两种方案。第一种是读写请求转到主库，在主</p>
<p>库上做DDL。第二种是从库上做DDL，完成后进行主从切换。关于第二种，有一个疑惑：</p>
<p>从库上做DDL，读写请求走主库，等到从库完成后，从库必须要同步DDL期间，主库完成的事</p>
<p>务后才能进行主从切换。而如果DDL操作是删除一列，那么在同步过程中会出错呀？（比如抛</p>
<p>出这一列不存在的错误）。2019-01-21</p>
<p> 作者回复</p>
<p>你说得对，这种方案下能支持的DDL只有以下几种：</p>
<p>创建&amp;#47;删除索引、新增最后一列、删除最后一列</p>
<p>其中DBA会认为“合理”的DDL需求就是： “创建&amp;#47;删除索引、新增最后一列”</p>
<p>新春快乐~</p>
<p>2019-02-04</p>
<p>black_mirror   0</p>
<p>林老师 您好</p>
<p>1.mysql_session_track_get_fitst这个函数，从github下载mysql源码后怎么尝试简单编译，如图</p>
<p>8？2. mysql_session_track_get_fitst这个函数貌似不支持python语言，我想模拟文中等gtid方法，</p>
<p>不会java怎么办？2019-01-21</p>
<p>black_mirror   0</p>
<p>林老师 您好</p>
<p>请问mysql_session_track_get_fitst这个函数查询了官方资料都需要可以修改源码</p>
<p>1.在不懂c++情况下，github上下载源码后怎么尝试简单编译使用，如图8代码</p>
<ol start="2">
<li>mysql_session_track_get_fitst函数貌似没有python语言api，不会java，想在代码层面模拟整</li>
</ol>
<p>个过程，还有木有解决方法？2019-01-21</p>
<p> 作者回复</p>
<p>不知道python是不是有方法可以把c代码作为扩展模块 </p>
<p>2019-01-21</p>
<p>辣椒   0</p>
<p>辣椒   0</p>
<p>老师，mysql_session_track_get_first是c的，有没有java的？2019-01-18</p>
<p> 作者回复</p>
<p>额，这个我还真不知道 ，抱歉哈。2019-01-18</p>
<p>信信   0</p>
<p>老师您好，文中判断主备无延迟方案的第二种和第三种方法，都是对比了主从执行完的日志是</p>
<p>否相同。因为不会出现图4下方说的：“从库认为已经没有同步延迟，但还是查不到 trx3 的。”因</p>
<p>为如果从库未执行trx3的话，第二，第三种方法都是不通过的。2019-01-18</p>
<p> 作者回复</p>
<p>不会哦</p>
<p>如果trx3还没传到备库，备库是会认为已经同步完成了</p>
<p>2019-01-18</p>
<p>Max   0</p>
<p>我一般是先是在从库上设置 set_log_bin&#x3D;off，然后执行ddl,语句。然后完成以后，主从做一下切换。然后在主库上在执行一下set_log_bin&#x3D;off,执行ddl语句。然后在做一下主从切换。个人对pt-online-scheman-change不是很推荐使用，它的原理基本是创建触发器，然后创建和</p>
<p>旧表一样结构的数据表，</p>
<p>把旧表的数据复制过去。最后删除旧表。以前做个一个测试，如果旧表一直在被select,删除过</p>
<p>程会一直会等待。所以个人不是很建议。万一不小心变成从删库到路步，那就得不偿失了。老师，有个问题想请教一下，一主多从可以多到什么地步，以前我们CTO解决的方案就是加机</p>
<p>器，一主十三从。当时我是反对的，其实个人建议还是从SQL，业务上面去优化。而不是一味的加机器。如果加</p>
<p>机器解决的话，还要DBA做什么呢？2019-01-17</p>
<p> 作者回复</p>
<p>前面的分析很好哈</p>
<p>然后一主13从有点多了，否则主库生成binlog太快的话，主库的网卡会被打爆。要这么多的话</p>
<p>，得做级联。DBA解决不能靠加机器解决的事情^_^ 而且如果通过优化，可以把13变成3，那也是DBA的价值</p>
<p>2019-01-17</p>
<p>coderfocus   0</p>
<p>一步一步 循序渐渐 讲的太棒了 感谢老师</p>
<p>2019-01-17</p>
<p>ThinkingQuest   0</p>
<p>楼上有人提到8小时自动断开连接的问题。 </p>
<p>mysql中有wait_timeout和interactive_timeout两个参数。 </p>
<p>这俩参数挺容易混淆的，往上博客文章说的很多，但是不敢相信他们。官方的解释在这里：</p>
<p><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_interactive_time">https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_interactive_time</a></p>
<p>out</p>
<p><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_wait_timeout">https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_wait_timeout</a></p>
<p>只说用这两个参数中的哪个，取决于客户端调用mysql_real_connect()的时候传递的options中</p>
<p>是否使用了CLIENT_INTERACTIVE选项。但是很多做java开发的同学，想必并不知道JDBC的connector用的是哪一个。 </p>
<p>我倾向于认为是interactive_timeout。 mysql client cli大概是wait_timeout吧。其实做一个实验就可以知道结果。 但是不阅读mysql代码，大概不能理解mysql为什么设计这么</p>
<p>两个timeout，是出于什么考虑的。2019-01-17</p>
<p> 作者回复</p>
<p>JDBC的connector我也没研究过，不过我认为应该是非interactive模式。需要这两个的原因，还是因为有不同的使用模式，给MySQL客户端和一些其他的可视化工具客</p>
<p>户端使用。2019-01-17</p>
<p>不停   0</p>
<p>高手，你这现在在哪里上班了，有兴趣来我们公司耍耍么？2019-01-16</p>
<p>万勇   0</p>
<p>老师，请教下。1.对大表做ddl，是可以采用先在备库上set global log_bin&#x3D;off，先做完ddl，然后切换主备库。为了保证数据一致性，在切主备的时候，数据库会有个不可用的时间段，对业务会造成影响。现在的架构方式，中间层还有proxy，意味着proxy也需要修改主备配置，做reload。这样做的话</p>
<p>，感觉成本太高，在真正的生产环境中，这种方法适用吗？2.目前我们常采用的是对几百万以上的表用pt-online-schema-change，这种方式会产生大量的b</p>
<p>inlog，业务高峰期不能做，会引起主备延迟。在生产业务中，我觉得等主库节点或者等gtid这</p>
<p>种方案挺不错，至少能保证业务，但也会增加主库的压力。3.5.7版本出的group_replication多写模式性能不知道如何？架构变动太大，还不敢上。2019-01-16</p>
<p> 作者回复</p>
<ol>
<li>是这样的，我们说的是，如果非紧急情况下，还是尽量用gh-ost，在“紧急”的情况下，才这么</li>
</ol>
<p>做；确实是要绕过proxy的，也就是说，这事儿是要负责运维的同学做；</p>
<ol start="2">
<li>pt工具是有这个问题，试一下gh-ost哈；group_replication多写模式国内我还没有听到国内有</li>
</ol>
<p>公司在生产上大规模用的，如果你有使用经验，分享一下哈</p>
<p>2019-01-16</p>
<p>永恒记忆   0</p>
<p>老师好，有几个问题想请教下，</p>
<p>1.如果不想有过期读，用等GTID的方案，那么每次查询都要有等GTID的相关操作，增加的这部</p>
<p>分对性能有多少影响；</p>
<p>2.我们用的读写分离proxy不支持等GTID，那是不是自己要在客户端实现这部分逻辑，等于读写</p>
<p>分离的架构既用了proxy，又在客户端做了相关策略，感觉这方案更适合有能力自研proxy的公</p>
<p>司啊；</p>
<p>3.感觉目前大多数生产环境还是用的读主库这种方式避免过期读，如果只能用这种方案的话该</p>
<p>怎么扩展mysql架构来避免主库压力太大呢。我们是项目上线很久然后加的读写分离，好多service层代码写的不好，可以读从库的sql被写到</p>
<p>了事务中，这样会被proxy转到主库上读，所以导致主库负担了好多读的sql，感觉读写分离不</p>
<p>仅对mysql这块要掌握，整体的代码结构上也要有所调整吧。2019-01-16</p>
<p> 作者回复</p>
<ol>
<li><p>这个等待时间其实就基本上是主备延迟的时间</p>
</li>
<li><p>用了proxy这事情就得proxy做了，就不要客户端做了。没有gtid，可以用倒数第二种方法呀：</p>
</li>
</ol>
<p>）</p>
<ol start="3">
<li>是的，其实“走主库”这种做法还挺多的。我之前看到有的公司的做法，就是直接拆库了。等</li>
</ol>
<p>于一套“一主多从”拆成多套。2019-01-16</p>
<p>HuaMax   0</p>
<p>课后题。对大表做ddl是一个大事务，等待从库执行，基本就会超时，最后都返回到主库执行，</p>
<p>这样的话不如跳过等待从库这一步，但是像老师文中提到需要做好限流。从另一个角度，对于</p>
<p>主库的ddl操作，从业务场景去考虑，一般随后到来的查询不会被这个ddl影响，而是对新的业务</p>
<p>变更有影响，这样的话，也可以跳过等待从库这一步，直接让从库执行即可。不知道理解是否</p>
<p>正确？2019-01-16</p>
<p> 作者回复</p>
<p>核心是要处理延迟问题，比如怎么操作可以不会产生延迟</p>
<p>2019-01-16</p>
<ul>
<li>晓 *   0</li>
</ul>
<p>老师好，如果用MGR或InnoDB cluster方案做读写分离的话可以替代文中提到的方案吗？这两</p>
<p>个方案建议在生产中大量使用吗？2019-01-16</p>
<p> 作者回复</p>
<p>MGR开始有国内公司在使用了</p>
<p>InnoDB cluster也可以的，但是一般就是平时一写多读，只在主备切换的时候，短暂允许多写</p>
<p>2019-01-16</p>
<pre><code>
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meng Qi</p>
  <div class="site-description" itemprop="description">recording</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">342</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Meng Qi</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">390k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">23:40</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">loading...</span><span id="times">loading...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("1/1/2018 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>

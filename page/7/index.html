<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.fastolf.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="recording">
<meta property="og:type" content="website">
<meta property="og:title" content="Qi">
<meta property="og:url" content="https://www.fastolf.com/page/7/index.html">
<meta property="og:site_name" content="Qi">
<meta property="og:description" content="recording">
<meta property="og:locale">
<meta property="article:author" content="Meng Qi">
<meta property="article:tag" content="Tech;Data;Vision">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.fastolf.com/page/7/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <title>Qi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
<a target="_blank" rel="noopener" href="https://github.com/gitmmq" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Qi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Cogito ergo sum</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/106.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/106.html" class="post-title-link" itemprop="url">机器学习-特征选择</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:51:28" itemprop="dateModified" datetime="2023-08-09T22:51:28+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>451</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>特征选择是从原始特征中选择出最具有代表性和影响力的特征，以降低维度、提高模型性能、减少过拟合等。以下是一些常见的特征选择方法的示例代码，使用了<code>scikit-learn</code>库：</p>
<p>首先，确保已安装 <code>scikit-learn</code> 库，可以通过以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scikit-learn</span><br></pre></td></tr></table></figure>

<p>接下来，使用下面的代码示例：</p>
<ol>
<li><strong>方差阈值法</strong>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个示例数据集</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">100</span>, n_features=<span class="number">5</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用方差阈值法进行特征选择</span></span><br><span class="line">var_threshold = VarianceThreshold(threshold=<span class="number">0.1</span>)</span><br><span class="line">X_selected = var_threshold.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original number of features:&quot;</span>, X.shape[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of selected features:&quot;</span>, X_selected.shape[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>互信息法</strong>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest, mutual_info_classif</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个示例数据集</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">100</span>, n_features=<span class="number">10</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用互信息法进行特征选择</span></span><br><span class="line">kbest = SelectKBest(score_func=mutual_info_classif, k=<span class="number">5</span>)</span><br><span class="line">X_selected = kbest.fit_transform(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original number of features:&quot;</span>, X.shape[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of selected features:&quot;</span>, X_selected.shape[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>递归特征消除法</strong>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个示例数据集</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">100</span>, n_features=<span class="number">10</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用递归特征消除法进行特征选择</span></span><br><span class="line">estimator = LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>)</span><br><span class="line">rfe = RFE(estimator, n_features_to_select=<span class="number">5</span>)</span><br><span class="line">X_selected = rfe.fit_transform(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original number of features:&quot;</span>, X.shape[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of selected features:&quot;</span>, X_selected.shape[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们分别使用了方差阈值法、互信息法和递归特征消除法进行特征选择。您可以根据问题的需求选择适合的特征选择方法，调整相关参数以达到最佳效果。特征选择是数据预处理的重要一步，可以提高模型性能并降低计算成本。</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6251584.html" title="SVD">奇异值分解在特征降维中的作用</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/lzllovesyl/p/5243370.html" title="SVD">奇异值分解在推荐系统中的应用</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/44165.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/44165.html" class="post-title-link" itemprop="url">欠采样undersampling，过采样oversampling</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:50:37" itemprop="dateModified" datetime="2023-08-09T22:50:37+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>775</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>又称为 上采样  下采样</p>
<h2 id="数据不平衡问题"><a href="#数据不平衡问题" class="headerlink" title="数据不平衡问题"></a>数据不平衡问题</h2><p>默认阈值(比如二分类正反例中0.5)导致模型输出倾向于数据多的类别</p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><ol>
<li>调整分类阈值，偏向数据少的类别</li>
<li>选择ROC或F1作为评估标准</li>
<li>过采样、欠采样</li>
</ol>
<h3 id="过采样"><a href="#过采样" class="headerlink" title="过采样"></a>过采样</h3><p>将样本数量少的类别生成的样本数量和数量多的类别一样多，合成新的样本来缓解类不平衡</p>
<p>注：随机过采样采用简单复制样本增加少数类样本，导致模型不够泛化</p>
<h3 id="欠采样"><a href="#欠采样" class="headerlink" title="欠采样"></a>欠采样</h3><p>从数量多的类别中抽取与等量的样本数据，抛弃一些样本来缓解类不平衡</p>
<h3 id="SMOTE"><a href="#SMOTE" class="headerlink" title="SMOTE"></a>SMOTE</h3><p>经典过采样</p>
<p>人工合成数据（Synthetic Minority Over-sampling Technique）</p>
<p>分析数量较少类别的样本数据，基于“插值”来为少数类合成新样本，并添加到数据集</p>
<ol>
<li>确定采样倍率 N（N为整数，N&gt;&#x3D;1）</li>
<li>计算少数类 样本x(i)到本样本欧式距离，得到x(i)的k个近邻</li>
<li>随机选择近邻x^, xnew &#x3D; x + rand(0,1)*(x^-x),重复N次，得到N个新样本</li>
<li>对所有少数类样本x(i)执行1，2操作，合成NT个新样本</li>
</ol>
<p>欠采样（Undersampling）和过采样（Oversampling）是处理不平衡数据集的常见方法，用于解决正负样本数量差异较大的情况。欠采样是减少多数类样本的数量，而过采样是增加少数类样本的数量。</p>
<p>以下是使用Python实现欠采样和过采样的示例代码，分别使用<code>imbalanced-learn</code>库来演示：</p>
<p>首先，确保已安装 <code>imbalanced-learn</code> 库，可以通过以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install imbalanced-learn</span><br></pre></td></tr></table></figure>

<p>接下来，使用下面的代码示例：</p>
<ol>
<li><strong>欠采样示例</strong>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> RandomUnderSampler</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个不平衡的示例数据集</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, weights=[<span class="number">0.99</span>], random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计类别分布</span></span><br><span class="line">counter = Counter(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original class distribution:&quot;</span>, counter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行欠采样</span></span><br><span class="line">undersample = RandomUnderSampler(sampling_strategy=<span class="number">0.5</span>, random_state=<span class="number">42</span>)</span><br><span class="line">X_resampled, y_resampled = undersample.fit_resample(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计欠采样后的类别分布</span></span><br><span class="line">counter_resampled = Counter(y_resampled)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Resampled class distribution:&quot;</span>, counter_resampled)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制类别分布图</span></span><br><span class="line">plt.bar(counter_resampled.keys(), counter_resampled.values())</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Class&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Count&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Resampled Class Distribution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>过采样示例</strong>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> RandomOverSampler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个不平衡的示例数据集</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, weights=[<span class="number">0.99</span>], random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计类别分布</span></span><br><span class="line">counter = Counter(y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original class distribution:&quot;</span>, counter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行过采样</span></span><br><span class="line">oversample = RandomOverSampler(sampling_strategy=<span class="number">0.5</span>, random_state=<span class="number">42</span>)</span><br><span class="line">X_resampled, y_resampled = oversample.fit_resample(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计过采样后的类别分布</span></span><br><span class="line">counter_resampled = Counter(y_resampled)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Resampled class distribution:&quot;</span>, counter_resampled)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制类别分布图</span></span><br><span class="line">plt.bar(counter_resampled.keys(), counter_resampled.values())</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Class&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Count&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Resampled Class Distribution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们使用<code>make_classification</code>函数创建了一个不平衡的示例数据集，然后分别使用<code>RandomUnderSampler</code>和<code>RandomOverSampler</code>进行欠采样和过采样。最后，绘制了欠采样和过采样后的类别分布图。</p>
<p>请注意，实际应用中您可能需要调整采样策略、超参数等来满足具体问题的需求。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/3313.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3313.html" class="post-title-link" itemprop="url">梯度下降法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:50:03" itemprop="dateModified" datetime="2023-08-09T22:50:03+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>408</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>梯度下降法（Gradient Descent）是一种优化算法，用于找到函数的局部最小值。它在机器学习中常用于训练模型，通过迭代地调整参数，使目标函数的值逐渐减小，从而达到最优解。</p>
<p>以下是一个使用Python实现梯度下降法的示例代码，用于最小化一个简单的二次函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义目标函数和其梯度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">target_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x**<span class="number">2</span> + <span class="number">4</span>*x + <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*x + <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">initial_x, learning_rate, num_iterations</span>):</span><br><span class="line">    x = initial_x</span><br><span class="line">    x_history = [x]</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">        x -= learning_rate * gradient(x)</span><br><span class="line">        x_history.append(x)</span><br><span class="line">    <span class="keyword">return</span> x, x_history</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化参数和超参数</span></span><br><span class="line">initial_x = -<span class="number">5</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">num_iterations = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行梯度下降算法</span></span><br><span class="line">optimal_x, x_history = gradient_descent(initial_x, learning_rate, num_iterations)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制函数和梯度下降路径</span></span><br><span class="line">x_values = np.linspace(-<span class="number">6</span>, <span class="number">2</span>, <span class="number">400</span>)</span><br><span class="line">y_values = target_function(x_values)</span><br><span class="line">plt.plot(x_values, y_values, label=<span class="string">&#x27;Function&#x27;</span>)</span><br><span class="line">plt.scatter(x_history, [target_function(x) <span class="keyword">for</span> x <span class="keyword">in</span> x_history], c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;Gradient Descent Path&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;Gradient Descent Example&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Optimal x:&quot;</span>, optimal_x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Minimum value:&quot;</span>, target_function(optimal_x))</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们首先定义了一个简单的二次函数作为目标函数，并计算了其梯度。然后，实现了梯度下降算法，其中包括初始参数、学习率和迭代次数等超参数。最后，我们运行梯度下降算法，并绘制了目标函数和梯度下降的路径。</p>
<p>请注意，这只是一个简单的梯度下降示例，用于说明概念。在实际应用中，您可能需要考虑更复杂的目标函数、调整学习率、使用不同的梯度下降变体等。</p>
<h2 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/46933.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/46933.html" class="post-title-link" itemprop="url">最大似然</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:49:10" itemprop="dateModified" datetime="2023-08-09T22:49:10+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>510</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该使得从模型中抽取该n组样本观测值的概率最大，而不是像最小二乘估计法旨在得到使得模型能最好地拟合样本数据的参数估计量。<br>最大似然估计（Maximum Likelihood Estimation，MLE）是一种常用的参数估计方法，用于根据观测数据来估计模型的参数，使得观测数据在该模型下的概率最大化。在统计学和机器学习中广泛应用。</p>
<p>以下是一个使用Python实现最大似然估计的示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成服从正态分布的随机样本</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">mu_true = <span class="number">2.0</span></span><br><span class="line">sigma_true = <span class="number">1.5</span></span><br><span class="line">data = np.random.normal(mu_true, sigma_true, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义似然函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">likelihood</span>(<span class="params">params, data</span>):</span><br><span class="line">    mu, sigma = params</span><br><span class="line">    log_likelihood = np.<span class="built_in">sum</span>(np.log(norm.pdf(data, loc=mu, scale=sigma)))</span><br><span class="line">    <span class="keyword">return</span> log_likelihood</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过最大化似然函数来估计参数</span></span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line">initial_params = [<span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># 初始参数猜测</span></span><br><span class="line">result = minimize(<span class="keyword">lambda</span> params: -likelihood(params, data), initial_params, method=<span class="string">&#x27;Nelder-Mead&#x27;</span>)</span><br><span class="line"></span><br><span class="line">estimated_mu, estimated_sigma = result.x</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Estimated mu:&quot;</span>, estimated_mu)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Estimated sigma:&quot;</span>, estimated_sigma)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据和拟合的正态分布</span></span><br><span class="line">plt.hist(data, bins=<span class="number">20</span>, density=<span class="literal">True</span>, alpha=<span class="number">0.6</span>, label=<span class="string">&#x27;Data&#x27;</span>)</span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">plt.plot(x, norm.pdf(x, loc=estimated_mu, scale=estimated_sigma), <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;MLE Fit&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Value&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability Density&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们首先生成了服从正态分布的随机样本数据。然后，定义了似然函数，该函数计算给定参数下观测数据的似然。接着，我们使用<code>scipy.optimize.minimize</code>函数来最大化似然函数，从而估计模型参数。</p>
<p>通过最大似然估计，我们得到了估计的均值和标准差，然后绘制了原始数据的直方图以及拟合的正态分布。这个示例展示了如何使用最大似然估计来拟合一个简单的正态分布模型。在实际应用中，您可能会遇到更复杂的模型和数据。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/60273.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/60273.html" class="post-title-link" itemprop="url">时间序列分析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:46:33" itemprop="dateModified" datetime="2023-08-09T22:46:33+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>453</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="自相关性"><a href="#自相关性" class="headerlink" title="自相关性"></a>自相关性</h2><p>数据清洗是数据预处理的重要步骤，用于识别和处理数据集中的错误、缺失值、重复值等问题，以确保数据的质量和可用性。以下是一些常见的数据清洗方法以及使用Python的示例代码：</p>
<ol>
<li><strong>处理缺失值</strong>：</li>
</ol>
<p>缺失值可能会影响模型性能，需要进行处理。常见的方法包括删除带有缺失值的行、使用均值或中位数填充缺失值等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建示例数据帧</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">4</span>],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [<span class="number">5</span>, np.nan, <span class="number">7</span>, <span class="number">8</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除包含缺失值的行</span></span><br><span class="line">cleaned_df = df.dropna()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用均值填充缺失值</span></span><br><span class="line">mean_fill_df = df.fillna(df.mean())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original DataFrame:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDataFrame after dropping rows with missing values:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cleaned_df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDataFrame after filling missing values with mean:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(mean_fill_df)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>处理重复值</strong>：</li>
</ol>
<p>重复值可能会导致分析结果失真，需要对其进行处理。可以使用<code>drop_duplicates</code>函数删除重复行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建示例数据帧</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [<span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除重复行</span></span><br><span class="line">deduplicated_df = df.drop_duplicates()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original DataFrame:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDataFrame after removing duplicate rows:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(deduplicated_df)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>异常值处理</strong>：</li>
</ol>
<p>异常值可能会影响模型的稳定性和预测性能。一种方法是使用统计方法识别和处理异常值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建示例数据帧</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">200</span>],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [<span class="number">5</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">50</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准差方法识别和处理异常值</span></span><br><span class="line">mean = df[<span class="string">&#x27;A&#x27;</span>].mean()</span><br><span class="line">std = df[<span class="string">&#x27;A&#x27;</span>].std()</span><br><span class="line">threshold = <span class="number">2</span>  <span class="comment"># 可根据需求调整</span></span><br><span class="line">df[<span class="string">&#x27;A&#x27;</span>] = np.where(np.<span class="built_in">abs</span>(df[<span class="string">&#x27;A&#x27;</span>] - mean) &gt; threshold * std, mean, df[<span class="string">&#x27;A&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original DataFrame:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure>

<p>以上只是数据清洗的一些常见方法示例，实际应用中根据问题的性质和数据的特点，可能需要采用不同的处理方式。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/12365.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/12365.html" class="post-title-link" itemprop="url">数据清洗</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:46:33" itemprop="dateModified" datetime="2023-08-09T22:46:33+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>449</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>数据清洗是数据预处理的重要步骤，用于识别和处理数据集中的错误、缺失值、重复值等问题，以确保数据的质量和可用性。以下是一些常见的数据清洗方法以及使用Python的示例代码：</p>
<ol>
<li><strong>处理缺失值</strong>：</li>
</ol>
<p>缺失值可能会影响模型性能，需要进行处理。常见的方法包括删除带有缺失值的行、使用均值或中位数填充缺失值等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建示例数据帧</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">4</span>],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [<span class="number">5</span>, np.nan, <span class="number">7</span>, <span class="number">8</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除包含缺失值的行</span></span><br><span class="line">cleaned_df = df.dropna()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用均值填充缺失值</span></span><br><span class="line">mean_fill_df = df.fillna(df.mean())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original DataFrame:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDataFrame after dropping rows with missing values:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cleaned_df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDataFrame after filling missing values with mean:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(mean_fill_df)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>处理重复值</strong>：</li>
</ol>
<p>重复值可能会导致分析结果失真，需要对其进行处理。可以使用<code>drop_duplicates</code>函数删除重复行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建示例数据帧</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [<span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除重复行</span></span><br><span class="line">deduplicated_df = df.drop_duplicates()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original DataFrame:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nDataFrame after removing duplicate rows:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(deduplicated_df)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>异常值处理</strong>：</li>
</ol>
<p>异常值可能会影响模型的稳定性和预测性能。一种方法是使用统计方法识别和处理异常值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建示例数据帧</span></span><br><span class="line">data = &#123;<span class="string">&#x27;A&#x27;</span>: [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">200</span>],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [<span class="number">5</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">50</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准差方法识别和处理异常值</span></span><br><span class="line">mean = df[<span class="string">&#x27;A&#x27;</span>].mean()</span><br><span class="line">std = df[<span class="string">&#x27;A&#x27;</span>].std()</span><br><span class="line">threshold = <span class="number">2</span>  <span class="comment"># 可根据需求调整</span></span><br><span class="line">df[<span class="string">&#x27;A&#x27;</span>] = np.where(np.<span class="built_in">abs</span>(df[<span class="string">&#x27;A&#x27;</span>] - mean) &gt; threshold * std, mean, df[<span class="string">&#x27;A&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original DataFrame:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure>

<p>以上只是数据清洗的一些常见方法示例，实际应用中根据问题的性质和数据的特点，可能需要采用不同的处理方式。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/13744.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/13744.html" class="post-title-link" itemprop="url">奇异值分解</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:45:46" itemprop="dateModified" datetime="2023-08-09T22:45:46+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>365</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>奇异值分解（Singular Value Decomposition，SVD）是一种常用的矩阵分解方法，将一个矩阵分解成三个矩阵的乘积。SVD在降维、矩阵逆、推荐系统等领域有广泛应用。</p>
<p>SVD将一个矩阵 ( A ) 分解为三个矩阵的乘积：( A &#x3D; U \Sigma V^T )，其中：</p>
<ul>
<li>( U ) 是一个正交矩阵，它的列向量是 ( A A^T ) 的特征向量。</li>
<li>( \Sigma ) 是一个对角矩阵，其对角线上的元素是 ( A A^T ) 特征值的平方根。</li>
<li>( V^T ) 是另一个正交矩阵，它的列向量是 ( A^T A ) 的特征向量。</li>
</ul>
<p>以下是一个使用Python实现奇异值分解的示例代码，使用了<code>numpy</code>库：</p>
<p>首先，确保已安装 <code>numpy</code> 库，可以通过以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure>

<p>接下来，使用下面的代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个示例矩阵</span></span><br><span class="line">A = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">              [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">              [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行奇异值分解</span></span><br><span class="line">U, S, VT = np.linalg.svd(A)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;U matrix:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(U)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nS matrix (diagonal values):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.diag(S))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nVT matrix:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(VT)</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们首先创建了一个示例矩阵 ( A )，然后使用<code>np.linalg.svd</code>函数进行奇异值分解。分别得到了矩阵 ( U )，对角矩阵 ( \Sigma ) 的对角线元素和矩阵 ( V^T )。</p>
<p>奇异值分解的一个常见应用是主成分分析（PCA），它通过对数据矩阵进行奇异值分解来实现数据降维。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/38286.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/38286.html" class="post-title-link" itemprop="url">多元回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-09 22:39:13" itemprop="dateModified" datetime="2023-08-09T22:39:13+08:00">2023-08-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>473</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>多元线性回归是一种用于建模和预测多个自变量与一个因变量之间关系的统计方法。它是线性回归的扩展，适用于多个自变量的情况。在多元线性回归中，我们试图找到一个线性关系，使得自变量的线性组合能够较好地预测因变量。</p>
<p>以下是一个使用Python实现多元线性回归的示例代码，使用了<code>numpy</code>和<code>scikit-learn</code>库：</p>
<p>首先，确保已安装 <code>numpy</code> 和 <code>scikit-learn</code> 库，可以通过以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy scikit-learn</span><br></pre></td></tr></table></figure>

<p>接下来，使用下面的代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">3</span>)  <span class="comment"># 100个样本，3个特征</span></span><br><span class="line">y = <span class="number">2</span> * X[:, <span class="number">0</span>] + <span class="number">3</span> * X[:, <span class="number">1</span>] + <span class="number">4</span> * X[:, <span class="number">2</span>] + <span class="number">1</span> + np.random.randn(<span class="number">100</span>)  <span class="comment"># 使用线性关系生成因变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多元线性回归模型</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean Squared Error:&quot;</span>, mse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型参数（系数和截距）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coefficients:&quot;</span>, model.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Intercept:&quot;</span>, model.intercept_)</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们首先生成了一个示例数据集，其中包含3个特征和一个因变量。然后，我们使用<code>train_test_split</code>函数将数据集划分为训练集和测试集。接着，我们创建了一个多元线性回归模型，并使用<code>fit</code>方法训练模型。在测试集上进行预测，并计算均方误差来衡量模型性能。</p>
<p>请注意，这只是一个简单的多元线性回归示例。在实际应用中，您可能需要考虑特征选择、模型评估、特征缩放等问题，以获得更好的回归模型。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/5567.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/5567.html" class="post-title-link" itemprop="url">基于信息熵分词</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-28 14:40:43" itemprop="dateModified" datetime="2022-12-28T14:40:43+08:00">2022-12-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>340</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>分片属性：分片概率、分片频度、自由度、凝固程度</p>
<h2 id="自由度"><a href="#自由度" class="headerlink" title="自由度"></a>自由度</h2><p>文本片段的自由运用程度</p>
<p>如果一个文本片段能够算作一个词的话，它应该能够灵活地出现在各种不同的环境中，具有非常丰富的左邻字集合和右邻字集合。</p>
<h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>衡量信息量大小</p>
<p>用信息熵来衡量一个文本片段的左邻字集合和右邻字集合丰富程度。考虑这么一句话”吃葡萄不吐葡萄皮不吃葡萄倒吐葡萄皮”，”葡萄”一词出现了四次，其中左邻字分别为 {吃, 吐, 吃, 吐} ，右邻字分别为 {不, 皮, 倒, 皮} 。根据公式，”葡萄”一词的左邻字的信息熵为 - (1&#x2F;2) · log(1&#x2F;2) - (1&#x2F;2) · log(1&#x2F;2) ≈ 0.693 ，它的右邻字的信息熵则为 - (1&#x2F;2) · log(1&#x2F;2) - (1&#x2F;4) · log(1&#x2F;4) - (1&#x2F;4) · log(1&#x2F;4) ≈ 1.04 。可见，在这个句子中，”葡萄”一词的右邻字更加丰富一些。</p>
<p>一个文本片段的自由运用程度为它的左邻字信息熵和右邻字信息熵中的较小值。</p>
<p>通过信息熵算法，可以很好的区分一些专有名词像玫瑰、蝙蝠等，一些地名像新西兰、伦敦等，这些自由度较低的词汇的</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/51507.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/51507.html" class="post-title-link" itemprop="url">决策树</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-27 17:31:27" itemprop="dateCreated datePublished" datetime="2022-12-27T17:31:27+08:00">2022-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-28 14:40:43" itemprop="dateModified" datetime="2022-12-28T14:40:43+08:00">2022-12-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mechine/" itemprop="url" rel="index"><span itemprop="name">mechine</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>796</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>用于分类和回归的非监督学习方法，通过简单的决策规则（if-else）预测目标</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul>
<li>思想简单，可视乎表达，易理解，可以处理多分类问题</li>
<li>可能会过拟合，此时需要剪枝、采用设置最小样本数目或树的深度</li>
<li>基于启发式算法，节点采用贪婪算法（局部最优），不能保证全局最优，可以随机抽取样本，训练多个树</li>
<li>过于复杂的概念，无法表达</li>
</ul>
<h2 id="决策树-CART"><a href="#决策树-CART" class="headerlink" title="决策树 CART"></a>决策树 CART</h2><p>CART: classifcation and regression tree</p>
<h2 id="irsi数据集构建分类决策树"><a href="#irsi数据集构建分类决策树" class="headerlink" title="irsi数据集构建分类决策树"></a>irsi数据集构建分类决策树</h2><pre><code>from sklearn.datasets import load_iris
from sklearn import tree

#加载iris数据集
iris = load_iris()

clf = tree.DecisionTreeClassifier()
clf = clf.fit(iris.data, iris.target)

import pydotplus
dot_data = tree.export_graphviz(clf, out_file=None)
#dot_data = tree.export_graphviz(clf, out_file=None, 
                              feature_names=iris.feature_names,  
                              class_names=iris.target_names,  
                              filled=True, rounded=True,  
                              special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data)
#导出决策树
graph.write_pdf(&quot;iris.pdf&quot;) 
#Image(graph.create_png())
</code></pre>
<p><img src="http://thyrsi.com/t6/625/1543991582x2890174459.jpg" alt="iris树"></p>
<h2 id="sklearn-example"><a href="#sklearn-example" class="headerlink" title="sklearn example"></a>sklearn example</h2><pre><code>import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

# Parameters
n_classes = 3
plot_colors = &quot;ryb&quot;
plot_step = 0.02

# Load data
iris = load_iris()

for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],
                                [1, 2], [1, 3], [2, 3]]):
    # We only take the two corresponding features
    X = iris.data[:, pair]
    y = iris.target

    # Train
    clf = DecisionTreeClassifier().fit(X, y)

    # Plot the decision boundary
    plt.subplot(2, 3, pairidx + 1)

    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),
                         np.arange(y_min, y_max, plot_step))
    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)

    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)

    plt.xlabel(iris.feature_names[pair[0]])
    plt.ylabel(iris.feature_names[pair[1]])

    # Plot the training points
    for i, color in zip(range(n_classes), plot_colors):
        idx = np.where(y == i)
        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],
                    cmap=plt.cm.RdYlBu, edgecolor=&#39;black&#39;, s=15)

plt.suptitle(&quot;Decision surface of a decision tree using paired features&quot;)
plt.legend(loc=&#39;lower right&#39;, borderpad=0, handletextpad=0)
plt.axis(&quot;tight&quot;)
plt.show()
</code></pre>
<p>   <img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_0011.png" alt="iris树"></p>
<p>链接：<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/auto_examples/tree/plot_iris.html#sphx-glr-auto-examples-tree-plot-iris-py">https://scikit-learn.org/stable/auto_examples&#x2F;tree&#x2F;plot_iris.html#sphx-glr-auto-examples-tree-plot-iris-py</a></p>
<h2 id="决策树回归"><a href="#决策树回归" class="headerlink" title="决策树回归"></a>决策树回归</h2><p>max_depth：图的深度，值太大会导致过拟合</p>
<pre><code># Import the necessary modules and libraries
import numpy as np
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt

# Create a random dataset
rng = np.random.RandomState(1)
X = np.sort(5 * rng.rand(80, 1), axis=0)
y = np.sin(X).ravel() #学习sin曲线
y[::5] += 3 * (0.5 - rng.rand(16)) #干扰值

# Fit regression model
regr_1 = DecisionTreeRegressor(max_depth=2)
regr_2 = DecisionTreeRegressor(max_depth=5)
regr_1.fit(X, y)
regr_2.fit(X, y)

# Predict
X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]
y_1 = regr_1.predict(X_test)
y_2 = regr_2.predict(X_test)

# Plot the results
plt.figure()
plt.scatter(X, y, s=20, edgecolor=&quot;black&quot;,
            c=&quot;darkorange&quot;, label=&quot;data&quot;)
plt.plot(X_test, y_1, color=&quot;cornflowerblue&quot;,
         label=&quot;max_depth=2&quot;, linewidth=2)
plt.plot(X_test, y_2, color=&quot;yellowgreen&quot;, label=&quot;max_depth=5&quot;, linewidth=2)
plt.xlabel(&quot;data&quot;)
plt.ylabel(&quot;target&quot;)
plt.title(&quot;Decision Tree Regression&quot;)
plt.legend()
plt.show()
</code></pre>
<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_001.png" alt="iris树"></p>
<p>链接：<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py">https://scikit-learn.org/stable/auto_examples&#x2F;tree&#x2F;plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py</a></p>
<h2 id="多输出问题"><a href="#多输出问题" class="headerlink" title="多输出问题"></a>多输出问题</h2><pre><code>import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor

# Create a random dataset
rng = np.random.RandomState(1)
X = np.sort(200 * rng.rand(100, 1) - 100, axis=0)
y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T #输出X正弦 余弦
y[::5, :] += (0.5 - rng.rand(20, 2)) #干扰

# Fit regression model
regr_1 = DecisionTreeRegressor(max_depth=2)
regr_2 = DecisionTreeRegressor(max_depth=5)
regr_3 = DecisionTreeRegressor(max_depth=8)
regr_1.fit(X, y)
regr_2.fit(X, y)
regr_3.fit(X, y)

# Predict
X_test = np.arange(-100.0, 100.0, 0.01)[:, np.newaxis]
y_1 = regr_1.predict(X_test)
y_2 = regr_2.predict(X_test)
y_3 = regr_3.predict(X_test)

# Plot the results
plt.figure()
s = 25
plt.scatter(y[:, 0], y[:, 1], c=&quot;navy&quot;, s=s,
            edgecolor=&quot;black&quot;, label=&quot;data&quot;)
plt.scatter(y_1[:, 0], y_1[:, 1], c=&quot;cornflowerblue&quot;, s=s,
            edgecolor=&quot;black&quot;, label=&quot;max_depth=2&quot;)
plt.scatter(y_2[:, 0], y_2[:, 1], c=&quot;red&quot;, s=s,
            edgecolor=&quot;black&quot;, label=&quot;max_depth=5&quot;)
plt.scatter(y_3[:, 0], y_3[:, 1], c=&quot;orange&quot;, s=s,
            edgecolor=&quot;black&quot;, label=&quot;max_depth=8&quot;)
plt.xlim([-6, 6])
plt.ylim([-6, 6])
plt.xlabel(&quot;target 1&quot;)
plt.ylabel(&quot;target 2&quot;)
plt.title(&quot;Multi-output Decision Tree Regression&quot;)
plt.legend(loc=&quot;best&quot;)
plt.show()
</code></pre>
<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_multioutput_001.png" alt="iris树"></p>
<p>链接：<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression_multioutput.html#sphx-glr-auto-examples-tree-plot-tree-regression-multioutput-py">https://scikit-learn.org/stable/auto_examples&#x2F;tree&#x2F;plot_tree_regression_multioutput.html#sphx-glr-auto-examples-tree-plot-tree-regression-multioutput-py</a>
 </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meng Qi</p>
  <div class="site-description" itemprop="description">recording</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">350</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Meng Qi</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">320k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">19:23</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">loading...</span><span id="times">loading...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("1/1/2018 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>

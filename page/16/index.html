<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.fastolf.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="recording">
<meta property="og:type" content="website">
<meta property="og:title" content="Qi">
<meta property="og:url" content="https://www.fastolf.com/page/16/index.html">
<meta property="og:site_name" content="Qi">
<meta property="og:description" content="recording">
<meta property="og:locale">
<meta property="article:author" content="Meng Qi">
<meta property="article:tag" content="Tech;Data;Vision">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.fastolf.com/page/16/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector/main.css" /><link rel="preload" as="style" href="/css/injector/light.css" /><link rel="preload" as="style" href="/css/injector/dark.css" />
  <title>Qi</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
<a target="_blank" rel="noopener" href="https://github.com/gitmmq" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Qi</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Cogito ergo sum</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/ab80f837.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/ab80f837.html" class="post-title-link" itemprop="url">mysql-order by执行原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-18 06:02:14" itemprop="dateCreated datePublished" datetime="2019-11-18T06:02:14+08:00">2019-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:46:13" itemprop="dateModified" datetime="2023-01-18T23:46:13+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>17 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>order by执行原理在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。</p>
<p>还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前1000个人的姓名、年龄。</p>
<p>假设这个表的部分定义是这样的：<br>这时，你的SQL语句可以这么写：<br>CREATE TABLE <code>t</code> (  <code>id</code> int(11) NOT NULL,  <code>city</code> varchar(16) NOT NULL,  <code>name</code> varchar(16) NOT NULL,  <code>age</code> int(11) NOT NULL,  <code>addr</code> varchar(128) DEFAULT NULL,  PRIMARY KEY (<code>id</code>),  KEY <code>city</code> (<code>city</code>)) ENGINE&#x3D;InnoDB;select city,name,age from t where city&#x3D;’杭州’ order by name limit 1000  ;这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为。</p>
<p>全字段排序前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在city字段加上索引。</p>
<p>在city字段上创建索引之后，我们用explain命令来看看这个语句的执行情况。</p>
<p>图1 使用explain命令查看语句的执行情况Extra这个字段中的“Using filesort”表示的就是需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer。</p>
<p>为了说明这个SQL查询语句的执行过程，我们先来看一下city这个索引的示意图。</p>
<p>图2 city字段的索引示意图从图中可以看到，满足city&#x3D;’杭州’条件的行，是从ID_X到ID_(X+N)的这些记录。</p>
<p>通常情况下，这个语句执行流程如下所示 ：</p>
<ol>
<li>初始化sort_buffer，确定放入name、city、age这三个字段；</li>
<li>从索引city找到第一个满足city&#x3D;’杭州’条件的主键id，也就是图中的ID_X；</li>
<li>到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；</li>
<li>从索引city取下一个记录的主键id；</li>
<li>重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；</li>
<li>对sort_buffer中的数据按照字段name做快速排序；</li>
<li>按照排序结果取前1000行返回给客户端。</li>
</ol>
<p>我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。</p>
<p>图3 全字段排序图中“按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。</p>
<p>sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的大小。</p>
<p>如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。</p>
<p>但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</p>
<p>你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。</p>
<p>这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。</p>
<p>&#x2F;* 打开optimizer_trace，只对本线程有效 <em>&#x2F;SET optimizer_trace&#x3D;’enabled&#x3D;on’; &#x2F;</em> @a保存Innodb_rows_read的初始值 <em>&#x2F;select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name &#x3D; ‘Innodb_rows_read’;&#x2F;</em> 执行语句 <em>&#x2F;select city, name,age from t where city&#x3D;’杭州’ order by name limit 1000; &#x2F;</em> 查看 OPTIMIZER_TRACE 输出 <em>&#x2F;SELECT * FROM <code>information_schema</code>.<code>OPTIMIZER_TRACE</code>\G&#x2F;</em> @b保存Innodb_rows_read的当前值 <em>&#x2F;select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name &#x3D; ‘Innodb_rows_read’;&#x2F;</em> 计算Innodb_rows_read差值 *&#x2F;select @b-@a;图4 全排序的OPTIMIZER_TRACE部分结果number_of_tmp_files表示的是，排序过程中使用的临时文件数。</p>
<p>你一定奇怪，为什么需要12个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。</p>
<p>可以这么简单理解，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。</p>
<p>然后把这12个有序文件再合并成一个有序的大文件。</p>
<p>如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存中完成。</p>
<p>否则就需要放在临时文件中排序。</p>
<p>sort_buffer_size越小，需要分成的份数越多，number_of_tmp_files的值就越大。</p>
<p>接下来，我再和你解释一下图4中其他两个值的意思。</p>
<p>我们的示例表中有4000条满足city&#x3D;’杭州’的记录，所以你可以看到 examined_rows&#x3D;4000，表示参与排序的行数是4000行。</p>
<p>sort_mode 里面的packed_additional_fields的意思是，排序过程对字符串做了“紧凑”处理。</p>
<p>即使name字段的定义是varchar(16)，在排序过程中还是要按照实际长度来分配空间的。</p>
<p>同时，最后一个查询语句select @b-@a 的返回结果是4000，表示整个执行过程只扫描了4000行。</p>
<p>这里需要注意的是，为了避免对结论造成干扰，我把internal_tmp_disk_storage_engine设置成MyISAM。</p>
<p>否则，select @b-@a的结果会显示为4001。</p>
<p>这是因为查询OPTIMIZER_TRACE这个表时，需要用到临时表，而internal_tmp_disk_storage_engine的默认值是InnoDB。</p>
<p>如果使用的是InnoDB引擎的话，把数据从临时表取出来的时候，会让Innodb_rows_read的值加1。</p>
<p>rowid排序在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。</p>
<p>但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。</p>
<p>所以如果单行很大，这个方法效率不够好。</p>
<p>那么，如果MySQL认为排序的单行长度太大会怎么做呢？接下来，我来修改一个参数，让MySQL采用另外一种算法。</p>
<p>max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。</p>
<p>它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。</p>
<p>city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我们再来看看计算过程有什么改变。</p>
<p>新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。</p>
<p>但这时，排序的结果就因为少了city和age字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：</p>
<ol>
<li>初始化sort_buffer，确定放入两个字段，即name和id；</li>
<li>从索引city找到第一个满足city&#x3D;’杭州’条件的主键id，也就是图中的ID_X；</li>
<li>到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中；</li>
<li>从索引city取下一个记录的主键id；</li>
<li>重复步骤3、4直到不满足city&#x3D;’杭州’条件为止，也就是图中的ID_Y；</li>
<li>对sort_buffer中的数据按照字段name进行排序；</li>
<li>遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回给客户端。</li>
</ol>
<p>这个执行流程的示意图如下，我把它称为rowid排序。</p>
<p>SET max_length_for_sort_data &#x3D; 16;图5 rowid排序对比图3的全字段排序流程图你会发现，rowid排序多访问了一次表t的主键索引，就是步骤7。</p>
<p>需要说明的是，最后的“结果集”是一个逻辑概念，实际上MySQL服务端从排序后的sort_buffer中依次取出id，然后到原表查到city、name和age这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。</p>
<p>根据这个说明过程和图示，你可以想一下，这个时候执行select @b-@a，结果会是多少呢？现在，我们就来看看结果有什么不同。</p>
<p>首先，图中的examined_rows的值还是4000，表示用于排序的数据是4000行。</p>
<p>但是select @b-@a这个语句的值变成5000了。</p>
<p>因为这时候除了排序过程外，在排序完成后，还要根据id去原表取值。</p>
<p>由于语句是limit 1000，因此会多读1000行。</p>
<p>图6 rowid排序的OPTIMIZER_TRACE部分输出从OPTIMIZER_TRACE的结果中，你还能看到另外两个信息也变了。</p>
<p>sort_mode变成了&lt;sort_key, rowid&gt;，表示参与排序的只有name和id这两个字段。</p>
<p>number_of_tmp_files变成10了，是因为这时候参与排序的行数虽然仍然是4000行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。</p>
<p>全字段排序 VS rowid排序我们来分析一下，从这两个执行流程里，还能得出什么结论。</p>
<p>如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。</p>
<p>如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。</p>
<p>这也就体现了MySQL的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。</p>
<p>对于InnoDB表来说，rowid排序会要求回表多造成磁盘读，因此不会被优先选择。</p>
<p>这个结论看上去有点废话的感觉，但是你要记住它，下一篇文章我们就会用到。</p>
<p>看到这里，你就了解了，MySQL做排序是一个成本比较高的操作。</p>
<p>那么你会问，是不是所有的order by都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。</p>
<p>其实，并不是所有的order by语句，都需要排序操作的。</p>
<p>从上面分析的执行过程，我们可以看到，MySQL之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。</p>
<p>你可以设想下，如果能够保证从city这个索引上取出来的行，天然就是按照name递增排序的话，是不是就可以不用再排序了呢？确实是这样的。</p>
<p>所以，我们可以在这个市民表上创建一个city和name的联合索引，对应的SQL语句是：<br>作为与city索引的对比，我们来看看这个索引的示意图。</p>
<p>图7 city和name联合索引示意图在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足city&#x3D;’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要city的值是杭州，name的值就一定是有序的。</p>
<p>这样整个查询过程的流程就变成了：</p>
<ol>
<li>从索引(city,name)找到第一个满足city&#x3D;’杭州’条件的主键id；</li>
<li>到主键id索引取出整行，取name、city、age三个字段的值，作为结果集的一部分直接返回；</li>
<li>从索引(city,name)取下一个记录主键id；<br>alter table t add index city_user(city, name);4. 重复步骤2、3，直到查到第1000条记录，或者是不满足city&#x3D;’杭州’条件时循环结束。</li>
</ol>
<p>图8 引入(city,name)联合索引后，查询语句的执行计划可以看到，这个查询过程不需要临时表，也不需要排序。</p>
<p>接下来，我们用explain的结果来印证一下。</p>
<p>图9 引入(city,name)联合索引后，查询语句的执行计划从图中可以看到，Extra字段中没有Using filesort了，也就是不需要排序了。</p>
<p>而且由于(city,name)这个联合索引本身有序，所以这个查询也不用把4000行全都读一遍，只要找到满足条件的前1000条记录就可以退出了。</p>
<p>也就是说，在我们这个例子里，只需要扫描1000次。</p>
<p>既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第5篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。</p>
<p>这里我们可以再稍微复习一下。</p>
<p>覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。</p>
<p>按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。</p>
<p>针对这个查询，我们可以创建一个city、name和age的联合索引，对应的SQL语句就是：<br>这时，对于city字段的值相同的行来说，还是按照name字段的值递增排序的，此时的查询语句也就不再需要排序了。</p>
<p>这样整个查询语句的执行流程就变成了：</p>
<ol>
<li>从索引(city,name,age)找到第一个满足city&#x3D;’杭州’条件的记录，取出其中的city、name和age这三个字段的值，作为结果集的一部分直接返回；</li>
<li>从索引(city,name,age)取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；</li>
<li>重复执行步骤2，直到查到第1000条记录，或者是不满足city&#x3D;’杭州’条件时循环结束。</li>
</ol>
<p>图10 引入(city,name,age)联合索引后，查询语句的执行流程然后，我们再来看看explain的结果。</p>
<p>alter table t add index city_user_age(city, name, age);图11 引入(city,name,age)联合索引后，查询语句的执行计划可以看到，Extra字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。</p>
<p>当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。</p>
<p>这是一个需要权衡的决定。</p>
<p>小结今天这篇文章，我和你介绍了MySQL里面order by语句的几种算法流程。</p>
<p>在开发系统的时候，你总是不可避免地会使用到order by语句。</p>
<p>你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。</p>
<p>最后，我给你留下一个思考题吧。</p>
<p>假设你的表里面已经有了city_name(city, name)这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前100条记录。</p>
<p>如果SQL查询语句是这么写的 ：<br>那么，这个语句执行的时候会有排序过程吗，为什么？如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？进一步地，如果有分页需求，要显示第101页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期的问题是，当MySQL去更新一行，但是要修改的值跟原来的值是相同的，这时候MySQL会真的去执行一次修改吗？还是看到值相同就直接返回呢？这是第一次我们课后问题的三个选项都有同学选的，所以我要和你需要详细说明一下。</p>
<p>第一个选项是，MySQL读出数据，发现值与原来相同，不更新，直接返回，执行结束。</p>
<p>这里我们可以用一个锁实验来确认。</p>
<p>mysql&gt; select * from t where city in (‘杭州’,”苏州”) order by name limit 100;假设，当前表t里的值是(1,2)。</p>
<p>图12 锁验证方式session B的update 语句被blocked了，加锁这个动作是InnoDB才能做的，所以排除选项1。</p>
<p>第二个选项是，MySQL调用了InnoDB引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。</p>
<p>有没有这种可能呢？这里我用一个可见性实验来确认。</p>
<p>假设当前表里的值是(1,2)。</p>
<p>图13 可见性验证方式session A的第二个select 语句是一致性读（快照读)，它是不能看见session B的更新的。</p>
<p>现在它返回的是(1,3)，表示它看见了某个新的版本，这个版本只能是session A自己的update语句做更新的时候生成。</p>
<p>（如果你对这个逻辑有疑惑的话，可以回顾下第8篇文章《事务到底是隔离的还是不隔离的？》中的相关内容）所以，我们上期思考题的答案应该是选项3，即：InnoDB认真执行了“把这个值修改成(1,2)”这个操作，该加锁的加锁，该更新的更新。</p>
<p>然后你会说，MySQL怎么这么笨，就不会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费InnoDB操作，多去更新一次了？其实MySQL是确认了的。</p>
<p>只是在这个语句里面，MySQL认为读出来的值，只有一个确定的(id&#x3D;1), 而要写的是(a&#x3D;3)，只从这两个信息是看不出来“不需要修改”的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/6d416b67.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/6d416b67.html" class="post-title-link" itemprop="url">mysql-答疑文章（一）：日志和索引相关问题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-16 06:06:30" itemprop="dateCreated datePublished" datetime="2019-11-16T06:06:30+08:00">2019-11-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>5.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>21 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>答疑文章（一）：日志和索引相关问题<br>在今天这篇答疑文章更新前，MySQL实战这个专栏已经更新了14篇。</p>
<p>在这些文章中，大家在评论区留下了很多高质量的留言。</p>
<p>现在，每篇文章的评论区都有热心的同学帮忙总结文章知识点，也有不少同学提出了很多高质量的问题，更有一些同学帮忙解答其他同学提出的问题。</p>
<p>在浏览这些留言并回复的过程中，我倍受鼓舞，也尽我所知地帮助你解决问题、和你讨论。</p>
<p>可以说，你们的留言活跃了整个专栏的氛围、提升了整个专栏的质量，谢谢你们。</p>
<p>评论区的大多数留言我都直接回复了，对于需要展开说明的问题，我都拿出小本子记了下来。</p>
<p>这些被记下来的问题，就是我们今天这篇答疑文章的素材了。</p>
<p>到目前为止，我已经收集了47个问题，很难通过今天这一篇文章全部展开。</p>
<p>所以，我就先从中找了几个联系非常紧密的问题，串了起来，希望可以帮你解决关于日志和索引的一些疑惑。</p>
<p>而其他问题，我们就留着后面慢慢展开吧。</p>
<p>日志相关问题我在第2篇文章《日志系统：一条SQL更新语句是如何执行的？》中，和你讲到binlog（归档日志）和redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明了如果没有两阶段提交，会导致MySQL出现主备数据不一致等问题。</p>
<p>在这篇文章下面，很多同学在问，在两阶段提交的不同瞬间，MySQL如果发生异常重启，是怎么保证数据完整性的？现在，我们就从这个问题开始吧。</p>
<p>我再放一次两阶段提交的图，方便你学习下面的内容。</p>
<p>图1 两阶段提交示意图这里，我要先和你解释一个误会式的问题。</p>
<p>有同学在评论区问到，这个图不是一个update语句的执行流程吗，怎么还会调用commit语句？他产生这个疑问的原因，是把两个“commit”的概念混淆了：</p>
<p>他说的“commit语句”，是指MySQL语法中，用于提交一个事务的命令。</p>
<p>一般跟begin&#x2F;starttransaction 配对使用。</p>
<p>而我们图中用到的这个“commit步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。</p>
<p>当这个步骤执行完成后，这个事务就提交完成了。</p>
<p>“commit语句”执行的时候，会包含“commit 步骤”。</p>
<p>而我们这个例子里面，没有显式地开启事务，因此这个update语句自己就是一个事务，在执行完成后提交事务时，就会用到这个“commit步骤“。</p>
<p>接下来，我们就一起分析一下在两阶段提交的不同时刻，MySQL异常重启会出现什么现象。</p>
<p>如果在图中时刻A的地方，也就是写入redo log 处于prepare阶段之后、写binlog之前，发生了崩溃（crash），由于此时binlog还没写，redo log也还没提交，所以崩溃恢复的时候，这个事务会回滚。</p>
<p>这时候，binlog还没写，所以也不会传到备库。</p>
<p>到这里，大家都可以理解。</p>
<p>大家出现问题的地方，主要集中在时刻B，也就是binlog写完，redo log还没commit前发生crash，那崩溃恢复的时候MySQL会怎么处理？我们先来看一下崩溃恢复时的判断规则。</p>
<ol>
<li><p>如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交；</p>
</li>
<li><p>如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整：</p>
</li>
</ol>
<p>a. 如果是，则提交事务；</p>
<p>b. 否则，回滚事务。</p>
<p>这里，时刻B发生crash对应的就是2(a)的情况，崩溃恢复过程中事务会被提交。</p>
<p>现在，我们继续延展一下这个问题。</p>
<p>追问1：MySQL怎么知道binlog是完整的?回答：一个事务的binlog是有完整格式的：</p>
<p>statement格式的binlog，最后会有COMMIT；</p>
<p>row格式的binlog，最后会有一个XID event。</p>
<p>另外，在MySQL 5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。</p>
<p>对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验checksum的结果来发现。</p>
<p>所以，MySQL还是有办法验证事务binlog的完整性的。</p>
<p>追问2：redo log 和 binlog是怎么关联起来的?回答：它们有一个共同的数据字段，叫XID。</p>
<p>崩溃恢复的时候，会按顺序扫描redo log：</p>
<p>如果碰到既有prepare、又有commit的redo log，就直接提交；</p>
<p>如果碰到只有parepare、而没有commit的redo log，就拿着XID去binlog找对应的事务。</p>
<p>追问3：处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计?回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。</p>
<p>在时刻B，也就是binlog写完以后MySQL发生崩溃，这时候binlog已经写入了，之后就会被从库（或者用这个binlog恢复出来的库）使用。</p>
<p>所以，在主库上也要提交这个事务。</p>
<p>采用这个策略，主库和备库的数据就保证了一致性。</p>
<p>追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redo log写完，再写binlog。</p>
<p>崩溃恢复的时候，必须得两个日志都完整才可以。</p>
<p>是不是一样的逻辑？回答：其实，两阶段提交是经典的分布式系统问题，并不是MySQL独有的。</p>
<p>如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。</p>
<p>对于InnoDB引擎来说，如果redo log提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。</p>
<p>而如果redo log直接提交，然后binlog写入的时候失败，InnoDB又回滚不了，数据和binlog日志又不一致了。</p>
<p>两阶段提交就是为了给所有人一个机会，当每个人都说“我ok”的时候，再一起提交。</p>
<p>追问5：不引入两个日志，也就没有两阶段提交的必要了。</p>
<p>只用binlog来支持崩溃恢复，又能支持归档，不就可以了？回答：这位同学的意思是，只保留binlog，然后可以把提交流程改成这样：… -&gt; “数据更新到内存” -&gt; “写 binlog” -&gt; “提交事务”，是不是也可以提供崩溃恢复的能力？答案是不可以。</p>
<p>如果说历史原因的话，那就是InnoDB并不是MySQL的原生存储引擎。</p>
<p>MySQL的原生引擎是MyISAM，设计之初就有没有支持崩溃恢复。</p>
<p>InnoDB在作为MySQL的插件加入MySQL引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。</p>
<p>InnoDB接入了MySQL后，发现既然binlog没有崩溃恢复的能力，那就用InnoDB原有的redo log好了。</p>
<p>而如果说实现上的原因的话，就有很多了。</p>
<p>就按照问题中说的，只用binlog来实现崩溃恢复的流程，我画了一张示意图，这里就没有redo log了。</p>
<p>图2 只用binlog支持崩溃恢复这样的流程下，binlog还是不能支持崩溃恢复的。</p>
<p>我说一个不支持的点吧：binlog没有能力恢复“数据页”。</p>
<p>如果在图中标的位置，也就是binlog2写完了，但是整个事务还没有commit的时候，MySQL发生了crash。</p>
<p>重启后，引擎内部事务2会回滚，然后应用binlog2可以补回来；但是对于事务1来说，系统已经认为提交完成了，不会再应用一次binlog1。</p>
<p>但是，InnoDB引擎使用的是WAL技术，执行事务的时候，写完内存和日志，事务就算完成了。</p>
<p>如果之后崩溃，要依赖于日志来恢复数据页。</p>
<p>也就是说在图中这个位置发生崩溃的话，事务1也是可能丢失了的，而且是数据页级的丢失。</p>
<p>此时，binlog里面并没有记录数据页的更新细节，是补不回来的。</p>
<p>你如果要说，那我优化一下binlog的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个redo log出来。</p>
<p>所以，至少现在的binlog能力，还不能支持崩溃恢复。</p>
<p>追问6：那能不能反过来，只用redo log，不要binlog？回答：如果只从崩溃恢复的角度来讲是可以的。</p>
<p>你可以把binlog关掉，这样就没有两阶段提交了，但系统依然是crash-safe的。</p>
<p>但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog都是开着的。</p>
<p>因为binlog有着redo log无法替代的功能。</p>
<p>一个是归档。</p>
<p>redo log是循环写，写到末尾是要回到开头继续写的。</p>
<p>这样历史日志没法保留，redo log也就起不到归档的作用。</p>
<p>一个就是MySQL系统依赖于binlog。</p>
<p>binlog作为MySQL一开始就有的功能，被用在了很多地方。</p>
<p>其中，MySQL系统高可用的基础，就是binlog复制。</p>
<p>还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费MySQL的binlog来更新自己的数据。</p>
<p>关掉binlog的话，这些下游系统就没法输入了。</p>
<p>总之，由于现在包括MySQL高可用在内的很多系统机制都依赖于binlog，所以“鸠占鹊巢”redolog还做不到。</p>
<p>你看，发展生态是多么重要。</p>
<p>追问7：redo log一般设置多大？回答：redo log太小的话，会导致很快就被写满，然后不得不强行刷redo log，这样WAL机制的能力就发挥不出来了。</p>
<p>所以，如果是现在常见的几个TB的磁盘的话，就不要太小气了，直接将redo log设置为4个文件、每个文件1GB吧。</p>
<p>追问8：正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？回答：这个问题其实问得非常好。</p>
<p>这里涉及到了，“redo log里面到底是什么”的问题。</p>
<p>实际上，redo log并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由redo log更新过去”的情况。</p>
<ol>
<li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。</li>
</ol>
<p>最终数据落盘，就是把内存中的数据页写盘。</p>
<p>这个过程，甚至与redo log毫无关系。</p>
<ol start="2">
<li>在崩溃恢复场景中，InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让redo log更新内存内容。</li>
</ol>
<p>更新完成后，内存页变成脏页，就回到了第一种情况的状态。</p>
<p>追问9：redo log buffer是什么？是先修改内存，还是先写redo log文件？回答：这两个问题可以一起回答。</p>
<p>在一个事务的更新过程中，日志是要写多次的。</p>
<p>比如下面这个事务：</p>
<p>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没commit的时候就直接写到redo log文件里。</p>
<p>所以，redo log buffer就是一块内存，用来先存redo日志的。</p>
<p>也就是说，在执行第一个insert的时候，数据的内存被修改了，redo log buffer也写入了日志。</p>
<p>但是，真正把日志写到redo log文件（文件名是 ib_logfile+数字），是在执行commit语句的时候做的。</p>
<p>（这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的IO消耗。</p>
<p>但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。</p>
<p>这个问题我们会在后面第22篇文章《MySQL有哪些“饮鸩止渴”的提高性能的方法？》中再详细展开）。</p>
<p>单独执行一个更新语句的时候，InnoDB会自己启动一个事务，在语句执行完成的时候提交。</p>
<p>过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。</p>
<p>以上这些问题，就是把大家提过的关于redo log和binlog的问题串起来，做的一次集中回答。</p>
<p>如果你还有问题，可以在评论区继续留言补充。</p>
<p>业务设计问题接下来，我再和你分享@ithunter 同学在第8篇文章《事务到底是隔离的还是不隔离的？》的评论区提到的跟索引相关的一个问题。</p>
<p>我觉得这个问题挺有趣、也挺实用的，其他同学也可能会碰上这样的场景，在这里解答和分享一下。</p>
<p>问题是这样的（我文字上稍微做了点修改，方便大家理解）：</p>
<p>begin;insert into t1 …insert into t2 …commit;业务上有这样的需求，A、B两个用户，如果互相关注，则成为好友。</p>
<p>设计上是有两张表，一个是like表，一个是friend表，like表有user_id、liker_id两个字段，我设置为复合唯一索引即首先，我要先赞一下这样的提问方式。</p>
<p>虽然极客时间现在的评论区还不能追加评论，但如果大家能够一次留言就把问题讲清楚的话，其实影响也不大。</p>
<p>所以，我希望你在留言提问的时候，也能借鉴这种方式。</p>
<p>接下来，我把@ithunter 同学说的表模拟出来，方便我们讨论。</p>
<p>虽然这个题干中，并没有说到friend表的索引结构。</p>
<p>但我猜测friend_1_id和friend_2_id也有索uk_user_id_liker_id。</p>
<p>语句执行逻辑是这样的：</p>
<p>以A关注B为例：</p>
<p>第一步，先查询对方有没有关注自己（B有没有关注A）select * from like where user_id &#x3D; B and liker_id &#x3D; A;如果有，则成为好友insert into friend;没有，则只是单向关注关系insert into like;但是如果A、B同时关注对方，会出现不会成为好友的情况。</p>
<p>因为上面第1步，双方都没关注对方。</p>
<p>第1步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。</p>
<p>请问这种情况，在MySQL锁层面有没有办法处理？CREATE TABLE <code>like</code> (  <code>id</code> int(11) NOT NULL AUTO_INCREMENT,  <code>user_id</code> int(11) NOT NULL,  <code>liker_id</code> int(11) NOT NULL,  PRIMARY KEY (<code>id</code>),  UNIQUE KEY <code>uk_user_id_liker_id</code> (<code>user_id</code>,<code>liker_id</code>)) ENGINE&#x3D;InnoDB;CREATE TABLE <code>friend</code> (  id<code>int(11) NOT NULL AUTO_INCREMENT, </code>friend_1_id<code>int(11) NOT NULL, </code>firned_2_id<code>int(11) NOT NULL,  UNIQUE KEY</code>uk_friend<code> (</code>friend_1_id<code>,</code>firned_2_id<code>)  PRIMARY KEY (</code>id&#96;)) ENGINE&#x3D;InnoDB;引，为便于描述，我给加上唯一索引。</p>
<p>顺便说明一下，“like”是关键字，我一般不建议使用关键字作为库名、表名、字段名或索引名。</p>
<p>我把他的疑问翻译一下，在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系。</p>
<p>现在，我用你已经熟悉的时刻顺序表的形式，把这两个事务的执行语句列出来：</p>
<p>图3 并发“喜欢”逻辑操作顺序由于一开始A和B之间没有关注关系，所以两个事务里面的select语句查出来的结果都是空。</p>
<p>因此，session 1的逻辑就是“既然B没有关注A，那就只插入一个单向关注关系”。</p>
<p>session 2也同样是这个逻辑。</p>
<p>这个结果对业务来说就是bug了。</p>
<p>因为在业务设定里面，这两个逻辑都执行完成以后，是应该在friend表里面插入一行记录的。</p>
<p>如提问里面说的，“第1步即使使用了排他锁也不行，因为记录不存在，行锁无法生效”。</p>
<p>不过，我想到了另外一个方法，来解决这个问题。</p>
<p>首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值1、2、3。</p>
<p>值是1的时候，表示user_id 关注 liker_id;值是2的时候，表示liker_id 关注 user_id;值是3的时候，表示互相关注。</p>
<p>然后，当 A关注B的时候，逻辑改成如下所示的样子：</p>
<p>应用代码里面，比较A和B的大小，如果A&lt;B，就执行下面的逻辑如果A&gt;B，则执行下面的逻辑这个设计里，让“like”表里的数据保证user_id &lt; liker_id，这样不论是A关注B，还是B关注A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。</p>
<p>然后，insert … on duplicate语句，确保了在事务内部，执行了这个SQL语句后，就强行占住了这个行锁，之后的select 判断relation_ship这个逻辑时就确保了是在行锁保护下的读操作。</p>
<p>操作符 “|” 是按位或，连同最后一句insert语句里的ignore，是为了保证重复调用时的幂等性。</p>
<p>这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是like表里面有一条关于A和B的记录，而且relation_ship的值是3， 并且friend表里面也有了A和B的这条记录。</p>
<p>mysql&gt; begin; &#x2F;<em>启动事务</em>&#x2F;insert into <code>like</code>(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship&#x3D;relation_ship | 1;select relation_ship from <code>like</code> where user_id&#x3D;A and liker_id&#x3D;B;&#x2F;*代码中判断返回的 relation_ship，  如果是1，事务结束，执行 commit  如果是3，则执行下面这两个语句：</p>
<p>  *&#x2F;insert ignore into friend(friend_1_id, friend_2_id) values(A,B);commit;mysql&gt; begin; &#x2F;<em>启动事务</em>&#x2F;insert into <code>like</code>(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship&#x3D;relation_ship | 2;select relation_ship from <code>like</code> where user_id&#x3D;B and liker_id&#x3D;A;&#x2F;*代码中判断返回的 relation_ship，  如果是2，事务结束，执行 commit  如果是3，则执行下面这两个语句：</p>
<p>*&#x2F;insert ignore into friend(friend_1_id, friend_2_id) values(B,A);commit;不知道你会不会吐槽：之前明明还说尽量不要使用唯一索引，结果这个例子一上来我就创建了两个。</p>
<p>这里我要再和你说明一下，之前文章我们讨论的，是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。</p>
<p>而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧。</p>
<p>小结这是专栏的第一篇答疑文章。</p>
<p>我针对前14篇文章，大家在评论区中的留言，从中摘取了关于日志和索引的相关问题，串成了今天这篇文章。</p>
<p>这里我也要再和你说一声，有些我答应在答疑文章中进行扩展的话题，今天这篇文章没来得及扩展，后续我会再找机会为你解答。</p>
<p>所以，篇幅所限，评论区见吧。</p>
<p>最后，虽然这篇是答疑文章，但课后问题还是要有的。</p>
<p>我们创建了一个简单的表t，并插入一行，然后对这一行做修改。</p>
<p>这时候，表t里有唯一的一行数据(1,2)。</p>
<p>假设，我现在要执行：</p>
<p>你会看到这样的结果：</p>
<p>结果显示，匹配(rows matched)了一行，修改(Changed)了0行。</p>
<p>仅从现象上看，MySQL内部在处理这个命令的时候，可以有以下三种选择：</p>
<ol>
<li><p>更新都是先读后写的，MySQL读出数据，发现a的值本来就是2，不更新，直接返回，执行mysql&gt; CREATE TABLE <code>t</code> (<code>id</code> int(11) NOT NULL primary key auto_increment,<code>a</code> int(11) DEFAULT NULL) ENGINE&#x3D;InnoDB;insert into t values(1,2);mysql&gt; update t set a&#x3D;2 where id&#x3D;1;结束；</p>
</li>
<li><p>MySQL调用了InnoDB引擎提供的“修改为(1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；</p>
</li>
<li><p>InnoDB认真执行了“把这个值修改成(1,2)”这个操作，该加锁的加锁，该更新的更新。</p>
</li>
</ol>
<p>你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步地，可以思考一下，MySQL为什么要选择这种策略呢？你可以把你的验证方法和思考写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期的问题是，用一个计数表记录一个业务表的总行数，在往业务表插入数据的时候，需要给计数值加1。</p>
<p>逻辑实现上是启动一个事务，执行两个语句：</p>
<ol>
<li><p>insert into 数据表；</p>
</li>
<li><p>update 计数表，计数值加1。</p>
</li>
</ol>
<p>从系统并发能力的角度考虑，怎么安排这两个语句的顺序。</p>
<p>这里，我直接复制 @阿建 的回答过来供你参考：</p>
<p>评论区有同学说，应该把update计数表放后面，因为这个计数表可能保存了多个业务表的计数值。</p>
<p>如果把update计数表放到事务的第一个语句，多个业务表同时插入数据的话，等待时间会更长。</p>
<p>这个答案的结论是对的，但是理解不太正确。</p>
<p>即使我们用一个计数表记录多个业务表的行数，也肯定会给表名字段加唯一索引。</p>
<p>类似于下面这样的表结构：</p>
<p>并发系统性能的角度考虑，应该先插入操作记录，再更新计数表。</p>
<p>知识点在《行锁功过：怎么减少行锁对性能的影响？》因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少事务之间的锁等待，提升并发度。</p>
<p>在更新计数表的时候，一定会传入where table_name&#x3D;$table_name，使用主键索引，更新加行锁只会锁在一行上。</p>
<p>而在不同业务表插入数据，是更新不同的行，不会有行锁。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/6fde2059.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/6fde2059.html" class="post-title-link" itemprop="url">mysql-count性能优化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-15 06:10:36" itemprop="dateCreated datePublished" datetime="2019-11-15T06:10:36+08:00">2019-11-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:46:13" itemprop="dateModified" datetime="2023-01-18T23:46:13+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><h2 id="count-语句实现方式"><a href="#count-语句实现方式" class="headerlink" title="count(*)语句实现方式"></a>count(*)语句实现方式</h2><p>在不同的MySQL引擎中，count(*)有不同的实现方式。</p>
<h3 id="MyISAM引擎"><a href="#MyISAM引擎" class="headerlink" title="MyISAM引擎"></a>MyISAM引擎</h3><p>MyISAM引擎把一个表的总行数存在了磁盘上，执行count(*)的时候会直接返回这个数，效率很高； 加 where 条件后，无法直接得到结果，也需要过滤。</p>
<h3 id="InnoDB引擎"><a href="#InnoDB引擎" class="headerlink" title="InnoDB引擎"></a>InnoDB引擎</h3><p>InnoDB引执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</p>
<p>InnoDB不论是在事务支持、并发能力还是在数据安全方面，InnoDB都优于MyISAM。</p>
<p>当你的记录数越来越多的时候，计算一个表的总行数会越来越慢。</p>
<h4 id="为什么InnoDB不跟MyISAM一样，也把数字存起来呢？因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB-表“应该返回多少行”也是不确定的。"><a href="#为什么InnoDB不跟MyISAM一样，也把数字存起来呢？因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB-表“应该返回多少行”也是不确定的。" class="headerlink" title="为什么InnoDB不跟MyISAM一样，也把数字存起来呢？因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。"></a>为什么InnoDB不跟MyISAM一样，也把数字存起来呢？因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。</h4><p>这里，我用一个算count(*)的例子来为你解释一下。</p>
<p>表“应该返回多少行”也是不确定的。</p>
<p>假设表t中现在有10000条记录，我们设计了三个用户并行的会话。</p>
<p>假设表t中现在有10000条记录，我们设计了三个用户并行的会话。</p>
<p>会话A先启动事务并查询一次表的总行数；</p>
<p>会话B启动事务，插入一行后记录后，查询表的总行数；</p>
<p>会话C先启动一个单独的语句，插入一行记录后，查询表的总行数。</p>
<p>会话C先启动一个单独的语句，插入一行记录后，查询表的总行数。</p>
<p>我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。</p>
<p>我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。</p>
<p>你会看到，在最后一个时刻，三个会话A、B、C会同时查询表t的总行数，但拿到的结果却不同。</p>
<p>这和InnoDB的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是MVCC来实现的。</p>
<p>每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断。</p>
<h2 id="优化方法InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。"><a href="#优化方法InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。" class="headerlink" title="优化方法InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。"></a>优化方法InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。</h2><p>所以，普通索引树比主键索引树小很多。</p>
<p>对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。</p>
<p>因此，MySQL优化器会找到最小的那棵树来遍历。</p>
<p>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</p>
<p>如果你用过show table status 命令的话，就会发现这个命令的输出结果里面也有一个TABLE_ROWS用于显示这个表当前有多少行，这个命令执行挺快的，那这个TABLE_ROWS能代替count(*)吗？索引统计的值是通过采样来估算的。</p>
<p>实际上，TABLE_ROWS就是从这个采样估算得来的，因此它也很不准。</p>
<p>是通过采样来估算的。</p>
<p>有多不准呢，官方文档说误差可能达到40%到50%。</p>
<p>所以，show table status命令显示的行数也不能直接使用。</p>
<p>MyISAM表虽然count(*)很快，但是不支持事务；</p>
<p>show table status命令虽然返回很快，但是不准确；</p>
<p>InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。</p>
<p>InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。</p>
<p>如果你现在有一个页面经常要显示交易系统的操作记录总数，到底## 最佳实现自己计数### 用缓存系统保存计数对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持。</p>
<p>可以用一个Redis服务来保存这个表的总行数。</p>
<p>这个表每被插入一行Redis计数就加1，每被删除一行Redis计数就减1。</p>
<p>这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？没错，缓存系统可能会丢失更新。</p>
<p>Redis的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。</p>
<p>但即使这样，仍然可能丢失更新。</p>
<p>试想如果刚刚在数据表中插入了一行，Redis中保存的值也加了1，然后Redis异常重启了，重启后你要从存储redis数据的地方把这个值读回来，而刚刚加1的这个计数操作却丢失了。</p>
<p>当然了，这还是有解的。</p>
<p>比如，Redis异常重启以后，到数据库里面单独执行一次count(*)获取真实的行数，再把这个值写回到Redis里就可以了。</p>
<p>异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。</p>
<p>但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。</p>
<p>即使Redis正常工作，这个值还是逻辑上不精确的。</p>
<p>你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的100条记录。</p>
<p>那么，这个页面的逻辑就需要先到Redis里面取出计数，再到数据表里面取数据记录，这个页面的逻辑就需要先到Redis里面取出计数，再到数据表里面取数据记录。</p>
<p>我们是这么定义不精确的：</p>
<ol>
<li><p>一种是，查到的100行结果里面有最新插入记录，而Redis的计数里还没加1；</p>
</li>
<li><p>另一种是，查到的100行结果里没有最新插入的记录，而Redis的计数里已经加了1。</p>
</li>
</ol>
<p>这两种情况，都是逻辑不一致的。</p>
<p>会话A是一个插入交易记录的逻辑，往数据表里插入一行R，然后Redis计数加1；会话B就是查询页面显示时需要的数据。</p>
<p>在图2的这个时序里，在T3时刻会话B来查询的时候，会显示出新插入的R这个记录，但是Redis的计数还没加1。</p>
<p>这时候，就会出现我们说的数据不一致。</p>
<p>你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改Redis计数。</p>
<p>而读的时候是先读Redis，再读数据表，这个顺序是相反的。</p>
<p>那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话A的更新顺序换一下，再看看执行结果。</p>
<p>问题了？我们现在把会话A的更新顺序换一下，再看看执行结果。</p>
<p>调整顺序后，会话B在T3时刻查询的时候，Redis计数加了1了，但还查不到新插入的R这一行，也是数据不一致的情况。</p>
<p>在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使Redis正常工作，这个计数值还是逻辑上不精确的。</p>
<h3 id="用数据库保存计数把这个计数直接放到数据库里单独的一张计数表C中，又会怎么样呢？首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。"><a href="#用数据库保存计数把这个计数直接放到数据库里单独的一张计数表C中，又会怎么样呢？首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。" class="headerlink" title="用数据库保存计数把这个计数直接放到数据库里单独的一张计数表C中，又会怎么样呢？首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。"></a>用数据库保存计数把这个计数直接放到数据库里单独的一张计数表C中，又会怎么样呢？首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。</h3><p>会话B的读操作仍然是在T3执行的，但是因为这时候更新事务还没有提交，所以计数值加1这个操作对会话B还不可见。</p>
<p>还没有提交，所以计数值加1这个操作对会话B还不可见。</p>
<p>因此，会话B看到的结果里， 查计数值和“最近100条记录”看到的结果，逻辑上就是一致的。</p>
<h2 id="不同的count用法基于InnoDB引擎，count-、count-主键id-、count-字段-和count-1-等不同用法的性能，有哪些差别。"><a href="#不同的count用法基于InnoDB引擎，count-、count-主键id-、count-字段-和count-1-等不同用法的性能，有哪些差别。" class="headerlink" title="不同的count用法基于InnoDB引擎，count(*)、count(主键id)、count(字段)和count(1)等不同用法的性能，有哪些差别。"></a>不同的count用法基于InnoDB引擎，count(*)、count(主键id)、count(字段)和count(1)等不同用法的性能，有哪些差别。</h2><p>首先你要弄清楚count()的语义。</p>
<p>count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。</p>
<p>最后返回累计值。</p>
<p>所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。</p>
<p>至于分析性能差别的时候，你可以记住这么几个原则：</p>
<ol>
<li><p>server层要什么就给什么；</p>
</li>
<li><p>InnoDB只给必要的值；</p>
</li>
<li><p>现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。</p>
</li>
</ol>
<p>这是什么意思呢？接下来，我们就一个个地来看看。</p>
<p>这是什么意思呢？接下来，我们就一个个地来看看。</p>
<p>对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。</p>
<p>server层拿到id后，判断是不可能为空的，就按行累加。</p>
<p>对于count(1)来说，InnoDB引擎遍历整张表，但不取值。</p>
<p>server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</p>
<p>单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。</p>
<p>因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。</p>
<p>返回id会涉及到解析数据行，以及拷贝字段值的操作。</p>
<p>对于count(字段)来说：</p>
<ol>
<li><p>如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；</p>
</li>
<li><p>如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。</p>
</li>
</ol>
<p>也就是前面的第一条原则，server层要什么字段，InnoDB就返回什么字段。</p>
<p>但是count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。</p>
<p>count(*)肯定不是null，按行累加。</p>
<p>看到这里，你一定会说，优化器就不能自己判断一下吗，主键id肯定非空啊，为什么不能按照count(*)来处理，多么简单的优化啊。</p>
<p>当然，MySQL专门针对这个语句进行优化，也不是不可以。</p>
<p>但是这种需要专门优化的情况太多了，而且MySQL已经优化过count(*)了，你直接使用这种用法就可以了。</p>
<p>所以结论是：按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(*)今天，我和你聊了聊MySQL中获得表行数的两种方法。</p>
<p>我们提到了在不同引擎中count(*)的实现<br>把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。</p>
<p>而把计数值也放在MySQL中，就解决了一致性视图的问题。</p>
<p>InnoDB引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。</p>
<p>我们用事务来确保计数准确。</p>
<p>由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。</p>
<p>但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/89a00def.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/89a00def.html" class="post-title-link" itemprop="url">mysql-为什么表数据删掉一半，表文件大小不变</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-14 06:15:11" itemprop="dateCreated datePublished" datetime="2019-11-14T06:15:11+08:00">2019-11-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:46:13" itemprop="dateModified" datetime="2023-01-18T23:46:13+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>为什么表数据删掉一半，表文件大小不变？经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？那么今天，我就和你聊聊数据库表的空间回收，看看如何解决这个问题。</p>
<p>这里，我们还是针对MySQL中应用最广泛的InnoDB引擎展开讨论。</p>
<p>一个InnoDB表包含两部分，即：表结构定义和数据。</p>
<p>在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。</p>
<p>而MySQL 8.0版本，则已经允许把表结构定义放在系统数据表中了。</p>
<p>因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。</p>
<p>接下来，我会先和你说明为什么简单地删除表数据达不到表空间回收的效果，然后再和你介绍正确回收空间的方法。</p>
<p>参数innodb_file_per_table表数据既可以存在共享表空间里，也可以是单独的文件。</p>
<p>这个行为是由参数innodb_file_per_table控制的：</p>
<ol>
<li><p>这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</p>
</li>
<li><p>这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。</p>
</li>
</ol>
<p>从MySQL 5.6.6版本开始，它的默认值就是ON了。</p>
<p>我建议你不论使用MySQL的哪个版本，都将这个值设置为ON。</p>
<p>因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过drop table命令，系统就会直接删除这个文件。</p>
<p>而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</p>
<p>所以，将innodb_file_per_table设置为ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。</p>
<p>我们在删除整个表的时候，可以使用drop table命令回收表空间。</p>
<p>但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。</p>
<p>我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。</p>
<p>数据删除流程我们先再来看一下InnoDB中一个索引的示意图。</p>
<p>在前面第4和第5篇文章中，我和你介绍索引时曾经提到过，InnoDB里的数据都是用B+树的结构组织的。</p>
<p>图1 B+树索引示意图假设，我们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。</p>
<p>如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。</p>
<p>但是，磁盘文件的大小并不会缩小。</p>
<p>现在，你已经知道了InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？答案是，整个数据页就可以被复用了。</p>
<p>但是，数据页的复用跟记录的复用是不同的。</p>
<p>记录的复用，只限于符合范围条件的数据。</p>
<p>比如上面的这个例子，R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。</p>
<p>但如果插入的是一个ID是800的行，就不能复用这个位置了。</p>
<p>而当整个页从B+树里面摘掉以后，可以复用到任何位置。</p>
<p>以图1为例，如果将数据页page A上的所有记录删除以后，page A会被标记为可复用。</p>
<p>这时候如果要插入一条ID&#x3D;50的记录需要使用新页的时候，page A是可以被复用的。</p>
<p>如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。</p>
<p>进一步地，如果我们用delete命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。</p>
<p>但是磁盘上，文件不会变小。</p>
<p>你现在知道了，delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。</p>
<p>也就是说，通过delete命令是不能回收表空间的。</p>
<p>这些可以复用，而没有被使用的空间，看起来就像是“空洞”。</p>
<p>实际上，不止是删除数据会造成空洞，插入数据也会。</p>
<p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。</p>
<p>但如果数据是随机插入的，就可能造成索引的数据页分裂。</p>
<p>假设图1中page A已经满了，这时我要再插入一行数据，会怎样呢？图2 插入数据导致页分裂可以看到，由于page A满了，再插入一个ID是550的数据时，就不得不再申请一个新的页面page B来保存数据了。</p>
<p>页分裂完成后，page A的末尾就留下了空洞（注意：实际上，可能不止1个记录的位置是空洞）。</p>
<p>另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。</p>
<p>不难理解，这也是会造成空洞的。</p>
<p>也就是说，经过大量增删改的表，都是可能是存在空洞的。</p>
<p>所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。</p>
<p>而重建表，就可以达到这样的目的。</p>
<p>重建表试想一下，如果你现在有一个表A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？你可以新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。</p>
<p>由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。</p>
<p>显然地，表B的主键索引更紧凑，数据页的利用率也更高。</p>
<p>如果我们把表B作为临时表，数据从表A导入表B的操作完成后，用表B替换A，从效果上看，就起到了收缩表A空间的作用。</p>
<p>这里，你可以使用alter table A engine&#x3D;InnoDB命令来重建表。</p>
<p>在MySQL 5.5版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自动完成转存数据、交换表名、删除旧表的操作。</p>
<p>图3 改锁表DDL显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会造成数据丢失。</p>
<p>因此，在整个DDL过程中，表A中不能有更新。</p>
<p>也就是说，这个DDL不是Online的。</p>
<p>而在MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。</p>
<p>我给你简单描述一下引入了Online DDL之后，重建表的流程：</p>
<ol>
<li><p>建立一个临时文件，扫描表A主键的所有数据页；</p>
</li>
<li><p>用数据页中表A的记录生成B+树，存储到临时文件中；</p>
</li>
<li><p>生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；</p>
</li>
<li><p>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；</p>
</li>
<li><p>用临时文件替换表A的数据文件。</p>
</li>
</ol>
<p>图4 Online DDL可以看到，与图3过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表A做增删改操作。</p>
<p>这也就是Online DDL名字的来源。</p>
<p>我记得有同学在第6篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL之前是要拿MDL写锁的，这样还能叫Online DDL吗？确实，图4的流程中，alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。</p>
<p>为什么要退化呢？为了实现Online，MDL读锁不会阻塞增删改操作。</p>
<p>那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做DDL。</p>
<p>而对于一个大表来说，Online DDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。</p>
<p>所以，相对于整个DDL过程来说，锁的时间非常短。</p>
<p>对业务来说，就可以认为是Online的。</p>
<p>需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。</p>
<p>对于很大的表来说，这个操作是很消耗IO和CPU资源的。</p>
<p>因此，如果是线上服务，你要很小心地控制操作时间。</p>
<p>如果想要比较安全的操作的话，我推荐你使用GitHub开源的gh-ost来做。</p>
<p>Online 和 inplace说到Online，我还要再和你澄清一下它和另一个跟DDL有关的、容易混淆的概念inplace的区别。</p>
<p>你可能注意到了，在图3中，我们把表A中的数据导出来的存放位置叫作tmp_table。</p>
<p>这是一个临时表，是在server层创建的。</p>
<p>在图4中，根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出来的。</p>
<p>整个DDL过程都在InnoDB内部完成。</p>
<p>对于server层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。</p>
<p>所以，我现在问你，如果你有一个1TB的表，现在磁盘间是1.2TB，能不能做一个inplace的DDL呢？答案是不能。</p>
<p>因为，tmp_file也是要占用临时空间的。</p>
<p>我们重建表的这个语句alter table t engine&#x3D;InnoDB，其实隐含的意思是：</p>
<p>跟inplace对应的就是拷贝表的方式了，用法是：</p>
<p>当你使用ALGORITHM&#x3D;copy的时候，表示的是强制拷贝表，对应的流程就是图3的操作过程。</p>
<p>但我这样说你可能会觉得，inplace跟Online是不是就是一个意思？其实不是的，只是在重建表这个逻辑中刚好是这样而已。</p>
<p>比如，如果我要给InnoDB表的一个字段加全文索引，写法是：</p>
<p>这个过程是inplace的，但会阻塞增删改操作，是非Online的。</p>
<p>如果说这两个逻辑之间的关系是什么的话，可以概括为：</p>
<ol>
<li>DDL过程如果是Online的，就一定是inplace的；</li>
</ol>
<p>alter table t engine&#x3D;innodb,ALGORITHM&#x3D;inplace;alter table t engine&#x3D;innodb,ALGORITHM&#x3D;copy;alter table t add FULLTEXT(field_name);2. 反过来未必，也就是说inplace的DDL，有可能不是Online的。</p>
<p>截止到MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引(SPATIAL index)就属于这种情况。</p>
<p>最后，我们再延伸一下。</p>
<p>在第10篇文章《MySQL为什么有时候会选错索引》的评论区中，有同学问到使用optimizetable、analyze table和alter table这三种方式重建表的区别。</p>
<p>这里，我顺便再简单和你解释一下。</p>
<p>从MySQL 5.6版本开始，alter table t engine &#x3D; InnoDB（也就是recreate）默认的就是上面图4的流程了；</p>
<p>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；</p>
<p>optimize table t 等于recreate+analyze。</p>
<p>小结今天这篇文章，我和你讨论了数据库中收缩表空间的方法。</p>
<p>现在你已经知道了，如果要收缩一个表，只是delete掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过alter table命令重建表，才能达到表文件变小的目的。</p>
<p>我跟你介绍了重建表的两种实现方式，Online DDL的方式是可以考虑在业务低峰期使用的，而MySQL 5.5及之前的版本，这个命令是会阻塞DML的，这个你需要特别小心。</p>
<p>最后，又到了我们的课后问题时间。</p>
<p>假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：</p>
<ol>
<li><p>一个表t文件大小为1TB；</p>
</li>
<li><p>对这个表执行 alter table t engine&#x3D;InnoDB；</p>
</li>
<li><p>发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了1.01TB。</p>
</li>
</ol>
<p>你觉得可能是什么原因呢 ？你可以把你觉得可能的原因写在留言区里，我会在下一篇文章的末尾把大家描述的合理的原因都列出来，以后其他同学就不用掉到这样的坑里了。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间在上期文章最后，我留给你的问题是，如果一个高配的机器，redo log设置太小，会发生什么情况。</p>
<p>每次事务提交都要写redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos一直追着CP。</p>
<p>这时候系统不得不停止所有更新，去推进checkpoint。</p>
<p>这时，你看到的现象就是磁盘压力很小，但是数据库出现间歇性的性能下跌。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/a5f547a0.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/a5f547a0.html" class="post-title-link" itemprop="url">mysql-为什么我的MySQL会“抖”一下</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-13 06:01:45" itemprop="dateCreated datePublished" datetime="2019-11-13T06:01:45+08:00">2019-11-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:46:13" itemprop="dateModified" datetime="2023-01-18T23:46:13+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>为什么我的MySQL会“抖”一下平时的工作中，不知道你有没有遇到过这样的场景，一条SQL语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。</p>
<p>看上去，这就像是数据库“抖”了一下。</p>
<p>今天，我们就一起来看一看这是什么原因。</p>
<p>你的SQL语句为什么变“慢”了在前面第2篇文章《日志系统：一条SQL更新语句是如何执行的？》中，我为你介绍了WAL机制。</p>
<p>现在你知道了，InnoDB在处理更新语句的时候，只做了写日志这一个磁盘操作。</p>
<p>这个日志叫作redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完redo log后，就返回给客户端，本次更新成功。</p>
<p>做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。</p>
<p>掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是flush。</p>
<p>在这个flush操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。</p>
<p>因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。</p>
<p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。</p>
<p>内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</p>
<p>不论是脏页还是干净页，都在内存中。</p>
<p>在这个例子里，内存对应的就是掌柜的记忆。</p>
<p>接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。</p>
<p>假设原来孔乙己欠账10文，这次又要赊9文。</p>
<p>图1 “孔乙己赊账”更新和flush过程回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p>
<p>那么，什么情况会引发数据库的flush过程呢？我们还是继续用咸亨酒店掌柜的这个例子，想一想：掌柜在什么情况下会把粉板上的赊账记录改到账本上？第一种场景是，粉板满了，记不下了。</p>
<p>这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。</p>
<p>当然在擦掉之前，他必须先将正确的账目记录到账本中才行。</p>
<p>这个场景，对应的就是InnoDB的redo log写满了。</p>
<p>这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。</p>
<p>我在第二讲画了一个redo log的示意图，这里我改成环形，便于大家理解。</p>
<p>图2 redo log状态图checkpoint可不是随便往前修改一下位置就可以的。</p>
<p>比如图2中，把checkpoint位置从CP推进到CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都flush到磁盘上。</p>
<p>之后，图中从write pos到CP’之间就是可以再写入的redo log的区域。</p>
<p>第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。</p>
<p>这种场景，对应的就是系统内存不足。</p>
<p>当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。</p>
<p>如果淘汰的是“脏页”，就要先将脏页写到磁盘。</p>
<p>你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的。</p>
<p>如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</p>
<p>一种是内存里存在，内存里就肯定是正确的结果，直接返回；</p>
<p>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。</p>
<p>这样的效率最高。</p>
<p>第三种场景是，生意不忙的时候，或者打烊之后。</p>
<p>这时候柜台没事，掌柜闲着也是闲着，不如更新账本。</p>
<p>这种场景，对应的就是MySQL认为系统“空闲”的时候。</p>
<p>当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。</p>
<p>第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。</p>
<p>这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。</p>
<p>这种场景，对应的就是MySQL正常关闭的情况。</p>
<p>这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</p>
<p>接下来，你可以分析一下上面四种场景对性能的影响。</p>
<p>其中，第三种情况是属于MySQL空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。</p>
<p>这两种情况下，你不会太关注“性能”问题。</p>
<p>所以这里，我们主要来分析一下前两种场景下的性能问题。</p>
<p>第一种是“redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。</p>
<p>因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。</p>
<p>如果你从监控上看，这时候更新数会跌为0。</p>
<p>第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。</p>
<p>InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</p>
<p>第一种是，还没有使用的；</p>
<p>第二种是，使用了并且是干净页；</p>
<p>第三种是，使用了并且是脏页。</p>
<p>InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。</p>
<p>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。</p>
<p>这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</p>
<p>所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p>
<ol>
<li><p>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</p>
</li>
<li><p>日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。</p>
</li>
</ol>
<p>所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况。</p>
<p>InnoDB刷脏页的控制策略接下来，我就来和你说说InnoDB脏页的控制策略，以及和这些策略相关的参数。</p>
<p>首先，你要正确地告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。</p>
<p>这就要用到innodb_io_capacity这个参数了，它会告诉InnoDB你的磁盘能力。</p>
<p>这个值我建议你设置成磁盘的IOPS。</p>
<p>磁盘的IOPS可以通过fio这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：</p>
<p>其实，因为没能正确地设置innodb_io_capacity参数，而导致的性能问题也比比皆是。</p>
<p>之前，就曾有其他公司的开发负责人找我看一个库的性能问题，说MySQL的写入速度很慢，TPS很低，但是数据库主机的IO压力并不大。</p>
<p>经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。</p>
<p>他的主机磁盘用的是SSD，但是innodb_io_capacity的值设置的是300。</p>
<p>于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。</p>
<p>虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。</p>
<p>所以接下来，我们就一起看看InnoDB怎么控制引擎按照“全力”的百分比来刷脏页。</p>
<p>根据我前面提到的知识点，试想一下，如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？这个问题可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是redo log写满。</p>
<p>所以，InnoDB的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是redo log写盘速度。</p>
<p> fio -filename&#x3D;$filename -direct&#x3D;1 -iodepth 1 -thread -rw&#x3D;randrw -ioengine&#x3D;psync -bs&#x3D;16k -size&#x3D;500M -numjobs&#x3D;10 -runtime&#x3D;10 -group_reporting -name&#x3D;mytest InnoDB会根据这两个因素先单独算出两个数字。</p>
<p>参数innodb_max_dirty_pages_pct是脏页比例上限，默认值是75%。</p>
<p>InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字，计算这个数字的伪代码类似这样：</p>
<p>InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的序号之间的差值，我们假设为N。</p>
<p>InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。</p>
<p>F2(N)算法比较复杂，你只要知道N越大，算出来的值越大就好了。</p>
<p>然后，根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度。</p>
<p>上述的计算流程比较抽象，不容易理解，所以我画了一个简单的流程图。</p>
<p>图中的F1、F2就是上面我们通过脏页比例和redo log写入速度算出来的两个值。</p>
<p>F1(M){  if M&gt;&#x3D;innodb_max_dirty_pages_pct then      return 100;  return 100*M&#x2F;innodb_max_dirty_pages_pct;}图3 InnoDB刷脏页速度策略现在你知道了，InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。</p>
<p>所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。</p>
<p>要尽量避免这种情况，你就要合理地设置innodb_io_capacity的值，并且平时要多关注脏页比例，不要让它经常接近75%。</p>
<p>其中，脏页比例是通过Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total得到的，具体的命令参考下面的代码：</p>
<p>接下来，我们再看一个有趣的策略。</p>
<p>一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。</p>
<p>而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。</p>
<p>在InnoDB中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。</p>
<p>找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。</p>
<p>机械硬盘的随机IOPS一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。</p>
<p>而如果使用的是SSD这类IOPS比较高的设备的话，我就建议你把innodb_flush_neighbors的值设置成0。</p>
<p>因为这时候IOPS往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。</p>
<p>在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。</p>
<p>小结今天这篇文章，我延续第2篇中介绍的WAL的概念，和你解释了这个机制后续需要的刷脏页操作和执行时机。</p>
<p>利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。</p>
<p>但是，由此也带来了内存脏页的问题。</p>
<p>脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。</p>
<p>在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。</p>
<p>文章最后，我给你留下一个思考题吧。</p>
<p>mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME &#x3D; ‘Innodb_buffer_pool_pages_dirty’;select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME &#x3D; ‘Innodb_buffer_pool_pages_total’;select @a&#x2F;@b;一个内存配置为128GB、innodb_io_capacity设置为20000的大规格实例，正常会建议你将redolog设置成4个1GB的文件。</p>
<p>但如果你在配置的时候不慎将redo log设置成了1个100M的文件，会发生什么情况呢？又为什么会出现这样的情况呢？你可以把你的分析结论写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期我留给你的问题是，给一个学号字段创建索引，有哪些方法。</p>
<p>由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。</p>
<p>因为维护的只是一个学校的，因此前面6位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是@gamil.com，因此可以只存入学年份加顺序编号，它们的长度是9位。</p>
<p>而其实在此基础上，可以用数字类型来存这9位数字。</p>
<p>比如201100001，这样只需要占4个字节。</p>
<p>其实这个就是一种hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。</p>
<p>评论区中，也有其他一些很不错的见解。</p>
<p>评论用户@封建的风 说，一个学校的总人数这种数据量，50年才100万学生，这个表肯定是小表。</p>
<p>为了业务简单，直接存原来的字符串。</p>
<p>这个答复里面包含了“优化成本和收益”的思想，我觉得值得at出来。</p>
<p>@小潘 同学提了另外一个极致的方向。</p>
<p>如果碰到表数据量特别大的场景，通过这种方式的收益是很不错的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/e1ece7cd.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/e1ece7cd.html" class="post-title-link" itemprop="url">mysql-怎么给字符串字段加索引</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-12 06:08:14" itemprop="dateCreated datePublished" datetime="2019-11-12T06:08:14+08:00">2019-11-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>怎么给字符串字段加索引？现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。</p>
<p>假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：</p>
<p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p>
<p>从第4和第5篇讲解索引的文章中，我们可以知道，如果email这个字段上没有索引，那么这个语句就只能做全表扫描。</p>
<p>同时，MySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。</p>
<p>默认地，mysql&gt; create table SUser(ID bigint unsigned primary key,email varchar(64), … )engine&#x3D;innodb; mysql&gt; select f1, f2 from SUser where email&#x3D;’xxx’;如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。</p>
<p>比如，这两个在email字段上创建索引的语句：</p>
<p>第一个语句创建的index1索引里面，包含了每个记录的整个字符串；而第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节。</p>
<p>那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图2和3所示，就是这两个索引的示意图。</p>
<p>图1 email 索引结构mysql&gt; alter table SUser add index index1(email);或mysql&gt; alter table SUser add index index2(email(6));图2 email(6) 索引结构从图中你可以看到，由于email(6)这个索引结构中每个邮箱字段都只取前6个字节（即：</p>
<p>zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。</p>
<p>但，这同时带来的损失是，可能会增加额外的记录扫描次数。</p>
<p>接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。</p>
<p>如果使用的是index1（即email整个字符串的索引结构），执行顺序是这样的：</p>
<ol>
<li><p>从index1索引树找到满足索引值是’<a href="mailto:&#x7a;&#x68;&#x61;&#110;&#103;&#115;&#115;&#120;&#x79;&#x7a;&#x40;&#120;&#120;&#x78;&#x2e;&#x63;&#111;&#109;">&#x7a;&#x68;&#x61;&#110;&#103;&#115;&#115;&#120;&#x79;&#x7a;&#x40;&#120;&#120;&#x78;&#x2e;&#x63;&#111;&#109;</a>’的这条记录，取得ID2的值；</p>
</li>
<li><p>到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集；</p>
</li>
<li><p>取index1索引树上刚刚查到的位置的下一条记录，发现已经不满足email&#x3D;‘<a href="mailto:&#x7a;&#x68;&#x61;&#110;&#103;&#115;&#x73;&#120;&#121;&#x7a;&#64;&#x78;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;">&#x7a;&#x68;&#x61;&#110;&#103;&#115;&#x73;&#120;&#121;&#x7a;&#64;&#x78;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;</a>’的条件了，循环结束。</p>
</li>
</ol>
<p>这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。</p>
<p>select id,name,email from SUser where email&#x3D;‘<a href="mailto:&#x7a;&#104;&#97;&#x6e;&#x67;&#115;&#x73;&#x78;&#x79;&#x7a;&#64;&#x78;&#120;&#x78;&#x2e;&#99;&#111;&#109;">&#x7a;&#104;&#97;&#x6e;&#x67;&#115;&#x73;&#x78;&#x79;&#x7a;&#64;&#x78;&#120;&#x78;&#x2e;&#99;&#111;&#109;</a>‘;如果使用的是index2（即email(6)索引结构），执行顺序是这样的：</p>
<ol>
<li><p>从index2索引树找到满足索引值是’zhangs’的记录，找到的第一个是ID1；</p>
</li>
<li><p>到主键上查到主键值是ID1的行，判断出email的值不是’<a href="mailto:&#122;&#x68;&#x61;&#x6e;&#103;&#115;&#115;&#x78;&#121;&#122;&#x40;&#x78;&#x78;&#x78;&#x2e;&#x63;&#111;&#109;">&#122;&#x68;&#x61;&#x6e;&#103;&#115;&#115;&#x78;&#121;&#122;&#x40;&#x78;&#x78;&#x78;&#x2e;&#x63;&#111;&#109;</a>’，这行记录丢弃；</p>
</li>
<li><p>取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整行然后判断，这次值对了，将这行记录加入结果集；</p>
</li>
<li><p>重复上一步，直到在idxe2上取到的值不是’zhangs’时，循环结束。</p>
</li>
</ol>
<p>在这个过程中，要回主键索引取4次数据，也就是扫描了4行。</p>
<p>通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。</p>
<p>但是，对于这个查询语句来说，如果你定义的index2不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。</p>
<p>也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</p>
<p>于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？实际上，我们在建立索引时关注的是区分度，区分度越高越好。</p>
<p>因为区分度越高，意味着重复的键值越少。</p>
<p>因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。</p>
<p>首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：</p>
<p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下4~7个字节的前缀索引，可以用这个语句：</p>
<p>mysql&gt; select count(distinct email) as L from SUser;当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。</p>
<p>然后，在返回的L4~L7中，找出不小于 L * 95%的值，假设这里L6、L7都满足，你就可以选择前缀长度为6。</p>
<p>前缀索引对覆盖索引的影响前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。</p>
<p>其实，前缀索引的影响不止如此，我们再看一下另外一个场景。</p>
<p>你先来看看这个SQL语句：</p>
<p>与前面例子中的SQL语句相比，这个语句只要求返回id和email字段。</p>
<p>所以，如果使用index1（即email整个字符串的索引结构）的话，可以利用覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查一次。</p>
<p>而如果使用index2（即email(6)索引结构）的话，就不得不回到ID索引再去判断email字段的值。</p>
<p>即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。</p>
<p>也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。</p>
<p>其他方式对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。</p>
<p>但是，遇到前缀的区分度不mysql&gt; select   count(distinct left(email,4)）as L4,  count(distinct left(email,5)）as L5,  count(distinct left(email,6)）as L6,  count(distinct left(email,7)）as L7,from SUser;select id,email from SUser where email&#x3D;‘<a href="mailto:&#x7a;&#104;&#97;&#110;&#103;&#x73;&#115;&#x78;&#121;&#x7a;&#64;&#120;&#x78;&#x78;&#46;&#99;&#111;&#109;">&#x7a;&#104;&#97;&#110;&#103;&#x73;&#115;&#x78;&#121;&#x7a;&#64;&#120;&#x78;&#x78;&#46;&#99;&#111;&#109;</a>‘;select id,name,email from SUser where email&#x3D;‘<a href="mailto:&#122;&#x68;&#x61;&#110;&#103;&#115;&#x73;&#x78;&#121;&#x7a;&#x40;&#x78;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;">&#122;&#x68;&#x61;&#110;&#103;&#115;&#x73;&#x78;&#121;&#x7a;&#x40;&#x78;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;</a>‘;够好的情况时，我们要怎么办呢？比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前6位一般会是相同的。</p>
<p>假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。</p>
<p>按照我们前面说的方法，可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。</p>
<p>但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。</p>
<p>那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。</p>
<p>答案是，有的。</p>
<p>第一种方式是使用倒序存储。</p>
<p>如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p>
<p>由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。</p>
<p>当然了，实践中你不要忘记使用count(distinct)方法去做个验证。</p>
<p>第二种方式是使用hash字段。</p>
<p>你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p>
<p>然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。</p>
<p>由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。</p>
<p>这样，索引的长度变成了4个字节，比原来小了很多。</p>
<p>mysql&gt; select field_list from t where id_card &#x3D; reverse(‘input_id_card_string’);mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc);mysql&gt; select field_list from t where id_card_crc&#x3D;crc32(‘input_id_card_string’) and id_card&#x3D;’input_id_card_string’接下来，我们再一起看看使用倒序存储和使用hash字段这两种方法的异同点。</p>
<p>首先，它们的相同点是，都不支持范围查询。</p>
<p>倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。</p>
<p>同样地，hash字段的方式也只能支持等值查询。</p>
<p>它们的区别，主要体现在以下三个方面：</p>
<ol>
<li>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段。</li>
</ol>
<p>当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段也差不多抵消了。</p>
<ol start="2">
<li>在CPU消耗方面，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数。</li>
</ol>
<p>如果只从这两个函数的计算复杂度来看的话，reverse函数额外消耗的CPU资源会更小些。</p>
<ol start="3">
<li>从查询效率上看，使用hash字段方式的查询性能相对更稳定一些。</li>
</ol>
<p>因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。</p>
<p>而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</p>
<p>小结在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。</p>
<p>我们来回顾一下，你可以使用的方式有：</p>
<ol>
<li><p>直接创建完整索引，这样可能比较占用空间；</p>
</li>
<li><p>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；</p>
</li>
<li><p>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；</p>
</li>
<li><p>创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。</p>
</li>
</ol>
<p>在实际应用中，你要根据业务字段的特点选择使用哪种方式。</p>
<p>好了，又到了最后的问题时间。</p>
<p>如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号@gmail.com”, 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。</p>
<p>系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。</p>
<p>就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？你可以把你的分析思路和设计结果写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上篇文章中的第一个例子，评论区有几位同学说没有复现，大家要检查一下隔离级别是不是RR（Repeatable Read，可重复读），创建的表t是不是InnoDB引擎。</p>
<p>我把复现过程做成了一个视频，供你参考。</p>
<p>在上一篇文章最后，我给你留的问题是，为什么经过这个操作序列，explain的结果就不对了？这里，我来为你分析一下原因。</p>
<p>delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。</p>
<p>但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。</p>
<p>这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。</p>
<p>这样，索引a上的数据其实就有两份。</p>
<p>然后你会说，不对啊，主键上的数据也不能删，那没有使用force index的语句，使用explain命令看到的扫描行数为什么还是100000左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段a作为索引更合适）是的，不过这个是主键，主键是直接按照表的行数来估计的。</p>
<p>而表的行数，优化器直接用的是show table status的值。</p>
<p>这个值的计算方法，我会在后面有文章为你详细讲解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/1591a1f8.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/1591a1f8.html" class="post-title-link" itemprop="url">mysql-MySQL为什么有时候会选错索引</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-11 06:15:26" itemprop="dateCreated datePublished" datetime="2019-11-11T06:15:26+08:00">2019-11-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:46:13" itemprop="dateModified" datetime="2023-01-18T23:46:13+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>17 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>MySQL为什么有时候会选错索引？</p>
<p>前面我们介绍过索引，你已经知道了在MySQL中一张表其实是可以支持多个索引的。</p>
<p>但是，你写SQL语句的时候，并没有主动指定使用哪个索引。</p>
<p>也就是说，使用哪个索引是由MySQL来确定的。</p>
<p>不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于MySQL选错了索引，而导致执行速度变得很慢？我们一起来看一个例子吧。</p>
<p>我们先建一个简单的表，表里有a、b两个字段，并分别建上索引：<br>CREATE TABLE <code>t</code> (  <code>id</code> int(11) NOT NULL,  <code>a</code> int(11) DEFAULT NULL,  <code>b</code> int(11) DEFAULT NULL,  PRIMARY KEY (<code>id</code>),  KEY <code>a</code> (<code>a</code>),  KEY <code>b</code> (<code>b</code>)) ENGINE&#x3D;InnoDB；<br>然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。</p>
<p>我是用存储过程来插入数据的，这里我贴出来方便你复现：<br>接下来，我们分析一条SQL语句：<br>你一定会说，这个语句还用分析吗，很简单呀，a上有索引，肯定是要使用索引a的。</p>
<p>你说得没错，图1显示的就是使用explain命令看到的这条语句的执行情况。</p>
<p>图1 使用explain命令查看语句执行情况从图1看上去，这条查询语句的执行也确实符合预期，key这个字段值是’a’，表示优化器选择了索引a。</p>
<p>不过别急，这个案例不会这么简单。</p>
<p>在我们已经准备好的包含了10万行数据的表上，我们再做如下操作。</p>
<p>delimiter ;;create procedure idata()begin  declare i int;  set i&#x3D;1;  while(i&lt;&#x3D;100000)do    insert into t values(i, i, i);    set i&#x3D;i+1;  end while;end;;delimiter ;call idata();mysql&gt; select * from t where a between 10000 and 20000;图2 session A和session B的执行流程这里，session A的操作你已经很熟悉了，它就是开启了一个事务。</p>
<p>随后，session B把数据都删除后，又调用了 idata这个存储过程，插入了10万行数据。</p>
<p>这时候，session B的查询语句select * from t where a between 10000 and 20000就不会再选择索引a了。</p>
<p>我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。</p>
<p>为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用force index(a)来让优化器强制使用索引a（这部分内容，我还会在这篇文章的后半部分中提到）。</p>
<p>下面的三条SQL语句，就是这个实验过程。</p>
<p>第一句，是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中；<br>第二句，Q1是session B原来的查询；<br>第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。</p>
<p>如图3所示是这三条SQL语句执行完成后的慢查询日志。</p>
<p>set long_query_time&#x3D;0;select * from t where a between 10000 and 20000; &#x2F;<em>Q1</em>&#x2F;select * from t force index(a) where a between 10000 and 20000;&#x2F;<em>Q2</em>&#x2F;图3 slow log结果可以看到，Q1扫描了10万行，显然是走了全表扫描，执行时间是40毫秒。</p>
<p>Q2扫描了10001行，执行了21毫秒。</p>
<p>也就是说，我们在没有使用force index的时候，MySQL用错了索引，导致了更长的执行时间。</p>
<p>这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。</p>
<p>这时，MySQL竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。</p>
<p>优化器的逻辑在第一篇文章中，我们就提到过，选择索引是优化器的工作。</p>
<p>而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。</p>
<p>在数据库里面，扫描行数是影响执行代价的因素之一。</p>
<p>扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。</p>
<p>当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。</p>
<p>我们这个简单的查询语句并没有涉及到临时表和排序，所以MySQL选错索引肯定是在判断扫描行数的时候出问题了。</p>
<p>那么，问题就是：扫描行数是怎么判断的？MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p>
<p>这个统计信息就是索引的“区分度”。</p>
<p>显然，一个索引上不同的值越多，这个索引的区分度就越好。</p>
<p>而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。</p>
<p>也就是说，这个基数越大，索引的区分度越好。</p>
<p>我们可以使用show index方法，看到一个索引的基数。</p>
<p>如图4所示，就是表t的show index 的结果。</p>
<p>虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。</p>
<p>图4 表t的show index 结果那么，MySQL是怎样得到索引的基数的呢？这里，我给你简单介绍一下MySQL采样统计的方法。</p>
<p>为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。</p>
<p>采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</p>
<p>而数据表是会持续更新的，索引统计信息也不会固定不变。</p>
<p>所以，当变更的数据行数超过1&#x2F;M的时候，会自动触发重新做一次索引统计。</p>
<p>在MySQL中，有两种存储索引统计的方式，可以通过设置参数innodb_stats_persistent的值来选择：<br>设置为on的时候，表示统计信息会持久化存储。</p>
<p>这时，默认的N是20，M是10。</p>
<p>设置为off的时候，表示统计信息只存储在内存中。</p>
<p>这时，默认的N是8，M是16。</p>
<p>由于是采样统计，所以不管N是20还是8，这个基数都是很容易不准的。</p>
<p>但，这还不是全部。</p>
<p>你可以从图4中看到，这次的索引统计值（cardinality列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。</p>
<p>其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。</p>
<p>接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。</p>
<p>图5 意外的explain结果rows这个字段表示的是预计扫描行数。</p>
<p>其中，Q1的结果还是符合预期的，rows的值是104620；但是Q2的rows值是37116，偏差就大了。</p>
<p>而图1中我们用explain命令看到的rows是只有10001行，是这个偏差误导了优化器的判断。</p>
<p>到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描37000行的执行计划不用，却选择了扫描行数是100000的执行计划呢？这是因为，如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。</p>
<p>而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。</p>
<p>优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。</p>
<p>当然，从执行时间看来，这个选择并不是最优的。</p>
<p>使用普通索引需要把回表的代价算进去，在图1执行explain的时候，也考虑了这个策略的代价 ，但图1的选择是对的。</p>
<p>也就是说，这个策略并没有问题。</p>
<p>所以冤有头债有主，MySQL选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。</p>
<p>至于为什么会得到错误的扫描行数，这个原因就作为课后问题，留给你去分析了。</p>
<p>既然是统计信息不对，那就修正。</p>
<p>analyze table t 命令，可以用来重新统计索引信息。</p>
<p>我们来看一下执行效果。</p>
<p>图6 执行analyze table t 命令恢复的explain结果这回对了。</p>
<p>所以在实践中，如果你发现explain的结果预估的rows值跟实际情况差距比较大，可以采用这个方法来处理。</p>
<p>其实，如果只是索引统计不准确，通过analyze命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。</p>
<p>依然是基于这个表t，我们看看另外一个语句：<br>从条件上看，这个查询没有符合条件的记录，因此会返回空集合。</p>
<p>在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？为了便于分析，我们先来看一下a、b这两个索引的结构图。</p>
<p>图7 a、b索引的结构图如果使用索引a进行查询，那么就是扫描索引a的前1000个值，然后取到对应的id，再到主键索引上去查出每一行，然后根据字段b来过滤。</p>
<p>显然这样需要扫描1000行。</p>
<p>如果使用索引b进行查询，那么就是扫描索引b的最后50001个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描50001行。</p>
<p>所以你一定会想，如果使用索引a的话，执行速度明显会快很多。</p>
<p>那么，下面我们就来看看到底是不是这么一回事儿。</p>
<p>mysql&gt; select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;图8是执行explain的结果。</p>
<p>图8 使用explain方法查看执行计划 2可以看到，返回结果中key字段显示，这次优化器选择了索引b，而rows字段显示需要扫描的行数是50198。</p>
<p>从这个结果中，你可以得到两个结论：</p>
<ol>
<li>扫描行数的估计值依然不准确；</li>
<li>这个例子里MySQL又选错了索引。</li>
</ol>
<p>索引选择异常和处理其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：<br>原本可以执行得很快的SQL语句，执行速度却比你预期的慢很多，你应该怎么办呢？一种方法是，像我们第一个例子一样，采用force index强行选择一个索引。</p>
<p>MySQL会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。</p>
<p>如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</p>
<p>我们来看看第二个例子。</p>
<p>刚开始分析时，我们认为选择索引a会更好。</p>
<p>现在，我们就来看看执行效果：<br>图9 使用不同索引的语句执行耗时可以看到，原本语句需要执行2.23秒，而当你使用force index(a)的时候，只用了0.05秒，比优化器的选择快了40多倍。</p>
<p>也就是说，优化器没有选择正确的索引，force index起到了“矫正”的作用。</p>
<p>不过很多程序员不喜欢使用force index，一来这么写不优美，二来如果索引改了名字，这个语句mysql&gt; explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;也得改，显得很麻烦。</p>
<p>而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。</p>
<p>但其实使用force index最主要的问题还是变更的及时性。</p>
<p>因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上force index。</p>
<p>而是等到线上出现问题的时候，你才会再去修改SQL语句、加上force index。</p>
<p>但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。</p>
<p>所以，数据库的问题最好还是在数据库内部来解决。</p>
<p>那么，在数据库里面该怎样解决呢？既然优化器放弃了使用索引a，说明a还不够合适，所以第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引。</p>
<p>比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p>
<p>我们来看看改之后的效果：<br>图10 order by b,a limit 1 执行结果之前优化器选择使用索引b，是因为它认为使用索引b可以避免排序（b本身是索引，已经是有序的了，如果选择索引b的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。</p>
<p>现在order by b,a 这种写法，要求按照b,a排序，就意味着使用这两个索引都需要排序。</p>
<p>因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描1000行的索引a。</p>
<p>当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有limit 1，因此如果有满足条件的记录， order by b limit 1和order by b,a limit 1 都会返回b是最小的那一行，逻辑上一致，才可以这么做。</p>
<p>如果你觉得修改语义这件事儿不太好，这里还有一种改法，图11是执行效果。</p>
<p>图11 改写SQL的explain在这个例子里，我们用limit 100让优化器意识到，使用b索引代价是很高的。</p>
<p>其实是我们根据数mysql&gt; select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;据特征诱导了一下优化器，也不具备通用性。</p>
<p>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</p>
<p>不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。</p>
<p>这种情况其实比较少，尤其是经过DBA索引优化过的库，再碰到这个bug，找到一个更合适的索引一般比较难。</p>
<p>如果我说还有一个方法是删掉索引b，你可能会觉得好笑。</p>
<p>但实际上我碰到过两次这样的例子，最终是DBA跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。</p>
<p>小结今天我们一起聊了聊索引统计的更新机制，并提到了优化器存在选错索引的可能性。</p>
<p>对于由于索引统计信息不准确导致的问题，你可以用analyze table来解决。</p>
<p>而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。</p>
<p>你可能会说，今天这篇文章后面的几个例子，怎么都没有展开说明其原理。</p>
<p>我要告诉你的是，今天的话题，我们面对的是MySQL的bug，每一个展开都必须深入到一行行代码去量化，实在不是我们在这里应该做的事情。</p>
<p>所以，我把我用过的解决方法跟你分享，希望你在碰到类似情况的时候，能够有一些思路。</p>
<p>你平时在处理MySQL优化器bug的时候有什么别的方法，也发到评论区分享一下吧。</p>
<p>最后，我给你留下一个思考题。</p>
<p>前面我们在构造第一个例子的过程中，通过session A的配合，让session B删除数据后又重新插入了一遍数据，然后就发现explain结果中，rows字段从10001变成37000多。</p>
<p>而如果没有session A的配合，只是单独执行delete from t 、call idata()、explain这三句话，会看到rows字段其实还是10000左右。</p>
<p>你可以自己验证一下这个结果。</p>
<p>这是什么原因呢？也请你分析一下吧。</p>
<p>你可以把你的分析结论写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间我在上一篇文章最后留给你的问题是，如果某次写入使用了change buffer机制，之后主机异常重启，是否会丢失change buffer和数据。</p>
<p>这个问题的答案是不会丢失，留言区的很多同学都回答对了。</p>
<p>虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，changebuffer也能找回来。</p>
<p>在评论区有同学问到，merge的过程是否会把数据直接写回磁盘，这是个好问题。</p>
<p>这里，我再为你分析一下。</p>
<p>merge的执行流程是这样的：</p>
<ol>
<li>从磁盘读入数据页到内存（老版本的数据页）；</li>
<li>从change buffer里找出这个数据页的change buffer 记录(可能有多个），依次应用，得到新版数据页；</li>
<li>写redo log。</li>
</ol>
<p>这个redo log包含了数据的变更和change buffer的变更。</p>
<p>到这里merge过程就结束了。</p>
<p>这时候，数据页和内存中change buffer对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/5ec5b1a0.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/5ec5b1a0.html" class="post-title-link" itemprop="url">mysql-普通索引和唯一索引，应该怎么选择</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-10 06:16:37" itemprop="dateCreated datePublished" datetime="2019-11-10T06:16:37+08:00">2019-11-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>17 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>普通索引和唯一索引，应该怎么选择今天的正文开始前，我要特意感谢一下评论区几位留下高质量留言的同学。</p>
<p>用户名是 @某、人 的同学，对文章的知识点做了梳理，然后提了关于事务可见性的问题，就是先启动但是后提交的事务，对数据可见性的影响。</p>
<p>@夏日雨同学也提到了这个问题，我在置顶评论中回复了，今天的文章末尾也会再展开说明。</p>
<p>@Justin和@倪大人两位同学提了两个好问题。</p>
<p>对于能够引发更深一步思考的问题，我会在回复的内容中写上“好问题”三个字，方便你搜索，你也可以去看看他们的留言。</p>
<p>非常感谢大家很细致地看文章，并且留下了那么多和很高质量的留言。</p>
<p>知道文章有给大家带来一些新理解，对我来说是一个很好的鼓励。</p>
<p>同时，也让其他认真看评论区的同学，有机会发现一些自己还没有意识到的、但可能还不清晰的知识点，这也在总体上提高了整个专栏的质量。</p>
<p>再次谢谢你们。</p>
<p>好了，现在就回到我们今天的正文内容。</p>
<p>在前面的基础篇文章中，我给你介绍过索引的基本概念，相信你已经了解了唯一索引和普通索引的区别。</p>
<p>今天我们就继续来谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。</p>
<p>如果市民系统需要按照身份证号查姓名，就会执行类似这样的SQL语句：</p>
<p>所以，你一定会考虑在id_card字段上建索引。</p>
<p>由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给id_card字段创建唯一索引，要么创建一个普通索引。</p>
<p>如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。</p>
<p>现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？简单起见，我们还是用第4篇文章《深入浅出索引（上）》中的例子来说明，假设字段 k 上的值都不重复。</p>
<p>图1 InnoDB的索引组织结构接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。</p>
<p>查询过程select name from CUser where id_card &#x3D; ‘xxxxxxxyyyyyyzzzzz’;假设，执行查询的语句是 select id from T where k&#x3D;5。</p>
<p>这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。</p>
<p>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k&#x3D;5条件的记录。</p>
<p>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</p>
<p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。</p>
<p>你知道的，InnoDB的数据是按数据页为单位来读写的。</p>
<p>也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。</p>
<p>在InnoDB中，每个数据页的大小默认是16KB。</p>
<p>因为引擎是按页读写的，所以说，当找到k&#x3D;5的记录的时候，它所在的数据页就都在内存里了。</p>
<p>那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。</p>
<p>当然，如果k&#x3D;5这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。</p>
<p>但是，我们之前计算过，对于整型字段，一个数据页可以放近千个key，因此出现这种情况的概率会很低。</p>
<p>所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU来说可以忽略不计。</p>
<p>更新过程为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下changebuffer。</p>
<p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。</p>
<p>在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。</p>
<p>通过这种方式就能保证这个数据逻辑的正确性。</p>
<p>需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。</p>
<p>也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。</p>
<p>将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。</p>
<p>除了访问这个数据页会触发merge外，系统有后台线程会定期merge。</p>
<p>在数据库正常关闭（shutdown）的过程中，也会执行merge操作。</p>
<p>显然，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。</p>
<p>而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。</p>
<p>那么，什么条件下可以使用change buffer呢？对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。</p>
<p>比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k&#x3D;4的记录，而这必须要将数据页读入内存才能判断。</p>
<p>如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。</p>
<p>因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。</p>
<p>change buffer用的是buffer pool里的内存，因此不能无限增大。</p>
<p>change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。</p>
<p>这个参数设置为50的时候，表示changebuffer的大小最多只能占用buffer pool的50%。</p>
<p>现在，你已经理解了change buffer的机制，那么我们再一起来看看如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。</p>
<p>第一种情况是，这个记录要更新的目标页在内存中。</p>
<p>这时，InnoDB的处理流程如下：</p>
<p>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；</p>
<p>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。</p>
<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。</p>
<p>但，这不是我们关注的重点。</p>
<p>第二种情况是，这个记录要更新的目标页不在内存中。</p>
<p>这时，InnoDB的处理流程如下：</p>
<p>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</p>
<p>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。</p>
<p>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。</p>
<p>change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p>
<p>之前我就碰到过一件事儿，有个DBA的同学跟我反馈说，他负责的某个业务的库内存命中率突然从99%降低到了75%，整个系统处于阻塞状态，更新语句全部堵住。</p>
<p>而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。</p>
<p>change buffer的使用场景通过上面的分析，你已经清楚了使用change buffer对更新过程的加速作用，也清楚了changebuffer只限于用在普通索引的场景下，而不适用于唯一索引。</p>
<p>那么，现在有一个问题就是：普通索引的所有场景，使用change buffer都可以起到加速作用吗？因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p>
<p>因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时changebuffer的使用效果最好。</p>
<p>这种业务模型常见的就是账单类、日志类的系统。</p>
<p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。</p>
<p>这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。</p>
<p>所以，对于这种业务模式来说，change buffer反而起到了副作用。</p>
<p>索引选择和实践回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。</p>
<p>其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。</p>
<p>所以，我建议你尽量选择普通索引。</p>
<p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。</p>
<p>而在其他情况下，change buffer都能提升更新性能。</p>
<p>在实际使用中，你会发现，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。</p>
<p>特别地，在使用机械硬盘时，change buffer这个机制的收效是非常显著的。</p>
<p>所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。</p>
<p>change buffer 和 redo log理解了change buffer的原理，你可能会联想到我在前面文章中和你介绍过的redo log和WAL。</p>
<p>在前面文章的评论中，我发现有同学混淆了redo log和change buffer。</p>
<p>WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。</p>
<p>所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。</p>
<p>现在，我们要在表上执行这个插入语句：</p>
<p>这里，我们假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB bufferpool)中，k2所在的数据页不在内存中。</p>
<p>如图2所示是带change buffer的更新状态图。</p>
<p>图2 带change buffer的更新过程分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</p>
<p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p>
<ol>
<li><p>Page 1在内存中，直接更新内存；</p>
</li>
<li><p>Page 2没有在内存中，就在内存的change buffer区域，记录下“我要往Page 2插入一行”这个信息备注：这里，你可以再回顾下第2篇文章《日志系统：一条SQL更新语句是如何执行的？》中的相关内容。</p>
</li>
</ol>
<p>mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2);3. 将上述两个动作记入redo log中（图中3和4）。</p>
<p>做完上面这些，事务就可以完成了。</p>
<p>所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。</p>
<p>同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。</p>
<p>那在这之后的读请求，要怎么处理呢？比如，我们现在要执行 select * from t where k in (k1, k2)。</p>
<p>这里，我画了这两个读请求的流程图。</p>
<p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。</p>
<p>所以，我在图中就没画出这两部分。</p>
<p>图3 带change buffer的读过程从图中可以看到：</p>
<ol>
<li>读Page 1的时候，直接从内存返回。</li>
</ol>
<p>有几位同学在前面文章的评论中问到，WAL之后如果读数据，是不是一定要读盘，是不是一定要从redo log里面把数据更新以后才可以返回？其实是不用的。</p>
<p>你可以看一下图3的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。</p>
<ol start="2">
<li>要读Page 2的时候，需要把Page 2从磁盘读入内存中，然后应用change buffer里面的操作日志，生成一个正确的版本并返回结果。</li>
</ol>
<p>可以看到，直到需要读Page 2的时候，这个数据页才会被读入内存。</p>
<p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。</p>
<p>小结今天，我从普通索引和唯一索引的选择开始，和你分享了数据的查询和更新过程，然后说明了change buffer的机制以及应用场景，最后讲到了索引选择的实践。</p>
<p>由于唯一索引用不上change buffer的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。</p>
<p>最后，又到了思考题时间。</p>
<p>通过图2你可以看到，change buffer一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致change buffer丢失呢？change buffer丢失可不是小事儿，再从磁盘读入数据可就没有了merge过程，就等于是数据丢失了。</p>
<p>会不会出现这种情况呢？你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>补充：</p>
<p>评论区大家对“是否使用唯一索引”有比较多的讨论，主要是纠结在“业务可能无法确保”的情况。</p>
<p>这里，我再说明一下：</p>
<p>首先，业务正确性优先。</p>
<p>咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。</p>
<p>如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。</p>
<p>这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。</p>
<p>然后，在一些“归档库”的场景，你是可以考虑使用唯一索引的。</p>
<p>比如，线上数据只需要保留半年，然后历史数据保存在归档库。</p>
<p>这时候，归档数据已经是确保没有唯一键冲突了。</p>
<p>要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。</p>
<p>上期问题时间上期的问题是：如何构造一个“数据无法修改”的场景。</p>
<p>评论区里已经有不少同学给出了正确答案，这里我再描述一下。</p>
<p>这样，session A看到的就是我截图的效果了。</p>
<p>其实，还有另外一种场景，同学们在留言区都还没有提到。</p>
<p>这个操作序列跑出来，session A看的内容也是能够复现我截图的效果的。</p>
<p>这个session B’启动的事务比A要早，其实是上期我们描述事务版本的可见性规则时留的彩蛋，因为规则里还有一个“活跃事务的判断”，我是准备留到这里再补充的。</p>
<p>当我试图在这里讲述完整规则的时候，发现第8篇文章《事务到底是隔离的还是不隔离的？》中的解释引入了太多的概念，以致于分析起来非常复杂。</p>
<p>因此，我重写了第8篇，这样我们人工去判断可见性的时候，才会更方便。</p>
<p>【看到这里，我建议你能够再重新打开第8篇文章并认真学习一次。</p>
<p>如果学习的过程中，有任何问题，也欢迎你给我留言】用新的方式来分析session B’的更新为什么对session A不可见就是：在session A视图数组创建的瞬间，session B’是活跃的，属于“版本未提交，不可见”这种情况。</p>
<p>业务中如果要绕过这类问题，@约书亚提供了一个“乐观锁”的解法，大家可以去上一篇的留言区看一下。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/c6101e2f.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/c6101e2f.html" class="post-title-link" itemprop="url">mysql-事务到底是隔离的还是不隔离的</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-09 06:17:41" itemprop="dateCreated datePublished" datetime="2019-11-09T06:17:41+08:00">2019-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:38" itemprop="dateModified" datetime="2023-01-18T23:34:38+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>4.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>18 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>事务到底是隔离的还是不隔离的？我在第3篇文章和你讲事务隔离级别的时候提到过，如果是可重复读隔离级别，事务T启动的时候会创建一个视图read-view，之后事务T执行期间，即使有其他事务修改了数据，事务T看到的仍然跟在启动时看到的一样。</p>
<p>也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。</p>
<p>但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。</p>
<p>问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？我给你举一个例子吧。</p>
<p>下面是一个只有两行的表的初始化语句。</p>
<p>mysql&gt; CREATE TABLE <code>t</code> (  <code>id</code> int(11) NOT NULL,  <code>k</code> int(11) DEFAULT NULL,  PRIMARY KEY (<code>id</code>)) ENGINE&#x3D;InnoDB;insert into t(id, k) values(1,1),(2,2);图1 事务A、B、C的执行流程这里，我们需要注意的是事务的启动时机。</p>
<p>begin&#x2F;start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。</p>
<p>如果你想要马上启动一个事务，可以使用start transaction withconsistent snapshot 这个命令。</p>
<p>还需要注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是默认autocommit&#x3D;1。</p>
<p>在这个例子中，事务C没有显式地使用begin&#x2F;commit，表示这个update语句本身就是一个事务，语句完成的时候会自动提交。</p>
<p>事务B在更新了行之后查询; 事务A在一个只读事务中查询，并且时间顺序上是在事务B的查询之后。</p>
<p>这时，如果我告诉你事务B查到的k的值是3，而事务A查到的k的值是1，你是不是感觉有点晕呢？所以，今天这篇文章，我其实就是想和你说明白这个问题，希望借由把这个疑惑解开的过程，能够帮助你对InnoDB的事务和锁有更进一步的理解。</p>
<p>在MySQL里，有两个“视图”的概念：</p>
<p>一个是view。</p>
<p>它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。</p>
<p>创建视图的语法是create view … ，而它的查询方法与表一样。</p>
<p>另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。</p>
<p>它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。</p>
<p>在第3篇文章《事务隔离：为什么你改了我还看不见？》中，我跟你解释过一遍MVCC的实现逻辑。</p>
<p>今天为了说明查询和更新的区别，我换一个方式来说明，把read view拆开。</p>
<p>你可以结合这两篇文章的说明来更深一步地理解MVCC。</p>
<p>“快照”在MVCC里是怎么工作的？在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。</p>
<p>注意，这个快照是基于整库的。</p>
<p>这时，你会说这看上去不太现实啊。</p>
<p>如果一个库有100G，那么我启动一个事务，MySQL就要拷贝100G的数据出来，这个过程得多慢啊。</p>
<p>可是，我平时的事务执行起来很快啊。</p>
<p>实际上，我们并不需要拷贝出这100G的数据。</p>
<p>我们先来看看这个快照是怎么实现的。</p>
<p>InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。</p>
<p>它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。</p>
<p>而每行数据也都是有多个版本的。</p>
<p>每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。</p>
<p>同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。</p>
<p>也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。</p>
<p>如图2所示，就是一个记录被多个事务连续更新后的状态。</p>
<p>图2 行状态变更图图中虚线框里是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id为25的事务更新的，因此它的row trx_id也是25。</p>
<p>你可能会问，前面的文章不是说，语句更新会生成undo log（回滚日志）吗？那么，undo log在哪呢？实际上，图2中的三个虚线箭头，就是undo log；而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的。</p>
<p>比如，需要V2的时候，就是通过V4依次执行U3、U2算出来。</p>
<p>明白了多版本和row trx_id的概念后，我们再来想一下，InnoDB是怎么定义那个“100G”的快照的。</p>
<p>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。</p>
<p>但是之后，这个事务执行期间，其他事务的更新对它不可见。</p>
<p>因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。</p>
<p>当然，如果“上一个版本”也不可见，那就得继续往前找。</p>
<p>还有，如果是这个事务自己更新的数据，它自己还是要认的。</p>
<p>在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。</p>
<p>“活跃”指的就是，启动了但还没提交。</p>
<p>数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。</p>
<p>这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p>
<p>而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。</p>
<p>这个视图数组把所有的row trx_id 分成了几种不同的情况。</p>
<p>图3 数据版本可见性规则这样，对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：</p>
<ol>
<li><p>如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</p>
</li>
<li><p>如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</p>
</li>
<li><p>如果落在黄色部分，那就包括两种情况a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；</p>
</li>
</ol>
<p>b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。</p>
<p>比如，对于图2中的数据来说，如果有一个事务，它的低水位是18，那么当它访问这一行数据时，就会从V4通过U3计算出V3，所以在它看来，这一行的值是11。</p>
<p>你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的2或者3(a)的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。</p>
<p>所以你现在知道了，InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</p>
<p>接下来，我们继续看一下图1中的三个事务，分析下事务A的语句返回的结果，为什么是k&#x3D;1。</p>
<p>这里，我们不妨做如下假设：</p>
<ol>
<li><p>事务A开始前，系统里面只有一个活跃事务ID是99；</p>
</li>
<li><p>事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务；</p>
</li>
<li><p>三个事务开始前，(1,1）这一行数据的row trx_id是90。</p>
</li>
</ol>
<p>这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。</p>
<p>为了简化分析，我先把其他干扰语句去掉，只画出跟事务A查询逻辑有关的操作：</p>
<p>图4 事务A查询数据逻辑图从图中可以看到，第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。</p>
<p>这时候，这个数据的最新版本的row trx_id是102，而90这个版本已经成为了历史版本。</p>
<p>第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。</p>
<p>这时候，这个数据的最新版本（即rowtrx_id）是101，而102又成为了历史版本。</p>
<p>你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。</p>
<p>但这个版本对事务A必须是不可见的，否则就变成脏读了。</p>
<p>好，现在事务A要来读数据了，它的视图数组是[99,100]。</p>
<p>当然了，读数据都是从当前版本读起的。</p>
<p>所以，事务A查询语句的读数据流程是这样的：</p>
<p>找到(1,3)的时候，判断出row trx_id&#x3D;101，比高水位大，处于红色区域，不可见；</p>
<p>接着，找到上一个历史版本，一看row trx_id&#x3D;102，比高水位大，处于红色区域，不可见；</p>
<p>再往前找，终于找到了（1,1)，它的row trx_id&#x3D;90，比低水位小，处于绿色区域，可见。</p>
<p>这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。</p>
<p>这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。</p>
<p>所以，我来给你翻译一下。</p>
<p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p>
<ol>
<li><p>版本未提交，不可见；</p>
</li>
<li><p>版本已提交，但是是在视图创建后提交的，不可见；</p>
</li>
<li><p>版本已提交，而且是在视图创建前提交的，可见。</p>
</li>
</ol>
<p>现在，我们用这个规则来判断图4中的查询结果，事务A的查询语句的视图数组是在事务A启动的时候生成的，这时候：</p>
<p>(1,3)还没提交，属于情况1，不可见；</p>
<p>(1,2)虽然提交了，但是是在视图数组创建之后提交的，属于情况2，不可见；</p>
<p>(1,1)是在视图数组创建之前提交的，可见。</p>
<p>你看，去掉数字对比后，只用时间先后顺序来判断，分析起来是不是轻松多了。</p>
<p>所以，后面我们就都用这个规则来分析。</p>
<p>更新逻辑细心的同学可能有疑问了：事务B的update语句，如果按照一致性读，好像结果不对哦？你看图5中，事务B的视图数组是先生成的，之后事务C才提交，不是应该看不见(1,2)吗，怎么能算出(1,3)来？图5 事务B更新逻辑图是的，如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。</p>
<p>但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。</p>
<p>因此，事务B此时的set k&#x3D;k+1是在（1,2）的基础上进行的操作。</p>
<p>所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</p>
<p>因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。</p>
<p>所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。</p>
<p>这里我们提到了一个概念，叫作当前读。</p>
<p>其实，除了update语句外，select语句如果加锁，也是当前读。</p>
<p>所以，如果把事务A的查询语句select * from t where id&#x3D;1修改一下，加上lock in share mode 或for update，也都可以读到版本号是101的数据，返回的k的值是3。</p>
<p>下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。</p>
<p>再往前一步，假设事务C不是马上提交的，而是变成了下面的事务C’，会怎么样呢？图6 事务A、B、C’的执行流程事务C’的不同是，更新后并没有马上提交，在它提交前，事务B的更新语句先发起了。</p>
<p>前面说过了，虽然事务C’还没提交，但是(1,2)这个版本也已经生成了，并且是当前的最新版本。</p>
<p>那么，事务B的更新语句会怎么处理呢？这时候，我们在上一篇文章中提到的“两阶段锁协议”就要上场了。</p>
<p>事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。</p>
<p>而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。</p>
<p>mysql&gt; select k from t where id&#x3D;1 lock in share mode;mysql&gt; select k from t where id&#x3D;1 for update;图7 事务B更新逻辑图（配合事务C’）到这里，我们把一致性读、当前读和行锁就串起来了。</p>
<p>现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。</p>
<p>如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p>
<p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：</p>
<p>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；</p>
<p>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。</p>
<p>那么，我们再看一下，在读提交隔离级别下，事务A和事务B的查询语句查到的k，分别应该是多少呢？这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。</p>
<p>所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的start transaction。</p>
<p>下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的read view框。</p>
<p>（注意：这里，我们用的还是事务C的逻辑直接提交，而不是事务C’）图8 读提交隔离级别下的事务状态图这时，事务A的查询语句的视图数组是在执行这个语句的时候创建的，时序上(1,2)、(1,3)的生成时间都在创建这个视图数组的时刻之前。</p>
<p>但是，在这个时刻：</p>
<p>(1,3)还没提交，属于情况1，不可见；</p>
<p>(1,2)提交了，属于情况3，可见。</p>
<p>所以，这时候事务A查询语句返回的是k&#x3D;2。</p>
<p>显然地，事务B查询结果k&#x3D;3。</p>
<p>小结InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。</p>
<p>普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。</p>
<p>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；</p>
<p>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</p>
<p>而当前读，总是读取已经提交完成的最新版本。</p>
<p>你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有row trx_id，因此只能遵循当前读的逻辑。</p>
<p>当然，MySQL 8.0已经可以把表结构放在InnoDB字典里了，也许以后会支持表结构的可重复读。</p>
<p>又到思考题时间了。</p>
<p>我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。</p>
<p>现在，我要把所有“字段c和id值相等的行”的c值清零，但是却发现了一个“诡异”的、改不掉的情况。</p>
<p>请你构造出这种情况，并说明其原理。</p>
<p>mysql&gt; CREATE TABLE <code>t</code> (  <code>id</code> int(11) NOT NULL,  <code>c</code> int(11) DEFAULT NULL,  PRIMARY KEY (<code>id</code>)) ENGINE&#x3D;InnoDB;insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间我在上一篇文章最后，留给你的问题是：怎么删除表的前10000行。</p>
<p>比较多的留言都选择了第二种方式，即：在一个连接中循环执行20次 delete from T limit 500。</p>
<p>确实是这样的，第二种方式是相对较好的。</p>
<p>第一种方式（即：直接执行delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。</p>
<p>第三种方式（即：在20个连接中同时执行delete from T limit 500），会人为造成锁冲突。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.fastolf.com/posts/3f0fbdd7.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Meng Qi">
      <meta itemprop="description" content="recording">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/3f0fbdd7.html" class="post-title-link" itemprop="url">mysql-行锁功过：怎么减少行锁对性能的影响</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-08 06:09:24" itemprop="dateCreated datePublished" datetime="2019-11-08T06:09:24+08:00">2019-11-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-18 23:34:39" itemprop="dateModified" datetime="2023-01-18T23:34:39+08:00">2023-01-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index"><span itemprop="name">mysql</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>3.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>12 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题解析"><a href="#问题解析" class="headerlink" title="问题解析"></a>问题解析</h1><p>行锁功过：怎么减少行锁对性能的影响？在上一篇文章中，我跟你介绍了MySQL的全局锁和表级锁，今天我们就来讲讲MySQL的行锁。</p>
<p>MySQL的行锁是在引擎层由各个引擎自己实现的。</p>
<p>但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。</p>
<p>不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。</p>
<p>InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。</p>
<p>我们今天就主要来聊聊InnoDB的行锁，以及如何通过减少锁冲突来提升业务并发度。</p>
<p>顾名思义，行锁就是针对数据表中行记录的锁。</p>
<p>这很好理解，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。</p>
<p>当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。</p>
<p>从两阶段锁说起我先给你举个例子。</p>
<p>在下面的操作序列中，事务B的update语句执行时会是什么现象呢？假设字段id是表t的主键。</p>
<p>这个问题的结论取决于事务A在执行完两条update语句后，持有哪些锁，以及在什么时候释放。</p>
<p>你可以验证一下：实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。</p>
<p>知道了这个答案，你一定知道了事务A持有的两个记录的行锁，都是在commit的时候才释放的。</p>
<p>也就是说，在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。</p>
<p>这个就是两阶段锁协议。</p>
<p>知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>
<p>我给你举个例子。</p>
<p>假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。</p>
<p>我们简化一点，这个业务需要涉及到以下操作：</p>
<ol>
<li><p>从顾客A账户余额中扣除电影票价；</p>
</li>
<li><p>给影院B的账户余额增加这张电影票价；</p>
</li>
<li><p>记录一条交易日志。</p>
</li>
</ol>
<p>也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。</p>
<p>当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。</p>
<p>那么，你会怎样安排这三个语句在事务中的顺序呢？试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。</p>
<p>因为它们要更新同一个影院账户的余额，需要修改同一行数据。</p>
<p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。</p>
<p>所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。</p>
<p>这就最大程度地减少了事务之间的锁等待，提升了并发度。</p>
<p>好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。</p>
<p>但是，这并没有完全解决你的困扰。</p>
<p>如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。</p>
<p>于是在活动时间开始的时候，你的MySQL就挂了。</p>
<p>你登上服务器一看，CPU消耗接近100%，但整个数据库每秒就执行不到100个事务。</p>
<p>这是什么原因呢？这里，我就要说到死锁和死锁检测了。</p>
<p>死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。</p>
<p>这里我用数据库中的行锁举个例子。</p>
<p>这时候，事务A在等待事务B释放id&#x3D;2的行锁，而事务B在等待事务A释放id&#x3D;1的行锁。</p>
<p> 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。</p>
<p>当出现死锁以后，有两种策略：</p>
<p>一种策略是，直接进入等待，直到超时。</p>
<p>这个超时时间可以通过参数innodb_lock_wait_timeout来设置。</p>
<p>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。</p>
<p>将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。</p>
<p>在InnoDB中，innodb_lock_wait_timeout的默认值是50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行。</p>
<p>对于在线服务来说，这个等待时间往往是无法接受的。</p>
<p>但是，我们又不可能直接把这个时间设置成一个很小的值，比如1s。</p>
<p>这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。</p>
<p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且innodb_deadlock_detect的默认值本身就是on。</p>
<p>主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。</p>
<p>你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p>
<p>那如果是我们上面说到的所有事务都要更新同一行的场景呢？每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。</p>
<p>假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。</p>
<p>虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。</p>
<p>因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。</p>
<p>根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的CPU资源。</p>
<p>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。</p>
<p>但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。</p>
<p>而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</p>
<p>另一个思路是控制并发度。</p>
<p>根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。</p>
<p>一个直接的想法就是，在客户端做并发控制。</p>
<p>但是，你会很快发现这个方法不太可行，因为客户端很多。</p>
<p>我见过一个应用，有600个客户端，这样即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到3000。</p>
<p>因此，这个并发控制要做在数据库服务端。</p>
<p>如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改MySQL源码的人，也可以做在MySQL里面。</p>
<p>基本思路就是，对于相同行的更新，在进入引擎之前排队。</p>
<p>这样在InnoDB内部就不会有大量的死锁检测工作了。</p>
<p>可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。</p>
<p>还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。</p>
<p>这样每次要给影院账户加金额的时候，随机选其中一条记录来加。</p>
<p>这样每次冲突概率变成原来的1&#x2F;10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。</p>
<p>这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。</p>
<p>如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成0的时候，代码要有特殊处理。</p>
<p>小结今天，我和你介绍了MySQL的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。</p>
<p>其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。</p>
<p>这里的原则&#x2F;我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。</p>
<p>但是，调整语句顺序并不能完全避免死锁。</p>
<p>所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。</p>
<p>减少死锁的主要方向，就是控制访问相同资源的并发事务量。</p>
<p>最后，我给你留下一个问题吧。</p>
<p>如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：</p>
<p>第一种，直接执行delete from T limit 10000;第二种，在一个连接中循环执行20次 delete from T limit 500;第三种，在20个连接中同时执行delete from T limit 500。</p>
<p>你会选择哪一种方法呢？为什么呢？你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。</p>
<p>感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>
<p>上期问题时间上期我给你留的问题是：当备库用–single-transaction做逻辑备份的时候，如果从主库的binlog传来一个DDL语句会怎么样？假设这个DDL是针对表t1的， 这里我把备份过程中几个关键的语句列出来：</p>
<p>Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；</p>
<p>&#x2F;* other tables <em>&#x2F;Q3:SAVEPOINT sp;&#x2F;</em> 时刻 1 <em>&#x2F;Q4:show create table <code>t1</code>;&#x2F;</em> 时刻 2 <em>&#x2F;Q5:SELECT * FROM <code>t1</code>;&#x2F;</em> 时刻 3 <em>&#x2F;Q6:ROLLBACK TO SAVEPOINT sp;&#x2F;</em> 时刻 4 <em>&#x2F;&#x2F;</em> other tables *&#x2F;在备份开始的时候，为了确保RR（可重复读）隔离级别，再设置一次RR隔离级别(Q1);启动事务，这里用 WITH CONSISTENT SNAPSHOT确保这个语句执行完就可以得到一个一致性视图（Q2)；</p>
<p>设置一个保存点，这个很重要（Q3）；</p>
<p>show create 是为了拿到表结构(Q4)，然后正式导数据 （Q5），回滚到SAVEPOINT sp，在这里的作用是释放 t1的MDL锁 （Q6。</p>
<p>当然这部分属于“超纲”，上文正文里面都没提到。</p>
<p>DDL从主库传过来的时间按照效果不同，我打了四个时刻。</p>
<p>题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。</p>
<p>参考答案如下：</p>
<ol>
<li><p>如果在Q4语句执行之前到达，现象：没有影响，备份拿到的是DDL后的表结构。</p>
</li>
<li><p>如果在“时刻 2”到达，则表结构被改过，Q5执行的时候，报 Table definition has changed,please retry transaction，现象：mysqldump终止；</p>
</li>
<li><p>如果在“时刻2”和“时刻3”之间到达，mysqldump占着t1的MDL读锁，binlog被阻塞，现象：</p>
</li>
</ol>
<p>主从延迟，直到Q6执行完成。</p>
<ol start="4">
<li>从“时刻4”开始，mysqldump释放了MDL读锁，现象：没有影响，备份拿到的是DDL前的表结构。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/15/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><span class="page-number current">16</span><a class="page-number" href="/page/17/">17</a><span class="space">&hellip;</span><a class="page-number" href="/page/34/">34</a><a class="extend next" rel="next" href="/page/17/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Meng Qi</p>
  <div class="site-description" itemprop="description">recording</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">337</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Meng Qi</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">312k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">18:55</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>
-->

<div>
<span id="timeDate">loading...</span><span id="times">loading...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("1/1/2018 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div id="moon-menu-item-back2bottom" class="moon-menu-item">
      <i class='fas fa-chevron-down'></i>    </div>
    
    <div id="moon-menu-item-back2top" class="moon-menu-item">
      <i class='fas fa-chevron-up'></i>    </div>
    
  </div>
  <div class="moon-menu-button">
    <svg class="moon-menu-bg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
    </svg>
    <div class="moon-menu-content">
      <div class="moon-menu-icon"><i class='fas fa-ellipsis-v'></i></div>
      <div class="moon-menu-text"></div>
    </div>
  </div>
</div><script src="/js/injector.js"></script>
</body>
</html>
